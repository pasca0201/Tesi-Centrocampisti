<html>
<head>
<title>test_ridge.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #6aab73;}
.s4 { color: #2aacb8;}
.s5 { color: #5f826b; font-style: italic;}
.s6 { color: #7a7e85;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_ridge.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">warnings</span>
<span class="s0">from </span><span class="s1">itertools </span><span class="s0">import </span><span class="s1">product</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">scipy </span><span class="s0">import </span><span class="s1">linalg</span>

<span class="s0">from </span><span class="s1">sklearn </span><span class="s0">import </span><span class="s1">config_context</span><span class="s2">, </span><span class="s1">datasets</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">base </span><span class="s0">import </span><span class="s1">clone</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">datasets </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">make_classification</span><span class="s2">,</span>
    <span class="s1">make_low_rank_matrix</span><span class="s2">,</span>
    <span class="s1">make_multilabel_classification</span><span class="s2">,</span>
    <span class="s1">make_regression</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">exceptions </span><span class="s0">import </span><span class="s1">ConvergenceWarning</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">linear_model </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">LinearRegression</span><span class="s2">,</span>
    <span class="s1">Ridge</span><span class="s2">,</span>
    <span class="s1">RidgeClassifier</span><span class="s2">,</span>
    <span class="s1">RidgeClassifierCV</span><span class="s2">,</span>
    <span class="s1">RidgeCV</span><span class="s2">,</span>
    <span class="s1">ridge_regression</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">_ridge </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">_check_gcv_mode</span><span class="s2">,</span>
    <span class="s1">_RidgeGCV</span><span class="s2">,</span>
    <span class="s1">_solve_cholesky</span><span class="s2">,</span>
    <span class="s1">_solve_cholesky_kernel</span><span class="s2">,</span>
    <span class="s1">_solve_lbfgs</span><span class="s2">,</span>
    <span class="s1">_solve_svd</span><span class="s2">,</span>
    <span class="s1">_X_CenterStackOp</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">metrics </span><span class="s0">import </span><span class="s1">get_scorer</span><span class="s2">, </span><span class="s1">make_scorer</span><span class="s2">, </span><span class="s1">mean_squared_error</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">model_selection </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">GridSearchCV</span><span class="s2">,</span>
    <span class="s1">GroupKFold</span><span class="s2">,</span>
    <span class="s1">KFold</span><span class="s2">,</span>
    <span class="s1">LeaveOneOut</span><span class="s2">,</span>
    <span class="s1">cross_val_predict</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">preprocessing </span><span class="s0">import </span><span class="s1">minmax_scale</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils </span><span class="s0">import </span><span class="s1">check_random_state</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">_array_api </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">_NUMPY_NAMESPACE_NAMES</span><span class="s2">,</span>
    <span class="s1">_atol_for_type</span><span class="s2">,</span>
    <span class="s1">_convert_to_numpy</span><span class="s2">,</span>
    <span class="s1">yield_namespace_device_dtype_combinations</span><span class="s2">,</span>
    <span class="s1">yield_namespaces</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">_testing </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">assert_allclose</span><span class="s2">,</span>
    <span class="s1">assert_almost_equal</span><span class="s2">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">,</span>
    <span class="s1">assert_array_equal</span><span class="s2">,</span>
    <span class="s1">ignore_warnings</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">estimator_checks </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">_array_api_for_tests</span><span class="s2">,</span>
    <span class="s1">_get_check_estimator_ids</span><span class="s2">,</span>
    <span class="s1">check_array_api_input_and_values</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">fixes </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">_IS_32BIT</span><span class="s2">,</span>
    <span class="s1">COO_CONTAINERS</span><span class="s2">,</span>
    <span class="s1">CSC_CONTAINERS</span><span class="s2">,</span>
    <span class="s1">CSR_CONTAINERS</span><span class="s2">,</span>
    <span class="s1">DOK_CONTAINERS</span><span class="s2">,</span>
    <span class="s1">LIL_CONTAINERS</span><span class="s2">,</span>
<span class="s2">)</span>

<span class="s1">SOLVERS </span><span class="s2">= [</span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s3">&quot;cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;lsqr&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">]</span>
<span class="s1">SPARSE_SOLVERS_WITH_INTERCEPT </span><span class="s2">= (</span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">)</span>
<span class="s1">SPARSE_SOLVERS_WITHOUT_INTERCEPT </span><span class="s2">= (</span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s3">&quot;cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;lsqr&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">)</span>

<span class="s1">diabetes </span><span class="s2">= </span><span class="s1">datasets</span><span class="s2">.</span><span class="s1">load_diabetes</span><span class="s2">()</span>
<span class="s1">X_diabetes</span><span class="s2">, </span><span class="s1">y_diabetes </span><span class="s2">= </span><span class="s1">diabetes</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">diabetes</span><span class="s2">.</span><span class="s1">target</span>
<span class="s1">ind </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">X_diabetes</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>
<span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
<span class="s1">rng</span><span class="s2">.</span><span class="s1">shuffle</span><span class="s2">(</span><span class="s1">ind</span><span class="s2">)</span>
<span class="s1">ind </span><span class="s2">= </span><span class="s1">ind</span><span class="s2">[:</span><span class="s4">200</span><span class="s2">]</span>
<span class="s1">X_diabetes</span><span class="s2">, </span><span class="s1">y_diabetes </span><span class="s2">= </span><span class="s1">X_diabetes</span><span class="s2">[</span><span class="s1">ind</span><span class="s2">], </span><span class="s1">y_diabetes</span><span class="s2">[</span><span class="s1">ind</span><span class="s2">]</span>

<span class="s1">iris </span><span class="s2">= </span><span class="s1">datasets</span><span class="s2">.</span><span class="s1">load_iris</span><span class="s2">()</span>
<span class="s1">X_iris</span><span class="s2">, </span><span class="s1">y_iris </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span>


<span class="s0">def </span><span class="s1">_accuracy_callable</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">, **</span><span class="s1">kwargs</span><span class="s2">):</span>
    <span class="s0">return </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">y_test </span><span class="s2">== </span><span class="s1">y_pred</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">_mean_squared_error_callable</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">):</span>
    <span class="s0">return </span><span class="s2">((</span><span class="s1">y_test </span><span class="s2">- </span><span class="s1">y_pred</span><span class="s2">) ** </span><span class="s4">2</span><span class="s2">).</span><span class="s1">mean</span><span class="s2">()</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">fixture</span><span class="s2">(</span><span class="s1">params</span><span class="s2">=[</span><span class="s3">&quot;long&quot;</span><span class="s2">, </span><span class="s3">&quot;wide&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">ols_ridge_dataset</span><span class="s2">(</span><span class="s1">global_random_seed</span><span class="s2">, </span><span class="s1">request</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Dataset with OLS and Ridge solutions, well conditioned X. 
 
    The construction is based on the SVD decomposition of X = U S V'. 
 
    Parameters 
    ---------- 
    type : {&quot;long&quot;, &quot;wide&quot;} 
        If &quot;long&quot;, then n_samples &gt; n_features. 
        If &quot;wide&quot;, then n_features &gt; n_samples. 
 
    For &quot;wide&quot;, we return the minimum norm solution w = X' (XX')^-1 y: 
 
        min ||w||_2 subject to X w = y 
 
    Returns 
    ------- 
    X : ndarray 
        Last column of 1, i.e. intercept. 
    y : ndarray 
    coef_ols : ndarray of shape 
        Minimum norm OLS solutions, i.e. min ||X w - y||_2_2 (with minimum ||w||_2 in 
        case of ambiguity) 
        Last coefficient is intercept. 
    coef_ridge : ndarray of shape (5,) 
        Ridge solution with alpha=1, i.e. min ||X w - y||_2_2 + ||w||_2^2. 
        Last coefficient is intercept. 
    &quot;&quot;&quot;</span>
    <span class="s6"># Make larger dim more than double as big as the smaller one.</span>
    <span class="s6"># This helps when constructing singular matrices like (X, X).</span>
    <span class="s0">if </span><span class="s1">request</span><span class="s2">.</span><span class="s1">param </span><span class="s2">== </span><span class="s3">&quot;long&quot;</span><span class="s2">:</span>
        <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s4">12</span><span class="s2">, </span><span class="s4">4</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s4">4</span><span class="s2">, </span><span class="s4">12</span>
    <span class="s1">k </span><span class="s2">= </span><span class="s1">min</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">global_random_seed</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">make_low_rank_matrix</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">effective_rank</span><span class="s2">=</span><span class="s1">k</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">rng</span>
    <span class="s2">)</span>
    <span class="s1">X</span><span class="s2">[:, -</span><span class="s4">1</span><span class="s2">] = </span><span class="s4">1  </span><span class="s6"># last columns acts as intercept</span>
    <span class="s1">U</span><span class="s2">, </span><span class="s1">s</span><span class="s2">, </span><span class="s1">Vt </span><span class="s2">= </span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">svd</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">s </span><span class="s2">&gt; </span><span class="s4">1e-3</span><span class="s2">)  </span><span class="s6"># to be sure</span>
    <span class="s1">U1</span><span class="s2">, </span><span class="s1">U2 </span><span class="s2">= </span><span class="s1">U</span><span class="s2">[:, :</span><span class="s1">k</span><span class="s2">], </span><span class="s1">U</span><span class="s2">[:, </span><span class="s1">k</span><span class="s2">:]</span>
    <span class="s1">Vt1</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">= </span><span class="s1">Vt</span><span class="s2">[:</span><span class="s1">k</span><span class="s2">, :], </span><span class="s1">Vt</span><span class="s2">[</span><span class="s1">k</span><span class="s2">:, :]</span>

    <span class="s0">if </span><span class="s1">request</span><span class="s2">.</span><span class="s1">param </span><span class="s2">== </span><span class="s3">&quot;long&quot;</span><span class="s2">:</span>
        <span class="s6"># Add a term that vanishes in the product X'y</span>
        <span class="s1">coef_ols </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">uniform</span><span class="s2">(</span><span class="s1">low</span><span class="s2">=-</span><span class="s4">10</span><span class="s2">, </span><span class="s1">high</span><span class="s2">=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">)</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">X </span><span class="s2">@ </span><span class="s1">coef_ols</span>
        <span class="s1">y </span><span class="s2">+= </span><span class="s1">U2 </span><span class="s2">@ </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_samples </span><span class="s2">- </span><span class="s1">n_features</span><span class="s2">) ** </span><span class="s4">2</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">uniform</span><span class="s2">(</span><span class="s1">low</span><span class="s2">=-</span><span class="s4">10</span><span class="s2">, </span><span class="s1">high</span><span class="s2">=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">)</span>
        <span class="s6"># w = X'(XX')^-1 y = V s^-1 U' y</span>
        <span class="s1">coef_ols </span><span class="s2">= </span><span class="s1">Vt1</span><span class="s2">.</span><span class="s1">T </span><span class="s2">@ </span><span class="s1">np</span><span class="s2">.</span><span class="s1">diag</span><span class="s2">(</span><span class="s4">1 </span><span class="s2">/ </span><span class="s1">s</span><span class="s2">) @ </span><span class="s1">U1</span><span class="s2">.</span><span class="s1">T </span><span class="s2">@ </span><span class="s1">y</span>

    <span class="s6"># Add penalty alpha * ||coef||_2^2 for alpha=1 and solve via normal equations.</span>
    <span class="s6"># Note that the problem is well conditioned such that we get accurate results.</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">1</span>
    <span class="s1">d </span><span class="s2">= </span><span class="s1">alpha </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">identity</span><span class="s2">(</span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">d</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">] = </span><span class="s4">0  </span><span class="s6"># intercept gets no penalty</span>
    <span class="s1">coef_ridge </span><span class="s2">= </span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">solve</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">T </span><span class="s2">@ </span><span class="s1">X </span><span class="s2">+ </span><span class="s1">d</span><span class="s2">, </span><span class="s1">X</span><span class="s2">.</span><span class="s1">T </span><span class="s2">@ </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s6"># To be sure</span>
    <span class="s1">R_OLS </span><span class="s2">= </span><span class="s1">y </span><span class="s2">- </span><span class="s1">X </span><span class="s2">@ </span><span class="s1">coef_ols</span>
    <span class="s1">R_Ridge </span><span class="s2">= </span><span class="s1">y </span><span class="s2">- </span><span class="s1">X </span><span class="s2">@ </span><span class="s1">coef_ridge</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">norm</span><span class="s2">(</span><span class="s1">R_OLS</span><span class="s2">) &lt; </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">norm</span><span class="s2">(</span><span class="s1">R_Ridge</span><span class="s2">)</span>

    <span class="s0">return </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">coef_ols</span><span class="s2">, </span><span class="s1">coef_ridge</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">SOLVERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridge_regression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">, </span><span class="s1">ols_ridge_dataset</span><span class="s2">, </span><span class="s1">global_random_seed</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test that Ridge converges for all solvers to correct solution. 
 
    We work with a simple constructed data set with known solution. 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">coef </span><span class="s2">= </span><span class="s1">ols_ridge_dataset</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">1.0  </span><span class="s6"># because ols_ridge_dataset uses this.</span>
    <span class="s1">params </span><span class="s2">= </span><span class="s1">dict</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-15 </span><span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">) </span><span class="s0">else </span><span class="s4">1e-10</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s6"># Calculate residuals and R2.</span>
    <span class="s1">res_null </span><span class="s2">= </span><span class="s1">y </span><span class="s2">- </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">res_Ridge </span><span class="s2">= </span><span class="s1">y </span><span class="s2">- </span><span class="s1">X </span><span class="s2">@ </span><span class="s1">coef</span>
    <span class="s1">R2_Ridge </span><span class="s2">= </span><span class="s4">1 </span><span class="s2">- </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">res_Ridge</span><span class="s2">**</span><span class="s4">2</span><span class="s2">) / </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">res_null</span><span class="s2">**</span><span class="s4">2</span><span class="s2">)</span>

    <span class="s1">model </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(**</span><span class="s1">params</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[:, :-</span><span class="s4">1</span><span class="s2">]  </span><span class="s6"># remove intercept</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">X </span><span class="s2">- </span><span class="s1">X</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">y </span><span class="s2">- </span><span class="s1">y</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">()</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s4">0</span>
    <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">coef </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">]</span>

    <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">intercept</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">) == </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">R2_Ridge</span><span class="s2">)</span>

    <span class="s6"># Same with sample_weight.</span>
    <span class="s1">model </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(**</span><span class="s1">params</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]))</span>
    <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">intercept</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">) == </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">R2_Ridge</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">solver_ </span><span class="s2">== </span><span class="s1">solver</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">SOLVERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridge_regression_hstacked_X</span><span class="s2">(</span>
    <span class="s1">solver</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">, </span><span class="s1">ols_ridge_dataset</span><span class="s2">, </span><span class="s1">global_random_seed</span>
<span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test that Ridge converges for all solvers to correct solution on hstacked data. 
 
    We work with a simple constructed data set with known solution. 
    Fit on [X] with alpha is the same as fit on [X, X]/2 with alpha/2. 
    For long X, [X, X] is a singular matrix. 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">coef </span><span class="s2">= </span><span class="s1">ols_ridge_dataset</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">1.0  </span><span class="s6"># because ols_ridge_dataset uses this.</span>

    <span class="s1">model </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-15 </span><span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">) </span><span class="s0">else </span><span class="s4">1e-10</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[:, :-</span><span class="s4">1</span><span class="s2">]  </span><span class="s6"># remove intercept</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s4">0.5 </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">((</span><span class="s1">X</span><span class="s2">, </span><span class="s1">X</span><span class="s2">), </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">matrix_rank</span><span class="s2">(</span><span class="s1">X</span><span class="s2">) &lt;= </span><span class="s1">min</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">- </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">X </span><span class="s2">- </span><span class="s1">X</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">y </span><span class="s2">- </span><span class="s1">y</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">()</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s4">0</span>
    <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">coef </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">]</span>

    <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">intercept</span><span class="s2">)</span>
    <span class="s6"># coefficients are not all on the same magnitude, adding a small atol to</span>
    <span class="s6"># make this test less brittle</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">coef</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">], </span><span class="s1">atol</span><span class="s2">=</span><span class="s4">1e-8</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">SOLVERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridge_regression_vstacked_X</span><span class="s2">(</span>
    <span class="s1">solver</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">, </span><span class="s1">ols_ridge_dataset</span><span class="s2">, </span><span class="s1">global_random_seed</span>
<span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test that Ridge converges for all solvers to correct solution on vstacked data. 
 
    We work with a simple constructed data set with known solution. 
    Fit on [X] with alpha is the same as fit on [X], [y] 
                                                [X], [y] with 2 * alpha. 
    For wide X, [X', X'] is a singular matrix. 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">coef </span><span class="s2">= </span><span class="s1">ols_ridge_dataset</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">1.0  </span><span class="s6"># because ols_ridge_dataset uses this.</span>

    <span class="s1">model </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">2 </span><span class="s2">* </span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-15 </span><span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">) </span><span class="s0">else </span><span class="s4">1e-10</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[:, :-</span><span class="s4">1</span><span class="s2">]  </span><span class="s6"># remove intercept</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">((</span><span class="s1">X</span><span class="s2">, </span><span class="s1">X</span><span class="s2">), </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">matrix_rank</span><span class="s2">(</span><span class="s1">X</span><span class="s2">) &lt;= </span><span class="s1">min</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">y</span><span class="s2">, </span><span class="s1">y</span><span class="s2">]</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">X </span><span class="s2">- </span><span class="s1">X</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">y </span><span class="s2">- </span><span class="s1">y</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">()</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s4">0</span>
    <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">coef </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">]</span>

    <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">intercept</span><span class="s2">)</span>
    <span class="s6"># coefficients are not all on the same magnitude, adding a small atol to</span>
    <span class="s6"># make this test less brittle</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s4">1e-8</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">SOLVERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridge_regression_unpenalized</span><span class="s2">(</span>
    <span class="s1">solver</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">, </span><span class="s1">ols_ridge_dataset</span><span class="s2">, </span><span class="s1">global_random_seed</span>
<span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test that unpenalized Ridge = OLS converges for all solvers to correct solution. 
 
    We work with a simple constructed data set with known solution. 
    Note: This checks the minimum norm solution for wide X, i.e. 
    n_samples &lt; n_features: 
        min ||w||_2 subject to X w = y 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">= </span><span class="s1">ols_ridge_dataset</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">0  </span><span class="s6"># OLS</span>
    <span class="s1">params </span><span class="s2">= </span><span class="s1">dict</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-15 </span><span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">) </span><span class="s0">else </span><span class="s4">1e-10</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">model </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(**</span><span class="s1">params</span><span class="s2">)</span>
    <span class="s6"># Note that cholesky might give a warning: &quot;Singular matrix in solving dual</span>
    <span class="s6"># problem. Using least-squares solution instead.&quot;</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[:, :-</span><span class="s4">1</span><span class="s2">]  </span><span class="s6"># remove intercept</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">]</span>
        <span class="s1">coef </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s4">0</span>
    <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s6"># FIXME: `assert_allclose(model.coef_, coef)` should work for all cases but fails</span>
    <span class="s6"># for the wide/fat case with n_features &gt; n_samples. The current Ridge solvers do</span>
    <span class="s6"># NOT return the minimum norm solution with fit_intercept=True.</span>
    <span class="s0">if </span><span class="s1">n_samples </span><span class="s2">&gt; </span><span class="s1">n_features </span><span class="s0">or not </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">intercept</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s6"># As it is an underdetermined problem, residuals = 0. This shows that we get</span>
        <span class="s6"># a solution to X w = y ....</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">X </span><span class="s2">@ </span><span class="s1">coef </span><span class="s2">+ </span><span class="s1">intercept</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s6"># But it is not the minimum norm solution. (This should be equal.)</span>
        <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">norm</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">]) &gt; </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">norm</span><span class="s2">(</span>
            <span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">intercept</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">]</span>
        <span class="s2">)</span>

        <span class="s1">pytest</span><span class="s2">.</span><span class="s1">xfail</span><span class="s2">(</span><span class="s1">reason</span><span class="s2">=</span><span class="s3">&quot;Ridge does not provide the minimum norm solution.&quot;</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">intercept</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">SOLVERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridge_regression_unpenalized_hstacked_X</span><span class="s2">(</span>
    <span class="s1">solver</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">, </span><span class="s1">ols_ridge_dataset</span><span class="s2">, </span><span class="s1">global_random_seed</span>
<span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test that unpenalized Ridge = OLS converges for all solvers to correct solution. 
 
    We work with a simple constructed data set with known solution. 
    OLS fit on [X] is the same as fit on [X, X]/2. 
    For long X, [X, X] is a singular matrix and we check against the minimum norm 
    solution: 
        min ||w||_2 subject to min ||X w - y||_2 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">= </span><span class="s1">ols_ridge_dataset</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">0  </span><span class="s6"># OLS</span>

    <span class="s1">model </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-15 </span><span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">) </span><span class="s0">else </span><span class="s4">1e-10</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[:, :-</span><span class="s4">1</span><span class="s2">]  </span><span class="s6"># remove intercept</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">]</span>
        <span class="s1">coef </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s4">0</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s4">0.5 </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">((</span><span class="s1">X</span><span class="s2">, </span><span class="s1">X</span><span class="s2">), </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">matrix_rank</span><span class="s2">(</span><span class="s1">X</span><span class="s2">) &lt;= </span><span class="s1">min</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">n_samples </span><span class="s2">&gt; </span><span class="s1">n_features </span><span class="s0">or not </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">intercept</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;cholesky&quot;</span><span class="s2">:</span>
            <span class="s6"># Cholesky is a bad choice for singular X.</span>
            <span class="s1">pytest</span><span class="s2">.</span><span class="s1">skip</span><span class="s2">()</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">coef</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">])</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s6"># FIXME: Same as in test_ridge_regression_unpenalized.</span>
        <span class="s6"># As it is an underdetermined problem, residuals = 0. This shows that we get</span>
        <span class="s6"># a solution to X w = y ....</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s6"># But it is not the minimum norm solution. (This should be equal.)</span>
        <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">norm</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">]) &gt; </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">norm</span><span class="s2">(</span>
            <span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">intercept</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">]</span>
        <span class="s2">)</span>

        <span class="s1">pytest</span><span class="s2">.</span><span class="s1">xfail</span><span class="s2">(</span><span class="s1">reason</span><span class="s2">=</span><span class="s3">&quot;Ridge does not provide the minimum norm solution.&quot;</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">intercept</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">coef</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">])</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">SOLVERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridge_regression_unpenalized_vstacked_X</span><span class="s2">(</span>
    <span class="s1">solver</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">, </span><span class="s1">ols_ridge_dataset</span><span class="s2">, </span><span class="s1">global_random_seed</span>
<span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test that unpenalized Ridge = OLS converges for all solvers to correct solution. 
 
    We work with a simple constructed data set with known solution. 
    OLS fit on [X] is the same as fit on [X], [y] 
                                         [X], [y]. 
    For wide X, [X', X'] is a singular matrix and we check against the minimum norm 
    solution: 
        min ||w||_2 subject to X w = y 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">= </span><span class="s1">ols_ridge_dataset</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">0  </span><span class="s6"># OLS</span>

    <span class="s1">model </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-15 </span><span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">) </span><span class="s0">else </span><span class="s4">1e-10</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[:, :-</span><span class="s4">1</span><span class="s2">]  </span><span class="s6"># remove intercept</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">]</span>
        <span class="s1">coef </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s4">0</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">((</span><span class="s1">X</span><span class="s2">, </span><span class="s1">X</span><span class="s2">), </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">matrix_rank</span><span class="s2">(</span><span class="s1">X</span><span class="s2">) &lt;= </span><span class="s1">min</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">y</span><span class="s2">, </span><span class="s1">y</span><span class="s2">]</span>
    <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">n_samples </span><span class="s2">&gt; </span><span class="s1">n_features </span><span class="s0">or not </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">intercept</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s6"># FIXME: Same as in test_ridge_regression_unpenalized.</span>
        <span class="s6"># As it is an underdetermined problem, residuals = 0. This shows that we get</span>
        <span class="s6"># a solution to X w = y ....</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s6"># But it is not the minimum norm solution. (This should be equal.)</span>
        <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">norm</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">]) &gt; </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">norm</span><span class="s2">(</span>
            <span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">intercept</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">]</span>
        <span class="s2">)</span>

        <span class="s1">pytest</span><span class="s2">.</span><span class="s1">xfail</span><span class="s2">(</span><span class="s1">reason</span><span class="s2">=</span><span class="s3">&quot;Ridge does not provide the minimum norm solution.&quot;</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">intercept</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">SOLVERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;sparse_container&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">] + </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;alpha&quot;</span><span class="s2">, [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1e-2</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridge_regression_sample_weights</span><span class="s2">(</span>
    <span class="s1">solver</span><span class="s2">,</span>
    <span class="s1">fit_intercept</span><span class="s2">,</span>
    <span class="s1">sparse_container</span><span class="s2">,</span>
    <span class="s1">alpha</span><span class="s2">,</span>
    <span class="s1">ols_ridge_dataset</span><span class="s2">,</span>
    <span class="s1">global_random_seed</span><span class="s2">,</span>
<span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test that Ridge with sample weights gives correct results. 
 
    We use the following trick: 
        ||y - Xw||_2 = (z - Aw)' W (z - Aw) 
    for z=[y, y], A' = [X', X'] (vstacked), and W[:n/2] + W[n/2:] = 1, W=diag(W) 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is not None</span><span class="s2">:</span>
        <span class="s0">if </span><span class="s1">fit_intercept </span><span class="s0">and </span><span class="s1">solver </span><span class="s0">not in </span><span class="s1">SPARSE_SOLVERS_WITH_INTERCEPT</span><span class="s2">:</span>
            <span class="s1">pytest</span><span class="s2">.</span><span class="s1">skip</span><span class="s2">()</span>
        <span class="s0">elif not </span><span class="s1">fit_intercept </span><span class="s0">and </span><span class="s1">solver </span><span class="s0">not in </span><span class="s1">SPARSE_SOLVERS_WITHOUT_INTERCEPT</span><span class="s2">:</span>
            <span class="s1">pytest</span><span class="s2">.</span><span class="s1">skip</span><span class="s2">()</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">coef </span><span class="s2">= </span><span class="s1">ols_ridge_dataset</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span>
    <span class="s1">sw </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">uniform</span><span class="s2">(</span><span class="s1">low</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">high</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">)</span>

    <span class="s1">model </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-15 </span><span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">] </span><span class="s0">else </span><span class="s4">1e-10</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">100_000</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[:, :-</span><span class="s4">1</span><span class="s2">]  </span><span class="s6"># remove intercept</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">((</span><span class="s1">X</span><span class="s2">, </span><span class="s1">X</span><span class="s2">), </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">y</span><span class="s2">, </span><span class="s1">y</span><span class="s2">]</span>
    <span class="s1">sw </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">sw</span><span class="s2">, </span><span class="s4">1 </span><span class="s2">- </span><span class="s1">sw</span><span class="s2">] * </span><span class="s1">alpha</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">X </span><span class="s2">- </span><span class="s1">X</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">y </span><span class="s2">- </span><span class="s1">y</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">()</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s4">0</span>
    <span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is not None</span><span class="s2">:</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sw</span><span class="s2">)</span>
    <span class="s1">coef </span><span class="s2">= </span><span class="s1">coef</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">]</span>

    <span class="s0">assert </span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">intercept</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_primal_dual_relationship</span><span class="s2">():</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">y_diabetes</span><span class="s2">.</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">coef </span><span class="s2">= </span><span class="s1">_solve_cholesky</span><span class="s2">(</span><span class="s1">X_diabetes</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">=[</span><span class="s4">1e-2</span><span class="s2">])</span>
    <span class="s1">K </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">X_diabetes</span><span class="s2">, </span><span class="s1">X_diabetes</span><span class="s2">.</span><span class="s1">T</span><span class="s2">)</span>
    <span class="s1">dual_coef </span><span class="s2">= </span><span class="s1">_solve_cholesky_kernel</span><span class="s2">(</span><span class="s1">K</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">=[</span><span class="s4">1e-2</span><span class="s2">])</span>
    <span class="s1">coef2 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">X_diabetes</span><span class="s2">.</span><span class="s1">T</span><span class="s2">, </span><span class="s1">dual_coef</span><span class="s2">).</span><span class="s1">T</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">coef</span><span class="s2">, </span><span class="s1">coef2</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_ridge_regression_convergence_fail</span><span class="s2">():</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s4">5</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s4">5</span><span class="s2">, </span><span class="s4">10</span><span class="s2">)</span>
    <span class="s1">warning_message </span><span class="s2">= </span><span class="s3">r&quot;sparse_cg did not converge after&quot; r&quot; [0-9]+ iterations.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">ConvergenceWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">warning_message</span><span class="s2">):</span>
        <span class="s1">ridge_regression</span><span class="s2">(</span>
            <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">1.0</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">0.0</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">verbose</span><span class="s2">=</span><span class="s4">1</span>
        <span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_ridge_shapes_type</span><span class="s2">():</span>
    <span class="s6"># Test shape of coef_ and intercept_</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s4">5</span><span class="s2">, </span><span class="s4">10</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">Y1 </span><span class="s2">= </span><span class="s1">y</span><span class="s2">[:, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">newaxis</span><span class="s2">]</span>
    <span class="s1">Y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">c_</span><span class="s2">[</span><span class="s1">y</span><span class="s2">, </span><span class="s4">1 </span><span class="s2">+ </span><span class="s1">y</span><span class="s2">]</span>

    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">()</span>

    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_features</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== ()</span>
    <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ndarray</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">float</span><span class="s2">)</span>

    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y1</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">1</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">1</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ndarray</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ndarray</span><span class="s2">)</span>

    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">2</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">2</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ndarray</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ndarray</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_ridge_intercept</span><span class="s2">():</span>
    <span class="s6"># Test intercept with multiple targets GH issue #708</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s4">5</span><span class="s2">, </span><span class="s4">10</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">Y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">c_</span><span class="s2">[</span><span class="s1">y</span><span class="s2">, </span><span class="s4">1.0 </span><span class="s2">+ </span><span class="s1">y</span><span class="s2">]</span>

    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">()</span>

    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">intercept </span><span class="s2">= </span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">intercept_</span>

    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">[</span><span class="s4">0</span><span class="s2">], </span><span class="s1">intercept</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">[</span><span class="s4">1</span><span class="s2">], </span><span class="s1">intercept </span><span class="s2">+ </span><span class="s4">1.0</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_ridge_vs_lstsq</span><span class="s2">():</span>
    <span class="s6"># On alpha=0., Ridge and OLS yield the same solution.</span>

    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s6"># we need more samples than features</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s4">5</span><span class="s2">, </span><span class="s4">4</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>

    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.0</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">ols </span><span class="s2">= </span><span class="s1">LinearRegression</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>

    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">ols</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">ols</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>

    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">ols</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">ols</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_ridge_individual_penalties</span><span class="s2">():</span>
    <span class="s6"># Tests the ridge object using individual penalties</span>

    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">42</span><span class="s2">)</span>

    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">n_targets </span><span class="s2">= </span><span class="s4">20</span><span class="s2">, </span><span class="s4">10</span><span class="s2">, </span><span class="s4">5</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_targets</span><span class="s2">)</span>

    <span class="s1">penalties </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">n_targets</span><span class="s2">)</span>

    <span class="s1">coef_cholesky </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span>
        <span class="s2">[</span>
            <span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;cholesky&quot;</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">target</span><span class="s2">).</span><span class="s1">coef_</span>
            <span class="s0">for </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">target </span><span class="s0">in </span><span class="s1">zip</span><span class="s2">(</span><span class="s1">penalties</span><span class="s2">, </span><span class="s1">y</span><span class="s2">.</span><span class="s1">T</span><span class="s2">)</span>
        <span class="s2">]</span>
    <span class="s2">)</span>

    <span class="s1">coefs_indiv_pen </span><span class="s2">= [</span>
        <span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">penalties</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-12</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">).</span><span class="s1">coef_</span>
        <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s3">&quot;lsqr&quot;</span><span class="s2">, </span><span class="s3">&quot;cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">]</span>
    <span class="s2">]</span>
    <span class="s0">for </span><span class="s1">coef_indiv_pen </span><span class="s0">in </span><span class="s1">coefs_indiv_pen</span><span class="s2">:</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">coef_cholesky</span><span class="s2">, </span><span class="s1">coef_indiv_pen</span><span class="s2">)</span>

    <span class="s6"># Test error is raised when number of targets and penalties do not match.</span>
    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">penalties</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s1">err_msg </span><span class="s2">= </span><span class="s3">&quot;Number of targets and number of penalties do not correspond: 4 != 5&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">err_msg</span><span class="s2">):</span>
        <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;n_col&quot;</span><span class="s2">, [(), (</span><span class="s4">1</span><span class="s2">,), (</span><span class="s4">3</span><span class="s2">,)])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_X_CenterStackOp</span><span class="s2">(</span><span class="s1">n_col</span><span class="s2">, </span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s4">11</span><span class="s2">, </span><span class="s4">8</span><span class="s2">)</span>
    <span class="s1">X_m </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s4">8</span><span class="s2">)</span>
    <span class="s1">sqrt_sw </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">len</span><span class="s2">(</span><span class="s1">X</span><span class="s2">))</span>
    <span class="s1">Y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s4">11</span><span class="s2">, *</span><span class="s1">n_col</span><span class="s2">)</span>
    <span class="s1">A </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s4">9</span><span class="s2">, *</span><span class="s1">n_col</span><span class="s2">)</span>
    <span class="s1">operator </span><span class="s2">= </span><span class="s1">_X_CenterStackOp</span><span class="s2">(</span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">X_m</span><span class="s2">, </span><span class="s1">sqrt_sw</span><span class="s2">)</span>
    <span class="s1">reference_operator </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">hstack</span><span class="s2">([</span><span class="s1">X </span><span class="s2">- </span><span class="s1">sqrt_sw</span><span class="s2">[:, </span><span class="s0">None</span><span class="s2">] * </span><span class="s1">X_m</span><span class="s2">, </span><span class="s1">sqrt_sw</span><span class="s2">[:, </span><span class="s0">None</span><span class="s2">]])</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">reference_operator</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">A</span><span class="s2">), </span><span class="s1">operator</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">A</span><span class="s2">))</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">reference_operator</span><span class="s2">.</span><span class="s1">T</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">Y</span><span class="s2">), </span><span class="s1">operator</span><span class="s2">.</span><span class="s1">T</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">Y</span><span class="s2">))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;shape&quot;</span><span class="s2">, [(</span><span class="s4">10</span><span class="s2">, </span><span class="s4">1</span><span class="s2">), (</span><span class="s4">13</span><span class="s2">, </span><span class="s4">9</span><span class="s2">), (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">7</span><span class="s2">), (</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">), (</span><span class="s4">20</span><span class="s2">, </span><span class="s4">20</span><span class="s2">)])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;uniform_weights&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_compute_gram</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">, </span><span class="s1">uniform_weights</span><span class="s2">, </span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(*</span><span class="s1">shape</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">uniform_weights</span><span class="s2">:</span>
        <span class="s1">sw </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">sw </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">chisquare</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>
    <span class="s1">sqrt_sw </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sqrt</span><span class="s2">(</span><span class="s1">sw</span><span class="s2">)</span>
    <span class="s1">X_mean </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">average</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">weights</span><span class="s2">=</span><span class="s1">sw</span><span class="s2">)</span>
    <span class="s1">X_centered </span><span class="s2">= (</span><span class="s1">X </span><span class="s2">- </span><span class="s1">X_mean</span><span class="s2">) * </span><span class="s1">sqrt_sw</span><span class="s2">[:, </span><span class="s0">None</span><span class="s2">]</span>
    <span class="s1">true_gram </span><span class="s2">= </span><span class="s1">X_centered</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">X_centered</span><span class="s2">.</span><span class="s1">T</span><span class="s2">)</span>
    <span class="s1">X_sparse </span><span class="s2">= </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X </span><span class="s2">* </span><span class="s1">sqrt_sw</span><span class="s2">[:, </span><span class="s0">None</span><span class="s2">])</span>
    <span class="s1">gcv </span><span class="s2">= </span><span class="s1">_RidgeGCV</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s1">computed_gram</span><span class="s2">, </span><span class="s1">computed_mean </span><span class="s2">= </span><span class="s1">gcv</span><span class="s2">.</span><span class="s1">_compute_gram</span><span class="s2">(</span><span class="s1">X_sparse</span><span class="s2">, </span><span class="s1">sqrt_sw</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">X_mean</span><span class="s2">, </span><span class="s1">computed_mean</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">true_gram</span><span class="s2">, </span><span class="s1">computed_gram</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;shape&quot;</span><span class="s2">, [(</span><span class="s4">10</span><span class="s2">, </span><span class="s4">1</span><span class="s2">), (</span><span class="s4">13</span><span class="s2">, </span><span class="s4">9</span><span class="s2">), (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">7</span><span class="s2">), (</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">), (</span><span class="s4">20</span><span class="s2">, </span><span class="s4">20</span><span class="s2">)])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;uniform_weights&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_compute_covariance</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">, </span><span class="s1">uniform_weights</span><span class="s2">, </span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(*</span><span class="s1">shape</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">uniform_weights</span><span class="s2">:</span>
        <span class="s1">sw </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">sw </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">chisquare</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>
    <span class="s1">sqrt_sw </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sqrt</span><span class="s2">(</span><span class="s1">sw</span><span class="s2">)</span>
    <span class="s1">X_mean </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">average</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">weights</span><span class="s2">=</span><span class="s1">sw</span><span class="s2">)</span>
    <span class="s1">X_centered </span><span class="s2">= (</span><span class="s1">X </span><span class="s2">- </span><span class="s1">X_mean</span><span class="s2">) * </span><span class="s1">sqrt_sw</span><span class="s2">[:, </span><span class="s0">None</span><span class="s2">]</span>
    <span class="s1">true_covariance </span><span class="s2">= </span><span class="s1">X_centered</span><span class="s2">.</span><span class="s1">T</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">X_centered</span><span class="s2">)</span>
    <span class="s1">X_sparse </span><span class="s2">= </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X </span><span class="s2">* </span><span class="s1">sqrt_sw</span><span class="s2">[:, </span><span class="s0">None</span><span class="s2">])</span>
    <span class="s1">gcv </span><span class="s2">= </span><span class="s1">_RidgeGCV</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s1">computed_cov</span><span class="s2">, </span><span class="s1">computed_mean </span><span class="s2">= </span><span class="s1">gcv</span><span class="s2">.</span><span class="s1">_compute_covariance</span><span class="s2">(</span><span class="s1">X_sparse</span><span class="s2">, </span><span class="s1">sqrt_sw</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">X_mean</span><span class="s2">, </span><span class="s1">computed_mean</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">true_covariance</span><span class="s2">, </span><span class="s1">computed_cov</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">_make_sparse_offset_regression</span><span class="s2">(</span>
    <span class="s1">n_samples</span><span class="s2">=</span><span class="s4">100</span><span class="s2">,</span>
    <span class="s1">n_features</span><span class="s2">=</span><span class="s4">100</span><span class="s2">,</span>
    <span class="s1">proportion_nonzero</span><span class="s2">=</span><span class="s4">0.5</span><span class="s2">,</span>
    <span class="s1">n_informative</span><span class="s2">=</span><span class="s4">10</span><span class="s2">,</span>
    <span class="s1">n_targets</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
    <span class="s1">bias</span><span class="s2">=</span><span class="s4">13.0</span><span class="s2">,</span>
    <span class="s1">X_offset</span><span class="s2">=</span><span class="s4">30.0</span><span class="s2">,</span>
    <span class="s1">noise</span><span class="s2">=</span><span class="s4">30.0</span><span class="s2">,</span>
    <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
    <span class="s1">coef</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s1">positive</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s1">random_state</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
<span class="s2">):</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">c </span><span class="s2">= </span><span class="s1">make_regression</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">,</span>
        <span class="s1">n_informative</span><span class="s2">=</span><span class="s1">n_informative</span><span class="s2">,</span>
        <span class="s1">n_targets</span><span class="s2">=</span><span class="s1">n_targets</span><span class="s2">,</span>
        <span class="s1">bias</span><span class="s2">=</span><span class="s1">bias</span><span class="s2">,</span>
        <span class="s1">noise</span><span class="s2">=</span><span class="s1">noise</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s1">shuffle</span><span class="s2">,</span>
        <span class="s1">coef</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">random_state</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s0">if </span><span class="s1">n_features </span><span class="s2">== </span><span class="s4">1</span><span class="s2">:</span>
        <span class="s1">c </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">([</span><span class="s1">c</span><span class="s2">])</span>
    <span class="s1">X </span><span class="s2">+= </span><span class="s1">X_offset</span>
    <span class="s1">mask </span><span class="s2">= (</span>
        <span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">).</span><span class="s1">binomial</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">proportion_nonzero</span><span class="s2">, </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">) &gt; </span><span class="s4">0</span>
    <span class="s2">)</span>
    <span class="s1">removed_X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">()</span>
    <span class="s1">X</span><span class="s2">[~</span><span class="s1">mask</span><span class="s2">] = </span><span class="s4">0.0</span>
    <span class="s1">removed_X</span><span class="s2">[</span><span class="s1">mask</span><span class="s2">] = </span><span class="s4">0.0</span>
    <span class="s1">y </span><span class="s2">-= </span><span class="s1">removed_X</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">c</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">positive</span><span class="s2">:</span>
        <span class="s1">y </span><span class="s2">+= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">abs</span><span class="s2">(</span><span class="s1">c</span><span class="s2">) + </span><span class="s4">1 </span><span class="s2">- </span><span class="s1">c</span><span class="s2">)</span>
        <span class="s1">c </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">abs</span><span class="s2">(</span><span class="s1">c</span><span class="s2">) + </span><span class="s4">1</span>
    <span class="s0">if </span><span class="s1">n_features </span><span class="s2">== </span><span class="s4">1</span><span class="s2">:</span>
        <span class="s1">c </span><span class="s2">= </span><span class="s1">c</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]</span>
    <span class="s0">if </span><span class="s1">coef</span><span class="s2">:</span>
        <span class="s0">return </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">c</span>
    <span class="s0">return </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;solver, sparse_container&quot;</span><span class="s2">,</span>
    <span class="s2">(</span>
        <span class="s2">(</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">sparse_container</span><span class="s2">)</span>
        <span class="s0">for </span><span class="s2">(</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">sparse_container</span><span class="s2">) </span><span class="s0">in </span><span class="s1">product</span><span class="s2">(</span>
            <span class="s2">[</span><span class="s3">&quot;cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s3">&quot;lsqr&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s3">&quot;ridgecv&quot;</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s0">None</span><span class="s2">] + </span><span class="s1">CSR_CONTAINERS</span><span class="s2">,</span>
        <span class="s2">)</span>
        <span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is None or </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s3">&quot;ridgecv&quot;</span><span class="s2">]</span>
    <span class="s2">),</span>
<span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;n_samples,dtype,proportion_nonzero&quot;</span><span class="s2">,</span>
    <span class="s2">[(</span><span class="s4">20</span><span class="s2">, </span><span class="s3">&quot;float32&quot;</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">), (</span><span class="s4">40</span><span class="s2">, </span><span class="s3">&quot;float32&quot;</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">), (</span><span class="s4">20</span><span class="s2">, </span><span class="s3">&quot;float64&quot;</span><span class="s2">, </span><span class="s4">0.2</span><span class="s2">)],</span>
<span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;seed&quot;</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s4">3</span><span class="s2">))</span>
<span class="s0">def </span><span class="s1">test_solver_consistency</span><span class="s2">(</span>
    <span class="s1">solver</span><span class="s2">, </span><span class="s1">proportion_nonzero</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">, </span><span class="s1">sparse_container</span><span class="s2">, </span><span class="s1">seed</span>
<span class="s2">):</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">1.0</span>
    <span class="s1">noise </span><span class="s2">= </span><span class="s4">50.0 </span><span class="s0">if </span><span class="s1">proportion_nonzero </span><span class="s2">&gt; </span><span class="s4">0.9 </span><span class="s0">else </span><span class="s4">500.0</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">_make_sparse_offset_regression</span><span class="s2">(</span>
        <span class="s1">bias</span><span class="s2">=</span><span class="s4">10</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s4">30</span><span class="s2">,</span>
        <span class="s1">proportion_nonzero</span><span class="s2">=</span><span class="s1">proportion_nonzero</span><span class="s2">,</span>
        <span class="s1">noise</span><span class="s2">=</span><span class="s1">noise</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">seed</span><span class="s2">,</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s6"># Manually scale the data to avoid pathological cases. We use</span>
    <span class="s6"># minmax_scale to deal with the sparse case without breaking</span>
    <span class="s6"># the sparsity pattern.</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">minmax_scale</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">svd_ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">dtype</span><span class="s2">, </span><span class="s1">copy</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">y</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">dtype</span><span class="s2">, </span><span class="s1">copy</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is not None</span><span class="s2">:</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;ridgecv&quot;</span><span class="s2">:</span>
        <span class="s1">ridge </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=[</span><span class="s1">alpha</span><span class="s2">])</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-10</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">)</span>
    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">svd_ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">svd_ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;gcv_mode&quot;</span><span class="s2">, [</span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s3">&quot;eigen&quot;</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;X_container&quot;</span><span class="s2">, [</span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">] + </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;X_shape&quot;</span><span class="s2">, [(</span><span class="s4">11</span><span class="s2">, </span><span class="s4">8</span><span class="s2">), (</span><span class="s4">11</span><span class="s2">, </span><span class="s4">20</span><span class="s2">)])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;y_shape, noise&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">((</span><span class="s4">11</span><span class="s2">,), </span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">((</span><span class="s4">11</span><span class="s2">, </span><span class="s4">1</span><span class="s2">), </span><span class="s4">30.0</span><span class="s2">),</span>
        <span class="s2">((</span><span class="s4">11</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s4">150.0</span><span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridge_gcv_vs_ridge_loo_cv</span><span class="s2">(</span>
    <span class="s1">gcv_mode</span><span class="s2">, </span><span class="s1">X_container</span><span class="s2">, </span><span class="s1">X_shape</span><span class="s2">, </span><span class="s1">y_shape</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">, </span><span class="s1">noise</span>
<span class="s2">):</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s1">X_shape</span>
    <span class="s1">n_targets </span><span class="s2">= </span><span class="s1">y_shape</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">] </span><span class="s0">if </span><span class="s1">len</span><span class="s2">(</span><span class="s1">y_shape</span><span class="s2">) == </span><span class="s4">2 </span><span class="s0">else </span><span class="s4">1</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">_make_sparse_offset_regression</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">,</span>
        <span class="s1">n_targets</span><span class="s2">=</span><span class="s1">n_targets</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">noise</span><span class="s2">=</span><span class="s1">noise</span><span class="s2">,</span>
        <span class="s1">n_informative</span><span class="s2">=</span><span class="s4">5</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">y</span><span class="s2">.</span><span class="s1">reshape</span><span class="s2">(</span><span class="s1">y_shape</span><span class="s2">)</span>

    <span class="s1">alphas </span><span class="s2">= [</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">10.0</span><span class="s2">, </span><span class="s4">1e3</span><span class="s2">]</span>
    <span class="s1">loo_ridge </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span>
        <span class="s1">cv</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
        <span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">,</span>
        <span class="s1">scoring</span><span class="s2">=</span><span class="s3">&quot;neg_mean_squared_error&quot;</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">gcv_ridge </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span>
        <span class="s1">gcv_mode</span><span class="s2">=</span><span class="s1">gcv_mode</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
        <span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">loo_ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">X_gcv </span><span class="s2">= </span><span class="s1">X_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_gcv</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">alpha_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">loo_ridge</span><span class="s2">.</span><span class="s1">alpha_</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">loo_ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">loo_ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_ridge_loo_cv_asym_scoring</span><span class="s2">():</span>
    <span class="s6"># checking on asymmetric scoring</span>
    <span class="s1">scoring </span><span class="s2">= </span><span class="s3">&quot;explained_variance&quot;</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s4">10</span><span class="s2">, </span><span class="s4">5</span>
    <span class="s1">n_targets </span><span class="s2">= </span><span class="s4">1</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">_make_sparse_offset_regression</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">,</span>
        <span class="s1">n_targets</span><span class="s2">=</span><span class="s1">n_targets</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">noise</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
        <span class="s1">n_informative</span><span class="s2">=</span><span class="s4">5</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">alphas </span><span class="s2">= [</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">10.0</span><span class="s2">, </span><span class="s4">1e3</span><span class="s2">]</span>
    <span class="s1">loo_ridge </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span>
        <span class="s1">cv</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scoring</span>
    <span class="s2">)</span>

    <span class="s1">gcv_ridge </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scoring</span><span class="s2">)</span>

    <span class="s1">loo_ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">alpha_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">loo_ridge</span><span class="s2">.</span><span class="s1">alpha_</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">loo_ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">loo_ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;gcv_mode&quot;</span><span class="s2">, [</span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s3">&quot;eigen&quot;</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;X_container&quot;</span><span class="s2">, [</span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">] + </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;n_features&quot;</span><span class="s2">, [</span><span class="s4">8</span><span class="s2">, </span><span class="s4">20</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;y_shape, fit_intercept, noise&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">((</span><span class="s4">11</span><span class="s2">,), </span><span class="s0">True</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">((</span><span class="s4">11</span><span class="s2">, </span><span class="s4">1</span><span class="s2">), </span><span class="s0">True</span><span class="s2">, </span><span class="s4">20.0</span><span class="s2">),</span>
        <span class="s2">((</span><span class="s4">11</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s0">True</span><span class="s2">, </span><span class="s4">150.0</span><span class="s2">),</span>
        <span class="s2">((</span><span class="s4">11</span><span class="s2">, </span><span class="s4">3</span><span class="s2">), </span><span class="s0">False</span><span class="s2">, </span><span class="s4">30.0</span><span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridge_gcv_sample_weights</span><span class="s2">(</span>
    <span class="s1">gcv_mode</span><span class="s2">, </span><span class="s1">X_container</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">y_shape</span><span class="s2">, </span><span class="s1">noise</span>
<span class="s2">):</span>
    <span class="s1">alphas </span><span class="s2">= [</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">10.0</span><span class="s2">, </span><span class="s4">1e3</span><span class="s2">]</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">n_targets </span><span class="s2">= </span><span class="s1">y_shape</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">] </span><span class="s0">if </span><span class="s1">len</span><span class="s2">(</span><span class="s1">y_shape</span><span class="s2">) == </span><span class="s4">2 </span><span class="s0">else </span><span class="s4">1</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">_make_sparse_offset_regression</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s4">11</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">,</span>
        <span class="s1">n_targets</span><span class="s2">=</span><span class="s1">n_targets</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">noise</span><span class="s2">=</span><span class="s1">noise</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">y</span><span class="s2">.</span><span class="s1">reshape</span><span class="s2">(</span><span class="s1">y_shape</span><span class="s2">)</span>

    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s4">3 </span><span class="s2">* </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">len</span><span class="s2">(</span><span class="s1">X</span><span class="s2">))</span>
    <span class="s1">sample_weight </span><span class="s2">= (</span><span class="s1">sample_weight </span><span class="s2">- </span><span class="s1">sample_weight</span><span class="s2">.</span><span class="s1">min</span><span class="s2">() + </span><span class="s4">1</span><span class="s2">).</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">int</span><span class="s2">)</span>
    <span class="s1">indices </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">repeat</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]), </span><span class="s1">sample_weight</span><span class="s2">)</span>
    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s1">sample_weight</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">float</span><span class="s2">)</span>
    <span class="s1">X_tiled</span><span class="s2">, </span><span class="s1">y_tiled </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[</span><span class="s1">indices</span><span class="s2">], </span><span class="s1">y</span><span class="s2">[</span><span class="s1">indices</span><span class="s2">]</span>

    <span class="s1">cv </span><span class="s2">= </span><span class="s1">GroupKFold</span><span class="s2">(</span><span class="s1">n_splits</span><span class="s2">=</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>
    <span class="s1">splits </span><span class="s2">= </span><span class="s1">cv</span><span class="s2">.</span><span class="s1">split</span><span class="s2">(</span><span class="s1">X_tiled</span><span class="s2">, </span><span class="s1">y_tiled</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">=</span><span class="s1">indices</span><span class="s2">)</span>
    <span class="s1">kfold </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span>
        <span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">,</span>
        <span class="s1">cv</span><span class="s2">=</span><span class="s1">splits</span><span class="s2">,</span>
        <span class="s1">scoring</span><span class="s2">=</span><span class="s3">&quot;neg_mean_squared_error&quot;</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">kfold</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_tiled</span><span class="s2">, </span><span class="s1">y_tiled</span><span class="s2">)</span>

    <span class="s1">ridge_reg </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">kfold</span><span class="s2">.</span><span class="s1">alpha_</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">)</span>
    <span class="s1">splits </span><span class="s2">= </span><span class="s1">cv</span><span class="s2">.</span><span class="s1">split</span><span class="s2">(</span><span class="s1">X_tiled</span><span class="s2">, </span><span class="s1">y_tiled</span><span class="s2">, </span><span class="s1">groups</span><span class="s2">=</span><span class="s1">indices</span><span class="s2">)</span>
    <span class="s1">predictions </span><span class="s2">= </span><span class="s1">cross_val_predict</span><span class="s2">(</span><span class="s1">ridge_reg</span><span class="s2">, </span><span class="s1">X_tiled</span><span class="s2">, </span><span class="s1">y_tiled</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s1">splits</span><span class="s2">)</span>
    <span class="s1">kfold_errors </span><span class="s2">= (</span><span class="s1">y_tiled </span><span class="s2">- </span><span class="s1">predictions</span><span class="s2">) ** </span><span class="s4">2</span>
    <span class="s1">kfold_errors </span><span class="s2">= [</span>
        <span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">kfold_errors</span><span class="s2">[</span><span class="s1">indices </span><span class="s2">== </span><span class="s1">i</span><span class="s2">], </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">) </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>
    <span class="s2">]</span>
    <span class="s1">kfold_errors </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">kfold_errors</span><span class="s2">)</span>

    <span class="s1">X_gcv </span><span class="s2">= </span><span class="s1">X_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">gcv_ridge </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span>
        <span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">,</span>
        <span class="s1">store_cv_results</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">gcv_mode</span><span class="s2">=</span><span class="s1">gcv_mode</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_gcv</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">len</span><span class="s2">(</span><span class="s1">y_shape</span><span class="s2">) == </span><span class="s4">2</span><span class="s2">:</span>
        <span class="s1">gcv_errors </span><span class="s2">= </span><span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">cv_results_</span><span class="s2">[:, :, </span><span class="s1">alphas</span><span class="s2">.</span><span class="s1">index</span><span class="s2">(</span><span class="s1">kfold</span><span class="s2">.</span><span class="s1">alpha_</span><span class="s2">)]</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">gcv_errors </span><span class="s2">= </span><span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">cv_results_</span><span class="s2">[:, </span><span class="s1">alphas</span><span class="s2">.</span><span class="s1">index</span><span class="s2">(</span><span class="s1">kfold</span><span class="s2">.</span><span class="s1">alpha_</span><span class="s2">)]</span>

    <span class="s0">assert </span><span class="s1">kfold</span><span class="s2">.</span><span class="s1">alpha_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">alpha_</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">gcv_errors</span><span class="s2">, </span><span class="s1">kfold_errors</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">kfold</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">gcv_ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">kfold</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;sparse_container&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">] + </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;mode, mode_n_greater_than_p, mode_p_greater_than_n&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">(</span><span class="s0">None</span><span class="s2">, </span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s3">&quot;eigen&quot;</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;auto&quot;</span><span class="s2">, </span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s3">&quot;eigen&quot;</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;eigen&quot;</span><span class="s2">, </span><span class="s3">&quot;eigen&quot;</span><span class="s2">, </span><span class="s3">&quot;eigen&quot;</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s3">&quot;svd&quot;</span><span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_check_gcv_mode_choice</span><span class="s2">(</span>
    <span class="s1">sparse_container</span><span class="s2">, </span><span class="s1">mode</span><span class="s2">, </span><span class="s1">mode_n_greater_than_p</span><span class="s2">, </span><span class="s1">mode_p_greater_than_n</span>
<span class="s2">):</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">= </span><span class="s1">make_regression</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s4">2</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is not None</span><span class="s2">:</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">_check_gcv_mode</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">mode</span><span class="s2">) == </span><span class="s1">mode_n_greater_than_p</span>
    <span class="s0">assert </span><span class="s1">_check_gcv_mode</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">T</span><span class="s2">, </span><span class="s1">mode</span><span class="s2">) == </span><span class="s1">mode_p_greater_than_n</span>


<span class="s0">def </span><span class="s1">_test_ridge_loo</span><span class="s2">(</span><span class="s1">sparse_container</span><span class="s2">):</span>
    <span class="s6"># test that can work with both dense or sparse matrices</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s1">X_diabetes</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]</span>

    <span class="s1">ret </span><span class="s2">= []</span>

    <span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is None</span><span class="s2">:</span>
        <span class="s1">X</span><span class="s2">, </span><span class="s1">fit_intercept </span><span class="s2">= </span><span class="s1">X_diabetes</span><span class="s2">, </span><span class="s0">True</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">X</span><span class="s2">, </span><span class="s1">fit_intercept </span><span class="s2">= </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X_diabetes</span><span class="s2">), </span><span class="s0">False</span>
    <span class="s1">ridge_gcv </span><span class="s2">= </span><span class="s1">_RidgeGCV</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">)</span>

    <span class="s6"># check best alpha</span>
    <span class="s1">ridge_gcv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>
    <span class="s1">alpha_ </span><span class="s2">= </span><span class="s1">ridge_gcv</span><span class="s2">.</span><span class="s1">alpha_</span>
    <span class="s1">ret</span><span class="s2">.</span><span class="s1">append</span><span class="s2">(</span><span class="s1">alpha_</span><span class="s2">)</span>

    <span class="s6"># check that we get same best alpha with custom loss_func</span>
    <span class="s1">f </span><span class="s2">= </span><span class="s1">ignore_warnings</span>
    <span class="s1">scoring </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">mean_squared_error</span><span class="s2">, </span><span class="s1">greater_is_better</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">ridge_gcv2 </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scoring</span><span class="s2">)</span>
    <span class="s1">f</span><span class="s2">(</span><span class="s1">ridge_gcv2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">)(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ridge_gcv2</span><span class="s2">.</span><span class="s1">alpha_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">alpha_</span><span class="s2">)</span>

    <span class="s6"># check that we get same best alpha with custom score_func</span>
    <span class="s0">def </span><span class="s1">func</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s2">-</span><span class="s1">mean_squared_error</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">scoring </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">func</span><span class="s2">)</span>
    <span class="s1">ridge_gcv3 </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scoring</span><span class="s2">)</span>
    <span class="s1">f</span><span class="s2">(</span><span class="s1">ridge_gcv3</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">)(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ridge_gcv3</span><span class="s2">.</span><span class="s1">alpha_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">alpha_</span><span class="s2">)</span>

    <span class="s6"># check that we get same best alpha with a scorer</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;neg_mean_squared_error&quot;</span><span class="s2">)</span>
    <span class="s1">ridge_gcv4 </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scorer</span><span class="s2">)</span>
    <span class="s1">ridge_gcv4</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ridge_gcv4</span><span class="s2">.</span><span class="s1">alpha_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">alpha_</span><span class="s2">)</span>

    <span class="s6"># check that we get same best alpha with sample weights</span>
    <span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is None</span><span class="s2">:</span>
        <span class="s1">ridge_gcv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">))</span>
        <span class="s0">assert </span><span class="s1">ridge_gcv</span><span class="s2">.</span><span class="s1">alpha_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">alpha_</span><span class="s2">)</span>

    <span class="s6"># simulate several responses</span>
    <span class="s1">Y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">vstack</span><span class="s2">((</span><span class="s1">y_diabetes</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)).</span><span class="s1">T</span>

    <span class="s1">ridge_gcv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s1">Y_pred </span><span class="s2">= </span><span class="s1">ridge_gcv</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">ridge_gcv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>
    <span class="s1">y_pred </span><span class="s2">= </span><span class="s1">ridge_gcv</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">vstack</span><span class="s2">((</span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">)).</span><span class="s1">T</span><span class="s2">, </span><span class="s1">Y_pred</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-5</span><span class="s2">)</span>

    <span class="s0">return </span><span class="s1">ret</span>


<span class="s0">def </span><span class="s1">_test_ridge_cv</span><span class="s2">(</span><span class="s1">sparse_container</span><span class="s2">):</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X_diabetes </span><span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is None else </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X_diabetes</span><span class="s2">)</span>
    <span class="s1">ridge_cv </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">()</span>
    <span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>
    <span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">len</span><span class="s2">(</span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">) == </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">type</span><span class="s2">(</span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">) </span><span class="s0">is </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span>

    <span class="s1">cv </span><span class="s2">= </span><span class="s1">KFold</span><span class="s2">(</span><span class="s4">5</span><span class="s2">)</span>
    <span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(</span><span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">)</span>
    <span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>
    <span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">len</span><span class="s2">(</span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">) == </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">type</span><span class="s2">(</span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">) </span><span class="s0">is </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;ridge, make_dataset&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">(</span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">store_cv_results</span><span class="s2">=</span><span class="s0">False</span><span class="s2">), </span><span class="s1">make_regression</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s1">RidgeClassifierCV</span><span class="s2">(</span><span class="s1">store_cv_results</span><span class="s2">=</span><span class="s0">False</span><span class="s2">), </span><span class="s1">make_classification</span><span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridge_gcv_cv_results_not_stored</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">, </span><span class="s1">make_dataset</span><span class="s2">):</span>
    <span class="s6"># Check that `cv_results_` is not stored when store_cv_results is False</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_dataset</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">6</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert not </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">, </span><span class="s3">&quot;cv_results_&quot;</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;ridge, make_dataset&quot;</span><span class="s2">,</span>
    <span class="s2">[(</span><span class="s1">RidgeCV</span><span class="s2">(), </span><span class="s1">make_regression</span><span class="s2">), (</span><span class="s1">RidgeClassifierCV</span><span class="s2">(), </span><span class="s1">make_classification</span><span class="s2">)],</span>
<span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;cv&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">, </span><span class="s4">3</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridge_best_score</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">, </span><span class="s1">make_dataset</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">):</span>
    <span class="s6"># check that the best_score_ is store</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_dataset</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">6</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(</span><span class="s1">store_cv_results</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">)</span>
    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">, </span><span class="s3">&quot;best_score_&quot;</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">best_score_</span><span class="s2">, </span><span class="s1">float</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_ridge_cv_individual_penalties</span><span class="s2">():</span>
    <span class="s6"># Tests the ridge_cv object optimizing individual penalties for each target</span>

    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">42</span><span class="s2">)</span>

    <span class="s6"># Create random dataset with multiple targets. Each target should have</span>
    <span class="s6"># a different optimal alpha.</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">n_targets </span><span class="s2">= </span><span class="s4">20</span><span class="s2">, </span><span class="s4">5</span><span class="s2">, </span><span class="s4">3</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_targets</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= (</span>
        <span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">y</span><span class="s2">[:, [</span><span class="s4">0</span><span class="s2">]], </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">((</span><span class="s4">1</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)))</span>
        <span class="s2">+ </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">y</span><span class="s2">[:, [</span><span class="s4">1</span><span class="s2">]], </span><span class="s4">0.05 </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">((</span><span class="s4">1</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)))</span>
        <span class="s2">+ </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">y</span><span class="s2">[:, [</span><span class="s4">2</span><span class="s2">]], </span><span class="s4">0.001 </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">((</span><span class="s4">1</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)))</span>
        <span class="s2">+ </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s2">)</span>

    <span class="s1">alphas </span><span class="s2">= (</span><span class="s4">1</span><span class="s2">, </span><span class="s4">100</span><span class="s2">, </span><span class="s4">1000</span><span class="s2">)</span>

    <span class="s6"># Find optimal alpha for each target</span>
    <span class="s1">optimal_alphas </span><span class="s2">= [</span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">target</span><span class="s2">).</span><span class="s1">alpha_ </span><span class="s0">for </span><span class="s1">target </span><span class="s0">in </span><span class="s1">y</span><span class="s2">.</span><span class="s1">T</span><span class="s2">]</span>

    <span class="s6"># Find optimal alphas for all targets simultaneously</span>
    <span class="s1">ridge_cv </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">alpha_per_target</span><span class="s2">=</span><span class="s0">True</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">optimal_alphas</span><span class="s2">, </span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">alpha_</span><span class="s2">)</span>

    <span class="s6"># The resulting regression weights should incorporate the different</span>
    <span class="s6"># alpha values.</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span>
        <span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">alpha_</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">).</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">coef_</span>
    <span class="s2">)</span>

    <span class="s6"># Test shape of alpha_ and cv_results_</span>
    <span class="s1">ridge_cv </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">alpha_per_target</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">store_cv_results</span><span class="s2">=</span><span class="s0">True</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span>
        <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span>
    <span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">alpha_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_targets</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">best_score_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_targets</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">cv_results_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">len</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">), </span><span class="s1">n_targets</span><span class="s2">)</span>

    <span class="s6"># Test edge case of there being only one alpha value</span>
    <span class="s1">ridge_cv </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">alpha_per_target</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">store_cv_results</span><span class="s2">=</span><span class="s0">True</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">alpha_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_targets</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">best_score_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_targets</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">cv_results_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_targets</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>

    <span class="s6"># Test edge case of there being only one target</span>
    <span class="s1">ridge_cv </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">alpha_per_target</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">store_cv_results</span><span class="s2">=</span><span class="s0">True</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span>
        <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">[:, </span><span class="s4">0</span><span class="s2">]</span>
    <span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">isscalar</span><span class="s2">(</span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">alpha_</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">isscalar</span><span class="s2">(</span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">best_score_</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">cv_results_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">len</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">))</span>

    <span class="s6"># Try with a custom scoring function</span>
    <span class="s1">ridge_cv </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">alpha_per_target</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s3">&quot;r2&quot;</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">optimal_alphas</span><span class="s2">, </span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">alpha_</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span>
        <span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">alpha_</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">).</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">coef_</span>
    <span class="s2">)</span>

    <span class="s6"># Using a custom CV object should throw an error in combination with</span>
    <span class="s6"># alpha_per_target=True</span>
    <span class="s1">ridge_cv </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s1">LeaveOneOut</span><span class="s2">(), </span><span class="s1">alpha_per_target</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;cv!=None and alpha_per_target=True are incompatible&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">ridge_cv </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s4">6</span><span class="s2">, </span><span class="s1">alpha_per_target</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">ridge_cv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">_test_ridge_diabetes</span><span class="s2">(</span><span class="s1">sparse_container</span><span class="s2">):</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X_diabetes </span><span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is None else </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X_diabetes</span><span class="s2">)</span>
    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">np</span><span class="s2">.</span><span class="s1">round</span><span class="s2">(</span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">), </span><span class="s4">5</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">_test_multi_ridge_diabetes</span><span class="s2">(</span><span class="s1">sparse_container</span><span class="s2">):</span>
    <span class="s6"># simulate several responses</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X_diabetes </span><span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is None else </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X_diabetes</span><span class="s2">)</span>
    <span class="s1">Y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">vstack</span><span class="s2">((</span><span class="s1">y_diabetes</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)).</span><span class="s1">T</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s1">X_diabetes</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">]</span>

    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">2</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">Y_pred </span><span class="s2">= </span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>
    <span class="s1">y_pred </span><span class="s2">= </span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">vstack</span><span class="s2">((</span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">)).</span><span class="s1">T</span><span class="s2">, </span><span class="s1">Y_pred</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">3</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">_test_ridge_classifiers</span><span class="s2">(</span><span class="s1">sparse_container</span><span class="s2">):</span>
    <span class="s1">n_classes </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">y_iris</span><span class="s2">).</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s1">X_iris</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X_iris </span><span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is None else </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X_iris</span><span class="s2">)</span>

    <span class="s0">for </span><span class="s1">reg </span><span class="s0">in </span><span class="s2">(</span><span class="s1">RidgeClassifier</span><span class="s2">(), </span><span class="s1">RidgeClassifierCV</span><span class="s2">()):</span>
        <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_iris</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">reg</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_classes</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
        <span class="s1">y_pred </span><span class="s2">= </span><span class="s1">reg</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">y_iris </span><span class="s2">== </span><span class="s1">y_pred</span><span class="s2">) &gt; </span><span class="s4">0.79</span>

    <span class="s1">cv </span><span class="s2">= </span><span class="s1">KFold</span><span class="s2">(</span><span class="s4">5</span><span class="s2">)</span>
    <span class="s1">reg </span><span class="s2">= </span><span class="s1">RidgeClassifierCV</span><span class="s2">(</span><span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">)</span>
    <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_iris</span><span class="s2">)</span>
    <span class="s1">y_pred </span><span class="s2">= </span><span class="s1">reg</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">y_iris </span><span class="s2">== </span><span class="s1">y_pred</span><span class="s2">) &gt;= </span><span class="s4">0.8</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;scoring&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">, </span><span class="s3">&quot;accuracy&quot;</span><span class="s2">, </span><span class="s1">_accuracy_callable</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;cv&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">, </span><span class="s1">KFold</span><span class="s2">(</span><span class="s4">5</span><span class="s2">)])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;sparse_container&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">] + </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridge_classifier_with_scoring</span><span class="s2">(</span><span class="s1">sparse_container</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">):</span>
    <span class="s6"># non-regression test for #14672</span>
    <span class="s6"># check that RidgeClassifierCV works with all sort of scoring and</span>
    <span class="s6"># cross-validation</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X_iris </span><span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is None else </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X_iris</span><span class="s2">)</span>
    <span class="s1">scoring_ </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">) </span><span class="s0">if </span><span class="s1">callable</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">) </span><span class="s0">else </span><span class="s1">scoring</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">RidgeClassifierCV</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scoring_</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">)</span>
    <span class="s6"># Smoke test to check that fit/predict does not raise error</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_iris</span><span class="s2">).</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;cv&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">, </span><span class="s1">KFold</span><span class="s2">(</span><span class="s4">5</span><span class="s2">)])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;sparse_container&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">] + </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridge_regression_custom_scoring</span><span class="s2">(</span><span class="s1">sparse_container</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">):</span>
    <span class="s6"># check that custom scoring is working as expected</span>
    <span class="s6"># check the tie breaking strategy (keep the first alpha tried)</span>

    <span class="s0">def </span><span class="s1">_dummy_score</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">, **</span><span class="s1">kwargs</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s4">0.42</span>

    <span class="s1">X </span><span class="s2">= </span><span class="s1">X_iris </span><span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is None else </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X_iris</span><span class="s2">)</span>
    <span class="s1">alphas </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">logspace</span><span class="s2">(-</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s1">num</span><span class="s2">=</span><span class="s4">5</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">RidgeClassifierCV</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">_dummy_score</span><span class="s2">), </span><span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_iris</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">best_score_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s4">0.42</span><span class="s2">)</span>
    <span class="s6"># In case of tie score, the first alphas will be kept</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">alpha_ </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>


<span class="s0">def </span><span class="s1">_test_tolerance</span><span class="s2">(</span><span class="s1">sparse_container</span><span class="s2">):</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X_diabetes </span><span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is None else </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X_diabetes</span><span class="s2">)</span>

    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-5</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>
    <span class="s1">score </span><span class="s2">= </span><span class="s1">ridge</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>

    <span class="s1">ridge2 </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">ridge2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>
    <span class="s1">score2 </span><span class="s2">= </span><span class="s1">ridge2</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">score </span><span class="s2">&gt;= </span><span class="s1">score2</span>


<span class="s0">def </span><span class="s1">check_array_api_attributes</span><span class="s2">(</span><span class="s1">name</span><span class="s2">, </span><span class="s1">estimator</span><span class="s2">, </span><span class="s1">array_namespace</span><span class="s2">, </span><span class="s1">device</span><span class="s2">, </span><span class="s1">dtype_name</span><span class="s2">):</span>
    <span class="s1">xp </span><span class="s2">= </span><span class="s1">_array_api_for_tests</span><span class="s2">(</span><span class="s1">array_namespace</span><span class="s2">, </span><span class="s1">device</span><span class="s2">)</span>

    <span class="s1">X_iris_np </span><span class="s2">= </span><span class="s1">X_iris</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">dtype_name</span><span class="s2">)</span>
    <span class="s1">y_iris_np </span><span class="s2">= </span><span class="s1">y_iris</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">dtype_name</span><span class="s2">)</span>

    <span class="s1">X_iris_xp </span><span class="s2">= </span><span class="s1">xp</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">X_iris_np</span><span class="s2">, </span><span class="s1">device</span><span class="s2">=</span><span class="s1">device</span><span class="s2">)</span>
    <span class="s1">y_iris_xp </span><span class="s2">= </span><span class="s1">xp</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">y_iris_np</span><span class="s2">, </span><span class="s1">device</span><span class="s2">=</span><span class="s1">device</span><span class="s2">)</span>

    <span class="s1">estimator</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_iris_np</span><span class="s2">, </span><span class="s1">y_iris_np</span><span class="s2">)</span>
    <span class="s1">coef_np </span><span class="s2">= </span><span class="s1">estimator</span><span class="s2">.</span><span class="s1">coef_</span>
    <span class="s1">intercept_np </span><span class="s2">= </span><span class="s1">estimator</span><span class="s2">.</span><span class="s1">intercept_</span>

    <span class="s0">with </span><span class="s1">config_context</span><span class="s2">(</span><span class="s1">array_api_dispatch</span><span class="s2">=</span><span class="s0">True</span><span class="s2">):</span>
        <span class="s1">estimator_xp </span><span class="s2">= </span><span class="s1">clone</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_iris_xp</span><span class="s2">, </span><span class="s1">y_iris_xp</span><span class="s2">)</span>
        <span class="s1">coef_xp </span><span class="s2">= </span><span class="s1">estimator_xp</span><span class="s2">.</span><span class="s1">coef_</span>
        <span class="s0">assert </span><span class="s1">coef_xp</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">4</span><span class="s2">,)</span>
        <span class="s0">assert </span><span class="s1">coef_xp</span><span class="s2">.</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">X_iris_xp</span><span class="s2">.</span><span class="s1">dtype</span>

        <span class="s1">assert_allclose</span><span class="s2">(</span>
            <span class="s1">_convert_to_numpy</span><span class="s2">(</span><span class="s1">coef_xp</span><span class="s2">, </span><span class="s1">xp</span><span class="s2">=</span><span class="s1">xp</span><span class="s2">),</span>
            <span class="s1">coef_np</span><span class="s2">,</span>
            <span class="s1">atol</span><span class="s2">=</span><span class="s1">_atol_for_type</span><span class="s2">(</span><span class="s1">dtype_name</span><span class="s2">),</span>
        <span class="s2">)</span>
        <span class="s1">intercept_xp </span><span class="s2">= </span><span class="s1">estimator_xp</span><span class="s2">.</span><span class="s1">intercept_</span>
        <span class="s0">assert </span><span class="s1">intercept_xp</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== ()</span>
        <span class="s0">assert </span><span class="s1">intercept_xp</span><span class="s2">.</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">X_iris_xp</span><span class="s2">.</span><span class="s1">dtype</span>

        <span class="s1">assert_allclose</span><span class="s2">(</span>
            <span class="s1">_convert_to_numpy</span><span class="s2">(</span><span class="s1">intercept_xp</span><span class="s2">, </span><span class="s1">xp</span><span class="s2">=</span><span class="s1">xp</span><span class="s2">),</span>
            <span class="s1">intercept_np</span><span class="s2">,</span>
            <span class="s1">atol</span><span class="s2">=</span><span class="s1">_atol_for_type</span><span class="s2">(</span><span class="s1">dtype_name</span><span class="s2">),</span>
        <span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;array_namespace, device, dtype_name&quot;</span><span class="s2">, </span><span class="s1">yield_namespace_device_dtype_combinations</span><span class="s2">()</span>
<span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;check&quot;</span><span class="s2">,</span>
    <span class="s2">[</span><span class="s1">check_array_api_input_and_values</span><span class="s2">, </span><span class="s1">check_array_api_attributes</span><span class="s2">],</span>
    <span class="s1">ids</span><span class="s2">=</span><span class="s1">_get_check_estimator_ids</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;estimator&quot;</span><span class="s2">,</span>
    <span class="s2">[</span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;svd&quot;</span><span class="s2">)],</span>
    <span class="s1">ids</span><span class="s2">=</span><span class="s1">_get_check_estimator_ids</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridge_array_api_compliance</span><span class="s2">(</span>
    <span class="s1">estimator</span><span class="s2">, </span><span class="s1">check</span><span class="s2">, </span><span class="s1">array_namespace</span><span class="s2">, </span><span class="s1">device</span><span class="s2">, </span><span class="s1">dtype_name</span>
<span class="s2">):</span>
    <span class="s1">name </span><span class="s2">= </span><span class="s1">estimator</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__name__</span>
    <span class="s1">check</span><span class="s2">(</span><span class="s1">name</span><span class="s2">, </span><span class="s1">estimator</span><span class="s2">, </span><span class="s1">array_namespace</span><span class="s2">, </span><span class="s1">device</span><span class="s2">=</span><span class="s1">device</span><span class="s2">, </span><span class="s1">dtype_name</span><span class="s2">=</span><span class="s1">dtype_name</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;array_namespace&quot;</span><span class="s2">, </span><span class="s1">yield_namespaces</span><span class="s2">(</span><span class="s1">include_numpy_namespaces</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_array_api_error_and_warnings_for_solver_parameter</span><span class="s2">(</span><span class="s1">array_namespace</span><span class="s2">):</span>
    <span class="s1">xp </span><span class="s2">= </span><span class="s1">_array_api_for_tests</span><span class="s2">(</span><span class="s1">array_namespace</span><span class="s2">, </span><span class="s1">device</span><span class="s2">=</span><span class="s0">None</span><span class="s2">)</span>

    <span class="s1">X_iris_xp </span><span class="s2">= </span><span class="s1">xp</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">X_iris</span><span class="s2">[:</span><span class="s4">5</span><span class="s2">])</span>
    <span class="s1">y_iris_xp </span><span class="s2">= </span><span class="s1">xp</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">y_iris</span><span class="s2">[:</span><span class="s4">5</span><span class="s2">])</span>

    <span class="s1">available_solvers </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">.</span><span class="s1">_parameter_constraints</span><span class="s2">[</span><span class="s3">&quot;solver&quot;</span><span class="s2">][</span><span class="s4">0</span><span class="s2">].</span><span class="s1">options</span>
    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s1">available_solvers </span><span class="s2">- {</span><span class="s3">&quot;auto&quot;</span><span class="s2">, </span><span class="s3">&quot;svd&quot;</span><span class="s2">}:</span>
        <span class="s1">ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">positive</span><span class="s2">=</span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">)</span>
        <span class="s1">expected_msg </span><span class="s2">= (</span>
            <span class="s3">f&quot;Array API dispatch to namespace </span><span class="s0">{</span><span class="s1">xp</span><span class="s2">.</span><span class="s1">__name__</span><span class="s0">} </span><span class="s3">only supports &quot;</span>
            <span class="s3">f&quot;solver 'svd'. Got '</span><span class="s0">{</span><span class="s1">solver</span><span class="s0">}</span><span class="s3">'.&quot;</span>
        <span class="s2">)</span>

        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">expected_msg</span><span class="s2">):</span>
            <span class="s0">with </span><span class="s1">config_context</span><span class="s2">(</span><span class="s1">array_api_dispatch</span><span class="s2">=</span><span class="s0">True</span><span class="s2">):</span>
                <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_iris_xp</span><span class="s2">, </span><span class="s1">y_iris_xp</span><span class="s2">)</span>

    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;auto&quot;</span><span class="s2">, </span><span class="s1">positive</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s1">expected_msg </span><span class="s2">= (</span>
        <span class="s3">&quot;The solvers that support positive fitting do not support &quot;</span>
        <span class="s3">f&quot;Array API dispatch to namespace </span><span class="s0">{</span><span class="s1">xp</span><span class="s2">.</span><span class="s1">__name__</span><span class="s0">}</span><span class="s3">. Please &quot;</span>
        <span class="s3">&quot;either disable Array API dispatch, or use a numpy-like &quot;</span>
        <span class="s3">&quot;namespace, or set `positive=False`.&quot;</span>
    <span class="s2">)</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">expected_msg</span><span class="s2">):</span>
        <span class="s0">with </span><span class="s1">config_context</span><span class="s2">(</span><span class="s1">array_api_dispatch</span><span class="s2">=</span><span class="s0">True</span><span class="s2">):</span>
            <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_iris_xp</span><span class="s2">, </span><span class="s1">y_iris_xp</span><span class="s2">)</span>

    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">()</span>
    <span class="s1">expected_msg </span><span class="s2">= (</span>
        <span class="s3">f&quot;Using Array API dispatch to namespace </span><span class="s0">{</span><span class="s1">xp</span><span class="s2">.</span><span class="s1">__name__</span><span class="s0">} </span><span class="s3">with `solver='auto'` &quot;</span>
        <span class="s3">&quot;will result in using the solver 'svd'. The results may differ from those &quot;</span>
        <span class="s3">&quot;when using a Numpy array, because in that case the preferred solver would &quot;</span>
        <span class="s3">&quot;be cholesky. Set `solver='svd'` to suppress this warning.&quot;</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">UserWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">expected_msg</span><span class="s2">):</span>
        <span class="s0">with </span><span class="s1">config_context</span><span class="s2">(</span><span class="s1">array_api_dispatch</span><span class="s2">=</span><span class="s0">True</span><span class="s2">):</span>
            <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_iris_xp</span><span class="s2">, </span><span class="s1">y_iris_xp</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;array_namespace&quot;</span><span class="s2">, </span><span class="s1">sorted</span><span class="s2">(</span><span class="s1">_NUMPY_NAMESPACE_NAMES</span><span class="s2">))</span>
<span class="s0">def </span><span class="s1">test_array_api_numpy_namespace_no_warning</span><span class="s2">(</span><span class="s1">array_namespace</span><span class="s2">):</span>
    <span class="s1">xp </span><span class="s2">= </span><span class="s1">_array_api_for_tests</span><span class="s2">(</span><span class="s1">array_namespace</span><span class="s2">, </span><span class="s1">device</span><span class="s2">=</span><span class="s0">None</span><span class="s2">)</span>

    <span class="s1">X_iris_xp </span><span class="s2">= </span><span class="s1">xp</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">X_iris</span><span class="s2">[:</span><span class="s4">5</span><span class="s2">])</span>
    <span class="s1">y_iris_xp </span><span class="s2">= </span><span class="s1">xp</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">y_iris</span><span class="s2">[:</span><span class="s4">5</span><span class="s2">])</span>

    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">()</span>
    <span class="s1">expected_msg </span><span class="s2">= (</span>
        <span class="s3">&quot;Results might be different than when Array API dispatch is &quot;</span>
        <span class="s3">&quot;disabled, or when a numpy-like namespace is used&quot;</span>
    <span class="s2">)</span>

    <span class="s0">with </span><span class="s1">warnings</span><span class="s2">.</span><span class="s1">catch_warnings</span><span class="s2">():</span>
        <span class="s1">warnings</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;error&quot;</span><span class="s2">, </span><span class="s1">message</span><span class="s2">=</span><span class="s1">expected_msg</span><span class="s2">, </span><span class="s1">category</span><span class="s2">=</span><span class="s1">UserWarning</span><span class="s2">)</span>
        <span class="s0">with </span><span class="s1">config_context</span><span class="s2">(</span><span class="s1">array_api_dispatch</span><span class="s2">=</span><span class="s0">True</span><span class="s2">):</span>
            <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_iris_xp</span><span class="s2">, </span><span class="s1">y_iris_xp</span><span class="s2">)</span>

    <span class="s6"># All numpy namespaces are compatible with all solver, in particular</span>
    <span class="s6"># solvers that support `positive=True` (like 'lbfgs') should work.</span>
    <span class="s0">with </span><span class="s1">config_context</span><span class="s2">(</span><span class="s1">array_api_dispatch</span><span class="s2">=</span><span class="s0">True</span><span class="s2">):</span>
        <span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;auto&quot;</span><span class="s2">, </span><span class="s1">positive</span><span class="s2">=</span><span class="s0">True</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_iris_xp</span><span class="s2">, </span><span class="s1">y_iris_xp</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;test_func&quot;</span><span class="s2">,</span>
    <span class="s2">(</span>
        <span class="s1">_test_ridge_loo</span><span class="s2">,</span>
        <span class="s1">_test_ridge_cv</span><span class="s2">,</span>
        <span class="s1">_test_ridge_diabetes</span><span class="s2">,</span>
        <span class="s1">_test_multi_ridge_diabetes</span><span class="s2">,</span>
        <span class="s1">_test_ridge_classifiers</span><span class="s2">,</span>
        <span class="s1">_test_tolerance</span><span class="s2">,</span>
    <span class="s2">),</span>
<span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_dense_sparse</span><span class="s2">(</span><span class="s1">test_func</span><span class="s2">, </span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s6"># test dense matrix</span>
    <span class="s1">ret_dense </span><span class="s2">= </span><span class="s1">test_func</span><span class="s2">(</span><span class="s0">None</span><span class="s2">)</span>
    <span class="s6"># test sparse matrix</span>
    <span class="s1">ret_sparse </span><span class="s2">= </span><span class="s1">test_func</span><span class="s2">(</span><span class="s1">csr_container</span><span class="s2">)</span>
    <span class="s6"># test that the outputs are the same</span>
    <span class="s0">if </span><span class="s1">ret_dense </span><span class="s0">is not None and </span><span class="s1">ret_sparse </span><span class="s0">is not None</span><span class="s2">:</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">ret_dense</span><span class="s2">, </span><span class="s1">ret_sparse</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">3</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_class_weights</span><span class="s2">():</span>
    <span class="s6"># Test class weights.</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[-</span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [-</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">], [-</span><span class="s4">0.8</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">], [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">]])</span>
    <span class="s1">y </span><span class="s2">= [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">]</span>

    <span class="s1">reg </span><span class="s2">= </span><span class="s1">RidgeClassifier</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">)</span>
    <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">([[</span><span class="s4">0.2</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">]]), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">1</span><span class="s2">]))</span>

    <span class="s6"># we give a small weights to class 1</span>
    <span class="s1">reg </span><span class="s2">= </span><span class="s1">RidgeClassifier</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">={</span><span class="s4">1</span><span class="s2">: </span><span class="s4">0.001</span><span class="s2">})</span>
    <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s6"># now the hyperplane should rotate clock-wise and</span>
    <span class="s6"># the prediction on this point should shift</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">([[</span><span class="s4">0.2</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">]]), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([-</span><span class="s4">1</span><span class="s2">]))</span>

    <span class="s6"># check if class_weight = 'balanced' can handle negative labels.</span>
    <span class="s1">reg </span><span class="s2">= </span><span class="s1">RidgeClassifier</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">=</span><span class="s3">&quot;balanced&quot;</span><span class="s2">)</span>
    <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">([[</span><span class="s4">0.2</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">]]), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">1</span><span class="s2">]))</span>

    <span class="s6"># class_weight = 'balanced', and class_weight = None should return</span>
    <span class="s6"># same values when y has equal number of all labels</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[-</span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [-</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">], [-</span><span class="s4">0.8</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">]])</span>
    <span class="s1">y </span><span class="s2">= [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s1">reg </span><span class="s2">= </span><span class="s1">RidgeClassifier</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">)</span>
    <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">rega </span><span class="s2">= </span><span class="s1">RidgeClassifier</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">=</span><span class="s3">&quot;balanced&quot;</span><span class="s2">)</span>
    <span class="s1">rega</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">len</span><span class="s2">(</span><span class="s1">rega</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">) == </span><span class="s4">2</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rega</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">rega</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;reg&quot;</span><span class="s2">, (</span><span class="s1">RidgeClassifier</span><span class="s2">, </span><span class="s1">RidgeClassifierCV</span><span class="s2">))</span>
<span class="s0">def </span><span class="s1">test_class_weight_vs_sample_weight</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Check class_weights resemble sample_weights behavior.&quot;&quot;&quot;</span>

    <span class="s6"># Iris is balanced, so no effect expected for using 'balanced' weights</span>
    <span class="s1">reg1 </span><span class="s2">= </span><span class="s1">reg</span><span class="s2">()</span>
    <span class="s1">reg1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">)</span>
    <span class="s1">reg2 </span><span class="s2">= </span><span class="s1">reg</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">=</span><span class="s3">&quot;balanced&quot;</span><span class="s2">)</span>
    <span class="s1">reg2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">reg1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">reg2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>

    <span class="s6"># Inflate importance of class 1, check against user-defined weights</span>
    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">)</span>
    <span class="s1">sample_weight</span><span class="s2">[</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target </span><span class="s2">== </span><span class="s4">1</span><span class="s2">] *= </span><span class="s4">100</span>
    <span class="s1">class_weight </span><span class="s2">= {</span><span class="s4">0</span><span class="s2">: </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">: </span><span class="s4">100.0</span><span class="s2">, </span><span class="s4">2</span><span class="s2">: </span><span class="s4">1.0</span><span class="s2">}</span>
    <span class="s1">reg1 </span><span class="s2">= </span><span class="s1">reg</span><span class="s2">()</span>
    <span class="s1">reg1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">)</span>
    <span class="s1">reg2 </span><span class="s2">= </span><span class="s1">reg</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">=</span><span class="s1">class_weight</span><span class="s2">)</span>
    <span class="s1">reg2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">reg1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">reg2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>

    <span class="s6"># Check that sample_weight and class_weight are multiplicative</span>
    <span class="s1">reg1 </span><span class="s2">= </span><span class="s1">reg</span><span class="s2">()</span>
    <span class="s1">reg1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">**</span><span class="s4">2</span><span class="s2">)</span>
    <span class="s1">reg2 </span><span class="s2">= </span><span class="s1">reg</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">=</span><span class="s1">class_weight</span><span class="s2">)</span>
    <span class="s1">reg2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">reg1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">reg2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_class_weights_cv</span><span class="s2">():</span>
    <span class="s6"># Test class weights for cross validated ridge classifier.</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[-</span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [-</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">], [-</span><span class="s4">0.8</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">], [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">]])</span>
    <span class="s1">y </span><span class="s2">= [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">]</span>

    <span class="s1">reg </span><span class="s2">= </span><span class="s1">RidgeClassifierCV</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">alphas</span><span class="s2">=[</span><span class="s4">0.01</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">])</span>
    <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s6"># we give a small weights to class 1</span>
    <span class="s1">reg </span><span class="s2">= </span><span class="s1">RidgeClassifierCV</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">={</span><span class="s4">1</span><span class="s2">: </span><span class="s4">0.001</span><span class="s2">}, </span><span class="s1">alphas</span><span class="s2">=[</span><span class="s4">0.01</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">10</span><span class="s2">])</span>
    <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">([[-</span><span class="s4">0.2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]]), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([-</span><span class="s4">1</span><span class="s2">]))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;scoring&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">, </span><span class="s3">&quot;neg_mean_squared_error&quot;</span><span class="s2">, </span><span class="s1">_mean_squared_error_callable</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridgecv_store_cv_results</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">):</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">42</span><span class="s2">)</span>

    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">8</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s4">5</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">alphas </span><span class="s2">= [</span><span class="s4">1e-1</span><span class="s2">, </span><span class="s4">1e0</span><span class="s2">, </span><span class="s4">1e1</span><span class="s2">]</span>
    <span class="s1">n_alphas </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">)</span>

    <span class="s1">scoring_ </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">) </span><span class="s0">if </span><span class="s1">callable</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">) </span><span class="s0">else </span><span class="s1">scoring</span>

    <span class="s1">r </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">store_cv_results</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scoring_</span><span class="s2">)</span>

    <span class="s6"># with len(y.shape) == 1</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">r</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">r</span><span class="s2">.</span><span class="s1">cv_results_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_alphas</span><span class="s2">)</span>

    <span class="s6"># with len(y.shape) == 2</span>
    <span class="s1">n_targets </span><span class="s2">= </span><span class="s4">3</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_targets</span><span class="s2">)</span>
    <span class="s1">r</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">r</span><span class="s2">.</span><span class="s1">cv_results_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_targets</span><span class="s2">, </span><span class="s1">n_alphas</span><span class="s2">)</span>

    <span class="s1">r </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">cv</span><span class="s2">=</span><span class="s4">3</span><span class="s2">, </span><span class="s1">store_cv_results</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scoring</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;cv!=None and store_cv_results&quot;</span><span class="s2">):</span>
        <span class="s1">r</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;scoring&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">, </span><span class="s3">&quot;accuracy&quot;</span><span class="s2">, </span><span class="s1">_accuracy_callable</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridge_classifier_cv_store_cv_results</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">):</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[-</span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [-</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">], [-</span><span class="s4">0.8</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">], [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">]])</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">])</span>

    <span class="s1">n_samples </span><span class="s2">= </span><span class="s1">x</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]</span>
    <span class="s1">alphas </span><span class="s2">= [</span><span class="s4">1e-1</span><span class="s2">, </span><span class="s4">1e0</span><span class="s2">, </span><span class="s4">1e1</span><span class="s2">]</span>
    <span class="s1">n_alphas </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">)</span>

    <span class="s1">scoring_ </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">) </span><span class="s0">if </span><span class="s1">callable</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">) </span><span class="s0">else </span><span class="s1">scoring</span>

    <span class="s1">r </span><span class="s2">= </span><span class="s1">RidgeClassifierCV</span><span class="s2">(</span>
        <span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">store_cv_results</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scoring_</span>
    <span class="s2">)</span>

    <span class="s6"># with len(y.shape) == 1</span>
    <span class="s1">n_targets </span><span class="s2">= </span><span class="s4">1</span>
    <span class="s1">r</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">r</span><span class="s2">.</span><span class="s1">cv_results_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_targets</span><span class="s2">, </span><span class="s1">n_alphas</span><span class="s2">)</span>

    <span class="s6"># with len(y.shape) == 2</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span>
        <span class="s2">[[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">], [</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">], [-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">]]</span>
    <span class="s2">).</span><span class="s1">transpose</span><span class="s2">()</span>
    <span class="s1">n_targets </span><span class="s2">= </span><span class="s1">y</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s1">r</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">r</span><span class="s2">.</span><span class="s1">cv_results_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_targets</span><span class="s2">, </span><span class="s1">n_alphas</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;Estimator&quot;</span><span class="s2">, [</span><span class="s1">RidgeCV</span><span class="s2">, </span><span class="s1">RidgeClassifierCV</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridgecv_alphas_conversion</span><span class="s2">(</span><span class="s1">Estimator</span><span class="s2">):</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">alphas </span><span class="s2">= (</span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">10.0</span><span class="s2">)</span>

    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s4">5</span><span class="s2">, </span><span class="s4">5</span>
    <span class="s0">if </span><span class="s1">Estimator </span><span class="s0">is </span><span class="s1">RidgeCV</span><span class="s2">:</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randint</span><span class="s2">(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>

    <span class="s1">ridge_est </span><span class="s2">= </span><span class="s1">Estimator</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s2">(</span>
        <span class="s1">ridge_est</span><span class="s2">.</span><span class="s1">alphas </span><span class="s0">is </span><span class="s1">alphas</span>
    <span class="s2">), </span><span class="s3">f&quot;`alphas` was mutated in `</span><span class="s0">{</span><span class="s1">Estimator</span><span class="s2">.</span><span class="s1">__name__</span><span class="s0">}</span><span class="s3">.__init__`&quot;</span>

    <span class="s1">ridge_est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">ridge_est</span><span class="s2">.</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;cv&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">, </span><span class="s4">3</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;Estimator&quot;</span><span class="s2">, [</span><span class="s1">RidgeCV</span><span class="s2">, </span><span class="s1">RidgeClassifierCV</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridgecv_alphas_zero</span><span class="s2">(</span><span class="s1">cv</span><span class="s2">, </span><span class="s1">Estimator</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Check alpha=0.0 raises error only when `cv=None`.&quot;&quot;&quot;</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">alphas </span><span class="s2">= (</span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">10.0</span><span class="s2">)</span>

    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s4">5</span><span class="s2">, </span><span class="s4">5</span>
    <span class="s0">if </span><span class="s1">Estimator </span><span class="s0">is </span><span class="s1">RidgeCV</span><span class="s2">:</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randint</span><span class="s2">(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>

    <span class="s1">ridge_est </span><span class="s2">= </span><span class="s1">Estimator</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">cv </span><span class="s0">is None</span><span class="s2">:</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">r&quot;alphas\[0\] == 0.0, must be &gt; 0.0.&quot;</span><span class="s2">):</span>
            <span class="s1">ridge_est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">ridge_est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_ridgecv_sample_weight</span><span class="s2">():</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">alphas </span><span class="s2">= (</span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">10.0</span><span class="s2">)</span>

    <span class="s6"># There are different algorithms for n_samples &gt; n_features</span>
    <span class="s6"># and the opposite, so test them both.</span>
    <span class="s0">for </span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s0">in </span><span class="s2">((</span><span class="s4">6</span><span class="s2">, </span><span class="s4">5</span><span class="s2">), (</span><span class="s4">5</span><span class="s2">, </span><span class="s4">10</span><span class="s2">)):</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
        <span class="s1">sample_weight </span><span class="s2">= </span><span class="s4">1.0 </span><span class="s2">+ </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">rand</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>

        <span class="s1">cv </span><span class="s2">= </span><span class="s1">KFold</span><span class="s2">(</span><span class="s4">5</span><span class="s2">)</span>
        <span class="s1">ridgecv </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s1">alphas</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">)</span>
        <span class="s1">ridgecv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>

        <span class="s6"># Check using GridSearchCV directly</span>
        <span class="s1">parameters </span><span class="s2">= {</span><span class="s3">&quot;alpha&quot;</span><span class="s2">: </span><span class="s1">alphas</span><span class="s2">}</span>
        <span class="s1">gs </span><span class="s2">= </span><span class="s1">GridSearchCV</span><span class="s2">(</span><span class="s1">Ridge</span><span class="s2">(), </span><span class="s1">parameters</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">)</span>
        <span class="s1">gs</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>

        <span class="s0">assert </span><span class="s1">ridgecv</span><span class="s2">.</span><span class="s1">alpha_ </span><span class="s2">== </span><span class="s1">gs</span><span class="s2">.</span><span class="s1">best_estimator_</span><span class="s2">.</span><span class="s1">alpha</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">ridgecv</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">gs</span><span class="s2">.</span><span class="s1">best_estimator_</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_raises_value_error_if_sample_weights_greater_than_1d</span><span class="s2">():</span>
    <span class="s6"># Sample weights must be either scalar or 1D</span>

    <span class="s1">n_sampless </span><span class="s2">= [</span><span class="s4">2</span><span class="s2">, </span><span class="s4">3</span><span class="s2">]</span>
    <span class="s1">n_featuress </span><span class="s2">= [</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]</span>

    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">42</span><span class="s2">)</span>

    <span class="s0">for </span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s0">in </span><span class="s1">zip</span><span class="s2">(</span><span class="s1">n_sampless</span><span class="s2">, </span><span class="s1">n_featuress</span><span class="s2">):</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
        <span class="s1">sample_weights_OK </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">) ** </span><span class="s4">2 </span><span class="s2">+ </span><span class="s4">1</span>
        <span class="s1">sample_weights_OK_1 </span><span class="s2">= </span><span class="s4">1.0</span>
        <span class="s1">sample_weights_OK_2 </span><span class="s2">= </span><span class="s4">2.0</span>
        <span class="s1">sample_weights_not_OK </span><span class="s2">= </span><span class="s1">sample_weights_OK</span><span class="s2">[:, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">newaxis</span><span class="s2">]</span>
        <span class="s1">sample_weights_not_OK_2 </span><span class="s2">= </span><span class="s1">sample_weights_OK</span><span class="s2">[</span><span class="s1">np</span><span class="s2">.</span><span class="s1">newaxis</span><span class="s2">, :]</span>

        <span class="s1">ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>

        <span class="s6"># make sure the &quot;OK&quot; sample weights actually work</span>
        <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weights_OK</span><span class="s2">)</span>
        <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weights_OK_1</span><span class="s2">)</span>
        <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weights_OK_2</span><span class="s2">)</span>

        <span class="s0">def </span><span class="s1">fit_ridge_not_ok</span><span class="s2">():</span>
            <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weights_not_OK</span><span class="s2">)</span>

        <span class="s0">def </span><span class="s1">fit_ridge_not_ok_2</span><span class="s2">():</span>
            <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weights_not_OK_2</span><span class="s2">)</span>

        <span class="s1">err_msg </span><span class="s2">= </span><span class="s3">&quot;Sample weights must be 1D array or scalar&quot;</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">err_msg</span><span class="s2">):</span>
            <span class="s1">fit_ridge_not_ok</span><span class="s2">()</span>

        <span class="s1">err_msg </span><span class="s2">= </span><span class="s3">&quot;Sample weights must be 1D array or scalar&quot;</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">err_msg</span><span class="s2">):</span>
            <span class="s1">fit_ridge_not_ok_2</span><span class="s2">()</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;n_samples,n_features&quot;</span><span class="s2">, [[</span><span class="s4">2</span><span class="s2">, </span><span class="s4">3</span><span class="s2">], [</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;sparse_container&quot;</span><span class="s2">,</span>
    <span class="s1">COO_CONTAINERS </span><span class="s2">+ </span><span class="s1">CSC_CONTAINERS </span><span class="s2">+ </span><span class="s1">CSR_CONTAINERS </span><span class="s2">+ </span><span class="s1">DOK_CONTAINERS </span><span class="s2">+ </span><span class="s1">LIL_CONTAINERS</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_sparse_design_with_sample_weights</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">sparse_container</span><span class="s2">):</span>
    <span class="s6"># Sample weights must work with sparse matrices</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">42</span><span class="s2">)</span>

    <span class="s1">sparse_ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">1.0</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">dense_ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">1.0</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>

    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">sample_weights </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">) ** </span><span class="s4">2 </span><span class="s2">+ </span><span class="s4">1</span>
    <span class="s1">X_sparse </span><span class="s2">= </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">sparse_ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_sparse</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weights</span><span class="s2">)</span>
    <span class="s1">dense_ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weights</span><span class="s2">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">sparse_ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">dense_ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">6</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_ridgecv_int_alphas</span><span class="s2">():</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[-</span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [-</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">], [-</span><span class="s4">0.8</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">], [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">]])</span>
    <span class="s1">y </span><span class="s2">= [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">]</span>

    <span class="s6"># Integers</span>
    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=(</span><span class="s4">1</span><span class="s2">, </span><span class="s4">10</span><span class="s2">, </span><span class="s4">100</span><span class="s2">))</span>
    <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;Estimator&quot;</span><span class="s2">, [</span><span class="s1">RidgeCV</span><span class="s2">, </span><span class="s1">RidgeClassifierCV</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;params, err_type, err_msg&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">({</span><span class="s3">&quot;alphas&quot;</span><span class="s2">: (</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">100</span><span class="s2">)}, </span><span class="s1">ValueError</span><span class="s2">, </span><span class="s3">r&quot;alphas\[1\] == -1, must be &gt; 0.0&quot;</span><span class="s2">),</span>
        <span class="s2">(</span>
            <span class="s2">{</span><span class="s3">&quot;alphas&quot;</span><span class="s2">: (-</span><span class="s4">0.1</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">10.0</span><span class="s2">)},</span>
            <span class="s1">ValueError</span><span class="s2">,</span>
            <span class="s3">r&quot;alphas\[0\] == -0.1, must be &gt; 0.0&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s2">(</span>
            <span class="s2">{</span><span class="s3">&quot;alphas&quot;</span><span class="s2">: (</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s3">&quot;1&quot;</span><span class="s2">)},</span>
            <span class="s1">TypeError</span><span class="s2">,</span>
            <span class="s3">r&quot;alphas\[2\] must be an instance of float, not str&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridgecv_alphas_validation</span><span class="s2">(</span><span class="s1">Estimator</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">err_type</span><span class="s2">, </span><span class="s1">err_msg</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Check the `alphas` validation in RidgeCV and RidgeClassifierCV.&quot;&quot;&quot;</span>

    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s4">5</span><span class="s2">, </span><span class="s4">5</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randint</span><span class="s2">(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">)</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">err_type</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">err_msg</span><span class="s2">):</span>
        <span class="s1">Estimator</span><span class="s2">(**</span><span class="s1">params</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;Estimator&quot;</span><span class="s2">, [</span><span class="s1">RidgeCV</span><span class="s2">, </span><span class="s1">RidgeClassifierCV</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridgecv_alphas_scalar</span><span class="s2">(</span><span class="s1">Estimator</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Check the case when `alphas` is a scalar. 
    This case was supported in the past when `alphas` where converted 
    into array in `__init__`. 
    We add this test to ensure backward compatibility. 
    &quot;&quot;&quot;</span>

    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s4">5</span><span class="s2">, </span><span class="s4">5</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">Estimator </span><span class="s0">is </span><span class="s1">RidgeCV</span><span class="s2">:</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randint</span><span class="s2">(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">)</span>

    <span class="s1">Estimator</span><span class="s2">(</span><span class="s1">alphas</span><span class="s2">=</span><span class="s4">1</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_sparse_cg_max_iter</span><span class="s2">():</span>
    <span class="s1">reg </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_diabetes</span><span class="s2">, </span><span class="s1">y_diabetes</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">reg</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] == </span><span class="s1">X_diabetes</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">]</span>


<span class="s2">@</span><span class="s1">ignore_warnings</span>
<span class="s0">def </span><span class="s1">test_n_iter</span><span class="s2">():</span>
    <span class="s6"># Test that self.n_iter_ is correct.</span>
    <span class="s1">n_targets </span><span class="s2">= </span><span class="s4">2</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">X_diabetes</span><span class="s2">, </span><span class="s1">y_diabetes</span>
    <span class="s1">y_n </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">tile</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, (</span><span class="s1">n_targets</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)).</span><span class="s1">T</span>

    <span class="s0">for </span><span class="s1">max_iter </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, </span><span class="s4">4</span><span class="s2">):</span>
        <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s3">&quot;lsqr&quot;</span><span class="s2">):</span>
            <span class="s1">reg </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s1">max_iter</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-12</span><span class="s2">)</span>
            <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_n</span><span class="s2">)</span>
            <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">n_iter_</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">tile</span><span class="s2">(</span><span class="s1">max_iter</span><span class="s2">, </span><span class="s1">n_targets</span><span class="s2">))</span>

    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s3">&quot;cholesky&quot;</span><span class="s2">):</span>
        <span class="s1">reg </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-1</span><span class="s2">)</span>
        <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_n</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">reg</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s0">is None</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, [</span><span class="s3">&quot;lsqr&quot;</span><span class="s2">, </span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">, </span><span class="s3">&quot;auto&quot;</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;with_sample_weight&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridge_fit_intercept_sparse</span><span class="s2">(</span>
    <span class="s1">solver</span><span class="s2">, </span><span class="s1">with_sample_weight</span><span class="s2">, </span><span class="s1">global_random_seed</span><span class="s2">, </span><span class="s1">csr_container</span>
<span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Check that ridge finds the same coefs and intercept on dense and sparse input 
    in the presence of sample weights. 
 
    For now only sparse_cg and lbfgs can correctly fit an intercept 
    with sparse X with default tol and max_iter. 
    'sag' is tested separately in test_ridge_fit_intercept_sparse_sag because it 
    requires more iterations and should raise a warning if default max_iter is used. 
    Other solvers raise an exception, as checked in 
    test_ridge_fit_intercept_sparse_error 
    &quot;&quot;&quot;</span>
    <span class="s1">positive </span><span class="s2">= </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;lbfgs&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">_make_sparse_offset_regression</span><span class="s2">(</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s4">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">, </span><span class="s1">positive</span><span class="s2">=</span><span class="s1">positive</span>
    <span class="s2">)</span>

    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s0">None</span>
    <span class="s0">if </span><span class="s1">with_sample_weight</span><span class="s2">:</span>
        <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">global_random_seed</span><span class="s2">)</span>
        <span class="s1">sample_weight </span><span class="s2">= </span><span class="s4">1.0 </span><span class="s2">+ </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">uniform</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>

    <span class="s6"># &quot;auto&quot; should switch to &quot;sparse_cg&quot; when X is sparse</span>
    <span class="s6"># so the reference we use for both (&quot;auto&quot; and &quot;sparse_cg&quot;) is</span>
    <span class="s6"># Ridge(solver=&quot;sparse_cg&quot;), fitted using the dense representation (note</span>
    <span class="s6"># that &quot;sparse_cg&quot; can fit sparse or dense data)</span>
    <span class="s1">dense_solver </span><span class="s2">= </span><span class="s3">&quot;sparse_cg&quot; </span><span class="s0">if </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;auto&quot; </span><span class="s0">else </span><span class="s1">solver</span>
    <span class="s1">dense_ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">dense_solver</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-12</span><span class="s2">, </span><span class="s1">positive</span><span class="s2">=</span><span class="s1">positive</span><span class="s2">)</span>
    <span class="s1">sparse_ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-12</span><span class="s2">, </span><span class="s1">positive</span><span class="s2">=</span><span class="s1">positive</span><span class="s2">)</span>

    <span class="s1">dense_ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>
    <span class="s1">sparse_ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>

    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">dense_ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">sparse_ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">dense_ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">sparse_ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">5e-7</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, [</span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s3">&quot;cholesky&quot;</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridge_fit_intercept_sparse_error</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">_make_sparse_offset_regression</span><span class="s2">(</span><span class="s1">n_features</span><span class="s2">=</span><span class="s4">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X_csr </span><span class="s2">= </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">sparse_ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">)</span>
    <span class="s1">err_msg </span><span class="s2">= </span><span class="s3">&quot;solver='{}' does not support&quot;</span><span class="s2">.</span><span class="s1">format</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">err_msg</span><span class="s2">):</span>
        <span class="s1">sparse_ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_csr</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;with_sample_weight&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridge_fit_intercept_sparse_sag</span><span class="s2">(</span>
    <span class="s1">with_sample_weight</span><span class="s2">, </span><span class="s1">global_random_seed</span><span class="s2">, </span><span class="s1">csr_container</span>
<span class="s2">):</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">_make_sparse_offset_regression</span><span class="s2">(</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">, </span><span class="s1">X_offset</span><span class="s2">=</span><span class="s4">5.0</span>
    <span class="s2">)</span>
    <span class="s0">if </span><span class="s1">with_sample_weight</span><span class="s2">:</span>
        <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">global_random_seed</span><span class="s2">)</span>
        <span class="s1">sample_weight </span><span class="s2">= </span><span class="s4">1.0 </span><span class="s2">+ </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">uniform</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">sample_weight </span><span class="s2">= </span><span class="s0">None</span>
    <span class="s1">X_csr </span><span class="s2">= </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">params </span><span class="s2">= </span><span class="s1">dict</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">1.0</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-10</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">100000</span>
    <span class="s2">)</span>
    <span class="s1">dense_ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(**</span><span class="s1">params</span><span class="s2">)</span>
    <span class="s1">sparse_ridge </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(**</span><span class="s1">params</span><span class="s2">)</span>
    <span class="s1">dense_ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">warnings</span><span class="s2">.</span><span class="s1">catch_warnings</span><span class="s2">():</span>
        <span class="s1">warnings</span><span class="s2">.</span><span class="s1">simplefilter</span><span class="s2">(</span><span class="s3">&quot;error&quot;</span><span class="s2">, </span><span class="s1">UserWarning</span><span class="s2">)</span>
        <span class="s1">sparse_ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_csr</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">dense_ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">sparse_ridge</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-4</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">dense_ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">sparse_ridge</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-4</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">UserWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">'&quot;sag&quot; solver requires.*'</span><span class="s2">):</span>
        <span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s0">None</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_csr</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;return_intercept&quot;</span><span class="s2">, [</span><span class="s0">False</span><span class="s2">, </span><span class="s0">True</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;sample_weight&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s4">1000</span><span class="s2">)])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;container&quot;</span><span class="s2">, [</span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">] + </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;solver&quot;</span><span class="s2">, [</span><span class="s3">&quot;auto&quot;</span><span class="s2">, </span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s3">&quot;cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;lsqr&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridge_regression_check_arguments_validity</span><span class="s2">(</span>
    <span class="s1">return_intercept</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">, </span><span class="s1">container</span><span class="s2">, </span><span class="s1">solver</span>
<span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;check if all combinations of arguments give valid estimations&quot;&quot;&quot;</span>

    <span class="s6"># test excludes 'svd' solver because it raises exception for sparse inputs</span>

    <span class="s1">rng </span><span class="s2">= </span><span class="s1">check_random_state</span><span class="s2">(</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">rand</span><span class="s2">(</span><span class="s4">1000</span><span class="s2">, </span><span class="s4">3</span><span class="s2">)</span>
    <span class="s1">true_coefs </span><span class="s2">= [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">]</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">true_coefs</span><span class="s2">)</span>
    <span class="s1">true_intercept </span><span class="s2">= </span><span class="s4">0.0</span>
    <span class="s0">if </span><span class="s1">return_intercept</span><span class="s2">:</span>
        <span class="s1">true_intercept </span><span class="s2">= </span><span class="s4">10000.0</span>
    <span class="s1">y </span><span class="s2">+= </span><span class="s1">true_intercept</span>
    <span class="s1">X_testing </span><span class="s2">= </span><span class="s1">container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">alpha</span><span class="s2">, </span><span class="s1">tol </span><span class="s2">= </span><span class="s4">1e-3</span><span class="s2">, </span><span class="s4">1e-6</span>
    <span class="s1">atol </span><span class="s2">= </span><span class="s4">1e-3 </span><span class="s0">if </span><span class="s1">_IS_32BIT </span><span class="s0">else </span><span class="s4">1e-4</span>

    <span class="s1">positive </span><span class="s2">= </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;lbfgs&quot;</span>

    <span class="s0">if </span><span class="s1">solver </span><span class="s0">not in </span><span class="s2">[</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;auto&quot;</span><span class="s2">] </span><span class="s0">and </span><span class="s1">return_intercept</span><span class="s2">:</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;In Ridge, only 'sag' solver&quot;</span><span class="s2">):</span>
            <span class="s1">ridge_regression</span><span class="s2">(</span>
                <span class="s1">X_testing</span><span class="s2">,</span>
                <span class="s1">y</span><span class="s2">,</span>
                <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
                <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
                <span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">,</span>
                <span class="s1">return_intercept</span><span class="s2">=</span><span class="s1">return_intercept</span><span class="s2">,</span>
                <span class="s1">positive</span><span class="s2">=</span><span class="s1">positive</span><span class="s2">,</span>
                <span class="s1">tol</span><span class="s2">=</span><span class="s1">tol</span><span class="s2">,</span>
            <span class="s2">)</span>
        <span class="s0">return</span>

    <span class="s1">out </span><span class="s2">= </span><span class="s1">ridge_regression</span><span class="s2">(</span>
        <span class="s1">X_testing</span><span class="s2">,</span>
        <span class="s1">y</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
        <span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">,</span>
        <span class="s1">positive</span><span class="s2">=</span><span class="s1">positive</span><span class="s2">,</span>
        <span class="s1">return_intercept</span><span class="s2">=</span><span class="s1">return_intercept</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s1">tol</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s0">if </span><span class="s1">return_intercept</span><span class="s2">:</span>
        <span class="s1">coef</span><span class="s2">, </span><span class="s1">intercept </span><span class="s2">= </span><span class="s1">out</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">coef</span><span class="s2">, </span><span class="s1">true_coefs</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s1">atol</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">intercept</span><span class="s2">, </span><span class="s1">true_intercept</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s1">atol</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">out</span><span class="s2">, </span><span class="s1">true_coefs</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s1">atol</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;solver&quot;</span><span class="s2">, [</span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s3">&quot;cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;lsqr&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_dtype_match</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">):</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">1.0</span>
    <span class="s1">positive </span><span class="s2">= </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;lbfgs&quot;</span>

    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s4">6</span><span class="s2">, </span><span class="s4">5</span>
    <span class="s1">X_64 </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y_64 </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">X_32 </span><span class="s2">= </span><span class="s1">X_64</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">)</span>
    <span class="s1">y_32 </span><span class="s2">= </span><span class="s1">y_64</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">)</span>

    <span class="s1">tol </span><span class="s2">= </span><span class="s4">2 </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">finfo</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">).</span><span class="s1">resolution</span>
    <span class="s6"># Check type consistency 32bits</span>
    <span class="s1">ridge_32 </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">500</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s1">tol</span><span class="s2">, </span><span class="s1">positive</span><span class="s2">=</span><span class="s1">positive</span>
    <span class="s2">)</span>
    <span class="s1">ridge_32</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_32</span><span class="s2">, </span><span class="s1">y_32</span><span class="s2">)</span>
    <span class="s1">coef_32 </span><span class="s2">= </span><span class="s1">ridge_32</span><span class="s2">.</span><span class="s1">coef_</span>

    <span class="s6"># Check type consistency 64 bits</span>
    <span class="s1">ridge_64 </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">500</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s1">tol</span><span class="s2">, </span><span class="s1">positive</span><span class="s2">=</span><span class="s1">positive</span>
    <span class="s2">)</span>
    <span class="s1">ridge_64</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_64</span><span class="s2">, </span><span class="s1">y_64</span><span class="s2">)</span>
    <span class="s1">coef_64 </span><span class="s2">= </span><span class="s1">ridge_64</span><span class="s2">.</span><span class="s1">coef_</span>

    <span class="s6"># Do the actual checks at once for easier debug</span>
    <span class="s0">assert </span><span class="s1">coef_32</span><span class="s2">.</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">X_32</span><span class="s2">.</span><span class="s1">dtype</span>
    <span class="s0">assert </span><span class="s1">coef_64</span><span class="s2">.</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">X_64</span><span class="s2">.</span><span class="s1">dtype</span>
    <span class="s0">assert </span><span class="s1">ridge_32</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_32</span><span class="s2">).</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">X_32</span><span class="s2">.</span><span class="s1">dtype</span>
    <span class="s0">assert </span><span class="s1">ridge_64</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_64</span><span class="s2">).</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">X_64</span><span class="s2">.</span><span class="s1">dtype</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">ridge_32</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">ridge_64</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-4</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s4">5e-4</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_dtype_match_cholesky</span><span class="s2">():</span>
    <span class="s6"># Test different alphas in cholesky solver to ensure full coverage.</span>
    <span class="s6"># This test is separated from test_dtype_match for clarity.</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.5</span><span class="s2">])</span>

    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">n_target </span><span class="s2">= </span><span class="s4">6</span><span class="s2">, </span><span class="s4">7</span><span class="s2">, </span><span class="s4">2</span>
    <span class="s1">X_64 </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y_64 </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_target</span><span class="s2">)</span>
    <span class="s1">X_32 </span><span class="s2">= </span><span class="s1">X_64</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">)</span>
    <span class="s1">y_32 </span><span class="s2">= </span><span class="s1">y_64</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">)</span>

    <span class="s6"># Check type consistency 32bits</span>
    <span class="s1">ridge_32 </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;cholesky&quot;</span><span class="s2">)</span>
    <span class="s1">ridge_32</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_32</span><span class="s2">, </span><span class="s1">y_32</span><span class="s2">)</span>
    <span class="s1">coef_32 </span><span class="s2">= </span><span class="s1">ridge_32</span><span class="s2">.</span><span class="s1">coef_</span>

    <span class="s6"># Check type consistency 64 bits</span>
    <span class="s1">ridge_64 </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;cholesky&quot;</span><span class="s2">)</span>
    <span class="s1">ridge_64</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_64</span><span class="s2">, </span><span class="s1">y_64</span><span class="s2">)</span>
    <span class="s1">coef_64 </span><span class="s2">= </span><span class="s1">ridge_64</span><span class="s2">.</span><span class="s1">coef_</span>

    <span class="s6"># Do all the checks at once, like this is easier to debug</span>
    <span class="s0">assert </span><span class="s1">coef_32</span><span class="s2">.</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">X_32</span><span class="s2">.</span><span class="s1">dtype</span>
    <span class="s0">assert </span><span class="s1">coef_64</span><span class="s2">.</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">X_64</span><span class="s2">.</span><span class="s1">dtype</span>
    <span class="s0">assert </span><span class="s1">ridge_32</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_32</span><span class="s2">).</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">X_32</span><span class="s2">.</span><span class="s1">dtype</span>
    <span class="s0">assert </span><span class="s1">ridge_64</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_64</span><span class="s2">).</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">X_64</span><span class="s2">.</span><span class="s1">dtype</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">ridge_32</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">ridge_64</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">5</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;solver&quot;</span><span class="s2">, [</span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s3">&quot;cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;lsqr&quot;</span><span class="s2">, </span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;seed&quot;</span><span class="s2">, </span><span class="s1">range</span><span class="s2">(</span><span class="s4">1</span><span class="s2">))</span>
<span class="s0">def </span><span class="s1">test_ridge_regression_dtype_stability</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">seed</span><span class="s2">):</span>
    <span class="s1">random_state </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">seed</span><span class="s2">)</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s4">6</span><span class="s2">, </span><span class="s4">5</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">random_state</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">coef </span><span class="s2">= </span><span class="s1">random_state</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">) + </span><span class="s4">0.01 </span><span class="s2">* </span><span class="s1">random_state</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">1.0</span>
    <span class="s1">positive </span><span class="s2">= </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;lbfgs&quot;</span>
    <span class="s1">results </span><span class="s2">= </span><span class="s1">dict</span><span class="s2">()</span>
    <span class="s6"># XXX: Sparse CG seems to be far less numerically stable than the</span>
    <span class="s6"># others, maybe we should not enable float32 for this one.</span>
    <span class="s1">atol </span><span class="s2">= </span><span class="s4">1e-3 </span><span class="s0">if </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;sparse_cg&quot; </span><span class="s0">else </span><span class="s4">1e-5</span>
    <span class="s0">for </span><span class="s1">current_dtype </span><span class="s0">in </span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">):</span>
        <span class="s1">results</span><span class="s2">[</span><span class="s1">current_dtype</span><span class="s2">] = </span><span class="s1">ridge_regression</span><span class="s2">(</span>
            <span class="s1">X</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">current_dtype</span><span class="s2">),</span>
            <span class="s1">y</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">current_dtype</span><span class="s2">),</span>
            <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
            <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
            <span class="s1">random_state</span><span class="s2">=</span><span class="s1">random_state</span><span class="s2">,</span>
            <span class="s1">sample_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
            <span class="s1">positive</span><span class="s2">=</span><span class="s1">positive</span><span class="s2">,</span>
            <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">500</span><span class="s2">,</span>
            <span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-10</span><span class="s2">,</span>
            <span class="s1">return_n_iter</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
            <span class="s1">return_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">results</span><span class="s2">[</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">].</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span>
    <span class="s0">assert </span><span class="s1">results</span><span class="s2">[</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">].</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">results</span><span class="s2">[</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">], </span><span class="s1">results</span><span class="s2">[</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">], </span><span class="s1">atol</span><span class="s2">=</span><span class="s1">atol</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_ridge_sag_with_X_fortran</span><span class="s2">():</span>
    <span class="s6"># check that Fortran array are converted when using SAG solver</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_regression</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s6"># for the order of X and y to not be C-ordered arrays</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asfortranarray</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[::</span><span class="s4">2</span><span class="s2">, :]</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">y</span><span class="s2">[::</span><span class="s4">2</span><span class="s2">]</span>
    <span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;sag&quot;</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;Classifier, params&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">(</span><span class="s1">RidgeClassifier</span><span class="s2">, {}),</span>
        <span class="s2">(</span><span class="s1">RidgeClassifierCV</span><span class="s2">, {</span><span class="s3">&quot;cv&quot;</span><span class="s2">: </span><span class="s0">None</span><span class="s2">}),</span>
        <span class="s2">(</span><span class="s1">RidgeClassifierCV</span><span class="s2">, {</span><span class="s3">&quot;cv&quot;</span><span class="s2">: </span><span class="s4">3</span><span class="s2">}),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridgeclassifier_multilabel</span><span class="s2">(</span><span class="s1">Classifier</span><span class="s2">, </span><span class="s1">params</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Check that multilabel classification is supported and give meaningful 
    results.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_multilabel_classification</span><span class="s2">(</span><span class="s1">n_classes</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">y</span><span class="s2">.</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">Y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">([</span><span class="s1">y</span><span class="s2">, </span><span class="s1">y</span><span class="s2">], </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">Classifier</span><span class="s2">(**</span><span class="s1">params</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s1">Y_pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">Y_pred</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== </span><span class="s1">Y</span><span class="s2">.</span><span class="s1">shape</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">Y_pred</span><span class="s2">[:, </span><span class="s4">0</span><span class="s2">], </span><span class="s1">Y_pred</span><span class="s2">[:, </span><span class="s4">1</span><span class="s2">])</span>
    <span class="s1">Ridge</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;sag&quot;</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, [</span><span class="s3">&quot;auto&quot;</span><span class="s2">, </span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;alpha&quot;</span><span class="s2">, [</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s4">1e-2</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridge_positive_regression_test</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test that positive Ridge finds true positive coefficients.&quot;&quot;&quot;</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">], [</span><span class="s4">3</span><span class="s2">, </span><span class="s4">4</span><span class="s2">], [</span><span class="s4">5</span><span class="s2">, </span><span class="s4">6</span><span class="s2">], [</span><span class="s4">7</span><span class="s2">, </span><span class="s4">8</span><span class="s2">]])</span>
    <span class="s1">coef </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">10</span><span class="s2">])</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s4">20</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">coef</span><span class="s2">) + </span><span class="s1">intercept</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">coef</span><span class="s2">)</span>

    <span class="s1">model </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">positive</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span>
    <span class="s2">)</span>
    <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_ </span><span class="s2">&gt;= </span><span class="s4">0</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;alpha&quot;</span><span class="s2">, [</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s4">1e-2</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridge_ground_truth_positive_test</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test that Ridge w/wo positive converges to the same solution. 
 
    Ridge with positive=True and positive=False must give the same 
    when the ground truth coefs are all positive. 
    &quot;&quot;&quot;</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s4">300</span><span class="s2">, </span><span class="s4">100</span><span class="s2">)</span>
    <span class="s1">coef </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">uniform</span><span class="s2">(</span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s4">1</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">X </span><span class="s2">@ </span><span class="s1">coef </span><span class="s2">+ </span><span class="s1">intercept</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">X </span><span class="s2">@ </span><span class="s1">coef</span>
    <span class="s1">y </span><span class="s2">+= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]) * </span><span class="s4">0.01</span>

    <span class="s1">results </span><span class="s2">= []</span>
    <span class="s0">for </span><span class="s1">positive </span><span class="s0">in </span><span class="s2">[</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">]:</span>
        <span class="s1">model </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span>
            <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">positive</span><span class="s2">=</span><span class="s1">positive</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-10</span>
        <span class="s2">)</span>
        <span class="s1">results</span><span class="s2">.</span><span class="s1">append</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">).</span><span class="s1">coef_</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(*</span><span class="s1">results</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s4">1e-6</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;solver&quot;</span><span class="s2">, [</span><span class="s3">&quot;svd&quot;</span><span class="s2">, </span><span class="s3">&quot;cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;lsqr&quot;</span><span class="s2">, </span><span class="s3">&quot;sparse_cg&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ridge_positive_error_test</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test input validation for positive argument in Ridge.&quot;&quot;&quot;</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">0.1</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">], [</span><span class="s4">3</span><span class="s2">, </span><span class="s4">4</span><span class="s2">]])</span>
    <span class="s1">coef </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">X </span><span class="s2">@ </span><span class="s1">coef</span>

    <span class="s1">model </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">positive</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;does not support positive&quot;</span><span class="s2">):</span>
        <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;only 'lbfgs' solver can be used&quot;</span><span class="s2">):</span>
        <span class="s1">_</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">= </span><span class="s1">ridge_regression</span><span class="s2">(</span>
            <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">positive</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">return_intercept</span><span class="s2">=</span><span class="s0">False</span>
        <span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;alpha&quot;</span><span class="s2">, [</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s4">1e-2</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_positive_ridge_loss</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Check ridge loss consistency when positive argument is enabled.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_regression</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">300</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s4">300</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">0.10</span>
    <span class="s1">n_checks </span><span class="s2">= </span><span class="s4">100</span>

    <span class="s0">def </span><span class="s1">ridge_loss</span><span class="s2">(</span><span class="s1">model</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">noise_scale</span><span class="s2">=</span><span class="s4">1e-8</span><span class="s2">):</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s1">model</span><span class="s2">.</span><span class="s1">intercept_</span>
        <span class="s0">if </span><span class="s1">random_state </span><span class="s0">is not None</span><span class="s2">:</span>
            <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">)</span>
            <span class="s1">coef </span><span class="s2">= </span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_ </span><span class="s2">+ </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">uniform</span><span class="s2">(</span><span class="s4">0</span><span class="s2">, </span><span class="s1">noise_scale</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">)</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">coef </span><span class="s2">= </span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span>

        <span class="s0">return </span><span class="s4">0.5 </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">((</span><span class="s1">y </span><span class="s2">- </span><span class="s1">X </span><span class="s2">@ </span><span class="s1">coef </span><span class="s2">- </span><span class="s1">intercept</span><span class="s2">) ** </span><span class="s4">2</span><span class="s2">) + </span><span class="s4">0.5 </span><span class="s2">* </span><span class="s1">alpha </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span>
            <span class="s1">coef</span><span class="s2">**</span><span class="s4">2</span>
        <span class="s2">)</span>

    <span class="s1">model </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">model_positive </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">positive</span><span class="s2">=</span><span class="s0">True</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s6"># Check 1:</span>
    <span class="s6">#   Loss for solution found by Ridge(positive=False)</span>
    <span class="s6">#   is lower than that for solution found by Ridge(positive=True)</span>
    <span class="s1">loss </span><span class="s2">= </span><span class="s1">ridge_loss</span><span class="s2">(</span><span class="s1">model</span><span class="s2">)</span>
    <span class="s1">loss_positive </span><span class="s2">= </span><span class="s1">ridge_loss</span><span class="s2">(</span><span class="s1">model_positive</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">loss </span><span class="s2">&lt;= </span><span class="s1">loss_positive</span>

    <span class="s6"># Check 2:</span>
    <span class="s6">#   Loss for solution found by Ridge(positive=True)</span>
    <span class="s6">#   is lower than that for small random positive perturbation</span>
    <span class="s6">#   of the positive solution.</span>
    <span class="s0">for </span><span class="s1">random_state </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s1">n_checks</span><span class="s2">):</span>
        <span class="s1">loss_perturbed </span><span class="s2">= </span><span class="s1">ridge_loss</span><span class="s2">(</span><span class="s1">model_positive</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">random_state</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">loss_positive </span><span class="s2">&lt;= </span><span class="s1">loss_perturbed</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;alpha&quot;</span><span class="s2">, [</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s4">1e-2</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_lbfgs_solver_consistency</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test that LBGFS gets almost the same coef of svd when positive=False.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_regression</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">300</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s4">300</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">expand_dims</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">([</span><span class="s1">alpha</span><span class="s2">])</span>
    <span class="s1">config </span><span class="s2">= {</span>
        <span class="s3">&quot;positive&quot;</span><span class="s2">: </span><span class="s0">False</span><span class="s2">,</span>
        <span class="s3">&quot;tol&quot;</span><span class="s2">: </span><span class="s4">1e-16</span><span class="s2">,</span>
        <span class="s3">&quot;max_iter&quot;</span><span class="s2">: </span><span class="s4">500000</span><span class="s2">,</span>
    <span class="s2">}</span>

    <span class="s1">coef_lbfgs </span><span class="s2">= </span><span class="s1">_solve_lbfgs</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, **</span><span class="s1">config</span><span class="s2">)</span>
    <span class="s1">coef_cholesky </span><span class="s2">= </span><span class="s1">_solve_svd</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">coef_lbfgs</span><span class="s2">, </span><span class="s1">coef_cholesky</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s4">1e-4</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_lbfgs_solver_error</span><span class="s2">():</span>
    <span class="s5">&quot;&quot;&quot;Test that LBFGS solver raises ConvergenceWarning.&quot;&quot;&quot;</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">], [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]])</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([-</span><span class="s4">1e10</span><span class="s2">, </span><span class="s4">1e10</span><span class="s2">])</span>

    <span class="s1">model </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-12</span><span class="s2">,</span>
        <span class="s1">positive</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">ConvergenceWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;lbfgs solver did not converge&quot;</span><span class="s2">):</span>
        <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, [</span><span class="s0">False</span><span class="s2">, </span><span class="s0">True</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;sparse_container&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">] + </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;data&quot;</span><span class="s2">, [</span><span class="s3">&quot;tall&quot;</span><span class="s2">, </span><span class="s3">&quot;wide&quot;</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">SOLVERS </span><span class="s2">+ [</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_ridge_sample_weight_consistency</span><span class="s2">(</span>
    <span class="s1">fit_intercept</span><span class="s2">, </span><span class="s1">sparse_container</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">, </span><span class="s1">global_random_seed</span>
<span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test that the impact of sample_weight is consistent. 
 
    Note that this test is stricter than the common test 
    check_sample_weights_invariance alone. 
    &quot;&quot;&quot;</span>
    <span class="s6"># filter out solver that do not support sparse input</span>
    <span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is not None</span><span class="s2">:</span>
        <span class="s0">if </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;svd&quot; </span><span class="s0">or </span><span class="s2">(</span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">) </span><span class="s0">and </span><span class="s1">fit_intercept</span><span class="s2">):</span>
            <span class="s1">pytest</span><span class="s2">.</span><span class="s1">skip</span><span class="s2">(</span><span class="s3">&quot;unsupported configuration&quot;</span><span class="s2">)</span>

    <span class="s6"># XXX: this test is quite sensitive to the seed used to generate the data:</span>
    <span class="s6"># ideally we would like the test to pass for any global_random_seed but this is not</span>
    <span class="s6"># the case at the moment.</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">12</span>
    <span class="s0">if </span><span class="s1">data </span><span class="s2">== </span><span class="s3">&quot;tall&quot;</span><span class="s2">:</span>
        <span class="s1">n_features </span><span class="s2">= </span><span class="s1">n_samples </span><span class="s2">// </span><span class="s4">2</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">n_features </span><span class="s2">= </span><span class="s1">n_samples </span><span class="s2">* </span><span class="s4">2</span>

    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">rand</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">rand</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is not None</span><span class="s2">:</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">params </span><span class="s2">= </span><span class="s1">dict</span><span class="s2">(</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">1.0</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
        <span class="s1">positive</span><span class="s2">=(</span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">),</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,  </span><span class="s6"># for sag/saga</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-12</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s6"># 1) sample_weight=np.ones(..) should be equivalent to sample_weight=None</span>
    <span class="s6"># same check as check_sample_weights_invariance(name, reg, kind=&quot;ones&quot;), but we also</span>
    <span class="s6"># test with sparse input.</span>
    <span class="s1">reg </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(**</span><span class="s1">params</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">)</span>
    <span class="s1">coef </span><span class="s2">= </span><span class="s1">reg</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">()</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s1">reg</span><span class="s2">.</span><span class="s1">intercept_</span>
    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones_like</span><span class="s2">(</span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-6</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">intercept</span><span class="s2">)</span>

    <span class="s6"># 2) setting elements of sample_weight to 0 is equivalent to removing these samples</span>
    <span class="s6"># same check as check_sample_weights_invariance(name, reg, kind=&quot;zeros&quot;), but we</span>
    <span class="s6"># also test with sparse input</span>
    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">uniform</span><span class="s2">(</span><span class="s1">low</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">high</span><span class="s2">=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>
    <span class="s1">sample_weight</span><span class="s2">[-</span><span class="s4">5</span><span class="s2">:] = </span><span class="s4">0</span>
    <span class="s1">y</span><span class="s2">[-</span><span class="s4">5</span><span class="s2">:] *= </span><span class="s4">1000  </span><span class="s6"># to make excluding those samples important</span>
    <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>
    <span class="s1">coef </span><span class="s2">= </span><span class="s1">reg</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">()</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">intercept </span><span class="s2">= </span><span class="s1">reg</span><span class="s2">.</span><span class="s1">intercept_</span>
    <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[:-</span><span class="s4">5</span><span class="s2">, :], </span><span class="s1">y</span><span class="s2">[:-</span><span class="s4">5</span><span class="s2">], </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">[:-</span><span class="s4">5</span><span class="s2">])</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-6</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">intercept</span><span class="s2">)</span>

    <span class="s6"># 3) scaling of sample_weight should have no effect</span>
    <span class="s6"># Note: For models with penalty, scaling the penalty term might work.</span>
    <span class="s1">reg2 </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(**</span><span class="s1">params</span><span class="s2">).</span><span class="s1">set_params</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">pi </span><span class="s2">* </span><span class="s1">params</span><span class="s2">[</span><span class="s3">&quot;alpha&quot;</span><span class="s2">])</span>
    <span class="s1">reg2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">pi </span><span class="s2">* </span><span class="s1">sample_weight</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">) </span><span class="s0">and not </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">pytest</span><span class="s2">.</span><span class="s1">xfail</span><span class="s2">(</span><span class="s3">f&quot;Solver </span><span class="s0">{</span><span class="s1">solver</span><span class="s0">} </span><span class="s3">does fail test for scaling of sample_weight.&quot;</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">reg2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-6</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">reg2</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">intercept</span><span class="s2">)</span>

    <span class="s6"># 4) check that multiplying sample_weight by 2 is equivalent</span>
    <span class="s6"># to repeating corresponding samples twice</span>
    <span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is not None</span><span class="s2">:</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">toarray</span><span class="s2">()</span>
    <span class="s1">X2 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">([</span><span class="s1">X</span><span class="s2">, </span><span class="s1">X</span><span class="s2">[: </span><span class="s1">n_samples </span><span class="s2">// </span><span class="s4">2</span><span class="s2">]], </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">y2 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">([</span><span class="s1">y</span><span class="s2">, </span><span class="s1">y</span><span class="s2">[: </span><span class="s1">n_samples </span><span class="s2">// </span><span class="s4">2</span><span class="s2">]])</span>
    <span class="s1">sample_weight_1 </span><span class="s2">= </span><span class="s1">sample_weight</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">()</span>
    <span class="s1">sample_weight_1</span><span class="s2">[: </span><span class="s1">n_samples </span><span class="s2">// </span><span class="s4">2</span><span class="s2">] *= </span><span class="s4">2</span>
    <span class="s1">sample_weight_2 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">(</span>
        <span class="s2">[</span><span class="s1">sample_weight</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">[: </span><span class="s1">n_samples </span><span class="s2">// </span><span class="s4">2</span><span class="s2">]], </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span>
    <span class="s2">)</span>
    <span class="s0">if </span><span class="s1">sparse_container </span><span class="s0">is not None</span><span class="s2">:</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s1">X2 </span><span class="s2">= </span><span class="s1">sparse_container</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">)</span>
    <span class="s1">reg1 </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(**</span><span class="s1">params</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight_1</span><span class="s2">)</span>
    <span class="s1">reg2 </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">(**</span><span class="s1">params</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">y2</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight_2</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">reg1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">reg2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">reg1</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">reg2</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">)</span>


<span class="s6"># TODO(1.7): Remove</span>
<span class="s0">def </span><span class="s1">test_ridge_store_cv_values_deprecated</span><span class="s2">():</span>
    <span class="s5">&quot;&quot;&quot;Check `store_cv_values` parameter deprecated.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_regression</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">6</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">store_cv_values</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;'store_cv_values' is deprecated&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">FutureWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s6"># Error when both set</span>
    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">store_cv_results</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">store_cv_values</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Both 'store_cv_values' and 'store_cv_results' were&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_ridge_cv_values_deprecated</span><span class="s2">():</span>
    <span class="s5">&quot;&quot;&quot;Check `cv_values_` deprecated.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_regression</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">6</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">ridge </span><span class="s2">= </span><span class="s1">RidgeCV</span><span class="s2">(</span><span class="s1">store_cv_results</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Attribute `cv_values_` is deprecated&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">FutureWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">ridge</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s1">ridge</span><span class="s2">.</span><span class="s1">cv_values_</span>


<span class="s6"># Metadata Routing Tests</span>
<span class="s6"># ======================</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">usefixtures</span><span class="s2">(</span><span class="s3">&quot;enable_slep006&quot;</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;metaestimator&quot;</span><span class="s2">, [</span><span class="s1">RidgeCV</span><span class="s2">, </span><span class="s1">RidgeClassifierCV</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_metadata_routing_with_default_scoring</span><span class="s2">(</span><span class="s1">metaestimator</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test that `RidgeCV` or `RidgeClassifierCV` with default `scoring` 
    argument (`None`), don't enter into `RecursionError` when metadata is routed. 
    &quot;&quot;&quot;</span>
    <span class="s1">metaestimator</span><span class="s2">().</span><span class="s1">get_metadata_routing</span><span class="s2">()</span>


<span class="s6"># End of Metadata Routing Tests</span>
<span class="s6"># =============================</span>
</pre>
</body>
</html>