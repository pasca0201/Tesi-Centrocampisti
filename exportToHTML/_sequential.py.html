<html>
<head>
<title>_sequential.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #cf8e6d;}
.s3 { color: #bcbec4;}
.s4 { color: #6aab73;}
.s5 { color: #2aacb8;}
.s6 { color: #7a7e85;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_sequential.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Sequential feature selection 
&quot;&quot;&quot;</span>

<span class="s2">from </span><span class="s1">numbers </span><span class="s2">import </span><span class="s1">Integral</span><span class="s3">, </span><span class="s1">Real</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">from </span><span class="s3">..</span><span class="s1">base </span><span class="s2">import </span><span class="s1">BaseEstimator</span><span class="s3">, </span><span class="s1">MetaEstimatorMixin</span><span class="s3">, </span><span class="s1">_fit_context</span><span class="s3">, </span><span class="s1">clone</span><span class="s3">, </span><span class="s1">is_classifier</span>
<span class="s2">from </span><span class="s3">..</span><span class="s1">metrics </span><span class="s2">import </span><span class="s1">get_scorer_names</span>
<span class="s2">from </span><span class="s3">..</span><span class="s1">model_selection </span><span class="s2">import </span><span class="s1">check_cv</span><span class="s3">, </span><span class="s1">cross_val_score</span>
<span class="s2">from </span><span class="s3">..</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">_param_validation </span><span class="s2">import </span><span class="s1">HasMethods</span><span class="s3">, </span><span class="s1">Interval</span><span class="s3">, </span><span class="s1">RealNotInt</span><span class="s3">, </span><span class="s1">StrOptions</span>
<span class="s2">from </span><span class="s3">..</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">_tags </span><span class="s2">import </span><span class="s1">_safe_tags</span>
<span class="s2">from </span><span class="s3">..</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">metadata_routing </span><span class="s2">import </span><span class="s1">_RoutingNotSupportedMixin</span>
<span class="s2">from </span><span class="s3">..</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">validation </span><span class="s2">import </span><span class="s1">check_is_fitted</span>
<span class="s2">from </span><span class="s3">.</span><span class="s1">_base </span><span class="s2">import </span><span class="s1">SelectorMixin</span>


<span class="s2">class </span><span class="s1">SequentialFeatureSelector</span><span class="s3">(</span>
    <span class="s1">_RoutingNotSupportedMixin</span><span class="s3">, </span><span class="s1">SelectorMixin</span><span class="s3">, </span><span class="s1">MetaEstimatorMixin</span><span class="s3">, </span><span class="s1">BaseEstimator</span>
<span class="s3">):</span>
    <span class="s0">&quot;&quot;&quot;Transformer that performs Sequential Feature Selection. 
 
    This Sequential Feature Selector adds (forward selection) or 
    removes (backward selection) features to form a feature subset in a 
    greedy fashion. At each stage, this estimator chooses the best feature to 
    add or remove based on the cross-validation score of an estimator. In 
    the case of unsupervised learning, this Sequential Feature Selector 
    looks only at the features (X), not the desired outputs (y). 
 
    Read more in the :ref:`User Guide &lt;sequential_feature_selection&gt;`. 
 
    .. versionadded:: 0.24 
 
    Parameters 
    ---------- 
    estimator : estimator instance 
        An unfitted estimator. 
 
    n_features_to_select : &quot;auto&quot;, int or float, default=&quot;auto&quot; 
        If `&quot;auto&quot;`, the behaviour depends on the `tol` parameter: 
 
        - if `tol` is not `None`, then features are selected while the score 
          change does not exceed `tol`. 
        - otherwise, half of the features are selected. 
 
        If integer, the parameter is the absolute number of features to select. 
        If float between 0 and 1, it is the fraction of features to select. 
 
        .. versionadded:: 1.1 
           The option `&quot;auto&quot;` was added in version 1.1. 
 
        .. versionchanged:: 1.3 
           The default changed from `&quot;warn&quot;` to `&quot;auto&quot;` in 1.3. 
 
    tol : float, default=None 
        If the score is not incremented by at least `tol` between two 
        consecutive feature additions or removals, stop adding or removing. 
 
        `tol` can be negative when removing features using `direction=&quot;backward&quot;`. 
        `tol` is required to be strictly positive when doing forward selection. 
        It can be useful to reduce the number of features at the cost of a small 
        decrease in the score. 
 
        `tol` is enabled only when `n_features_to_select` is `&quot;auto&quot;`. 
 
        .. versionadded:: 1.1 
 
    direction : {'forward', 'backward'}, default='forward' 
        Whether to perform forward selection or backward selection. 
 
    scoring : str or callable, default=None 
        A single str (see :ref:`scoring_parameter`) or a callable 
        (see :ref:`scoring`) to evaluate the predictions on the test set. 
 
        NOTE that when using a custom scorer, it should return a single 
        value. 
 
        If None, the estimator's score method is used. 
 
    cv : int, cross-validation generator or an iterable, default=None 
        Determines the cross-validation splitting strategy. 
        Possible inputs for cv are: 
 
        - None, to use the default 5-fold cross validation, 
        - integer, to specify the number of folds in a `(Stratified)KFold`, 
        - :term:`CV splitter`, 
        - An iterable yielding (train, test) splits as arrays of indices. 
 
        For integer/None inputs, if the estimator is a classifier and ``y`` is 
        either binary or multiclass, 
        :class:`~sklearn.model_selection.StratifiedKFold` is used. In all other 
        cases, :class:`~sklearn.model_selection.KFold` is used. These splitters 
        are instantiated with `shuffle=False` so the splits will be the same 
        across calls. 
 
        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various 
        cross-validation strategies that can be used here. 
 
    n_jobs : int, default=None 
        Number of jobs to run in parallel. When evaluating a new feature to 
        add or remove, the cross-validation procedure is parallel over the 
        folds. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    Attributes 
    ---------- 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. Only defined if the 
        underlying estimator exposes such an attribute when fit. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    n_features_to_select_ : int 
        The number of features that were selected. 
 
    support_ : ndarray of shape (n_features,), dtype=bool 
        The mask of selected features. 
 
    See Also 
    -------- 
    GenericUnivariateSelect : Univariate feature selector with configurable 
        strategy. 
    RFE : Recursive feature elimination based on importance weights. 
    RFECV : Recursive feature elimination based on importance weights, with 
        automatic selection of the number of features. 
    SelectFromModel : Feature selection based on thresholds of importance 
        weights. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.feature_selection import SequentialFeatureSelector 
    &gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier 
    &gt;&gt;&gt; from sklearn.datasets import load_iris 
    &gt;&gt;&gt; X, y = load_iris(return_X_y=True) 
    &gt;&gt;&gt; knn = KNeighborsClassifier(n_neighbors=3) 
    &gt;&gt;&gt; sfs = SequentialFeatureSelector(knn, n_features_to_select=3) 
    &gt;&gt;&gt; sfs.fit(X, y) 
    SequentialFeatureSelector(estimator=KNeighborsClassifier(n_neighbors=3), 
                              n_features_to_select=3) 
    &gt;&gt;&gt; sfs.get_support() 
    array([ True, False,  True,  True]) 
    &gt;&gt;&gt; sfs.transform(X).shape 
    (150, 3) 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s3">: </span><span class="s1">dict </span><span class="s3">= {</span>
        <span class="s4">&quot;estimator&quot;</span><span class="s3">: [</span><span class="s1">HasMethods</span><span class="s3">([</span><span class="s4">&quot;fit&quot;</span><span class="s3">])],</span>
        <span class="s4">&quot;n_features_to_select&quot;</span><span class="s3">: [</span>
            <span class="s1">StrOptions</span><span class="s3">({</span><span class="s4">&quot;auto&quot;</span><span class="s3">}),</span>
            <span class="s1">Interval</span><span class="s3">(</span><span class="s1">RealNotInt</span><span class="s3">, </span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s1">closed</span><span class="s3">=</span><span class="s4">&quot;right&quot;</span><span class="s3">),</span>
            <span class="s1">Interval</span><span class="s3">(</span><span class="s1">Integral</span><span class="s3">, </span><span class="s5">0</span><span class="s3">, </span><span class="s2">None</span><span class="s3">, </span><span class="s1">closed</span><span class="s3">=</span><span class="s4">&quot;neither&quot;</span><span class="s3">),</span>
        <span class="s3">],</span>
        <span class="s4">&quot;tol&quot;</span><span class="s3">: [</span><span class="s2">None</span><span class="s3">, </span><span class="s1">Interval</span><span class="s3">(</span><span class="s1">Real</span><span class="s3">, </span><span class="s2">None</span><span class="s3">, </span><span class="s2">None</span><span class="s3">, </span><span class="s1">closed</span><span class="s3">=</span><span class="s4">&quot;neither&quot;</span><span class="s3">)],</span>
        <span class="s4">&quot;direction&quot;</span><span class="s3">: [</span><span class="s1">StrOptions</span><span class="s3">({</span><span class="s4">&quot;forward&quot;</span><span class="s3">, </span><span class="s4">&quot;backward&quot;</span><span class="s3">})],</span>
        <span class="s4">&quot;scoring&quot;</span><span class="s3">: [</span><span class="s2">None</span><span class="s3">, </span><span class="s1">StrOptions</span><span class="s3">(</span><span class="s1">set</span><span class="s3">(</span><span class="s1">get_scorer_names</span><span class="s3">())), </span><span class="s1">callable</span><span class="s3">],</span>
        <span class="s4">&quot;cv&quot;</span><span class="s3">: [</span><span class="s4">&quot;cv_object&quot;</span><span class="s3">],</span>
        <span class="s4">&quot;n_jobs&quot;</span><span class="s3">: [</span><span class="s2">None</span><span class="s3">, </span><span class="s1">Integral</span><span class="s3">],</span>
    <span class="s3">}</span>

    <span class="s2">def </span><span class="s1">__init__</span><span class="s3">(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">estimator</span><span class="s3">,</span>
        <span class="s3">*,</span>
        <span class="s1">n_features_to_select</span><span class="s3">=</span><span class="s4">&quot;auto&quot;</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
        <span class="s1">direction</span><span class="s3">=</span><span class="s4">&quot;forward&quot;</span><span class="s3">,</span>
        <span class="s1">scoring</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
        <span class="s1">cv</span><span class="s3">=</span><span class="s5">5</span><span class="s3">,</span>
        <span class="s1">n_jobs</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
    <span class="s3">):</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">estimator </span><span class="s3">= </span><span class="s1">estimator</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select </span><span class="s3">= </span><span class="s1">n_features_to_select</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">tol </span><span class="s3">= </span><span class="s1">tol</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">direction </span><span class="s3">= </span><span class="s1">direction</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">scoring </span><span class="s3">= </span><span class="s1">scoring</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">cv </span><span class="s3">= </span><span class="s1">cv</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">n_jobs </span><span class="s3">= </span><span class="s1">n_jobs</span>

    <span class="s3">@</span><span class="s1">_fit_context</span><span class="s3">(</span>
        <span class="s6"># SequentialFeatureSelector.estimator is not validated yet</span>
        <span class="s1">prefer_skip_nested_validation</span><span class="s3">=</span><span class="s2">False</span>
    <span class="s3">)</span>
    <span class="s2">def </span><span class="s1">fit</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">=</span><span class="s2">None</span><span class="s3">):</span>
        <span class="s0">&quot;&quot;&quot;Learn the features to select from X. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Training vectors, where `n_samples` is the number of samples and 
            `n_features` is the number of predictors. 
 
        y : array-like of shape (n_samples,), default=None 
            Target values. This parameter may be ignored for 
            unsupervised learning. 
 
        Returns 
        ------- 
        self : object 
            Returns the instance itself. 
        &quot;&quot;&quot;</span>
        <span class="s1">tags </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_get_tags</span><span class="s3">()</span>
        <span class="s1">X </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_validate_data</span><span class="s3">(</span>
            <span class="s1">X</span><span class="s3">,</span>
            <span class="s1">accept_sparse</span><span class="s3">=</span><span class="s4">&quot;csc&quot;</span><span class="s3">,</span>
            <span class="s1">ensure_min_features</span><span class="s3">=</span><span class="s5">2</span><span class="s3">,</span>
            <span class="s1">force_all_finite</span><span class="s3">=</span><span class="s2">not </span><span class="s1">tags</span><span class="s3">.</span><span class="s1">get</span><span class="s3">(</span><span class="s4">&quot;allow_nan&quot;</span><span class="s3">, </span><span class="s2">True</span><span class="s3">),</span>
        <span class="s3">)</span>
        <span class="s1">n_features </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">1</span><span class="s3">]</span>

        <span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select </span><span class="s3">== </span><span class="s4">&quot;auto&quot;</span><span class="s3">:</span>
            <span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">tol </span><span class="s2">is not None</span><span class="s3">:</span>
                <span class="s6"># With auto feature selection, `n_features_to_select_` will be updated</span>
                <span class="s6"># to `support_.sum()` after features are selected.</span>
                <span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select_ </span><span class="s3">= </span><span class="s1">n_features </span><span class="s3">- </span><span class="s5">1</span>
            <span class="s2">else</span><span class="s3">:</span>
                <span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select_ </span><span class="s3">= </span><span class="s1">n_features </span><span class="s3">// </span><span class="s5">2</span>
        <span class="s2">elif </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select</span><span class="s3">, </span><span class="s1">Integral</span><span class="s3">):</span>
            <span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select </span><span class="s3">&gt;= </span><span class="s1">n_features</span><span class="s3">:</span>
                <span class="s2">raise </span><span class="s1">ValueError</span><span class="s3">(</span><span class="s4">&quot;n_features_to_select must be &lt; n_features.&quot;</span><span class="s3">)</span>
            <span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select_ </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select</span>
        <span class="s2">elif </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select</span><span class="s3">, </span><span class="s1">Real</span><span class="s3">):</span>
            <span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select_ </span><span class="s3">= </span><span class="s1">int</span><span class="s3">(</span><span class="s1">n_features </span><span class="s3">* </span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select</span><span class="s3">)</span>

        <span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">tol </span><span class="s2">is not None and </span><span class="s1">self</span><span class="s3">.</span><span class="s1">tol </span><span class="s3">&lt; </span><span class="s5">0 </span><span class="s2">and </span><span class="s1">self</span><span class="s3">.</span><span class="s1">direction </span><span class="s3">== </span><span class="s4">&quot;forward&quot;</span><span class="s3">:</span>
            <span class="s2">raise </span><span class="s1">ValueError</span><span class="s3">(</span>
                <span class="s4">&quot;tol must be strictly positive when doing forward selection&quot;</span>
            <span class="s3">)</span>

        <span class="s1">cv </span><span class="s3">= </span><span class="s1">check_cv</span><span class="s3">(</span><span class="s1">self</span><span class="s3">.</span><span class="s1">cv</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">classifier</span><span class="s3">=</span><span class="s1">is_classifier</span><span class="s3">(</span><span class="s1">self</span><span class="s3">.</span><span class="s1">estimator</span><span class="s3">))</span>

        <span class="s1">cloned_estimator </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">self</span><span class="s3">.</span><span class="s1">estimator</span><span class="s3">)</span>

        <span class="s6"># the current mask corresponds to the set of features:</span>
        <span class="s6"># - that we have already *selected* if we do forward selection</span>
        <span class="s6"># - that we have already *excluded* if we do backward selection</span>
        <span class="s1">current_mask </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">shape</span><span class="s3">=</span><span class="s1">n_features</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">bool</span><span class="s3">)</span>
        <span class="s1">n_iterations </span><span class="s3">= (</span>
            <span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select_</span>
            <span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select </span><span class="s3">== </span><span class="s4">&quot;auto&quot; </span><span class="s2">or </span><span class="s1">self</span><span class="s3">.</span><span class="s1">direction </span><span class="s3">== </span><span class="s4">&quot;forward&quot;</span>
            <span class="s2">else </span><span class="s1">n_features </span><span class="s3">- </span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select_</span>
        <span class="s3">)</span>

        <span class="s1">old_score </span><span class="s3">= -</span><span class="s1">np</span><span class="s3">.</span><span class="s1">inf</span>
        <span class="s1">is_auto_select </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">tol </span><span class="s2">is not None and </span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select </span><span class="s3">== </span><span class="s4">&quot;auto&quot;</span>
        <span class="s2">for </span><span class="s1">_ </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">n_iterations</span><span class="s3">):</span>
            <span class="s1">new_feature_idx</span><span class="s3">, </span><span class="s1">new_score </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_get_best_new_feature_score</span><span class="s3">(</span>
                <span class="s1">cloned_estimator</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">, </span><span class="s1">current_mask</span>
            <span class="s3">)</span>
            <span class="s2">if </span><span class="s1">is_auto_select </span><span class="s2">and </span><span class="s3">((</span><span class="s1">new_score </span><span class="s3">- </span><span class="s1">old_score</span><span class="s3">) &lt; </span><span class="s1">self</span><span class="s3">.</span><span class="s1">tol</span><span class="s3">):</span>
                <span class="s2">break</span>

            <span class="s1">old_score </span><span class="s3">= </span><span class="s1">new_score</span>
            <span class="s1">current_mask</span><span class="s3">[</span><span class="s1">new_feature_idx</span><span class="s3">] = </span><span class="s2">True</span>

        <span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">direction </span><span class="s3">== </span><span class="s4">&quot;backward&quot;</span><span class="s3">:</span>
            <span class="s1">current_mask </span><span class="s3">= ~</span><span class="s1">current_mask</span>

        <span class="s1">self</span><span class="s3">.</span><span class="s1">support_ </span><span class="s3">= </span><span class="s1">current_mask</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">n_features_to_select_ </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">support_</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">()</span>

        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">_get_best_new_feature_score</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">estimator</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">, </span><span class="s1">current_mask</span><span class="s3">):</span>
        <span class="s6"># Return the best new feature and its score to add to the current_mask,</span>
        <span class="s6"># i.e. return the best new feature and its score to add (resp. remove)</span>
        <span class="s6"># when doing forward selection (resp. backward selection).</span>
        <span class="s6"># Feature will be added if the current score and past score are greater</span>
        <span class="s6"># than tol when n_feature is auto,</span>
        <span class="s1">candidate_feature_indices </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">flatnonzero</span><span class="s3">(~</span><span class="s1">current_mask</span><span class="s3">)</span>
        <span class="s1">scores </span><span class="s3">= {}</span>
        <span class="s2">for </span><span class="s1">feature_idx </span><span class="s2">in </span><span class="s1">candidate_feature_indices</span><span class="s3">:</span>
            <span class="s1">candidate_mask </span><span class="s3">= </span><span class="s1">current_mask</span><span class="s3">.</span><span class="s1">copy</span><span class="s3">()</span>
            <span class="s1">candidate_mask</span><span class="s3">[</span><span class="s1">feature_idx</span><span class="s3">] = </span><span class="s2">True</span>
            <span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">direction </span><span class="s3">== </span><span class="s4">&quot;backward&quot;</span><span class="s3">:</span>
                <span class="s1">candidate_mask </span><span class="s3">= ~</span><span class="s1">candidate_mask</span>
            <span class="s1">X_new </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[:, </span><span class="s1">candidate_mask</span><span class="s3">]</span>
            <span class="s1">scores</span><span class="s3">[</span><span class="s1">feature_idx</span><span class="s3">] = </span><span class="s1">cross_val_score</span><span class="s3">(</span>
                <span class="s1">estimator</span><span class="s3">,</span>
                <span class="s1">X_new</span><span class="s3">,</span>
                <span class="s1">y</span><span class="s3">,</span>
                <span class="s1">cv</span><span class="s3">=</span><span class="s1">cv</span><span class="s3">,</span>
                <span class="s1">scoring</span><span class="s3">=</span><span class="s1">self</span><span class="s3">.</span><span class="s1">scoring</span><span class="s3">,</span>
                <span class="s1">n_jobs</span><span class="s3">=</span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_jobs</span><span class="s3">,</span>
            <span class="s3">).</span><span class="s1">mean</span><span class="s3">()</span>
        <span class="s1">new_feature_idx </span><span class="s3">= </span><span class="s1">max</span><span class="s3">(</span><span class="s1">scores</span><span class="s3">, </span><span class="s1">key</span><span class="s3">=</span><span class="s2">lambda </span><span class="s1">feature_idx</span><span class="s3">: </span><span class="s1">scores</span><span class="s3">[</span><span class="s1">feature_idx</span><span class="s3">])</span>
        <span class="s2">return </span><span class="s1">new_feature_idx</span><span class="s3">, </span><span class="s1">scores</span><span class="s3">[</span><span class="s1">new_feature_idx</span><span class="s3">]</span>

    <span class="s2">def </span><span class="s1">_get_support_mask</span><span class="s3">(</span><span class="s1">self</span><span class="s3">):</span>
        <span class="s1">check_is_fitted</span><span class="s3">(</span><span class="s1">self</span><span class="s3">)</span>
        <span class="s2">return </span><span class="s1">self</span><span class="s3">.</span><span class="s1">support_</span>

    <span class="s2">def </span><span class="s1">_more_tags</span><span class="s3">(</span><span class="s1">self</span><span class="s3">):</span>
        <span class="s2">return </span><span class="s3">{</span>
            <span class="s4">&quot;allow_nan&quot;</span><span class="s3">: </span><span class="s1">_safe_tags</span><span class="s3">(</span><span class="s1">self</span><span class="s3">.</span><span class="s1">estimator</span><span class="s3">, </span><span class="s1">key</span><span class="s3">=</span><span class="s4">&quot;allow_nan&quot;</span><span class="s3">),</span>
        <span class="s3">}</span>
</pre>
</body>
</html>