<html>
<head>
<title>_argkmin.pyx.tp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #bcbec4;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_argkmin.pyx.tp</font>
</center></td></tr></table>
<pre><span class="s0">from libc.stdlib cimport free, malloc</span>
<span class="s0">from libc.float cimport DBL_MAX</span>
<span class="s0">from cython cimport final</span>
<span class="s0">from cython.parallel cimport parallel, prange</span>

<span class="s0">from ...utils._heap cimport heap_push</span>
<span class="s0">from ...utils._sorting cimport simultaneous_sort</span>
<span class="s0">from ...utils._typedefs cimport intp_t, float64_t</span>

<span class="s0">import numpy as np</span>
<span class="s0">import warnings</span>

<span class="s0">from numbers import Integral</span>
<span class="s0">from scipy.sparse import issparse</span>
<span class="s0">from ...utils import check_array, check_scalar</span>
<span class="s0">from ...utils.fixes import _in_unstable_openblas_configuration</span>
<span class="s0">from ...utils.parallel import _get_threadpool_controller</span>

<span class="s0">{{for name_suffix in ['64', '32']}}</span>

<span class="s0">from ._base cimport (</span>
    <span class="s0">BaseDistancesReduction{{name_suffix}},</span>
    <span class="s0">_sqeuclidean_row_norms{{name_suffix}},</span>
<span class="s0">)</span>

<span class="s0">from ._datasets_pair cimport DatasetsPair{{name_suffix}}</span>

<span class="s0">from ._middle_term_computer cimport MiddleTermComputer{{name_suffix}}</span>


<span class="s0">cdef class ArgKmin{{name_suffix}}(BaseDistancesReduction{{name_suffix}}):</span>
    <span class="s0">&quot;&quot;&quot;float{{name_suffix}} implementation of the ArgKmin.&quot;&quot;&quot;</span>

    <span class="s0">@classmethod</span>
    <span class="s0">def compute(</span>
        <span class="s0">cls,</span>
        <span class="s0">X,</span>
        <span class="s0">Y,</span>
        <span class="s0">intp_t k,</span>
        <span class="s0">metric=&quot;euclidean&quot;,</span>
        <span class="s0">chunk_size=None,</span>
        <span class="s0">dict metric_kwargs=None,</span>
        <span class="s0">str strategy=None,</span>
        <span class="s0">bint return_distance=False,</span>
    <span class="s0">):</span>
        <span class="s0">&quot;&quot;&quot;Compute the argkmin reduction.</span>

        <span class="s0">This classmethod is responsible for introspecting the arguments</span>
        <span class="s0">values to dispatch to the most appropriate implementation of</span>
        <span class="s0">:class:`ArgKmin{{name_suffix}}`.</span>

        <span class="s0">This allows decoupling the API entirely from the implementation details</span>
        <span class="s0">whilst maintaining RAII: all temporarily allocated datastructures necessary</span>
        <span class="s0">for the concrete implementation are therefore freed when this classmethod</span>
        <span class="s0">returns.</span>

        <span class="s0">No instance should directly be created outside of this class method.</span>
        <span class="s0">&quot;&quot;&quot;</span>
        <span class="s0"># Limit the number of threads in second level of nested parallelism for BLAS</span>
        <span class="s0"># to avoid threads over-subscription (in DOT or GEMM for instance).</span>
        <span class="s0">with _get_threadpool_controller().limit(limits=1, user_api='blas'):</span>
          <span class="s0">if metric in (&quot;euclidean&quot;, &quot;sqeuclidean&quot;):</span>
              <span class="s0"># Specialized implementation of ArgKmin for the Euclidean distance</span>
              <span class="s0"># for the dense-dense and sparse-sparse cases.</span>
              <span class="s0"># This implementation computes the distances by chunk using</span>
              <span class="s0"># a decomposition of the Squared Euclidean distance.</span>
              <span class="s0"># This specialisation has an improved arithmetic intensity for both</span>
              <span class="s0"># the dense and sparse settings, allowing in most case speed-ups of</span>
              <span class="s0"># several orders of magnitude compared to the generic ArgKmin</span>
              <span class="s0"># implementation.</span>
              <span class="s0"># Note that squared norms of X and Y are precomputed in the</span>
              <span class="s0"># constructor of this class by issuing BLAS calls that may use</span>
              <span class="s0"># multithreading (depending on the BLAS implementation), hence calling</span>
              <span class="s0"># the constructor needs to be protected under the threadpool_limits</span>
              <span class="s0"># context, along with the main calls to _parallel_on_Y and</span>
              <span class="s0"># _parallel_on_X.</span>
              <span class="s0"># For more information see MiddleTermComputer.</span>
              <span class="s0">use_squared_distances = metric == &quot;sqeuclidean&quot;</span>
              <span class="s0">pda = EuclideanArgKmin{{name_suffix}}(</span>
                  <span class="s0">X=X, Y=Y, k=k,</span>
                  <span class="s0">use_squared_distances=use_squared_distances,</span>
                  <span class="s0">chunk_size=chunk_size,</span>
                  <span class="s0">strategy=strategy,</span>
                  <span class="s0">metric_kwargs=metric_kwargs,</span>
              <span class="s0">)</span>
          <span class="s0">else:</span>
              <span class="s0"># Fall back on a generic implementation that handles most scipy</span>
              <span class="s0"># metrics by computing the distances between 2 vectors at a time.</span>
              <span class="s0">pda = ArgKmin{{name_suffix}}(</span>
                  <span class="s0">datasets_pair=DatasetsPair{{name_suffix}}.get_for(X, Y, metric, metric_kwargs),</span>
                  <span class="s0">k=k,</span>
                  <span class="s0">chunk_size=chunk_size,</span>
                  <span class="s0">strategy=strategy,</span>
              <span class="s0">)</span>

          <span class="s0">if pda.execute_in_parallel_on_Y:</span>
              <span class="s0">pda._parallel_on_Y()</span>
          <span class="s0">else:</span>
              <span class="s0">pda._parallel_on_X()</span>

        <span class="s0">return pda._finalize_results(return_distance)</span>

    <span class="s0">def __init__(</span>
        <span class="s0">self,</span>
        <span class="s0">DatasetsPair{{name_suffix}} datasets_pair,</span>
        <span class="s0">chunk_size=None,</span>
        <span class="s0">strategy=None,</span>
        <span class="s0">intp_t k=1,</span>
    <span class="s0">):</span>
        <span class="s0">super().__init__(</span>
            <span class="s0">datasets_pair=datasets_pair,</span>
            <span class="s0">chunk_size=chunk_size,</span>
            <span class="s0">strategy=strategy,</span>
        <span class="s0">)</span>
        <span class="s0">self.k = check_scalar(k, &quot;k&quot;, Integral, min_val=1)</span>

        <span class="s0"># Allocating pointers to datastructures but not the datastructures themselves.</span>
        <span class="s0"># There are as many pointers as effective threads.</span>
        <span class="s0">#</span>
        <span class="s0"># For the sake of explicitness:</span>
        <span class="s0">#   - when parallelizing on X, the pointers of those heaps are referencing</span>
        <span class="s0">#   (with proper offsets) addresses of the two main heaps (see below)</span>
        <span class="s0">#   - when parallelizing on Y, the pointers of those heaps are referencing</span>
        <span class="s0">#   small heaps which are thread-wise-allocated and whose content will be</span>
        <span class="s0">#   merged with the main heaps'.</span>
        <span class="s0">self.heaps_r_distances_chunks = &lt;float64_t **&gt; malloc(</span>
            <span class="s0">sizeof(float64_t *) * self.chunks_n_threads</span>
        <span class="s0">)</span>
        <span class="s0">self.heaps_indices_chunks = &lt;intp_t **&gt; malloc(</span>
            <span class="s0">sizeof(intp_t *) * self.chunks_n_threads</span>
        <span class="s0">)</span>

        <span class="s0"># Main heaps which will be returned as results by `ArgKmin{{name_suffix}}.compute`.</span>
        <span class="s0">self.argkmin_indices = np.full((self.n_samples_X, self.k), 0, dtype=np.intp)</span>
        <span class="s0">self.argkmin_distances = np.full((self.n_samples_X, self.k), DBL_MAX, dtype=np.float64)</span>

    <span class="s0">def __dealloc__(self):</span>
        <span class="s0">if self.heaps_indices_chunks is not NULL:</span>
            <span class="s0">free(self.heaps_indices_chunks)</span>

        <span class="s0">if self.heaps_r_distances_chunks is not NULL:</span>
            <span class="s0">free(self.heaps_r_distances_chunks)</span>

    <span class="s0">cdef void _compute_and_reduce_distances_on_chunks(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
        <span class="s0">intp_t Y_start,</span>
        <span class="s0">intp_t Y_end,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t i, j</span>
            <span class="s0">intp_t n_samples_X = X_end - X_start</span>
            <span class="s0">intp_t n_samples_Y = Y_end - Y_start</span>
            <span class="s0">float64_t *heaps_r_distances = self.heaps_r_distances_chunks[thread_num]</span>
            <span class="s0">intp_t *heaps_indices = self.heaps_indices_chunks[thread_num]</span>

        <span class="s0"># Pushing the distances and their associated indices on a heap</span>
        <span class="s0"># which by construction will keep track of the argkmin.</span>
        <span class="s0">for i in range(n_samples_X):</span>
            <span class="s0">for j in range(n_samples_Y):</span>
                <span class="s0">heap_push(</span>
                    <span class="s0">values=heaps_r_distances + i * self.k,</span>
                    <span class="s0">indices=heaps_indices + i * self.k,</span>
                    <span class="s0">size=self.k,</span>
                    <span class="s0">val=self.datasets_pair.surrogate_dist(X_start + i, Y_start + j),</span>
                    <span class="s0">val_idx=Y_start + j,</span>
                <span class="s0">)</span>

    <span class="s0">cdef void _parallel_on_X_init_chunk(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0"># As this strategy is embarrassingly parallel, we can set each</span>
        <span class="s0"># thread's heaps pointer to the proper position on the main heaps.</span>
        <span class="s0">self.heaps_r_distances_chunks[thread_num] = &amp;self.argkmin_distances[X_start, 0]</span>
        <span class="s0">self.heaps_indices_chunks[thread_num] = &amp;self.argkmin_indices[X_start, 0]</span>

    <span class="s0">cdef void _parallel_on_X_prange_iter_finalize(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t idx</span>

        <span class="s0"># Sorting the main heaps portion associated to `X[X_start:X_end]`</span>
        <span class="s0"># in ascending order w.r.t the distances.</span>
        <span class="s0">for idx in range(X_end - X_start):</span>
            <span class="s0">simultaneous_sort(</span>
                <span class="s0">self.heaps_r_distances_chunks[thread_num] + idx * self.k,</span>
                <span class="s0">self.heaps_indices_chunks[thread_num] + idx * self.k,</span>
                <span class="s0">self.k</span>
            <span class="s0">)</span>

    <span class="s0">cdef void _parallel_on_Y_init(</span>
        <span class="s0">self,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">cdef:</span>
            <span class="s0"># Maximum number of scalar elements (the last chunks can be smaller)</span>
            <span class="s0">intp_t heaps_size = self.X_n_samples_chunk * self.k</span>
            <span class="s0">intp_t thread_num</span>

        <span class="s0"># The allocation is done in parallel for data locality purposes: this way</span>
        <span class="s0"># the heaps used in each threads are allocated in pages which are closer</span>
        <span class="s0"># to the CPU core used by the thread.</span>
        <span class="s0"># See comments about First Touch Placement Policy:</span>
        <span class="s0"># https://www.openmp.org/wp-content/uploads/openmp-webinar-vanderPas-20210318.pdf #noqa</span>
        <span class="s0">for thread_num in prange(self.chunks_n_threads, schedule='static', nogil=True,</span>
                                 <span class="s0">num_threads=self.chunks_n_threads):</span>
            <span class="s0"># As chunks of X are shared across threads, so must their</span>
            <span class="s0"># heaps. To solve this, each thread has its own heaps</span>
            <span class="s0"># which are then synchronised back in the main ones.</span>
            <span class="s0">self.heaps_r_distances_chunks[thread_num] = &lt;float64_t *&gt; malloc(</span>
                <span class="s0">heaps_size * sizeof(float64_t)</span>
            <span class="s0">)</span>
            <span class="s0">self.heaps_indices_chunks[thread_num] = &lt;intp_t *&gt; malloc(</span>
                <span class="s0">heaps_size * sizeof(intp_t)</span>
            <span class="s0">)</span>

    <span class="s0">cdef void _parallel_on_Y_parallel_init(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0"># Initialising heaps (memset can't be used here)</span>
        <span class="s0">for idx in range(self.X_n_samples_chunk * self.k):</span>
            <span class="s0">self.heaps_r_distances_chunks[thread_num][idx] = DBL_MAX</span>
            <span class="s0">self.heaps_indices_chunks[thread_num][idx] = -1</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_Y_synchronize(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t idx, jdx, thread_num</span>
        <span class="s0">with nogil, parallel(num_threads=self.effective_n_threads):</span>
            <span class="s0"># Synchronising the thread heaps with the main heaps.</span>
            <span class="s0"># This is done in parallel sample-wise (no need for locks).</span>
            <span class="s0">#</span>
            <span class="s0"># This might break each thread's data locality as each heap which</span>
            <span class="s0"># was allocated in a thread is being now being used in several threads.</span>
            <span class="s0">#</span>
            <span class="s0"># Still, this parallel pattern has shown to be efficient in practice.</span>
            <span class="s0">for idx in prange(X_end - X_start, schedule=&quot;static&quot;):</span>
                <span class="s0">for thread_num in range(self.chunks_n_threads):</span>
                    <span class="s0">for jdx in range(self.k):</span>
                        <span class="s0">heap_push(</span>
                            <span class="s0">values=&amp;self.argkmin_distances[X_start + idx, 0],</span>
                            <span class="s0">indices=&amp;self.argkmin_indices[X_start + idx, 0],</span>
                            <span class="s0">size=self.k,</span>
                            <span class="s0">val=self.heaps_r_distances_chunks[thread_num][idx * self.k + jdx],</span>
                            <span class="s0">val_idx=self.heaps_indices_chunks[thread_num][idx * self.k + jdx],</span>
                        <span class="s0">)</span>

    <span class="s0">cdef void _parallel_on_Y_finalize(</span>
        <span class="s0">self,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t idx, thread_num</span>

        <span class="s0">with nogil, parallel(num_threads=self.chunks_n_threads):</span>
            <span class="s0"># Deallocating temporary datastructures</span>
            <span class="s0">for thread_num in prange(self.chunks_n_threads, schedule='static'):</span>
                <span class="s0">free(self.heaps_r_distances_chunks[thread_num])</span>
                <span class="s0">free(self.heaps_indices_chunks[thread_num])</span>

            <span class="s0"># Sorting the main in ascending order w.r.t the distances.</span>
            <span class="s0"># This is done in parallel sample-wise (no need for locks).</span>
            <span class="s0">for idx in prange(self.n_samples_X, schedule='static'):</span>
                <span class="s0">simultaneous_sort(</span>
                    <span class="s0">&amp;self.argkmin_distances[idx, 0],</span>
                    <span class="s0">&amp;self.argkmin_indices[idx, 0],</span>
                    <span class="s0">self.k,</span>
                <span class="s0">)</span>
        <span class="s0">return</span>

    <span class="s0">cdef void compute_exact_distances(self) noexcept nogil:</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t i, j</span>
            <span class="s0">float64_t[:, ::1] distances = self.argkmin_distances</span>
        <span class="s0">for i in prange(self.n_samples_X, schedule='static', nogil=True,</span>
                        <span class="s0">num_threads=self.effective_n_threads):</span>
            <span class="s0">for j in range(self.k):</span>
                <span class="s0">distances[i, j] = self.datasets_pair.distance_metric._rdist_to_dist(</span>
                    <span class="s0"># Guard against potential -0., causing nan production.</span>
                    <span class="s0">max(distances[i, j], 0.)</span>
                <span class="s0">)</span>

    <span class="s0">def _finalize_results(self, bint return_distance=False):</span>
        <span class="s0">if return_distance:</span>
            <span class="s0"># We need to recompute distances because we relied on</span>
            <span class="s0"># surrogate distances for the reduction.</span>
            <span class="s0">self.compute_exact_distances()</span>

            <span class="s0"># Values are returned identically to the way `KNeighborsMixin.kneighbors`</span>
            <span class="s0"># returns values. This is counter-intuitive but this allows not using</span>
            <span class="s0"># complex adaptations where `ArgKmin.compute` is called.</span>
            <span class="s0">return np.asarray(self.argkmin_distances), np.asarray(self.argkmin_indices)</span>

        <span class="s0">return np.asarray(self.argkmin_indices)</span>


<span class="s0">cdef class EuclideanArgKmin{{name_suffix}}(ArgKmin{{name_suffix}}):</span>
    <span class="s0">&quot;&quot;&quot;EuclideanDistance-specialisation of ArgKmin{{name_suffix}}.&quot;&quot;&quot;</span>

    <span class="s0">@classmethod</span>
    <span class="s0">def is_usable_for(cls, X, Y, metric) -&gt; bool:</span>
        <span class="s0">return (ArgKmin{{name_suffix}}.is_usable_for(X, Y, metric) and</span>
                <span class="s0">not _in_unstable_openblas_configuration())</span>

    <span class="s0">def __init__(</span>
        <span class="s0">self,</span>
        <span class="s0">X,</span>
        <span class="s0">Y,</span>
        <span class="s0">intp_t k,</span>
        <span class="s0">bint use_squared_distances=False,</span>
        <span class="s0">chunk_size=None,</span>
        <span class="s0">strategy=None,</span>
        <span class="s0">metric_kwargs=None,</span>
    <span class="s0">):</span>
        <span class="s0">if (</span>
            <span class="s0">isinstance(metric_kwargs, dict) and</span>
            <span class="s0">(metric_kwargs.keys() - {&quot;X_norm_squared&quot;, &quot;Y_norm_squared&quot;})</span>
        <span class="s0">):</span>
            <span class="s0">warnings.warn(</span>
                <span class="s0">f&quot;Some metric_kwargs have been passed ({metric_kwargs}) but aren't &quot;</span>
                <span class="s0">f&quot;usable for this case (EuclideanArgKmin64) and will be ignored.&quot;,</span>
                <span class="s0">UserWarning,</span>
                <span class="s0">stacklevel=3,</span>
            <span class="s0">)</span>

        <span class="s0">super().__init__(</span>
            <span class="s0"># The datasets pair here is used for exact distances computations</span>
            <span class="s0">datasets_pair=DatasetsPair{{name_suffix}}.get_for(X, Y, metric=&quot;euclidean&quot;),</span>
            <span class="s0">chunk_size=chunk_size,</span>
            <span class="s0">strategy=strategy,</span>
            <span class="s0">k=k,</span>
        <span class="s0">)</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t dist_middle_terms_chunks_size = self.Y_n_samples_chunk * self.X_n_samples_chunk</span>

        <span class="s0">self.middle_term_computer = MiddleTermComputer{{name_suffix}}.get_for(</span>
            <span class="s0">X,</span>
            <span class="s0">Y,</span>
            <span class="s0">self.effective_n_threads,</span>
            <span class="s0">self.chunks_n_threads,</span>
            <span class="s0">dist_middle_terms_chunks_size,</span>
            <span class="s0">n_features=X.shape[1],</span>
            <span class="s0">chunk_size=self.chunk_size,</span>
        <span class="s0">)</span>

        <span class="s0">if metric_kwargs is not None and &quot;Y_norm_squared&quot; in metric_kwargs:</span>
            <span class="s0">self.Y_norm_squared = check_array(</span>
                <span class="s0">metric_kwargs.pop(&quot;Y_norm_squared&quot;),</span>
                <span class="s0">ensure_2d=False,</span>
                <span class="s0">input_name=&quot;Y_norm_squared&quot;,</span>
                <span class="s0">dtype=np.float64,</span>
            <span class="s0">)</span>
        <span class="s0">else:</span>
            <span class="s0">self.Y_norm_squared = _sqeuclidean_row_norms{{name_suffix}}(</span>
                <span class="s0">Y,</span>
                <span class="s0">self.effective_n_threads,</span>
            <span class="s0">)</span>

        <span class="s0">if metric_kwargs is not None and &quot;X_norm_squared&quot; in metric_kwargs:</span>
            <span class="s0">self.X_norm_squared = check_array(</span>
                <span class="s0">metric_kwargs.pop(&quot;X_norm_squared&quot;),</span>
                <span class="s0">ensure_2d=False,</span>
                <span class="s0">input_name=&quot;X_norm_squared&quot;,</span>
                <span class="s0">dtype=np.float64,</span>
            <span class="s0">)</span>
        <span class="s0">else:</span>
            <span class="s0"># Do not recompute norms if datasets are identical.</span>
            <span class="s0">self.X_norm_squared = (</span>
                <span class="s0">self.Y_norm_squared if X is Y else</span>
                <span class="s0">_sqeuclidean_row_norms{{name_suffix}}(</span>
                    <span class="s0">X,</span>
                    <span class="s0">self.effective_n_threads,</span>
                <span class="s0">)</span>
            <span class="s0">)</span>

        <span class="s0">self.use_squared_distances = use_squared_distances</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void compute_exact_distances(self) noexcept nogil:</span>
        <span class="s0">if not self.use_squared_distances:</span>
            <span class="s0">ArgKmin{{name_suffix}}.compute_exact_distances(self)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_X_parallel_init(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">ArgKmin{{name_suffix}}._parallel_on_X_parallel_init(self, thread_num)</span>
        <span class="s0">self.middle_term_computer._parallel_on_X_parallel_init(thread_num)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_X_init_chunk(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">ArgKmin{{name_suffix}}._parallel_on_X_init_chunk(self, thread_num, X_start, X_end)</span>
        <span class="s0">self.middle_term_computer._parallel_on_X_init_chunk(thread_num, X_start, X_end)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_X_pre_compute_and_reduce_distances_on_chunks(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
        <span class="s0">intp_t Y_start,</span>
        <span class="s0">intp_t Y_end,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">ArgKmin{{name_suffix}}._parallel_on_X_pre_compute_and_reduce_distances_on_chunks(</span>
            <span class="s0">self,</span>
            <span class="s0">X_start, X_end,</span>
            <span class="s0">Y_start, Y_end,</span>
            <span class="s0">thread_num,</span>
        <span class="s0">)</span>
        <span class="s0">self.middle_term_computer._parallel_on_X_pre_compute_and_reduce_distances_on_chunks(</span>
            <span class="s0">X_start, X_end, Y_start, Y_end, thread_num,</span>
        <span class="s0">)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_Y_init(</span>
        <span class="s0">self,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">ArgKmin{{name_suffix}}._parallel_on_Y_init(self)</span>
        <span class="s0">self.middle_term_computer._parallel_on_Y_init()</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_Y_parallel_init(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">ArgKmin{{name_suffix}}._parallel_on_Y_parallel_init(self, thread_num, X_start, X_end)</span>
        <span class="s0">self.middle_term_computer._parallel_on_Y_parallel_init(thread_num, X_start, X_end)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_Y_pre_compute_and_reduce_distances_on_chunks(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
        <span class="s0">intp_t Y_start,</span>
        <span class="s0">intp_t Y_end,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">ArgKmin{{name_suffix}}._parallel_on_Y_pre_compute_and_reduce_distances_on_chunks(</span>
            <span class="s0">self,</span>
            <span class="s0">X_start, X_end,</span>
            <span class="s0">Y_start, Y_end,</span>
            <span class="s0">thread_num,</span>
        <span class="s0">)</span>
        <span class="s0">self.middle_term_computer._parallel_on_Y_pre_compute_and_reduce_distances_on_chunks(</span>
            <span class="s0">X_start, X_end, Y_start, Y_end, thread_num</span>
        <span class="s0">)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _compute_and_reduce_distances_on_chunks(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
        <span class="s0">intp_t Y_start,</span>
        <span class="s0">intp_t Y_end,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t i, j</span>
            <span class="s0">float64_t sqeuclidean_dist_i_j</span>
            <span class="s0">intp_t n_X = X_end - X_start</span>
            <span class="s0">intp_t n_Y = Y_end - Y_start</span>
            <span class="s0">float64_t * dist_middle_terms = self.middle_term_computer._compute_dist_middle_terms(</span>
                <span class="s0">X_start, X_end, Y_start, Y_end, thread_num</span>
            <span class="s0">)</span>
            <span class="s0">float64_t * heaps_r_distances = self.heaps_r_distances_chunks[thread_num]</span>
            <span class="s0">intp_t * heaps_indices = self.heaps_indices_chunks[thread_num]</span>

        <span class="s0"># Pushing the distance and their associated indices on heaps</span>
        <span class="s0"># which keep tracks of the argkmin.</span>
        <span class="s0">for i in range(n_X):</span>
            <span class="s0">for j in range(n_Y):</span>
                <span class="s0">sqeuclidean_dist_i_j = (</span>
                    <span class="s0">self.X_norm_squared[i + X_start] +</span>
                    <span class="s0">dist_middle_terms[i * n_Y + j] +</span>
                    <span class="s0">self.Y_norm_squared[j + Y_start]</span>
                <span class="s0">)</span>

                <span class="s0"># Catastrophic cancellation might cause -0. to be present,</span>
                <span class="s0"># e.g. when computing d(x_i, y_i) when X is Y.</span>
                <span class="s0">sqeuclidean_dist_i_j = max(0., sqeuclidean_dist_i_j)</span>

                <span class="s0">heap_push(</span>
                    <span class="s0">values=heaps_r_distances + i * self.k,</span>
                    <span class="s0">indices=heaps_indices + i * self.k,</span>
                    <span class="s0">size=self.k,</span>
                    <span class="s0">val=sqeuclidean_dist_i_j,</span>
                    <span class="s0">val_idx=j + Y_start,</span>
                <span class="s0">)</span>

<span class="s0">{{endfor}}</span>
</pre>
</body>
</html>