<html>
<head>
<title>random_projection.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
random_projection.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Random projection transformers. 
 
Random projections are a simple and computationally efficient way to 
reduce the dimensionality of the data by trading a controlled amount 
of accuracy (as additional variance) for faster processing times and 
smaller model sizes. 
 
The dimensions and distribution of random projections matrices are 
controlled so as to preserve the pairwise distances between any two 
samples of the dataset. 
 
The main theoretical result behind the efficiency of random projection is the 
`Johnson-Lindenstrauss lemma (quoting Wikipedia) 
&lt;https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma&gt;`_: 
 
  In mathematics, the Johnson-Lindenstrauss lemma is a result 
  concerning low-distortion embeddings of points from high-dimensional 
  into low-dimensional Euclidean space. The lemma states that a small set 
  of points in a high-dimensional space can be embedded into a space of 
  much lower dimension in such a way that distances between the points are 
  nearly preserved. The map used for the embedding is at least Lipschitz, 
  and can even be taken to be an orthogonal projection. 
&quot;&quot;&quot;</span>

<span class="s2"># Authors: Olivier Grisel &lt;olivier.grisel@ensta.org&gt;,</span>
<span class="s2">#          Arnaud Joly &lt;a.joly@ulg.ac.be&gt;</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">warnings</span>
<span class="s3">from </span><span class="s1">abc </span><span class="s3">import </span><span class="s1">ABCMeta</span><span class="s4">, </span><span class="s1">abstractmethod</span>
<span class="s3">from </span><span class="s1">numbers </span><span class="s3">import </span><span class="s1">Integral</span><span class="s4">, </span><span class="s1">Real</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">import </span><span class="s1">scipy</span><span class="s4">.</span><span class="s1">sparse </span><span class="s3">as </span><span class="s1">sp</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">linalg</span>

<span class="s3">from </span><span class="s4">.</span><span class="s1">base </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">BaseEstimator</span><span class="s4">,</span>
    <span class="s1">ClassNamePrefixFeaturesOutMixin</span><span class="s4">,</span>
    <span class="s1">TransformerMixin</span><span class="s4">,</span>
    <span class="s1">_fit_context</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">exceptions </span><span class="s3">import </span><span class="s1">DataDimensionalityWarning</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils </span><span class="s3">import </span><span class="s1">check_random_state</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_param_validation </span><span class="s3">import </span><span class="s1">Interval</span><span class="s4">, </span><span class="s1">StrOptions</span><span class="s4">, </span><span class="s1">validate_params</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">extmath </span><span class="s3">import </span><span class="s1">safe_sparse_dot</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">random </span><span class="s3">import </span><span class="s1">sample_without_replacement</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">validation </span><span class="s3">import </span><span class="s1">check_array</span><span class="s4">, </span><span class="s1">check_is_fitted</span>

<span class="s1">__all__ </span><span class="s4">= [</span>
    <span class="s5">&quot;SparseRandomProjection&quot;</span><span class="s4">,</span>
    <span class="s5">&quot;GaussianRandomProjection&quot;</span><span class="s4">,</span>
    <span class="s5">&quot;johnson_lindenstrauss_min_dim&quot;</span><span class="s4">,</span>
<span class="s4">]</span>


<span class="s4">@</span><span class="s1">validate_params</span><span class="s4">(</span>
    <span class="s4">{</span>
        <span class="s5">&quot;n_samples&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">, </span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;eps&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">, </span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;neither&quot;</span><span class="s4">)],</span>
    <span class="s4">},</span>
    <span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">def </span><span class="s1">johnson_lindenstrauss_min_dim</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">, *, </span><span class="s1">eps</span><span class="s4">=</span><span class="s6">0.1</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Find a 'safe' number of components to randomly project to. 
 
    The distortion introduced by a random projection `p` only changes the 
    distance between two points by a factor (1 +- eps) in a euclidean space 
    with good probability. The projection `p` is an eps-embedding as defined 
    by: 
 
      (1 - eps) ||u - v||^2 &lt; ||p(u) - p(v)||^2 &lt; (1 + eps) ||u - v||^2 
 
    Where u and v are any rows taken from a dataset of shape (n_samples, 
    n_features), eps is in ]0, 1[ and p is a projection by a random Gaussian 
    N(0, 1) matrix of shape (n_components, n_features) (or a sparse 
    Achlioptas matrix). 
 
    The minimum number of components to guarantee the eps-embedding is 
    given by: 
 
      n_components &gt;= 4 log(n_samples) / (eps^2 / 2 - eps^3 / 3) 
 
    Note that the number of dimensions is independent of the original 
    number of features but instead depends on the size of the dataset: 
    the larger the dataset, the higher is the minimal dimensionality of 
    an eps-embedding. 
 
    Read more in the :ref:`User Guide &lt;johnson_lindenstrauss&gt;`. 
 
    Parameters 
    ---------- 
    n_samples : int or array-like of int 
        Number of samples that should be an integer greater than 0. If an array 
        is given, it will compute a safe number of components array-wise. 
 
    eps : float or array-like of shape (n_components,), dtype=float, \ 
            default=0.1 
        Maximum distortion rate in the range (0, 1) as defined by the 
        Johnson-Lindenstrauss lemma. If an array is given, it will compute a 
        safe number of components array-wise. 
 
    Returns 
    ------- 
    n_components : int or ndarray of int 
        The minimal number of components to guarantee with good probability 
        an eps-embedding with n_samples. 
 
    References 
    ---------- 
 
    .. [1] https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma 
 
    .. [2] `Sanjoy Dasgupta and Anupam Gupta, 1999, 
           &quot;An elementary proof of the Johnson-Lindenstrauss Lemma.&quot; 
           &lt;https://citeseerx.ist.psu.edu/doc_view/pid/95cd464d27c25c9c8690b378b894d337cdf021f9&gt;`_ 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.random_projection import johnson_lindenstrauss_min_dim 
    &gt;&gt;&gt; johnson_lindenstrauss_min_dim(1e6, eps=0.5) 
    np.int64(663) 
 
    &gt;&gt;&gt; johnson_lindenstrauss_min_dim(1e6, eps=[0.5, 0.1, 0.01]) 
    array([    663,   11841, 1112658]) 
 
    &gt;&gt;&gt; johnson_lindenstrauss_min_dim([1e4, 1e5, 1e6], eps=0.1) 
    array([ 7894,  9868, 11841]) 
    &quot;&quot;&quot;</span>
    <span class="s1">eps </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">asarray</span><span class="s4">(</span><span class="s1">eps</span><span class="s4">)</span>
    <span class="s1">n_samples </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">asarray</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">)</span>

    <span class="s3">if </span><span class="s1">np</span><span class="s4">.</span><span class="s1">any</span><span class="s4">(</span><span class="s1">eps </span><span class="s4">&lt;= </span><span class="s6">0.0</span><span class="s4">) </span><span class="s3">or </span><span class="s1">np</span><span class="s4">.</span><span class="s1">any</span><span class="s4">(</span><span class="s1">eps </span><span class="s4">&gt;= </span><span class="s6">1</span><span class="s4">):</span>
        <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span><span class="s5">&quot;The JL bound is defined for eps in ]0, 1[, got %r&quot; </span><span class="s4">% </span><span class="s1">eps</span><span class="s4">)</span>

    <span class="s3">if </span><span class="s1">np</span><span class="s4">.</span><span class="s1">any</span><span class="s4">(</span><span class="s1">n_samples </span><span class="s4">&lt;= </span><span class="s6">0</span><span class="s4">):</span>
        <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
            <span class="s5">&quot;The JL bound is defined for n_samples greater than zero, got %r&quot;</span>
            <span class="s4">% </span><span class="s1">n_samples</span>
        <span class="s4">)</span>

    <span class="s1">denominator </span><span class="s4">= (</span><span class="s1">eps</span><span class="s4">**</span><span class="s6">2 </span><span class="s4">/ </span><span class="s6">2</span><span class="s4">) - (</span><span class="s1">eps</span><span class="s4">**</span><span class="s6">3 </span><span class="s4">/ </span><span class="s6">3</span><span class="s4">)</span>
    <span class="s3">return </span><span class="s4">(</span><span class="s6">4 </span><span class="s4">* </span><span class="s1">np</span><span class="s4">.</span><span class="s1">log</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">) / </span><span class="s1">denominator</span><span class="s4">).</span><span class="s1">astype</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">int64</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">_check_density</span><span class="s4">(</span><span class="s1">density</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Factorize density check according to Li et al.&quot;&quot;&quot;</span>
    <span class="s3">if </span><span class="s1">density </span><span class="s4">== </span><span class="s5">&quot;auto&quot;</span><span class="s4">:</span>
        <span class="s1">density </span><span class="s4">= </span><span class="s6">1 </span><span class="s4">/ </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sqrt</span><span class="s4">(</span><span class="s1">n_features</span><span class="s4">)</span>

    <span class="s3">elif </span><span class="s1">density </span><span class="s4">&lt;= </span><span class="s6">0 </span><span class="s3">or </span><span class="s1">density </span><span class="s4">&gt; </span><span class="s6">1</span><span class="s4">:</span>
        <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span><span class="s5">&quot;Expected density in range ]0, 1], got: %r&quot; </span><span class="s4">% </span><span class="s1">density</span><span class="s4">)</span>
    <span class="s3">return </span><span class="s1">density</span>


<span class="s3">def </span><span class="s1">_check_input_size</span><span class="s4">(</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Factorize argument checking for random matrix generation.&quot;&quot;&quot;</span>
    <span class="s3">if </span><span class="s1">n_components </span><span class="s4">&lt;= </span><span class="s6">0</span><span class="s4">:</span>
        <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
            <span class="s5">&quot;n_components must be strictly positive, got %d&quot; </span><span class="s4">% </span><span class="s1">n_components</span>
        <span class="s4">)</span>
    <span class="s3">if </span><span class="s1">n_features </span><span class="s4">&lt;= </span><span class="s6">0</span><span class="s4">:</span>
        <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span><span class="s5">&quot;n_features must be strictly positive, got %d&quot; </span><span class="s4">% </span><span class="s1">n_features</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">_gaussian_random_matrix</span><span class="s4">(</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Generate a dense Gaussian random matrix. 
 
    The components of the random matrix are drawn from 
 
        N(0, 1.0 / n_components). 
 
    Read more in the :ref:`User Guide &lt;gaussian_random_matrix&gt;`. 
 
    Parameters 
    ---------- 
    n_components : int, 
        Dimensionality of the target projection space. 
 
    n_features : int, 
        Dimensionality of the original source space. 
 
    random_state : int, RandomState instance or None, default=None 
        Controls the pseudo random number generator used to generate the matrix 
        at fit time. 
        Pass an int for reproducible output across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    Returns 
    ------- 
    components : ndarray of shape (n_components, n_features) 
        The generated Gaussian random matrix. 
 
    See Also 
    -------- 
    GaussianRandomProjection 
    &quot;&quot;&quot;</span>
    <span class="s1">_check_input_size</span><span class="s4">(</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">)</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">random_state</span><span class="s4">)</span>
    <span class="s1">components </span><span class="s4">= </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">normal</span><span class="s4">(</span>
        <span class="s1">loc</span><span class="s4">=</span><span class="s6">0.0</span><span class="s4">, </span><span class="s1">scale</span><span class="s4">=</span><span class="s6">1.0 </span><span class="s4">/ </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sqrt</span><span class="s4">(</span><span class="s1">n_components</span><span class="s4">), </span><span class="s1">size</span><span class="s4">=(</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">)</span>
    <span class="s4">)</span>
    <span class="s3">return </span><span class="s1">components</span>


<span class="s3">def </span><span class="s1">_sparse_random_matrix</span><span class="s4">(</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">, </span><span class="s1">density</span><span class="s4">=</span><span class="s5">&quot;auto&quot;</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Generalized Achlioptas random sparse matrix for random projection. 
 
    Setting density to 1 / 3 will yield the original matrix by Dimitris 
    Achlioptas while setting a lower value will yield the generalization 
    by Ping Li et al. 
 
    If we note :math:`s = 1 / density`, the components of the random matrix are 
    drawn from: 
 
      - -sqrt(s) / sqrt(n_components)   with probability 1 / 2s 
      -  0                              with probability 1 - 1 / s 
      - +sqrt(s) / sqrt(n_components)   with probability 1 / 2s 
 
    Read more in the :ref:`User Guide &lt;sparse_random_matrix&gt;`. 
 
    Parameters 
    ---------- 
    n_components : int, 
        Dimensionality of the target projection space. 
 
    n_features : int, 
        Dimensionality of the original source space. 
 
    density : float or 'auto', default='auto' 
        Ratio of non-zero component in the random projection matrix in the 
        range `(0, 1]` 
 
        If density = 'auto', the value is set to the minimum density 
        as recommended by Ping Li et al.: 1 / sqrt(n_features). 
 
        Use density = 1 / 3.0 if you want to reproduce the results from 
        Achlioptas, 2001. 
 
    random_state : int, RandomState instance or None, default=None 
        Controls the pseudo random number generator used to generate the matrix 
        at fit time. 
        Pass an int for reproducible output across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    Returns 
    ------- 
    components : {ndarray, sparse matrix} of shape (n_components, n_features) 
        The generated Gaussian random matrix. Sparse matrix will be of CSR 
        format. 
 
    See Also 
    -------- 
    SparseRandomProjection 
 
    References 
    ---------- 
 
    .. [1] Ping Li, T. Hastie and K. W. Church, 2006, 
           &quot;Very Sparse Random Projections&quot;. 
           https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf 
 
    .. [2] D. Achlioptas, 2001, &quot;Database-friendly random projections&quot;, 
           https://cgi.di.uoa.gr/~optas/papers/jl.pdf 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_check_input_size</span><span class="s4">(</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">)</span>
    <span class="s1">density </span><span class="s4">= </span><span class="s1">_check_density</span><span class="s4">(</span><span class="s1">density</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">)</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">random_state</span><span class="s4">)</span>

    <span class="s3">if </span><span class="s1">density </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
        <span class="s2"># skip index generation if totally dense</span>
        <span class="s1">components </span><span class="s4">= </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">binomial</span><span class="s4">(</span><span class="s6">1</span><span class="s4">, </span><span class="s6">0.5</span><span class="s4">, (</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">)) * </span><span class="s6">2 </span><span class="s4">- </span><span class="s6">1</span>
        <span class="s3">return </span><span class="s6">1 </span><span class="s4">/ </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sqrt</span><span class="s4">(</span><span class="s1">n_components</span><span class="s4">) * </span><span class="s1">components</span>

    <span class="s3">else</span><span class="s4">:</span>
        <span class="s2"># Generate location of non zero elements</span>
        <span class="s1">indices </span><span class="s4">= []</span>
        <span class="s1">offset </span><span class="s4">= </span><span class="s6">0</span>
        <span class="s1">indptr </span><span class="s4">= [</span><span class="s1">offset</span><span class="s4">]</span>
        <span class="s3">for </span><span class="s1">_ </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">n_components</span><span class="s4">):</span>
            <span class="s2"># find the indices of the non-zero components for row i</span>
            <span class="s1">n_nonzero_i </span><span class="s4">= </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">binomial</span><span class="s4">(</span><span class="s1">n_features</span><span class="s4">, </span><span class="s1">density</span><span class="s4">)</span>
            <span class="s1">indices_i </span><span class="s4">= </span><span class="s1">sample_without_replacement</span><span class="s4">(</span>
                <span class="s1">n_features</span><span class="s4">, </span><span class="s1">n_nonzero_i</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
            <span class="s4">)</span>
            <span class="s1">indices</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">indices_i</span><span class="s4">)</span>
            <span class="s1">offset </span><span class="s4">+= </span><span class="s1">n_nonzero_i</span>
            <span class="s1">indptr</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">offset</span><span class="s4">)</span>

        <span class="s1">indices </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">concatenate</span><span class="s4">(</span><span class="s1">indices</span><span class="s4">)</span>

        <span class="s2"># Among non zero components the probability of the sign is 50%/50%</span>
        <span class="s1">data </span><span class="s4">= </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">binomial</span><span class="s4">(</span><span class="s6">1</span><span class="s4">, </span><span class="s6">0.5</span><span class="s4">, </span><span class="s1">size</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">size</span><span class="s4">(</span><span class="s1">indices</span><span class="s4">)) * </span><span class="s6">2 </span><span class="s4">- </span><span class="s6">1</span>

        <span class="s2"># build the CSR structure by concatenating the rows</span>
        <span class="s1">components </span><span class="s4">= </span><span class="s1">sp</span><span class="s4">.</span><span class="s1">csr_matrix</span><span class="s4">(</span>
            <span class="s4">(</span><span class="s1">data</span><span class="s4">, </span><span class="s1">indices</span><span class="s4">, </span><span class="s1">indptr</span><span class="s4">), </span><span class="s1">shape</span><span class="s4">=(</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">)</span>
        <span class="s4">)</span>

        <span class="s3">return </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sqrt</span><span class="s4">(</span><span class="s6">1 </span><span class="s4">/ </span><span class="s1">density</span><span class="s4">) / </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sqrt</span><span class="s4">(</span><span class="s1">n_components</span><span class="s4">) * </span><span class="s1">components</span>


<span class="s3">class </span><span class="s1">BaseRandomProjection</span><span class="s4">(</span>
    <span class="s1">TransformerMixin</span><span class="s4">, </span><span class="s1">BaseEstimator</span><span class="s4">, </span><span class="s1">ClassNamePrefixFeaturesOutMixin</span><span class="s4">, </span><span class="s1">metaclass</span><span class="s4">=</span><span class="s1">ABCMeta</span>
<span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Base class for random projections. 
 
    Warning: This class should not be used directly. 
    Use derived classes instead. 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s5">&quot;n_components&quot;</span><span class="s4">: [</span>
            <span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">),</span>
            <span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;auto&quot;</span><span class="s4">}),</span>
        <span class="s4">],</span>
        <span class="s5">&quot;eps&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;neither&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;compute_inverse_components&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;random_state&quot;</span><span class="s4">: [</span><span class="s5">&quot;random_state&quot;</span><span class="s4">],</span>
    <span class="s4">}</span>

    <span class="s4">@</span><span class="s1">abstractmethod</span>
    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">n_components</span><span class="s4">=</span><span class="s5">&quot;auto&quot;</span><span class="s4">,</span>
        <span class="s4">*,</span>
        <span class="s1">eps</span><span class="s4">=</span><span class="s6">0.1</span><span class="s4">,</span>
        <span class="s1">compute_inverse_components</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_components </span><span class="s4">= </span><span class="s1">n_components</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">eps </span><span class="s4">= </span><span class="s1">eps</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">compute_inverse_components </span><span class="s4">= </span><span class="s1">compute_inverse_components</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">random_state </span><span class="s4">= </span><span class="s1">random_state</span>

    <span class="s4">@</span><span class="s1">abstractmethod</span>
    <span class="s3">def </span><span class="s1">_make_random_matrix</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Generate the random projection matrix. 
 
        Parameters 
        ---------- 
        n_components : int, 
            Dimensionality of the target projection space. 
 
        n_features : int, 
            Dimensionality of the original source space. 
 
        Returns 
        ------- 
        components : {ndarray, sparse matrix} of shape (n_components, n_features) 
            The generated random matrix. Sparse matrix will be of CSR format. 
 
        &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">_compute_inverse_components</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Compute the pseudo-inverse of the (densified) components.&quot;&quot;&quot;</span>
        <span class="s1">components </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span>
        <span class="s3">if </span><span class="s1">sp</span><span class="s4">.</span><span class="s1">issparse</span><span class="s4">(</span><span class="s1">components</span><span class="s4">):</span>
            <span class="s1">components </span><span class="s4">= </span><span class="s1">components</span><span class="s4">.</span><span class="s1">toarray</span><span class="s4">()</span>
        <span class="s3">return </span><span class="s1">linalg</span><span class="s4">.</span><span class="s1">pinv</span><span class="s4">(</span><span class="s1">components</span><span class="s4">, </span><span class="s1">check_finite</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Generate a sparse random projection matrix. 
 
        Parameters 
        ---------- 
        X : {ndarray, sparse matrix} of shape (n_samples, n_features) 
            Training set: only the shape is used to find optimal random 
            matrix dimensions based on the theory referenced in the 
            afore mentioned papers. 
 
        y : Ignored 
            Not used, present here for API consistency by convention. 
 
        Returns 
        ------- 
        self : object 
            BaseRandomProjection class instance. 
        &quot;&quot;&quot;</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">, </span><span class="s1">accept_sparse</span><span class="s4">=[</span><span class="s5">&quot;csr&quot;</span><span class="s4">, </span><span class="s5">&quot;csc&quot;</span><span class="s4">], </span><span class="s1">dtype</span><span class="s4">=[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">]</span>
        <span class="s4">)</span>

        <span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_features </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components </span><span class="s4">== </span><span class="s5">&quot;auto&quot;</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">n_components_ </span><span class="s4">= </span><span class="s1">johnson_lindenstrauss_min_dim</span><span class="s4">(</span>
                <span class="s1">n_samples</span><span class="s4">=</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">eps</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">eps</span>
            <span class="s4">)</span>

            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components_ </span><span class="s4">&lt;= </span><span class="s6">0</span><span class="s4">:</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                    <span class="s5">&quot;eps=%f and n_samples=%d lead to a target dimension of &quot;</span>
                    <span class="s5">&quot;%d which is invalid&quot; </span><span class="s4">% (</span><span class="s1">self</span><span class="s4">.</span><span class="s1">eps</span><span class="s4">, </span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components_</span><span class="s4">)</span>
                <span class="s4">)</span>

            <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components_ </span><span class="s4">&gt; </span><span class="s1">n_features</span><span class="s4">:</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                    <span class="s5">&quot;eps=%f and n_samples=%d lead to a target dimension of &quot;</span>
                    <span class="s5">&quot;%d which is larger than the original space with &quot;</span>
                    <span class="s5">&quot;n_features=%d&quot;</span>
                    <span class="s4">% (</span><span class="s1">self</span><span class="s4">.</span><span class="s1">eps</span><span class="s4">, </span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components_</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">)</span>
                <span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components </span><span class="s4">&gt; </span><span class="s1">n_features</span><span class="s4">:</span>
                <span class="s1">warnings</span><span class="s4">.</span><span class="s1">warn</span><span class="s4">(</span>
                    <span class="s5">&quot;The number of components is higher than the number of&quot;</span>
                    <span class="s5">&quot; features: n_features &lt; n_components (%s &lt; %s).&quot;</span>
                    <span class="s5">&quot;The dimensionality of the problem will not be reduced.&quot;</span>
                    <span class="s4">% (</span><span class="s1">n_features</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components</span><span class="s4">),</span>
                    <span class="s1">DataDimensionalityWarning</span><span class="s4">,</span>
                <span class="s4">)</span>

            <span class="s1">self</span><span class="s4">.</span><span class="s1">n_components_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components</span>

        <span class="s2"># Generate a projection matrix of size [n_components, n_features]</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">components_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_make_random_matrix</span><span class="s4">(</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">n_components_</span><span class="s4">, </span><span class="s1">n_features</span>
        <span class="s4">).</span><span class="s1">astype</span><span class="s4">(</span><span class="s1">X</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">, </span><span class="s1">copy</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">compute_inverse_components</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">inverse_components_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_compute_inverse_components</span><span class="s4">()</span>

        <span class="s2"># Required by ClassNamePrefixFeaturesOutMixin.get_feature_names_out.</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_n_features_out </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components</span>

        <span class="s3">return </span><span class="s1">self</span>

    <span class="s3">def </span><span class="s1">inverse_transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Project data back to its original space. 
 
        Returns an array X_original whose transform would be X. Note that even 
        if X is sparse, X_original is dense: this may use a lot of RAM. 
 
        If `compute_inverse_components` is False, the inverse of the components is 
        computed during each call to `inverse_transform` which can be costly. 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix} of shape (n_samples, n_components) 
            Data to be transformed back. 
 
        Returns 
        ------- 
        X_original : ndarray of shape (n_samples, n_features) 
            Reconstructed data. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>

        <span class="s1">X </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">], </span><span class="s1">accept_sparse</span><span class="s4">=(</span><span class="s5">&quot;csr&quot;</span><span class="s4">, </span><span class="s5">&quot;csc&quot;</span><span class="s4">))</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">compute_inverse_components</span><span class="s4">:</span>
            <span class="s3">return </span><span class="s1">X </span><span class="s4">@ </span><span class="s1">self</span><span class="s4">.</span><span class="s1">inverse_components_</span><span class="s4">.</span><span class="s1">T</span>

        <span class="s1">inverse_components </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_compute_inverse_components</span><span class="s4">()</span>
        <span class="s3">return </span><span class="s1">X </span><span class="s4">@ </span><span class="s1">inverse_components</span><span class="s4">.</span><span class="s1">T</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span>
            <span class="s5">&quot;preserves_dtype&quot;</span><span class="s4">: [</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">],</span>
        <span class="s4">}</span>


<span class="s3">class </span><span class="s1">GaussianRandomProjection</span><span class="s4">(</span><span class="s1">BaseRandomProjection</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Reduce dimensionality through Gaussian random projection. 
 
    The components of the random matrix are drawn from N(0, 1 / n_components). 
 
    Read more in the :ref:`User Guide &lt;gaussian_random_matrix&gt;`. 
 
    .. versionadded:: 0.13 
 
    Parameters 
    ---------- 
    n_components : int or 'auto', default='auto' 
        Dimensionality of the target projection space. 
 
        n_components can be automatically adjusted according to the 
        number of samples in the dataset and the bound given by the 
        Johnson-Lindenstrauss lemma. In that case the quality of the 
        embedding is controlled by the ``eps`` parameter. 
 
        It should be noted that Johnson-Lindenstrauss lemma can yield 
        very conservative estimated of the required number of components 
        as it makes no assumption on the structure of the dataset. 
 
    eps : float, default=0.1 
        Parameter to control the quality of the embedding according to 
        the Johnson-Lindenstrauss lemma when `n_components` is set to 
        'auto'. The value should be strictly positive. 
 
        Smaller values lead to better embedding and higher number of 
        dimensions (n_components) in the target projection space. 
 
    compute_inverse_components : bool, default=False 
        Learn the inverse transform by computing the pseudo-inverse of the 
        components during fit. Note that computing the pseudo-inverse does not 
        scale well to large matrices. 
 
    random_state : int, RandomState instance or None, default=None 
        Controls the pseudo random number generator used to generate the 
        projection matrix at fit time. 
        Pass an int for reproducible output across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    Attributes 
    ---------- 
    n_components_ : int 
        Concrete number of components computed when n_components=&quot;auto&quot;. 
 
    components_ : ndarray of shape (n_components, n_features) 
        Random matrix used for the projection. 
 
    inverse_components_ : ndarray of shape (n_features, n_components) 
        Pseudo-inverse of the components, only computed if 
        `compute_inverse_components` is True. 
 
        .. versionadded:: 1.1 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    See Also 
    -------- 
    SparseRandomProjection : Reduce dimensionality through sparse 
        random projection. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.random_projection import GaussianRandomProjection 
    &gt;&gt;&gt; rng = np.random.RandomState(42) 
    &gt;&gt;&gt; X = rng.rand(25, 3000) 
    &gt;&gt;&gt; transformer = GaussianRandomProjection(random_state=rng) 
    &gt;&gt;&gt; X_new = transformer.fit_transform(X) 
    &gt;&gt;&gt; X_new.shape 
    (25, 2759) 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">n_components</span><span class="s4">=</span><span class="s5">&quot;auto&quot;</span><span class="s4">,</span>
        <span class="s4">*,</span>
        <span class="s1">eps</span><span class="s4">=</span><span class="s6">0.1</span><span class="s4">,</span>
        <span class="s1">compute_inverse_components</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">super</span><span class="s4">().</span><span class="s1">__init__</span><span class="s4">(</span>
            <span class="s1">n_components</span><span class="s4">=</span><span class="s1">n_components</span><span class="s4">,</span>
            <span class="s1">eps</span><span class="s4">=</span><span class="s1">eps</span><span class="s4">,</span>
            <span class="s1">compute_inverse_components</span><span class="s4">=</span><span class="s1">compute_inverse_components</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span><span class="s4">,</span>
        <span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_make_random_matrix</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Generate the random projection matrix. 
 
        Parameters 
        ---------- 
        n_components : int, 
            Dimensionality of the target projection space. 
 
        n_features : int, 
            Dimensionality of the original source space. 
 
        Returns 
        ------- 
        components : ndarray of shape (n_components, n_features) 
            The generated random matrix. 
        &quot;&quot;&quot;</span>
        <span class="s1">random_state </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">_gaussian_random_matrix</span><span class="s4">(</span>
            <span class="s1">n_components</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span>
        <span class="s4">)</span>

    <span class="s3">def </span><span class="s1">transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Project the data by using matrix product with the random matrix. 
 
        Parameters 
        ---------- 
        X : {ndarray, sparse matrix} of shape (n_samples, n_features) 
            The input data to project into a smaller dimensional space. 
 
        Returns 
        ------- 
        X_new : ndarray of shape (n_samples, n_components) 
            Projected array. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">, </span><span class="s1">accept_sparse</span><span class="s4">=[</span><span class="s5">&quot;csr&quot;</span><span class="s4">, </span><span class="s5">&quot;csc&quot;</span><span class="s4">], </span><span class="s1">reset</span><span class="s4">=</span><span class="s3">False</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">]</span>
        <span class="s4">)</span>

        <span class="s3">return </span><span class="s1">X </span><span class="s4">@ </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">.</span><span class="s1">T</span>


<span class="s3">class </span><span class="s1">SparseRandomProjection</span><span class="s4">(</span><span class="s1">BaseRandomProjection</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Reduce dimensionality through sparse random projection. 
 
    Sparse random matrix is an alternative to dense random 
    projection matrix that guarantees similar embedding quality while being 
    much more memory efficient and allowing faster computation of the 
    projected data. 
 
    If we note `s = 1 / density` the components of the random matrix are 
    drawn from: 
 
      - -sqrt(s) / sqrt(n_components)   with probability 1 / 2s 
      -  0                              with probability 1 - 1 / s 
      - +sqrt(s) / sqrt(n_components)   with probability 1 / 2s 
 
    Read more in the :ref:`User Guide &lt;sparse_random_matrix&gt;`. 
 
    .. versionadded:: 0.13 
 
    Parameters 
    ---------- 
    n_components : int or 'auto', default='auto' 
        Dimensionality of the target projection space. 
 
        n_components can be automatically adjusted according to the 
        number of samples in the dataset and the bound given by the 
        Johnson-Lindenstrauss lemma. In that case the quality of the 
        embedding is controlled by the ``eps`` parameter. 
 
        It should be noted that Johnson-Lindenstrauss lemma can yield 
        very conservative estimated of the required number of components 
        as it makes no assumption on the structure of the dataset. 
 
    density : float or 'auto', default='auto' 
        Ratio in the range (0, 1] of non-zero component in the random 
        projection matrix. 
 
        If density = 'auto', the value is set to the minimum density 
        as recommended by Ping Li et al.: 1 / sqrt(n_features). 
 
        Use density = 1 / 3.0 if you want to reproduce the results from 
        Achlioptas, 2001. 
 
    eps : float, default=0.1 
        Parameter to control the quality of the embedding according to 
        the Johnson-Lindenstrauss lemma when n_components is set to 
        'auto'. This value should be strictly positive. 
 
        Smaller values lead to better embedding and higher number of 
        dimensions (n_components) in the target projection space. 
 
    dense_output : bool, default=False 
        If True, ensure that the output of the random projection is a 
        dense numpy array even if the input and random projection matrix 
        are both sparse. In practice, if the number of components is 
        small the number of zero components in the projected data will 
        be very small and it will be more CPU and memory efficient to 
        use a dense representation. 
 
        If False, the projected data uses a sparse representation if 
        the input is sparse. 
 
    compute_inverse_components : bool, default=False 
        Learn the inverse transform by computing the pseudo-inverse of the 
        components during fit. Note that the pseudo-inverse is always a dense 
        array, even if the training data was sparse. This means that it might be 
        necessary to call `inverse_transform` on a small batch of samples at a 
        time to avoid exhausting the available memory on the host. Moreover, 
        computing the pseudo-inverse does not scale well to large matrices. 
 
    random_state : int, RandomState instance or None, default=None 
        Controls the pseudo random number generator used to generate the 
        projection matrix at fit time. 
        Pass an int for reproducible output across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    Attributes 
    ---------- 
    n_components_ : int 
        Concrete number of components computed when n_components=&quot;auto&quot;. 
 
    components_ : sparse matrix of shape (n_components, n_features) 
        Random matrix used for the projection. Sparse matrix will be of CSR 
        format. 
 
    inverse_components_ : ndarray of shape (n_features, n_components) 
        Pseudo-inverse of the components, only computed if 
        `compute_inverse_components` is True. 
 
        .. versionadded:: 1.1 
 
    density_ : float in range 0.0 - 1.0 
        Concrete density computed from when density = &quot;auto&quot;. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    See Also 
    -------- 
    GaussianRandomProjection : Reduce dimensionality through Gaussian 
        random projection. 
 
    References 
    ---------- 
 
    .. [1] Ping Li, T. Hastie and K. W. Church, 2006, 
           &quot;Very Sparse Random Projections&quot;. 
           https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf 
 
    .. [2] D. Achlioptas, 2001, &quot;Database-friendly random projections&quot;, 
           https://cgi.di.uoa.gr/~optas/papers/jl.pdf 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.random_projection import SparseRandomProjection 
    &gt;&gt;&gt; rng = np.random.RandomState(42) 
    &gt;&gt;&gt; X = rng.rand(25, 3000) 
    &gt;&gt;&gt; transformer = SparseRandomProjection(random_state=rng) 
    &gt;&gt;&gt; X_new = transformer.fit_transform(X) 
    &gt;&gt;&gt; X_new.shape 
    (25, 2759) 
    &gt;&gt;&gt; # very few components are non-zero 
    &gt;&gt;&gt; np.mean(transformer.components_ != 0) 
    np.float64(0.0182...) 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s4">**</span><span class="s1">BaseRandomProjection</span><span class="s4">.</span><span class="s1">_parameter_constraints</span><span class="s4">,</span>
        <span class="s5">&quot;density&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0.0</span><span class="s4">, </span><span class="s6">1.0</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;right&quot;</span><span class="s4">), </span><span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;auto&quot;</span><span class="s4">})],</span>
        <span class="s5">&quot;dense_output&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
    <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">n_components</span><span class="s4">=</span><span class="s5">&quot;auto&quot;</span><span class="s4">,</span>
        <span class="s4">*,</span>
        <span class="s1">density</span><span class="s4">=</span><span class="s5">&quot;auto&quot;</span><span class="s4">,</span>
        <span class="s1">eps</span><span class="s4">=</span><span class="s6">0.1</span><span class="s4">,</span>
        <span class="s1">dense_output</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">compute_inverse_components</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">super</span><span class="s4">().</span><span class="s1">__init__</span><span class="s4">(</span>
            <span class="s1">n_components</span><span class="s4">=</span><span class="s1">n_components</span><span class="s4">,</span>
            <span class="s1">eps</span><span class="s4">=</span><span class="s1">eps</span><span class="s4">,</span>
            <span class="s1">compute_inverse_components</span><span class="s4">=</span><span class="s1">compute_inverse_components</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span><span class="s4">,</span>
        <span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">dense_output </span><span class="s4">= </span><span class="s1">dense_output</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">density </span><span class="s4">= </span><span class="s1">density</span>

    <span class="s3">def </span><span class="s1">_make_random_matrix</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Generate the random projection matrix 
 
        Parameters 
        ---------- 
        n_components : int 
            Dimensionality of the target projection space. 
 
        n_features : int 
            Dimensionality of the original source space. 
 
        Returns 
        ------- 
        components : sparse matrix of shape (n_components, n_features) 
            The generated random matrix in CSR format. 
 
        &quot;&quot;&quot;</span>
        <span class="s1">random_state </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">density_ </span><span class="s4">= </span><span class="s1">_check_density</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">density</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">_sparse_random_matrix</span><span class="s4">(</span>
            <span class="s1">n_components</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">, </span><span class="s1">density</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">density_</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span>
        <span class="s4">)</span>

    <span class="s3">def </span><span class="s1">transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Project the data by using matrix product with the random matrix. 
 
        Parameters 
        ---------- 
        X : {ndarray, sparse matrix} of shape (n_samples, n_features) 
            The input data to project into a smaller dimensional space. 
 
        Returns 
        ------- 
        X_new : {ndarray, sparse matrix} of shape (n_samples, n_components) 
            Projected array. It is a sparse matrix only when the input is sparse and 
            `dense_output = False`. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">, </span><span class="s1">accept_sparse</span><span class="s4">=[</span><span class="s5">&quot;csr&quot;</span><span class="s4">, </span><span class="s5">&quot;csc&quot;</span><span class="s4">], </span><span class="s1">reset</span><span class="s4">=</span><span class="s3">False</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">]</span>
        <span class="s4">)</span>

        <span class="s3">return </span><span class="s1">safe_sparse_dot</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">.</span><span class="s1">T</span><span class="s4">, </span><span class="s1">dense_output</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">dense_output</span><span class="s4">)</span>
</pre>
</body>
</html>