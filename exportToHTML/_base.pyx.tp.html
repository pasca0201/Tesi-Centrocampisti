<html>
<head>
<title>_base.pyx.tp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #bcbec4;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_base.pyx.tp</font>
</center></td></tr></table>
<pre><span class="s0">from cython cimport final</span>
<span class="s0">from cython.operator cimport dereference as deref</span>
<span class="s0">from cython.parallel cimport parallel, prange</span>
<span class="s0">from libcpp.vector cimport vector</span>

<span class="s0">from ...utils._cython_blas cimport _dot</span>
<span class="s0">from ...utils._openmp_helpers cimport omp_get_thread_num</span>
<span class="s0">from ...utils._typedefs cimport intp_t, float32_t, float64_t, int32_t</span>

<span class="s0">import numpy as np</span>

<span class="s0">from scipy.sparse import issparse</span>
<span class="s0">from numbers import Integral</span>
<span class="s0">from sklearn import get_config</span>
<span class="s0">from sklearn.utils import check_scalar</span>
<span class="s0">from ...utils._openmp_helpers import _openmp_effective_n_threads</span>

<span class="s0">#####################</span>

<span class="s0">cdef float64_t[::1] _sqeuclidean_row_norms64_dense(</span>
    <span class="s0">const float64_t[:, ::1] X,</span>
    <span class="s0">intp_t num_threads,</span>
<span class="s0">):</span>
    <span class="s0">&quot;&quot;&quot;Compute the squared euclidean norm of the rows of X in parallel.</span>

    <span class="s0">This is faster than using np.einsum(&quot;ij, ij-&gt;i&quot;) even when using a single thread.</span>
    <span class="s0">&quot;&quot;&quot;</span>
    <span class="s0">cdef:</span>
        <span class="s0"># Casting for X to remove the const qualifier is needed because APIs</span>
        <span class="s0"># exposed via scipy.linalg.cython_blas aren't reflecting the arguments'</span>
        <span class="s0"># const qualifier.</span>
        <span class="s0"># See: https://github.com/scipy/scipy/issues/14262</span>
        <span class="s0">float64_t * X_ptr = &lt;float64_t *&gt; &amp;X[0, 0]</span>
        <span class="s0">intp_t idx = 0</span>
        <span class="s0">intp_t n = X.shape[0]</span>
        <span class="s0">intp_t d = X.shape[1]</span>
        <span class="s0">float64_t[::1] squared_row_norms = np.empty(n, dtype=np.float64)</span>

    <span class="s0">for idx in prange(n, schedule='static', nogil=True, num_threads=num_threads):</span>
        <span class="s0">squared_row_norms[idx] = _dot(d, X_ptr + idx * d, 1, X_ptr + idx * d, 1)</span>

    <span class="s0">return squared_row_norms</span>


<span class="s0">cdef float64_t[::1] _sqeuclidean_row_norms32_dense(</span>
    <span class="s0">const float32_t[:, ::1] X,</span>
    <span class="s0">intp_t num_threads,</span>
<span class="s0">):</span>
    <span class="s0">&quot;&quot;&quot;Compute the squared euclidean norm of the rows of X in parallel.</span>

    <span class="s0">This is faster than using np.einsum(&quot;ij, ij-&gt;i&quot;) even when using a single thread.</span>
    <span class="s0">&quot;&quot;&quot;</span>
    <span class="s0">cdef:</span>
        <span class="s0"># Casting for X to remove the const qualifier is needed because APIs</span>
        <span class="s0"># exposed via scipy.linalg.cython_blas aren't reflecting the arguments'</span>
        <span class="s0"># const qualifier.</span>
        <span class="s0"># See: https://github.com/scipy/scipy/issues/14262</span>
        <span class="s0">float32_t * X_ptr = &lt;float32_t *&gt; &amp;X[0, 0]</span>
        <span class="s0">intp_t i = 0, j = 0</span>
        <span class="s0">intp_t thread_num</span>
        <span class="s0">intp_t n = X.shape[0]</span>
        <span class="s0">intp_t d = X.shape[1]</span>
        <span class="s0">float64_t[::1] squared_row_norms = np.empty(n, dtype=np.float64)</span>

        <span class="s0"># To upcast the i-th row of X from float32 to float64</span>
        <span class="s0">vector[vector[float64_t]] X_i_upcast = vector[vector[float64_t]](</span>
            <span class="s0">num_threads, vector[float64_t](d)</span>
        <span class="s0">)</span>

    <span class="s0">with nogil, parallel(num_threads=num_threads):</span>
        <span class="s0">thread_num = omp_get_thread_num()</span>

        <span class="s0">for i in prange(n, schedule='static'):</span>
            <span class="s0"># Upcasting the i-th row of X from float32 to float64</span>
            <span class="s0">for j in range(d):</span>
                <span class="s0">X_i_upcast[thread_num][j] = &lt;float64_t&gt; deref(X_ptr + i * d + j)</span>

            <span class="s0">squared_row_norms[i] = _dot(</span>
                <span class="s0">d, X_i_upcast[thread_num].data(), 1,</span>
                <span class="s0">X_i_upcast[thread_num].data(), 1,</span>
            <span class="s0">)</span>

    <span class="s0">return squared_row_norms</span>


<span class="s0">cdef float64_t[::1] _sqeuclidean_row_norms64_sparse(</span>
    <span class="s0">const float64_t[:] X_data,</span>
    <span class="s0">const int32_t[:] X_indptr,</span>
    <span class="s0">intp_t num_threads,</span>
<span class="s0">):</span>
    <span class="s0">cdef:</span>
        <span class="s0">intp_t n = X_indptr.shape[0] - 1</span>
        <span class="s0">int32_t X_i_ptr, idx = 0</span>
        <span class="s0">float64_t[::1] squared_row_norms = np.zeros(n, dtype=np.float64)</span>

    <span class="s0">for idx in prange(n, schedule='static', nogil=True, num_threads=num_threads):</span>
        <span class="s0">for X_i_ptr in range(X_indptr[idx], X_indptr[idx+1]):</span>
            <span class="s0">squared_row_norms[idx] += X_data[X_i_ptr] * X_data[X_i_ptr]</span>

    <span class="s0">return squared_row_norms</span>


<span class="s0">{{for name_suffix in [&quot;64&quot;, &quot;32&quot;]}}</span>

<span class="s0">from ._datasets_pair cimport DatasetsPair{{name_suffix}}</span>


<span class="s0">cpdef float64_t[::1] _sqeuclidean_row_norms{{name_suffix}}(</span>
    <span class="s0">X,</span>
    <span class="s0">intp_t num_threads,</span>
<span class="s0">):</span>
    <span class="s0">if issparse(X):</span>
        <span class="s0"># TODO: remove this instruction which is a cast in the float32 case</span>
        <span class="s0"># by moving squared row norms computations in MiddleTermComputer.</span>
        <span class="s0">X_data = np.asarray(X.data, dtype=np.float64)</span>
        <span class="s0">X_indptr = np.asarray(X.indptr, dtype=np.int32)</span>
        <span class="s0">return _sqeuclidean_row_norms64_sparse(X_data, X_indptr, num_threads)</span>
    <span class="s0">else:</span>
        <span class="s0">return _sqeuclidean_row_norms{{name_suffix}}_dense(X, num_threads)</span>


<span class="s0">cdef class BaseDistancesReduction{{name_suffix}}:</span>
    <span class="s0">&quot;&quot;&quot;</span>
    <span class="s0">Base float{{name_suffix}} implementation template of the pairwise-distances</span>
    <span class="s0">reduction backends.</span>

    <span class="s0">Implementations inherit from this template and may override the several</span>
    <span class="s0">defined hooks as needed in order to easily extend functionality with</span>
    <span class="s0">minimal redundant code.</span>
    <span class="s0">&quot;&quot;&quot;</span>

    <span class="s0">def __init__(</span>
        <span class="s0">self,</span>
        <span class="s0">DatasetsPair{{name_suffix}} datasets_pair,</span>
        <span class="s0">chunk_size=None,</span>
        <span class="s0">strategy=None,</span>
     <span class="s0">):</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t X_n_full_chunks, Y_n_full_chunks</span>

        <span class="s0">if chunk_size is None:</span>
            <span class="s0">chunk_size = get_config().get(&quot;pairwise_dist_chunk_size&quot;, 256)</span>

        <span class="s0">self.chunk_size = check_scalar(chunk_size, &quot;chunk_size&quot;, Integral, min_val=20)</span>

        <span class="s0">self.effective_n_threads = _openmp_effective_n_threads()</span>

        <span class="s0">self.datasets_pair = datasets_pair</span>

        <span class="s0">self.n_samples_X = datasets_pair.n_samples_X()</span>
        <span class="s0">self.X_n_samples_chunk = min(self.n_samples_X, self.chunk_size)</span>
        <span class="s0">X_n_full_chunks = self.n_samples_X // self.X_n_samples_chunk</span>
        <span class="s0">X_n_samples_remainder = self.n_samples_X % self.X_n_samples_chunk</span>
        <span class="s0">self.X_n_chunks = X_n_full_chunks + (X_n_samples_remainder != 0)</span>

        <span class="s0">if X_n_samples_remainder != 0:</span>
            <span class="s0">self.X_n_samples_last_chunk = X_n_samples_remainder</span>
        <span class="s0">else:</span>
            <span class="s0">self.X_n_samples_last_chunk = self.X_n_samples_chunk</span>

        <span class="s0">self.n_samples_Y = datasets_pair.n_samples_Y()</span>
        <span class="s0">self.Y_n_samples_chunk = min(self.n_samples_Y, self.chunk_size)</span>
        <span class="s0">Y_n_full_chunks = self.n_samples_Y // self.Y_n_samples_chunk</span>
        <span class="s0">Y_n_samples_remainder = self.n_samples_Y % self.Y_n_samples_chunk</span>
        <span class="s0">self.Y_n_chunks = Y_n_full_chunks + (Y_n_samples_remainder != 0)</span>

        <span class="s0">if Y_n_samples_remainder != 0:</span>
            <span class="s0">self.Y_n_samples_last_chunk = Y_n_samples_remainder</span>
        <span class="s0">else:</span>
            <span class="s0">self.Y_n_samples_last_chunk = self.Y_n_samples_chunk</span>

        <span class="s0">if strategy is None:</span>
            <span class="s0">strategy = get_config().get(&quot;pairwise_dist_parallel_strategy&quot;, 'auto')</span>

        <span class="s0">if strategy not in ('parallel_on_X', 'parallel_on_Y', 'auto'):</span>
            <span class="s0">raise RuntimeError(f&quot;strategy must be 'parallel_on_X, 'parallel_on_Y', &quot;</span>
                               <span class="s0">f&quot;or 'auto', but currently strategy='{self.strategy}'.&quot;)</span>

        <span class="s0">if strategy == 'auto':</span>
            <span class="s0"># This is a simple heuristic whose constant for the</span>
            <span class="s0"># comparison has been chosen based on experiments.</span>
            <span class="s0"># parallel_on_X has less synchronization overhead than</span>
            <span class="s0"># parallel_on_Y and should therefore be used whenever</span>
            <span class="s0"># n_samples_X is large enough to not starve any of the</span>
            <span class="s0"># available hardware threads.</span>
            <span class="s0">if self.n_samples_Y &lt; self.n_samples_X:</span>
                <span class="s0"># No point to even consider parallelizing on Y in this case. This</span>
                <span class="s0"># is in particular important to do this on machines with a large</span>
                <span class="s0"># number of hardware threads.</span>
                <span class="s0">strategy = 'parallel_on_X'</span>
            <span class="s0">elif 4 * self.chunk_size * self.effective_n_threads &lt; self.n_samples_X:</span>
                <span class="s0"># If Y is larger than X, but X is still large enough to allow for</span>
                <span class="s0"># parallelism, we might still want to favor parallelizing on X.</span>
                <span class="s0">strategy = 'parallel_on_X'</span>
            <span class="s0">else:</span>
                <span class="s0">strategy = 'parallel_on_Y'</span>

        <span class="s0">self.execute_in_parallel_on_Y = strategy == &quot;parallel_on_Y&quot;</span>

        <span class="s0"># Not using less, not using more.</span>
        <span class="s0">self.chunks_n_threads = min(</span>
            <span class="s0">self.Y_n_chunks if self.execute_in_parallel_on_Y else self.X_n_chunks,</span>
            <span class="s0">self.effective_n_threads,</span>
        <span class="s0">)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_X(self) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Perform computation and reduction in parallel on chunks of X.</span>

        <span class="s0">This strategy dispatches tasks statically on threads. Each task</span>
        <span class="s0">processes exactly only one chunk of X, computing and reducing</span>
        <span class="s0">distances matrices between vectors of this chunk and vectors of all</span>
        <span class="s0">chunks of Y, one chunk of Y at a time.</span>

        <span class="s0">This strategy is embarrassingly parallel with no intermediate data</span>
        <span class="s0">structures synchronization at all.</span>

        <span class="s0">Private datastructures are modified internally by threads.</span>

        <span class="s0">Private template methods can be implemented on subclasses to</span>
        <span class="s0">interact with those datastructures at various stages.</span>
        <span class="s0">&quot;&quot;&quot;</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t Y_start, Y_end, X_start, X_end, X_chunk_idx, Y_chunk_idx</span>
            <span class="s0">intp_t thread_num</span>

        <span class="s0">with nogil, parallel(num_threads=self.chunks_n_threads):</span>
            <span class="s0">thread_num = omp_get_thread_num()</span>

            <span class="s0"># Allocating thread datastructures</span>
            <span class="s0">self._parallel_on_X_parallel_init(thread_num)</span>

            <span class="s0">for X_chunk_idx in prange(self.X_n_chunks, schedule='static'):</span>
                <span class="s0">X_start = X_chunk_idx * self.X_n_samples_chunk</span>
                <span class="s0">if X_chunk_idx == self.X_n_chunks - 1:</span>
                    <span class="s0">X_end = X_start + self.X_n_samples_last_chunk</span>
                <span class="s0">else:</span>
                    <span class="s0">X_end = X_start + self.X_n_samples_chunk</span>

                <span class="s0"># Reinitializing thread datastructures for the new X chunk</span>
                <span class="s0">self._parallel_on_X_init_chunk(thread_num, X_start, X_end)</span>

                <span class="s0">for Y_chunk_idx in range(self.Y_n_chunks):</span>
                    <span class="s0">Y_start = Y_chunk_idx * self.Y_n_samples_chunk</span>
                    <span class="s0">if Y_chunk_idx == self.Y_n_chunks - 1:</span>
                        <span class="s0">Y_end = Y_start + self.Y_n_samples_last_chunk</span>
                    <span class="s0">else:</span>
                        <span class="s0">Y_end = Y_start + self.Y_n_samples_chunk</span>

                    <span class="s0">self._parallel_on_X_pre_compute_and_reduce_distances_on_chunks(</span>
                        <span class="s0">X_start, X_end,</span>
                        <span class="s0">Y_start, Y_end,</span>
                        <span class="s0">thread_num,</span>
                    <span class="s0">)</span>

                    <span class="s0">self._compute_and_reduce_distances_on_chunks(</span>
                        <span class="s0">X_start, X_end,</span>
                        <span class="s0">Y_start, Y_end,</span>
                        <span class="s0">thread_num,</span>
                    <span class="s0">)</span>

                <span class="s0"># Adjusting thread datastructures on the full pass on Y</span>
                <span class="s0">self._parallel_on_X_prange_iter_finalize(thread_num, X_start, X_end)</span>

            <span class="s0"># end: for X_chunk_idx</span>

            <span class="s0"># Deallocating thread datastructures</span>
            <span class="s0">self._parallel_on_X_parallel_finalize(thread_num)</span>

        <span class="s0"># end: with nogil, parallel</span>
        <span class="s0">return</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_Y(self) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Perform computation and reduction in parallel on chunks of Y.</span>

        <span class="s0">This strategy is a sequence of embarrassingly parallel subtasks:</span>
        <span class="s0">chunks of X are iterated over sequentially, and for each chunk of X,</span>
        <span class="s0">tasks are dispatched statically on threads. Each task processes one</span>
        <span class="s0">and only one chunk of Y, computing and reducing distances matrices</span>
        <span class="s0">between vectors of the chunk of X and vectors of the Y.</span>

        <span class="s0">It comes with lock-free and parallelized intermediate data structures</span>
        <span class="s0">that synchronize at each iteration of the sequential outer loop on X</span>
        <span class="s0">chunks.</span>

        <span class="s0">Private datastructures are modified internally by threads.</span>

        <span class="s0">Private template methods can be implemented on subclasses to</span>
        <span class="s0">interact with those datastructures at various stages.</span>
        <span class="s0">&quot;&quot;&quot;</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t Y_start, Y_end, X_start, X_end, X_chunk_idx, Y_chunk_idx</span>
            <span class="s0">intp_t thread_num</span>

        <span class="s0"># Allocating datastructures shared by all threads</span>
        <span class="s0">self._parallel_on_Y_init()</span>

        <span class="s0">for X_chunk_idx in range(self.X_n_chunks):</span>
            <span class="s0">X_start = X_chunk_idx * self.X_n_samples_chunk</span>
            <span class="s0">if X_chunk_idx == self.X_n_chunks - 1:</span>
                <span class="s0">X_end = X_start + self.X_n_samples_last_chunk</span>
            <span class="s0">else:</span>
                <span class="s0">X_end = X_start + self.X_n_samples_chunk</span>

            <span class="s0">with nogil, parallel(num_threads=self.chunks_n_threads):</span>
                <span class="s0">thread_num = omp_get_thread_num()</span>

                <span class="s0"># Initializing datastructures used in this thread</span>
                <span class="s0">self._parallel_on_Y_parallel_init(thread_num, X_start, X_end)</span>

                <span class="s0">for Y_chunk_idx in prange(self.Y_n_chunks, schedule='static'):</span>
                    <span class="s0">Y_start = Y_chunk_idx * self.Y_n_samples_chunk</span>
                    <span class="s0">if Y_chunk_idx == self.Y_n_chunks - 1:</span>
                        <span class="s0">Y_end = Y_start + self.Y_n_samples_last_chunk</span>
                    <span class="s0">else:</span>
                        <span class="s0">Y_end = Y_start + self.Y_n_samples_chunk</span>

                    <span class="s0">self._parallel_on_Y_pre_compute_and_reduce_distances_on_chunks(</span>
                        <span class="s0">X_start, X_end,</span>
                        <span class="s0">Y_start, Y_end,</span>
                        <span class="s0">thread_num,</span>
                    <span class="s0">)</span>

                    <span class="s0">self._compute_and_reduce_distances_on_chunks(</span>
                        <span class="s0">X_start, X_end,</span>
                        <span class="s0">Y_start, Y_end,</span>
                        <span class="s0">thread_num,</span>
                    <span class="s0">)</span>
                <span class="s0"># end: prange</span>

            <span class="s0"># end: with nogil, parallel</span>

            <span class="s0"># Synchronizing the thread datastructures with the main ones</span>
            <span class="s0">self._parallel_on_Y_synchronize(X_start, X_end)</span>

        <span class="s0"># end: for X_chunk_idx</span>
        <span class="s0"># Deallocating temporary datastructures and adjusting main datastructures</span>
        <span class="s0">self._parallel_on_Y_finalize()</span>
        <span class="s0">return</span>

    <span class="s0"># Placeholder methods which have to be implemented</span>

    <span class="s0">cdef void _compute_and_reduce_distances_on_chunks(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
        <span class="s0">intp_t Y_start,</span>
        <span class="s0">intp_t Y_end,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Compute the pairwise distances on two chunks of X and Y and reduce them.</span>

        <span class="s0">This is THE core computational method of BaseDistancesReduction{{name_suffix}}.</span>
        <span class="s0">This must be implemented in subclasses agnostically from the parallelization</span>
        <span class="s0">strategies.</span>
        <span class="s0">&quot;&quot;&quot;</span>
        <span class="s0">return</span>

    <span class="s0">def _finalize_results(self, bint return_distance):</span>
        <span class="s0">&quot;&quot;&quot;Callback adapting datastructures before returning results.</span>

        <span class="s0">This must be implemented in subclasses.</span>
        <span class="s0">&quot;&quot;&quot;</span>
        <span class="s0">return None</span>

    <span class="s0"># Placeholder methods which can be implemented</span>

    <span class="s0">cdef void compute_exact_distances(self) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Convert rank-preserving distances to exact distances or recompute them.&quot;&quot;&quot;</span>
        <span class="s0">return</span>

    <span class="s0">cdef void _parallel_on_X_parallel_init(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Allocate datastructures used in a thread given its number.&quot;&quot;&quot;</span>
        <span class="s0">return</span>

    <span class="s0">cdef void _parallel_on_X_init_chunk(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Initialize datastructures used in a thread given its number.</span>

        <span class="s0">In this method, EuclideanDistance specialisations of subclass of</span>
        <span class="s0">BaseDistancesReduction _must_ call:</span>

        <span class="s0">self.middle_term_computer._parallel_on_X_init_chunk(</span>
            <span class="s0">thread_num, X_start, X_end,</span>
        <span class="s0">)</span>

        <span class="s0">to ensure the proper upcast of X[X_start:X_end] to float64 prior</span>
        <span class="s0">to the reduction with float64 accumulator buffers when X.dtype is</span>
        <span class="s0">float32.</span>
        <span class="s0">&quot;&quot;&quot;</span>
        <span class="s0">return</span>

    <span class="s0">cdef void _parallel_on_X_pre_compute_and_reduce_distances_on_chunks(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
        <span class="s0">intp_t Y_start,</span>
        <span class="s0">intp_t Y_end,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Initialize datastructures just before the _compute_and_reduce_distances_on_chunks.</span>

        <span class="s0">In this method, EuclideanDistance specialisations of subclass of</span>
        <span class="s0">BaseDistancesReduction _must_ call:</span>

        <span class="s0">self.middle_term_computer._parallel_on_X_pre_compute_and_reduce_distances_on_chunks(</span>
            <span class="s0">X_start, X_end, Y_start, Y_end, thread_num,</span>
        <span class="s0">)</span>

        <span class="s0">to ensure the proper upcast of Y[Y_start:Y_end] to float64 prior</span>
        <span class="s0">to the reduction with float64 accumulator buffers when Y.dtype is</span>
        <span class="s0">float32.</span>
        <span class="s0">&quot;&quot;&quot;</span>
        <span class="s0">return</span>

    <span class="s0">cdef void _parallel_on_X_prange_iter_finalize(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Interact with datastructures after a reduction on chunks.&quot;&quot;&quot;</span>
        <span class="s0">return</span>

    <span class="s0">cdef void _parallel_on_X_parallel_finalize(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Interact with datastructures after executing all the reductions.&quot;&quot;&quot;</span>
        <span class="s0">return</span>

    <span class="s0">cdef void _parallel_on_Y_init(</span>
        <span class="s0">self,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Allocate datastructures used in all threads.&quot;&quot;&quot;</span>
        <span class="s0">return</span>

    <span class="s0">cdef void _parallel_on_Y_parallel_init(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Initialize datastructures used in a thread given its number.</span>

        <span class="s0">In this method, EuclideanDistance specialisations of subclass of</span>
        <span class="s0">BaseDistancesReduction _must_ call:</span>

        <span class="s0">self.middle_term_computer._parallel_on_Y_parallel_init(</span>
            <span class="s0">thread_num, X_start, X_end,</span>
        <span class="s0">)</span>

        <span class="s0">to ensure the proper upcast of X[X_start:X_end] to float64 prior</span>
        <span class="s0">to the reduction with float64 accumulator buffers when X.dtype is</span>
        <span class="s0">float32.</span>
        <span class="s0">&quot;&quot;&quot;</span>
        <span class="s0">return</span>

    <span class="s0">cdef void _parallel_on_Y_pre_compute_and_reduce_distances_on_chunks(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
        <span class="s0">intp_t Y_start,</span>
        <span class="s0">intp_t Y_end,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Initialize datastructures just before the _compute_and_reduce_distances_on_chunks.</span>

        <span class="s0">In this method, EuclideanDistance specialisations of subclass of</span>
        <span class="s0">BaseDistancesReduction _must_ call:</span>

        <span class="s0">self.middle_term_computer._parallel_on_Y_pre_compute_and_reduce_distances_on_chunks(</span>
            <span class="s0">X_start, X_end, Y_start, Y_end, thread_num,</span>
        <span class="s0">)</span>

        <span class="s0">to ensure the proper upcast of Y[Y_start:Y_end] to float64 prior</span>
        <span class="s0">to the reduction with float64 accumulator buffers when Y.dtype is</span>
        <span class="s0">float32.</span>
        <span class="s0">&quot;&quot;&quot;</span>
        <span class="s0">return</span>

    <span class="s0">cdef void _parallel_on_Y_synchronize(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Update thread datastructures before leaving a parallel region.&quot;&quot;&quot;</span>
        <span class="s0">return</span>

    <span class="s0">cdef void _parallel_on_Y_finalize(</span>
        <span class="s0">self,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Update datastructures after executing all the reductions.&quot;&quot;&quot;</span>
        <span class="s0">return</span>

<span class="s0">{{endfor}}</span>
</pre>
</body>
</html>