<html>
<head>
<title>test_bagging.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #2aacb8;}
.s6 { color: #6aab73;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_bagging.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Testing for the bagging ensemble module (sklearn.ensemble.bagging). 
&quot;&quot;&quot;</span>

<span class="s2"># Author: Gilles Louppe</span>
<span class="s2"># License: BSD 3 clause</span>
<span class="s3">from </span><span class="s1">itertools </span><span class="s3">import </span><span class="s1">cycle</span><span class="s4">, </span><span class="s1">product</span>

<span class="s3">import </span><span class="s1">joblib</span>
<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">import </span><span class="s1">pytest</span>

<span class="s3">import </span><span class="s1">sklearn</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">base </span><span class="s3">import </span><span class="s1">BaseEstimator</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">datasets </span><span class="s3">import </span><span class="s1">load_diabetes</span><span class="s4">, </span><span class="s1">load_iris</span><span class="s4">, </span><span class="s1">make_hastie_10_2</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">dummy </span><span class="s3">import </span><span class="s1">DummyClassifier</span><span class="s4">, </span><span class="s1">DummyRegressor</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">ensemble </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">AdaBoostClassifier</span><span class="s4">,</span>
    <span class="s1">AdaBoostRegressor</span><span class="s4">,</span>
    <span class="s1">BaggingClassifier</span><span class="s4">,</span>
    <span class="s1">BaggingRegressor</span><span class="s4">,</span>
    <span class="s1">HistGradientBoostingClassifier</span><span class="s4">,</span>
    <span class="s1">HistGradientBoostingRegressor</span><span class="s4">,</span>
    <span class="s1">RandomForestClassifier</span><span class="s4">,</span>
    <span class="s1">RandomForestRegressor</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">feature_selection </span><span class="s3">import </span><span class="s1">SelectKBest</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">linear_model </span><span class="s3">import </span><span class="s1">LogisticRegression</span><span class="s4">, </span><span class="s1">Perceptron</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">model_selection </span><span class="s3">import </span><span class="s1">GridSearchCV</span><span class="s4">, </span><span class="s1">ParameterGrid</span><span class="s4">, </span><span class="s1">train_test_split</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">neighbors </span><span class="s3">import </span><span class="s1">KNeighborsClassifier</span><span class="s4">, </span><span class="s1">KNeighborsRegressor</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">pipeline </span><span class="s3">import </span><span class="s1">make_pipeline</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">preprocessing </span><span class="s3">import </span><span class="s1">FunctionTransformer</span><span class="s4">, </span><span class="s1">scale</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">random_projection </span><span class="s3">import </span><span class="s1">SparseRandomProjection</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">svm </span><span class="s3">import </span><span class="s1">SVC</span><span class="s4">, </span><span class="s1">SVR</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">tree </span><span class="s3">import </span><span class="s1">DecisionTreeClassifier</span><span class="s4">, </span><span class="s1">DecisionTreeRegressor</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">utils </span><span class="s3">import </span><span class="s1">check_random_state</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_testing </span><span class="s3">import </span><span class="s1">assert_array_almost_equal</span><span class="s4">, </span><span class="s1">assert_array_equal</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">fixes </span><span class="s3">import </span><span class="s1">CSC_CONTAINERS</span><span class="s4">, </span><span class="s1">CSR_CONTAINERS</span>

<span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>

<span class="s2"># also load the iris dataset</span>
<span class="s2"># and randomly permute it</span>
<span class="s1">iris </span><span class="s4">= </span><span class="s1">load_iris</span><span class="s4">()</span>
<span class="s1">perm </span><span class="s4">= </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">permutation</span><span class="s4">(</span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span><span class="s4">.</span><span class="s1">size</span><span class="s4">)</span>
<span class="s1">iris</span><span class="s4">.</span><span class="s1">data </span><span class="s4">= </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">[</span><span class="s1">perm</span><span class="s4">]</span>
<span class="s1">iris</span><span class="s4">.</span><span class="s1">target </span><span class="s4">= </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span><span class="s4">[</span><span class="s1">perm</span><span class="s4">]</span>

<span class="s2"># also load the diabetes dataset</span>
<span class="s2"># and randomly permute it</span>
<span class="s1">diabetes </span><span class="s4">= </span><span class="s1">load_diabetes</span><span class="s4">()</span>
<span class="s1">perm </span><span class="s4">= </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">permutation</span><span class="s4">(</span><span class="s1">diabetes</span><span class="s4">.</span><span class="s1">target</span><span class="s4">.</span><span class="s1">size</span><span class="s4">)</span>
<span class="s1">diabetes</span><span class="s4">.</span><span class="s1">data </span><span class="s4">= </span><span class="s1">diabetes</span><span class="s4">.</span><span class="s1">data</span><span class="s4">[</span><span class="s1">perm</span><span class="s4">]</span>
<span class="s1">diabetes</span><span class="s4">.</span><span class="s1">target </span><span class="s4">= </span><span class="s1">diabetes</span><span class="s4">.</span><span class="s1">target</span><span class="s4">[</span><span class="s1">perm</span><span class="s4">]</span>


<span class="s3">def </span><span class="s1">test_classification</span><span class="s4">():</span>
    <span class="s2"># Check classification for various parameter settings.</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
    <span class="s4">)</span>
    <span class="s1">grid </span><span class="s4">= </span><span class="s1">ParameterGrid</span><span class="s4">(</span>
        <span class="s4">{</span>
            <span class="s6">&quot;max_samples&quot;</span><span class="s4">: [</span><span class="s5">0.5</span><span class="s4">, </span><span class="s5">1.0</span><span class="s4">],</span>
            <span class="s6">&quot;max_features&quot;</span><span class="s4">: [</span><span class="s5">1</span><span class="s4">, </span><span class="s5">4</span><span class="s4">],</span>
            <span class="s6">&quot;bootstrap&quot;</span><span class="s4">: [</span><span class="s3">True</span><span class="s4">, </span><span class="s3">False</span><span class="s4">],</span>
            <span class="s6">&quot;bootstrap_features&quot;</span><span class="s4">: [</span><span class="s3">True</span><span class="s4">, </span><span class="s3">False</span><span class="s4">],</span>
        <span class="s4">}</span>
    <span class="s4">)</span>
    <span class="s1">estimators </span><span class="s4">= [</span>
        <span class="s3">None</span><span class="s4">,</span>
        <span class="s1">DummyClassifier</span><span class="s4">(),</span>
        <span class="s1">Perceptron</span><span class="s4">(</span><span class="s1">max_iter</span><span class="s4">=</span><span class="s5">20</span><span class="s4">),</span>
        <span class="s1">DecisionTreeClassifier</span><span class="s4">(</span><span class="s1">max_depth</span><span class="s4">=</span><span class="s5">2</span><span class="s4">),</span>
        <span class="s1">KNeighborsClassifier</span><span class="s4">(),</span>
        <span class="s1">SVC</span><span class="s4">(),</span>
    <span class="s4">]</span>
    <span class="s2"># Try different parameter settings with different base classifiers without</span>
    <span class="s2"># doing the full cartesian product to keep the test durations low.</span>
    <span class="s3">for </span><span class="s1">params</span><span class="s4">, </span><span class="s1">estimator </span><span class="s3">in </span><span class="s1">zip</span><span class="s4">(</span><span class="s1">grid</span><span class="s4">, </span><span class="s1">cycle</span><span class="s4">(</span><span class="s1">estimators</span><span class="s4">)):</span>
        <span class="s1">BaggingClassifier</span><span class="s4">(</span>
            <span class="s1">estimator</span><span class="s4">=</span><span class="s1">estimator</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">,</span>
            <span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">2</span><span class="s4">,</span>
            <span class="s4">**</span><span class="s1">params</span><span class="s4">,</span>
        <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">).</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span>
    <span class="s6">&quot;sparse_container, params, method&quot;</span><span class="s4">,</span>
    <span class="s1">product</span><span class="s4">(</span>
        <span class="s1">CSR_CONTAINERS </span><span class="s4">+ </span><span class="s1">CSC_CONTAINERS</span><span class="s4">,</span>
        <span class="s4">[</span>
            <span class="s4">{</span>
                <span class="s6">&quot;max_samples&quot;</span><span class="s4">: </span><span class="s5">0.5</span><span class="s4">,</span>
                <span class="s6">&quot;max_features&quot;</span><span class="s4">: </span><span class="s5">2</span><span class="s4">,</span>
                <span class="s6">&quot;bootstrap&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">,</span>
                <span class="s6">&quot;bootstrap_features&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">,</span>
            <span class="s4">},</span>
            <span class="s4">{</span>
                <span class="s6">&quot;max_samples&quot;</span><span class="s4">: </span><span class="s5">1.0</span><span class="s4">,</span>
                <span class="s6">&quot;max_features&quot;</span><span class="s4">: </span><span class="s5">4</span><span class="s4">,</span>
                <span class="s6">&quot;bootstrap&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">,</span>
                <span class="s6">&quot;bootstrap_features&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">,</span>
            <span class="s4">},</span>
            <span class="s4">{</span><span class="s6">&quot;max_features&quot;</span><span class="s4">: </span><span class="s5">2</span><span class="s4">, </span><span class="s6">&quot;bootstrap&quot;</span><span class="s4">: </span><span class="s3">False</span><span class="s4">, </span><span class="s6">&quot;bootstrap_features&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">},</span>
            <span class="s4">{</span><span class="s6">&quot;max_samples&quot;</span><span class="s4">: </span><span class="s5">0.5</span><span class="s4">, </span><span class="s6">&quot;bootstrap&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">, </span><span class="s6">&quot;bootstrap_features&quot;</span><span class="s4">: </span><span class="s3">False</span><span class="s4">},</span>
        <span class="s4">],</span>
        <span class="s4">[</span><span class="s6">&quot;predict&quot;</span><span class="s4">, </span><span class="s6">&quot;predict_proba&quot;</span><span class="s4">, </span><span class="s6">&quot;predict_log_proba&quot;</span><span class="s4">, </span><span class="s6">&quot;decision_function&quot;</span><span class="s4">],</span>
    <span class="s4">),</span>
<span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_sparse_classification</span><span class="s4">(</span><span class="s1">sparse_container</span><span class="s4">, </span><span class="s1">params</span><span class="s4">, </span><span class="s1">method</span><span class="s4">):</span>
    <span class="s2"># Check classification for various parameter settings on sparse input.</span>

    <span class="s3">class </span><span class="s1">CustomSVC</span><span class="s4">(</span><span class="s1">SVC</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;SVC variant that records the nature of the training set&quot;&quot;&quot;</span>

        <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">):</span>
            <span class="s1">super</span><span class="s4">().</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">data_type_ </span><span class="s4">= </span><span class="s1">type</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
            <span class="s3">return </span><span class="s1">self</span>

    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">scale</span><span class="s4">(</span><span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">), </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
    <span class="s4">)</span>

    <span class="s1">X_train_sparse </span><span class="s4">= </span><span class="s1">sparse_container</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">)</span>
    <span class="s1">X_test_sparse </span><span class="s4">= </span><span class="s1">sparse_container</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
    <span class="s2"># Trained on sparse format</span>
    <span class="s1">sparse_classifier </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
        <span class="s1">estimator</span><span class="s4">=</span><span class="s1">CustomSVC</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s6">&quot;linear&quot;</span><span class="s4">, </span><span class="s1">decision_function_shape</span><span class="s4">=</span><span class="s6">&quot;ovr&quot;</span><span class="s4">),</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">,</span>
        <span class="s4">**</span><span class="s1">params</span><span class="s4">,</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train_sparse</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>
    <span class="s1">sparse_results </span><span class="s4">= </span><span class="s1">getattr</span><span class="s4">(</span><span class="s1">sparse_classifier</span><span class="s4">, </span><span class="s1">method</span><span class="s4">)(</span><span class="s1">X_test_sparse</span><span class="s4">)</span>

    <span class="s2"># Trained on dense format</span>
    <span class="s1">dense_classifier </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
        <span class="s1">estimator</span><span class="s4">=</span><span class="s1">CustomSVC</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s6">&quot;linear&quot;</span><span class="s4">, </span><span class="s1">decision_function_shape</span><span class="s4">=</span><span class="s6">&quot;ovr&quot;</span><span class="s4">),</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">,</span>
        <span class="s4">**</span><span class="s1">params</span><span class="s4">,</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>
    <span class="s1">dense_results </span><span class="s4">= </span><span class="s1">getattr</span><span class="s4">(</span><span class="s1">dense_classifier</span><span class="s4">, </span><span class="s1">method</span><span class="s4">)(</span><span class="s1">X_test</span><span class="s4">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s4">(</span><span class="s1">sparse_results</span><span class="s4">, </span><span class="s1">dense_results</span><span class="s4">)</span>

    <span class="s1">sparse_type </span><span class="s4">= </span><span class="s1">type</span><span class="s4">(</span><span class="s1">X_train_sparse</span><span class="s4">)</span>
    <span class="s1">types </span><span class="s4">= [</span><span class="s1">i</span><span class="s4">.</span><span class="s1">data_type_ </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">sparse_classifier</span><span class="s4">.</span><span class="s1">estimators_</span><span class="s4">]</span>

    <span class="s3">assert </span><span class="s1">all</span><span class="s4">([</span><span class="s1">t </span><span class="s4">== </span><span class="s1">sparse_type </span><span class="s3">for </span><span class="s1">t </span><span class="s3">in </span><span class="s1">types</span><span class="s4">])</span>


<span class="s3">def </span><span class="s1">test_regression</span><span class="s4">():</span>
    <span class="s2"># Check regression for various parameter settings.</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">diabetes</span><span class="s4">.</span><span class="s1">data</span><span class="s4">[:</span><span class="s5">50</span><span class="s4">], </span><span class="s1">diabetes</span><span class="s4">.</span><span class="s1">target</span><span class="s4">[:</span><span class="s5">50</span><span class="s4">], </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
    <span class="s4">)</span>
    <span class="s1">grid </span><span class="s4">= </span><span class="s1">ParameterGrid</span><span class="s4">(</span>
        <span class="s4">{</span>
            <span class="s6">&quot;max_samples&quot;</span><span class="s4">: [</span><span class="s5">0.5</span><span class="s4">, </span><span class="s5">1.0</span><span class="s4">],</span>
            <span class="s6">&quot;max_features&quot;</span><span class="s4">: [</span><span class="s5">0.5</span><span class="s4">, </span><span class="s5">1.0</span><span class="s4">],</span>
            <span class="s6">&quot;bootstrap&quot;</span><span class="s4">: [</span><span class="s3">True</span><span class="s4">, </span><span class="s3">False</span><span class="s4">],</span>
            <span class="s6">&quot;bootstrap_features&quot;</span><span class="s4">: [</span><span class="s3">True</span><span class="s4">, </span><span class="s3">False</span><span class="s4">],</span>
        <span class="s4">}</span>
    <span class="s4">)</span>

    <span class="s3">for </span><span class="s1">estimator </span><span class="s3">in </span><span class="s4">[</span>
        <span class="s3">None</span><span class="s4">,</span>
        <span class="s1">DummyRegressor</span><span class="s4">(),</span>
        <span class="s1">DecisionTreeRegressor</span><span class="s4">(),</span>
        <span class="s1">KNeighborsRegressor</span><span class="s4">(),</span>
        <span class="s1">SVR</span><span class="s4">(),</span>
    <span class="s4">]:</span>
        <span class="s3">for </span><span class="s1">params </span><span class="s3">in </span><span class="s1">grid</span><span class="s4">:</span>
            <span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">=</span><span class="s1">estimator</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">, **</span><span class="s1">params</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span>
                <span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span>
            <span class="s4">).</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s6">&quot;sparse_container&quot;</span><span class="s4">, </span><span class="s1">CSR_CONTAINERS </span><span class="s4">+ </span><span class="s1">CSC_CONTAINERS</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_sparse_regression</span><span class="s4">(</span><span class="s1">sparse_container</span><span class="s4">):</span>
    <span class="s2"># Check regression for various parameter settings on sparse input.</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">diabetes</span><span class="s4">.</span><span class="s1">data</span><span class="s4">[:</span><span class="s5">50</span><span class="s4">], </span><span class="s1">diabetes</span><span class="s4">.</span><span class="s1">target</span><span class="s4">[:</span><span class="s5">50</span><span class="s4">], </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
    <span class="s4">)</span>

    <span class="s3">class </span><span class="s1">CustomSVR</span><span class="s4">(</span><span class="s1">SVR</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;SVC variant that records the nature of the training set&quot;&quot;&quot;</span>

        <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">):</span>
            <span class="s1">super</span><span class="s4">().</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">data_type_ </span><span class="s4">= </span><span class="s1">type</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
            <span class="s3">return </span><span class="s1">self</span>

    <span class="s1">parameter_sets </span><span class="s4">= [</span>
        <span class="s4">{</span>
            <span class="s6">&quot;max_samples&quot;</span><span class="s4">: </span><span class="s5">0.5</span><span class="s4">,</span>
            <span class="s6">&quot;max_features&quot;</span><span class="s4">: </span><span class="s5">2</span><span class="s4">,</span>
            <span class="s6">&quot;bootstrap&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">,</span>
            <span class="s6">&quot;bootstrap_features&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">,</span>
        <span class="s4">},</span>
        <span class="s4">{</span>
            <span class="s6">&quot;max_samples&quot;</span><span class="s4">: </span><span class="s5">1.0</span><span class="s4">,</span>
            <span class="s6">&quot;max_features&quot;</span><span class="s4">: </span><span class="s5">4</span><span class="s4">,</span>
            <span class="s6">&quot;bootstrap&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">,</span>
            <span class="s6">&quot;bootstrap_features&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">,</span>
        <span class="s4">},</span>
        <span class="s4">{</span><span class="s6">&quot;max_features&quot;</span><span class="s4">: </span><span class="s5">2</span><span class="s4">, </span><span class="s6">&quot;bootstrap&quot;</span><span class="s4">: </span><span class="s3">False</span><span class="s4">, </span><span class="s6">&quot;bootstrap_features&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">},</span>
        <span class="s4">{</span><span class="s6">&quot;max_samples&quot;</span><span class="s4">: </span><span class="s5">0.5</span><span class="s4">, </span><span class="s6">&quot;bootstrap&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">, </span><span class="s6">&quot;bootstrap_features&quot;</span><span class="s4">: </span><span class="s3">False</span><span class="s4">},</span>
    <span class="s4">]</span>

    <span class="s1">X_train_sparse </span><span class="s4">= </span><span class="s1">sparse_container</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">)</span>
    <span class="s1">X_test_sparse </span><span class="s4">= </span><span class="s1">sparse_container</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
    <span class="s3">for </span><span class="s1">params </span><span class="s3">in </span><span class="s1">parameter_sets</span><span class="s4">:</span>
        <span class="s2"># Trained on sparse format</span>
        <span class="s1">sparse_classifier </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span>
            <span class="s1">estimator</span><span class="s4">=</span><span class="s1">CustomSVR</span><span class="s4">(), </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">, **</span><span class="s1">params</span>
        <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train_sparse</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>
        <span class="s1">sparse_results </span><span class="s4">= </span><span class="s1">sparse_classifier</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test_sparse</span><span class="s4">)</span>

        <span class="s2"># Trained on dense format</span>
        <span class="s1">dense_results </span><span class="s4">= (</span>
            <span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">=</span><span class="s1">CustomSVR</span><span class="s4">(), </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">, **</span><span class="s1">params</span><span class="s4">)</span>
            <span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>
            <span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
        <span class="s4">)</span>

        <span class="s1">sparse_type </span><span class="s4">= </span><span class="s1">type</span><span class="s4">(</span><span class="s1">X_train_sparse</span><span class="s4">)</span>
        <span class="s1">types </span><span class="s4">= [</span><span class="s1">i</span><span class="s4">.</span><span class="s1">data_type_ </span><span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">sparse_classifier</span><span class="s4">.</span><span class="s1">estimators_</span><span class="s4">]</span>

        <span class="s1">assert_array_almost_equal</span><span class="s4">(</span><span class="s1">sparse_results</span><span class="s4">, </span><span class="s1">dense_results</span><span class="s4">)</span>
        <span class="s3">assert </span><span class="s1">all</span><span class="s4">([</span><span class="s1">t </span><span class="s4">== </span><span class="s1">sparse_type </span><span class="s3">for </span><span class="s1">t </span><span class="s3">in </span><span class="s1">types</span><span class="s4">])</span>
        <span class="s1">assert_array_almost_equal</span><span class="s4">(</span><span class="s1">sparse_results</span><span class="s4">, </span><span class="s1">dense_results</span><span class="s4">)</span>


<span class="s3">class </span><span class="s1">DummySizeEstimator</span><span class="s4">(</span><span class="s1">BaseEstimator</span><span class="s4">):</span>
    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">):</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">training_size_ </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">]</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">training_hash_ </span><span class="s4">= </span><span class="s1">joblib</span><span class="s4">.</span><span class="s1">hash</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">predict</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ones</span><span class="s4">(</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">])</span>


<span class="s3">def </span><span class="s1">test_bootstrap_samples</span><span class="s4">():</span>
    <span class="s2"># Test that bootstrapping samples generate non-perfect base estimators.</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">diabetes</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">diabetes</span><span class="s4">.</span><span class="s1">target</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
    <span class="s4">)</span>

    <span class="s1">estimator </span><span class="s4">= </span><span class="s1">DecisionTreeRegressor</span><span class="s4">().</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s2"># without bootstrap, all trees are perfect on the training set</span>
    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span>
        <span class="s1">estimator</span><span class="s4">=</span><span class="s1">DecisionTreeRegressor</span><span class="s4">(),</span>
        <span class="s1">max_samples</span><span class="s4">=</span><span class="s5">1.0</span><span class="s4">,</span>
        <span class="s1">bootstrap</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">,</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s3">assert </span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">) == </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s2"># with bootstrap, trees are no longer perfect on the training set</span>
    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span>
        <span class="s1">estimator</span><span class="s4">=</span><span class="s1">DecisionTreeRegressor</span><span class="s4">(),</span>
        <span class="s1">max_samples</span><span class="s4">=</span><span class="s5">1.0</span><span class="s4">,</span>
        <span class="s1">bootstrap</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">,</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s3">assert </span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">) &gt; </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s2"># check that each sampling correspond to a complete bootstrap resample.</span>
    <span class="s2"># the size of each bootstrap should be the same as the input data but</span>
    <span class="s2"># the data should be different (checked using the hash of the data).</span>
    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">=</span><span class="s1">DummySizeEstimator</span><span class="s4">(), </span><span class="s1">bootstrap</span><span class="s4">=</span><span class="s3">True</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span>
        <span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span>
    <span class="s4">)</span>
    <span class="s1">training_hash </span><span class="s4">= []</span>
    <span class="s3">for </span><span class="s1">estimator </span><span class="s3">in </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">estimators_</span><span class="s4">:</span>
        <span class="s3">assert </span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">training_size_ </span><span class="s4">== </span><span class="s1">X_train</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">]</span>
        <span class="s1">training_hash</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">training_hash_</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">len</span><span class="s4">(</span><span class="s1">set</span><span class="s4">(</span><span class="s1">training_hash</span><span class="s4">)) == </span><span class="s1">len</span><span class="s4">(</span><span class="s1">training_hash</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_bootstrap_features</span><span class="s4">():</span>
    <span class="s2"># Test that bootstrapping features may generate duplicate features.</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">diabetes</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">diabetes</span><span class="s4">.</span><span class="s1">target</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
    <span class="s4">)</span>

    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span>
        <span class="s1">estimator</span><span class="s4">=</span><span class="s1">DecisionTreeRegressor</span><span class="s4">(),</span>
        <span class="s1">max_features</span><span class="s4">=</span><span class="s5">1.0</span><span class="s4">,</span>
        <span class="s1">bootstrap_features</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">,</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s3">for </span><span class="s1">features </span><span class="s3">in </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">estimators_features_</span><span class="s4">:</span>
        <span class="s3">assert </span><span class="s1">diabetes</span><span class="s4">.</span><span class="s1">data</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">1</span><span class="s4">] == </span><span class="s1">np</span><span class="s4">.</span><span class="s1">unique</span><span class="s4">(</span><span class="s1">features</span><span class="s4">).</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">]</span>

    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span>
        <span class="s1">estimator</span><span class="s4">=</span><span class="s1">DecisionTreeRegressor</span><span class="s4">(),</span>
        <span class="s1">max_features</span><span class="s4">=</span><span class="s5">1.0</span><span class="s4">,</span>
        <span class="s1">bootstrap_features</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">,</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s3">for </span><span class="s1">features </span><span class="s3">in </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">estimators_features_</span><span class="s4">:</span>
        <span class="s3">assert </span><span class="s1">diabetes</span><span class="s4">.</span><span class="s1">data</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">1</span><span class="s4">] &gt; </span><span class="s1">np</span><span class="s4">.</span><span class="s1">unique</span><span class="s4">(</span><span class="s1">features</span><span class="s4">).</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">]</span>


<span class="s3">def </span><span class="s1">test_probability</span><span class="s4">():</span>
    <span class="s2"># Predict probabilities.</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
    <span class="s4">)</span>

    <span class="s3">with </span><span class="s1">np</span><span class="s4">.</span><span class="s1">errstate</span><span class="s4">(</span><span class="s1">divide</span><span class="s4">=</span><span class="s6">&quot;ignore&quot;</span><span class="s4">, </span><span class="s1">invalid</span><span class="s4">=</span><span class="s6">&quot;ignore&quot;</span><span class="s4">):</span>
        <span class="s2"># Normal case</span>
        <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
            <span class="s1">estimator</span><span class="s4">=</span><span class="s1">DecisionTreeClassifier</span><span class="s4">(), </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
        <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

        <span class="s1">assert_array_almost_equal</span><span class="s4">(</span>
            <span class="s1">np</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">), </span><span class="s1">axis</span><span class="s4">=</span><span class="s5">1</span><span class="s4">), </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ones</span><span class="s4">(</span><span class="s1">len</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">))</span>
        <span class="s4">)</span>

        <span class="s1">assert_array_almost_equal</span><span class="s4">(</span>
            <span class="s1">ensemble</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">), </span><span class="s1">np</span><span class="s4">.</span><span class="s1">exp</span><span class="s4">(</span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">predict_log_proba</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">))</span>
        <span class="s4">)</span>

        <span class="s2"># Degenerate case, where some classes are missing</span>
        <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
            <span class="s1">estimator</span><span class="s4">=</span><span class="s1">LogisticRegression</span><span class="s4">(), </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">, </span><span class="s1">max_samples</span><span class="s4">=</span><span class="s5">5</span>
        <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

        <span class="s1">assert_array_almost_equal</span><span class="s4">(</span>
            <span class="s1">np</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">), </span><span class="s1">axis</span><span class="s4">=</span><span class="s5">1</span><span class="s4">), </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ones</span><span class="s4">(</span><span class="s1">len</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">))</span>
        <span class="s4">)</span>

        <span class="s1">assert_array_almost_equal</span><span class="s4">(</span>
            <span class="s1">ensemble</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">), </span><span class="s1">np</span><span class="s4">.</span><span class="s1">exp</span><span class="s4">(</span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">predict_log_proba</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">))</span>
        <span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_oob_score_classification</span><span class="s4">():</span>
    <span class="s2"># Check that oob prediction is a good estimation of the generalization</span>
    <span class="s2"># error.</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
    <span class="s4">)</span>

    <span class="s3">for </span><span class="s1">estimator </span><span class="s3">in </span><span class="s4">[</span><span class="s1">DecisionTreeClassifier</span><span class="s4">(), </span><span class="s1">SVC</span><span class="s4">()]:</span>
        <span class="s1">clf </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
            <span class="s1">estimator</span><span class="s4">=</span><span class="s1">estimator</span><span class="s4">,</span>
            <span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">100</span><span class="s4">,</span>
            <span class="s1">bootstrap</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">oob_score</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">,</span>
        <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

        <span class="s1">test_score </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_test</span><span class="s4">)</span>

        <span class="s3">assert </span><span class="s1">abs</span><span class="s4">(</span><span class="s1">test_score </span><span class="s4">- </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">oob_score_</span><span class="s4">) &lt; </span><span class="s5">0.1</span>

        <span class="s2"># Test with few estimators</span>
        <span class="s1">warn_msg </span><span class="s4">= (</span>
            <span class="s6">&quot;Some inputs do not have OOB scores. This probably means too few &quot;</span>
            <span class="s6">&quot;estimators were used to compute any reliable oob estimates.&quot;</span>
        <span class="s4">)</span>
        <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">warns</span><span class="s4">(</span><span class="s1">UserWarning</span><span class="s4">, </span><span class="s1">match</span><span class="s4">=</span><span class="s1">warn_msg</span><span class="s4">):</span>
            <span class="s1">clf </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
                <span class="s1">estimator</span><span class="s4">=</span><span class="s1">estimator</span><span class="s4">,</span>
                <span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">1</span><span class="s4">,</span>
                <span class="s1">bootstrap</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
                <span class="s1">oob_score</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
                <span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">,</span>
            <span class="s4">)</span>
            <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_oob_score_regression</span><span class="s4">():</span>
    <span class="s2"># Check that oob prediction is a good estimation of the generalization</span>
    <span class="s2"># error.</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">diabetes</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">diabetes</span><span class="s4">.</span><span class="s1">target</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
    <span class="s4">)</span>

    <span class="s1">clf </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span>
        <span class="s1">estimator</span><span class="s4">=</span><span class="s1">DecisionTreeRegressor</span><span class="s4">(),</span>
        <span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">50</span><span class="s4">,</span>
        <span class="s1">bootstrap</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
        <span class="s1">oob_score</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">,</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s1">test_score </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_test</span><span class="s4">)</span>

    <span class="s3">assert </span><span class="s1">abs</span><span class="s4">(</span><span class="s1">test_score </span><span class="s4">- </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">oob_score_</span><span class="s4">) &lt; </span><span class="s5">0.1</span>

    <span class="s2"># Test with few estimators</span>
    <span class="s1">warn_msg </span><span class="s4">= (</span>
        <span class="s6">&quot;Some inputs do not have OOB scores. This probably means too few &quot;</span>
        <span class="s6">&quot;estimators were used to compute any reliable oob estimates.&quot;</span>
    <span class="s4">)</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">warns</span><span class="s4">(</span><span class="s1">UserWarning</span><span class="s4">, </span><span class="s1">match</span><span class="s4">=</span><span class="s1">warn_msg</span><span class="s4">):</span>
        <span class="s1">regr </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span>
            <span class="s1">estimator</span><span class="s4">=</span><span class="s1">DecisionTreeRegressor</span><span class="s4">(),</span>
            <span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">1</span><span class="s4">,</span>
            <span class="s1">bootstrap</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">oob_score</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">regr</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_single_estimator</span><span class="s4">():</span>
    <span class="s2"># Check singleton ensembles.</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">diabetes</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">diabetes</span><span class="s4">.</span><span class="s1">target</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
    <span class="s4">)</span>

    <span class="s1">clf1 </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span>
        <span class="s1">estimator</span><span class="s4">=</span><span class="s1">KNeighborsRegressor</span><span class="s4">(),</span>
        <span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">1</span><span class="s4">,</span>
        <span class="s1">bootstrap</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">bootstrap_features</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">,</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s1">clf2 </span><span class="s4">= </span><span class="s1">KNeighborsRegressor</span><span class="s4">().</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s4">(</span><span class="s1">clf1</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">), </span><span class="s1">clf2</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">))</span>


<span class="s3">def </span><span class="s1">test_error</span><span class="s4">():</span>
    <span class="s2"># Test support of decision_function</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span>
    <span class="s1">base </span><span class="s4">= </span><span class="s1">DecisionTreeClassifier</span><span class="s4">()</span>
    <span class="s3">assert not </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">base</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">), </span><span class="s6">&quot;decision_function&quot;</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_parallel_classification</span><span class="s4">():</span>
    <span class="s2"># Check parallel classification.</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span>
    <span class="s4">)</span>

    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
        <span class="s1">DecisionTreeClassifier</span><span class="s4">(), </span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">3</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s2"># predict_proba</span>
    <span class="s1">y1 </span><span class="s4">= </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
    <span class="s1">ensemble</span><span class="s4">.</span><span class="s1">set_params</span><span class="s4">(</span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>
    <span class="s1">y2 </span><span class="s4">= </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s4">(</span><span class="s1">y1</span><span class="s4">, </span><span class="s1">y2</span><span class="s4">)</span>

    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
        <span class="s1">DecisionTreeClassifier</span><span class="s4">(), </span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">1</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s1">y3 </span><span class="s4">= </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s4">(</span><span class="s1">y1</span><span class="s4">, </span><span class="s1">y3</span><span class="s4">)</span>

    <span class="s2"># decision_function</span>
    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
        <span class="s1">SVC</span><span class="s4">(</span><span class="s1">decision_function_shape</span><span class="s4">=</span><span class="s6">&quot;ovr&quot;</span><span class="s4">), </span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">3</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s1">decisions1 </span><span class="s4">= </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">decision_function</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
    <span class="s1">ensemble</span><span class="s4">.</span><span class="s1">set_params</span><span class="s4">(</span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>
    <span class="s1">decisions2 </span><span class="s4">= </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">decision_function</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s4">(</span><span class="s1">decisions1</span><span class="s4">, </span><span class="s1">decisions2</span><span class="s4">)</span>

    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
        <span class="s1">SVC</span><span class="s4">(</span><span class="s1">decision_function_shape</span><span class="s4">=</span><span class="s6">&quot;ovr&quot;</span><span class="s4">), </span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">1</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s1">decisions3 </span><span class="s4">= </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">decision_function</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s4">(</span><span class="s1">decisions1</span><span class="s4">, </span><span class="s1">decisions3</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_parallel_regression</span><span class="s4">():</span>
    <span class="s2"># Check parallel regression.</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>

    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">diabetes</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">diabetes</span><span class="s4">.</span><span class="s1">target</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
    <span class="s4">)</span>

    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s1">DecisionTreeRegressor</span><span class="s4">(), </span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">3</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span>
        <span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span>
    <span class="s4">)</span>

    <span class="s1">ensemble</span><span class="s4">.</span><span class="s1">set_params</span><span class="s4">(</span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>
    <span class="s1">y1 </span><span class="s4">= </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
    <span class="s1">ensemble</span><span class="s4">.</span><span class="s1">set_params</span><span class="s4">(</span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">2</span><span class="s4">)</span>
    <span class="s1">y2 </span><span class="s4">= </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s4">(</span><span class="s1">y1</span><span class="s4">, </span><span class="s1">y2</span><span class="s4">)</span>

    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s1">DecisionTreeRegressor</span><span class="s4">(), </span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">1</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span>
        <span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span>
    <span class="s4">)</span>

    <span class="s1">y3 </span><span class="s4">= </span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s4">(</span><span class="s1">y1</span><span class="s4">, </span><span class="s1">y3</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_gridsearch</span><span class="s4">():</span>
    <span class="s2"># Check that bagging ensembles can be grid-searched.</span>
    <span class="s2"># Transform iris into a binary classification task</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span>
    <span class="s1">y</span><span class="s4">[</span><span class="s1">y </span><span class="s4">== </span><span class="s5">2</span><span class="s4">] = </span><span class="s5">1</span>

    <span class="s2"># Grid search with scoring based on decision_function</span>
    <span class="s1">parameters </span><span class="s4">= {</span><span class="s6">&quot;n_estimators&quot;</span><span class="s4">: (</span><span class="s5">1</span><span class="s4">, </span><span class="s5">2</span><span class="s4">), </span><span class="s6">&quot;estimator__C&quot;</span><span class="s4">: (</span><span class="s5">1</span><span class="s4">, </span><span class="s5">2</span><span class="s4">)}</span>

    <span class="s1">GridSearchCV</span><span class="s4">(</span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">SVC</span><span class="s4">()), </span><span class="s1">parameters</span><span class="s4">, </span><span class="s1">scoring</span><span class="s4">=</span><span class="s6">&quot;roc_auc&quot;</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_estimator</span><span class="s4">():</span>
    <span class="s2"># Check estimator and its default values.</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>

    <span class="s2"># Classification</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
    <span class="s4">)</span>

    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s3">None</span><span class="s4">, </span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">3</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s3">assert </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">estimator_</span><span class="s4">, </span><span class="s1">DecisionTreeClassifier</span><span class="s4">)</span>

    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
        <span class="s1">DecisionTreeClassifier</span><span class="s4">(), </span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">3</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s3">assert </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">estimator_</span><span class="s4">, </span><span class="s1">DecisionTreeClassifier</span><span class="s4">)</span>

    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">Perceptron</span><span class="s4">(), </span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">3</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span>
        <span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span>
    <span class="s4">)</span>

    <span class="s3">assert </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">estimator_</span><span class="s4">, </span><span class="s1">Perceptron</span><span class="s4">)</span>

    <span class="s2"># Regression</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span>
        <span class="s1">diabetes</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">diabetes</span><span class="s4">.</span><span class="s1">target</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span>
    <span class="s4">)</span>

    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s3">None</span><span class="s4">, </span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">3</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s3">assert </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">estimator_</span><span class="s4">, </span><span class="s1">DecisionTreeRegressor</span><span class="s4">)</span>

    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s1">DecisionTreeRegressor</span><span class="s4">(), </span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">3</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span>
        <span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span>
    <span class="s4">)</span>

    <span class="s3">assert </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">estimator_</span><span class="s4">, </span><span class="s1">DecisionTreeRegressor</span><span class="s4">)</span>

    <span class="s1">ensemble </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s1">SVR</span><span class="s4">(), </span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">3</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">ensemble</span><span class="s4">.</span><span class="s1">estimator_</span><span class="s4">, </span><span class="s1">SVR</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_bagging_with_pipeline</span><span class="s4">():</span>
    <span class="s1">estimator </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
        <span class="s1">make_pipeline</span><span class="s4">(</span><span class="s1">SelectKBest</span><span class="s4">(</span><span class="s1">k</span><span class="s4">=</span><span class="s5">1</span><span class="s4">), </span><span class="s1">DecisionTreeClassifier</span><span class="s4">()), </span><span class="s1">max_features</span><span class="s4">=</span><span class="s5">2</span>
    <span class="s4">)</span>
    <span class="s1">estimator</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">[</span><span class="s5">0</span><span class="s4">].</span><span class="s1">steps</span><span class="s4">[-</span><span class="s5">1</span><span class="s4">][</span><span class="s5">1</span><span class="s4">].</span><span class="s1">random_state</span><span class="s4">, </span><span class="s1">int</span><span class="s4">)</span>


<span class="s3">class </span><span class="s1">DummyZeroEstimator</span><span class="s4">(</span><span class="s1">BaseEstimator</span><span class="s4">):</span>
    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">):</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">classes_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">unique</span><span class="s4">(</span><span class="s1">y</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span>

    <span class="s3">def </span><span class="s1">predict</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">classes_</span><span class="s4">[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">], </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">int</span><span class="s4">)]</span>


<span class="s3">def </span><span class="s1">test_bagging_sample_weight_unsupported_but_passed</span><span class="s4">():</span>
    <span class="s1">estimator </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">DummyZeroEstimator</span><span class="s4">())</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>

    <span class="s1">estimator</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span><span class="s4">).</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">)</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">ValueError</span><span class="s4">):</span>
        <span class="s1">estimator</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span>
            <span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">,</span>
            <span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span><span class="s4">,</span>
            <span class="s1">sample_weight</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">.</span><span class="s1">randint</span><span class="s4">(</span><span class="s5">10</span><span class="s4">, </span><span class="s1">size</span><span class="s4">=(</span><span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">])),</span>
        <span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_warm_start</span><span class="s4">(</span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">42</span><span class="s4">):</span>
    <span class="s2"># Test if fitting incrementally with warm start gives a forest of the</span>
    <span class="s2"># right size and the same results as a normal fit.</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">make_hastie_10_2</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">=</span><span class="s5">20</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>

    <span class="s1">clf_ws </span><span class="s4">= </span><span class="s3">None</span>
    <span class="s3">for </span><span class="s1">n_estimators </span><span class="s3">in </span><span class="s4">[</span><span class="s5">5</span><span class="s4">, </span><span class="s5">10</span><span class="s4">]:</span>
        <span class="s3">if </span><span class="s1">clf_ws </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">clf_ws </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
                <span class="s1">n_estimators</span><span class="s4">=</span><span class="s1">n_estimators</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span><span class="s4">, </span><span class="s1">warm_start</span><span class="s4">=</span><span class="s3">True</span>
            <span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">clf_ws</span><span class="s4">.</span><span class="s1">set_params</span><span class="s4">(</span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s1">n_estimators</span><span class="s4">)</span>
        <span class="s1">clf_ws</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
        <span class="s3">assert </span><span class="s1">len</span><span class="s4">(</span><span class="s1">clf_ws</span><span class="s4">) == </span><span class="s1">n_estimators</span>

    <span class="s1">clf_no_ws </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
        <span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">10</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span><span class="s4">, </span><span class="s1">warm_start</span><span class="s4">=</span><span class="s3">False</span>
    <span class="s4">)</span>
    <span class="s1">clf_no_ws</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

    <span class="s3">assert </span><span class="s1">set</span><span class="s4">([</span><span class="s1">tree</span><span class="s4">.</span><span class="s1">random_state </span><span class="s3">for </span><span class="s1">tree </span><span class="s3">in </span><span class="s1">clf_ws</span><span class="s4">]) == </span><span class="s1">set</span><span class="s4">(</span>
        <span class="s4">[</span><span class="s1">tree</span><span class="s4">.</span><span class="s1">random_state </span><span class="s3">for </span><span class="s1">tree </span><span class="s3">in </span><span class="s1">clf_no_ws</span><span class="s4">]</span>
    <span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_warm_start_smaller_n_estimators</span><span class="s4">():</span>
    <span class="s2"># Test if warm start'ed second fit with smaller n_estimators raises error.</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">make_hastie_10_2</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">=</span><span class="s5">20</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>
    <span class="s1">clf </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">5</span><span class="s4">, </span><span class="s1">warm_start</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">set_params</span><span class="s4">(</span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">4</span><span class="s4">)</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">ValueError</span><span class="s4">):</span>
        <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_warm_start_equal_n_estimators</span><span class="s4">():</span>
    <span class="s2"># Test that nothing happens when fitting without increasing n_estimators</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">make_hastie_10_2</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">=</span><span class="s5">20</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">43</span><span class="s4">)</span>

    <span class="s1">clf </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">5</span><span class="s4">, </span><span class="s1">warm_start</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">83</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>

    <span class="s1">y_pred </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
    <span class="s2"># modify X to nonsense values, this should not change anything</span>
    <span class="s1">X_train </span><span class="s4">+= </span><span class="s5">1.0</span>

    <span class="s1">warn_msg </span><span class="s4">= </span><span class="s6">&quot;Warm-start fitting without increasing n_estimators does not&quot;</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">warns</span><span class="s4">(</span><span class="s1">UserWarning</span><span class="s4">, </span><span class="s1">match</span><span class="s4">=</span><span class="s1">warn_msg</span><span class="s4">):</span>
        <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>
    <span class="s1">assert_array_equal</span><span class="s4">(</span><span class="s1">y_pred</span><span class="s4">, </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">))</span>


<span class="s3">def </span><span class="s1">test_warm_start_equivalence</span><span class="s4">():</span>
    <span class="s2"># warm started classifier with 5+5 estimators should be equivalent to</span>
    <span class="s2"># one classifier with 10 estimators</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">make_hastie_10_2</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">=</span><span class="s5">20</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>
    <span class="s1">X_train</span><span class="s4">, </span><span class="s1">X_test</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">, </span><span class="s1">y_test </span><span class="s4">= </span><span class="s1">train_test_split</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">43</span><span class="s4">)</span>

    <span class="s1">clf_ws </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">5</span><span class="s4">, </span><span class="s1">warm_start</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">3141</span><span class="s4">)</span>
    <span class="s1">clf_ws</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>
    <span class="s1">clf_ws</span><span class="s4">.</span><span class="s1">set_params</span><span class="s4">(</span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">10</span><span class="s4">)</span>
    <span class="s1">clf_ws</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>
    <span class="s1">y1 </span><span class="s4">= </span><span class="s1">clf_ws</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>

    <span class="s1">clf </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">10</span><span class="s4">, </span><span class="s1">warm_start</span><span class="s4">=</span><span class="s3">False</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">3141</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>
    <span class="s1">y2 </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s4">(</span><span class="s1">y1</span><span class="s4">, </span><span class="s1">y2</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_warm_start_with_oob_score_fails</span><span class="s4">():</span>
    <span class="s2"># Check using oob_score and warm_start simultaneously fails</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">make_hastie_10_2</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">=</span><span class="s5">20</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>
    <span class="s1">clf </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">5</span><span class="s4">, </span><span class="s1">warm_start</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">oob_score</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">ValueError</span><span class="s4">):</span>
        <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_oob_score_removed_on_warm_start</span><span class="s4">():</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">make_hastie_10_2</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">=</span><span class="s5">100</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>

    <span class="s1">clf </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">5</span><span class="s4">, </span><span class="s1">oob_score</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

    <span class="s1">clf</span><span class="s4">.</span><span class="s1">set_params</span><span class="s4">(</span><span class="s1">warm_start</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">oob_score</span><span class="s4">=</span><span class="s3">False</span><span class="s4">, </span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">10</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">AttributeError</span><span class="s4">):</span>
        <span class="s1">getattr</span><span class="s4">(</span><span class="s1">clf</span><span class="s4">, </span><span class="s6">&quot;oob_score_&quot;</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_oob_score_consistency</span><span class="s4">():</span>
    <span class="s2"># Make sure OOB scores are identical when random_state, estimator, and</span>
    <span class="s2"># training data are fixed and fitting is done twice</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">make_hastie_10_2</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">=</span><span class="s5">200</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>
    <span class="s1">bagging </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
        <span class="s1">KNeighborsClassifier</span><span class="s4">(),</span>
        <span class="s1">max_samples</span><span class="s4">=</span><span class="s5">0.5</span><span class="s4">,</span>
        <span class="s1">max_features</span><span class="s4">=</span><span class="s5">0.5</span><span class="s4">,</span>
        <span class="s1">oob_score</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">,</span>
    <span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">bagging</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">).</span><span class="s1">oob_score_ </span><span class="s4">== </span><span class="s1">bagging</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">).</span><span class="s1">oob_score_</span>


<span class="s3">def </span><span class="s1">test_estimators_samples</span><span class="s4">():</span>
    <span class="s2"># Check that format of estimators_samples_ is correct and that results</span>
    <span class="s2"># generated at fit time can be identically reproduced at a later time</span>
    <span class="s2"># using data saved in object attributes.</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">make_hastie_10_2</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">=</span><span class="s5">200</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>
    <span class="s1">bagging </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
        <span class="s1">LogisticRegression</span><span class="s4">(),</span>
        <span class="s1">max_samples</span><span class="s4">=</span><span class="s5">0.5</span><span class="s4">,</span>
        <span class="s1">max_features</span><span class="s4">=</span><span class="s5">0.5</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">,</span>
        <span class="s1">bootstrap</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s4">)</span>
    <span class="s1">bagging</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

    <span class="s2"># Get relevant attributes</span>
    <span class="s1">estimators_samples </span><span class="s4">= </span><span class="s1">bagging</span><span class="s4">.</span><span class="s1">estimators_samples_</span>
    <span class="s1">estimators_features </span><span class="s4">= </span><span class="s1">bagging</span><span class="s4">.</span><span class="s1">estimators_features_</span>
    <span class="s1">estimators </span><span class="s4">= </span><span class="s1">bagging</span><span class="s4">.</span><span class="s1">estimators_</span>

    <span class="s2"># Test for correct formatting</span>
    <span class="s3">assert </span><span class="s1">len</span><span class="s4">(</span><span class="s1">estimators_samples</span><span class="s4">) == </span><span class="s1">len</span><span class="s4">(</span><span class="s1">estimators</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">len</span><span class="s4">(</span><span class="s1">estimators_samples</span><span class="s4">[</span><span class="s5">0</span><span class="s4">]) == </span><span class="s1">len</span><span class="s4">(</span><span class="s1">X</span><span class="s4">) // </span><span class="s5">2</span>
    <span class="s3">assert </span><span class="s1">estimators_samples</span><span class="s4">[</span><span class="s5">0</span><span class="s4">].</span><span class="s1">dtype</span><span class="s4">.</span><span class="s1">kind </span><span class="s4">== </span><span class="s6">&quot;i&quot;</span>

    <span class="s2"># Re-fit single estimator to test for consistent sampling</span>
    <span class="s1">estimator_index </span><span class="s4">= </span><span class="s5">0</span>
    <span class="s1">estimator_samples </span><span class="s4">= </span><span class="s1">estimators_samples</span><span class="s4">[</span><span class="s1">estimator_index</span><span class="s4">]</span>
    <span class="s1">estimator_features </span><span class="s4">= </span><span class="s1">estimators_features</span><span class="s4">[</span><span class="s1">estimator_index</span><span class="s4">]</span>
    <span class="s1">estimator </span><span class="s4">= </span><span class="s1">estimators</span><span class="s4">[</span><span class="s1">estimator_index</span><span class="s4">]</span>

    <span class="s1">X_train </span><span class="s4">= (</span><span class="s1">X</span><span class="s4">[</span><span class="s1">estimator_samples</span><span class="s4">])[:, </span><span class="s1">estimator_features</span><span class="s4">]</span>
    <span class="s1">y_train </span><span class="s4">= </span><span class="s1">y</span><span class="s4">[</span><span class="s1">estimator_samples</span><span class="s4">]</span>

    <span class="s1">orig_coefs </span><span class="s4">= </span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">coef_</span>
    <span class="s1">estimator</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>
    <span class="s1">new_coefs </span><span class="s4">= </span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">coef_</span>

    <span class="s1">assert_array_almost_equal</span><span class="s4">(</span><span class="s1">orig_coefs</span><span class="s4">, </span><span class="s1">new_coefs</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_estimators_samples_deterministic</span><span class="s4">():</span>
    <span class="s2"># This test is a regression test to check that with a random step</span>
    <span class="s2"># (e.g. SparseRandomProjection) and a given random state, the results</span>
    <span class="s2"># generated at fit time can be identically reproduced at a later time using</span>
    <span class="s2"># data saved in object attributes. Check issue #9524 for full discussion.</span>

    <span class="s1">iris </span><span class="s4">= </span><span class="s1">load_iris</span><span class="s4">()</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span>

    <span class="s1">base_pipeline </span><span class="s4">= </span><span class="s1">make_pipeline</span><span class="s4">(</span>
        <span class="s1">SparseRandomProjection</span><span class="s4">(</span><span class="s1">n_components</span><span class="s4">=</span><span class="s5">2</span><span class="s4">), </span><span class="s1">LogisticRegression</span><span class="s4">()</span>
    <span class="s4">)</span>
    <span class="s1">clf </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">=</span><span class="s1">base_pipeline</span><span class="s4">, </span><span class="s1">max_samples</span><span class="s4">=</span><span class="s5">0.5</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">pipeline_estimator_coef </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">estimators_</span><span class="s4">[</span><span class="s5">0</span><span class="s4">].</span><span class="s1">steps</span><span class="s4">[-</span><span class="s5">1</span><span class="s4">][</span><span class="s5">1</span><span class="s4">].</span><span class="s1">coef_</span><span class="s4">.</span><span class="s1">copy</span><span class="s4">()</span>

    <span class="s1">estimator </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">estimators_</span><span class="s4">[</span><span class="s5">0</span><span class="s4">]</span>
    <span class="s1">estimator_sample </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">estimators_samples_</span><span class="s4">[</span><span class="s5">0</span><span class="s4">]</span>
    <span class="s1">estimator_feature </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">estimators_features_</span><span class="s4">[</span><span class="s5">0</span><span class="s4">]</span>

    <span class="s1">X_train </span><span class="s4">= (</span><span class="s1">X</span><span class="s4">[</span><span class="s1">estimator_sample</span><span class="s4">])[:, </span><span class="s1">estimator_feature</span><span class="s4">]</span>
    <span class="s1">y_train </span><span class="s4">= </span><span class="s1">y</span><span class="s4">[</span><span class="s1">estimator_sample</span><span class="s4">]</span>

    <span class="s1">estimator</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>
    <span class="s1">assert_array_equal</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">steps</span><span class="s4">[-</span><span class="s5">1</span><span class="s4">][</span><span class="s5">1</span><span class="s4">].</span><span class="s1">coef_</span><span class="s4">, </span><span class="s1">pipeline_estimator_coef</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_max_samples_consistency</span><span class="s4">():</span>
    <span class="s2"># Make sure validated max_samples and original max_samples are identical</span>
    <span class="s2"># when valid integer max_samples supplied by user</span>
    <span class="s1">max_samples </span><span class="s4">= </span><span class="s5">100</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">make_hastie_10_2</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">=</span><span class="s5">2 </span><span class="s4">* </span><span class="s1">max_samples</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>
    <span class="s1">bagging </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span>
        <span class="s1">KNeighborsClassifier</span><span class="s4">(),</span>
        <span class="s1">max_samples</span><span class="s4">=</span><span class="s1">max_samples</span><span class="s4">,</span>
        <span class="s1">max_features</span><span class="s4">=</span><span class="s5">0.5</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">,</span>
    <span class="s4">)</span>
    <span class="s1">bagging</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">bagging</span><span class="s4">.</span><span class="s1">_max_samples </span><span class="s4">== </span><span class="s1">max_samples</span>


<span class="s3">def </span><span class="s1">test_set_oob_score_label_encoding</span><span class="s4">():</span>
    <span class="s2"># Make sure the oob_score doesn't change when the labels change</span>
    <span class="s2"># See: https://github.com/scikit-learn/scikit-learn/issues/8933</span>
    <span class="s1">random_state </span><span class="s4">= </span><span class="s5">5</span>
    <span class="s1">X </span><span class="s4">= [[-</span><span class="s5">1</span><span class="s4">], [</span><span class="s5">0</span><span class="s4">], [</span><span class="s5">1</span><span class="s4">]] * </span><span class="s5">5</span>
    <span class="s1">Y1 </span><span class="s4">= [</span><span class="s6">&quot;A&quot;</span><span class="s4">, </span><span class="s6">&quot;B&quot;</span><span class="s4">, </span><span class="s6">&quot;C&quot;</span><span class="s4">] * </span><span class="s5">5</span>
    <span class="s1">Y2 </span><span class="s4">= [-</span><span class="s5">1</span><span class="s4">, </span><span class="s5">0</span><span class="s4">, </span><span class="s5">1</span><span class="s4">] * </span><span class="s5">5</span>
    <span class="s1">Y3 </span><span class="s4">= [</span><span class="s5">0</span><span class="s4">, </span><span class="s5">1</span><span class="s4">, </span><span class="s5">2</span><span class="s4">] * </span><span class="s5">5</span>
    <span class="s1">x1 </span><span class="s4">= (</span>
        <span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">oob_score</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span><span class="s4">)</span>
        <span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">Y1</span><span class="s4">)</span>
        <span class="s4">.</span><span class="s1">oob_score_</span>
    <span class="s4">)</span>
    <span class="s1">x2 </span><span class="s4">= (</span>
        <span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">oob_score</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span><span class="s4">)</span>
        <span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">Y2</span><span class="s4">)</span>
        <span class="s4">.</span><span class="s1">oob_score_</span>
    <span class="s4">)</span>
    <span class="s1">x3 </span><span class="s4">= (</span>
        <span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">oob_score</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span><span class="s4">)</span>
        <span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">Y3</span><span class="s4">)</span>
        <span class="s4">.</span><span class="s1">oob_score_</span>
    <span class="s4">)</span>
    <span class="s3">assert </span><span class="s4">[</span><span class="s1">x1</span><span class="s4">, </span><span class="s1">x2</span><span class="s4">] == [</span><span class="s1">x3</span><span class="s4">, </span><span class="s1">x3</span><span class="s4">]</span>


<span class="s3">def </span><span class="s1">replace</span><span class="s4">(</span><span class="s1">X</span><span class="s4">):</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">astype</span><span class="s4">(</span><span class="s6">&quot;float&quot;</span><span class="s4">, </span><span class="s1">copy</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s1">X</span><span class="s4">[~</span><span class="s1">np</span><span class="s4">.</span><span class="s1">isfinite</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)] = </span><span class="s5">0</span>
    <span class="s3">return </span><span class="s1">X</span>


<span class="s3">def </span><span class="s1">test_bagging_regressor_with_missing_inputs</span><span class="s4">():</span>
    <span class="s2"># Check that BaggingRegressor can accept X with missing/infinite data</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span>
        <span class="s4">[</span>
            <span class="s4">[</span><span class="s5">1</span><span class="s4">, </span><span class="s5">3</span><span class="s4">, </span><span class="s5">5</span><span class="s4">],</span>
            <span class="s4">[</span><span class="s5">2</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s5">6</span><span class="s4">],</span>
            <span class="s4">[</span><span class="s5">2</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">nan</span><span class="s4">, </span><span class="s5">6</span><span class="s4">],</span>
            <span class="s4">[</span><span class="s5">2</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span><span class="s4">, </span><span class="s5">6</span><span class="s4">],</span>
            <span class="s4">[</span><span class="s5">2</span><span class="s4">, -</span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span><span class="s4">, </span><span class="s5">6</span><span class="s4">],</span>
        <span class="s4">]</span>
    <span class="s4">)</span>
    <span class="s1">y_values </span><span class="s4">= [</span>
        <span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s5">2</span><span class="s4">, </span><span class="s5">3</span><span class="s4">, </span><span class="s5">3</span><span class="s4">, </span><span class="s5">3</span><span class="s4">, </span><span class="s5">3</span><span class="s4">]),</span>
        <span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span>
            <span class="s4">[</span>
                <span class="s4">[</span><span class="s5">2</span><span class="s4">, </span><span class="s5">1</span><span class="s4">, </span><span class="s5">9</span><span class="s4">],</span>
                <span class="s4">[</span><span class="s5">3</span><span class="s4">, </span><span class="s5">6</span><span class="s4">, </span><span class="s5">8</span><span class="s4">],</span>
                <span class="s4">[</span><span class="s5">3</span><span class="s4">, </span><span class="s5">6</span><span class="s4">, </span><span class="s5">8</span><span class="s4">],</span>
                <span class="s4">[</span><span class="s5">3</span><span class="s4">, </span><span class="s5">6</span><span class="s4">, </span><span class="s5">8</span><span class="s4">],</span>
                <span class="s4">[</span><span class="s5">3</span><span class="s4">, </span><span class="s5">6</span><span class="s4">, </span><span class="s5">8</span><span class="s4">],</span>
            <span class="s4">]</span>
        <span class="s4">),</span>
    <span class="s4">]</span>
    <span class="s3">for </span><span class="s1">y </span><span class="s3">in </span><span class="s1">y_values</span><span class="s4">:</span>
        <span class="s1">regressor </span><span class="s4">= </span><span class="s1">DecisionTreeRegressor</span><span class="s4">()</span>
        <span class="s1">pipeline </span><span class="s4">= </span><span class="s1">make_pipeline</span><span class="s4">(</span><span class="s1">FunctionTransformer</span><span class="s4">(</span><span class="s1">replace</span><span class="s4">), </span><span class="s1">regressor</span><span class="s4">)</span>
        <span class="s1">pipeline</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">).</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s1">bagging_regressor </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s1">pipeline</span><span class="s4">)</span>
        <span class="s1">y_hat </span><span class="s4">= </span><span class="s1">bagging_regressor</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">).</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s3">assert </span><span class="s1">y</span><span class="s4">.</span><span class="s1">shape </span><span class="s4">== </span><span class="s1">y_hat</span><span class="s4">.</span><span class="s1">shape</span>

        <span class="s2"># Verify that exceptions can be raised by wrapper regressor</span>
        <span class="s1">regressor </span><span class="s4">= </span><span class="s1">DecisionTreeRegressor</span><span class="s4">()</span>
        <span class="s1">pipeline </span><span class="s4">= </span><span class="s1">make_pipeline</span><span class="s4">(</span><span class="s1">regressor</span><span class="s4">)</span>
        <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">ValueError</span><span class="s4">):</span>
            <span class="s1">pipeline</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
        <span class="s1">bagging_regressor </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s1">pipeline</span><span class="s4">)</span>
        <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">ValueError</span><span class="s4">):</span>
            <span class="s1">bagging_regressor</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_bagging_classifier_with_missing_inputs</span><span class="s4">():</span>
    <span class="s2"># Check that BaggingClassifier can accept X with missing/infinite data</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span>
        <span class="s4">[</span>
            <span class="s4">[</span><span class="s5">1</span><span class="s4">, </span><span class="s5">3</span><span class="s4">, </span><span class="s5">5</span><span class="s4">],</span>
            <span class="s4">[</span><span class="s5">2</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s5">6</span><span class="s4">],</span>
            <span class="s4">[</span><span class="s5">2</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">nan</span><span class="s4">, </span><span class="s5">6</span><span class="s4">],</span>
            <span class="s4">[</span><span class="s5">2</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span><span class="s4">, </span><span class="s5">6</span><span class="s4">],</span>
            <span class="s4">[</span><span class="s5">2</span><span class="s4">, -</span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span><span class="s4">, </span><span class="s5">6</span><span class="s4">],</span>
        <span class="s4">]</span>
    <span class="s4">)</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s5">3</span><span class="s4">, </span><span class="s5">6</span><span class="s4">, </span><span class="s5">6</span><span class="s4">, </span><span class="s5">6</span><span class="s4">, </span><span class="s5">6</span><span class="s4">])</span>
    <span class="s1">classifier </span><span class="s4">= </span><span class="s1">DecisionTreeClassifier</span><span class="s4">()</span>
    <span class="s1">pipeline </span><span class="s4">= </span><span class="s1">make_pipeline</span><span class="s4">(</span><span class="s1">FunctionTransformer</span><span class="s4">(</span><span class="s1">replace</span><span class="s4">), </span><span class="s1">classifier</span><span class="s4">)</span>
    <span class="s1">pipeline</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">).</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
    <span class="s1">bagging_classifier </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">pipeline</span><span class="s4">)</span>
    <span class="s1">bagging_classifier</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">y_hat </span><span class="s4">= </span><span class="s1">bagging_classifier</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">y</span><span class="s4">.</span><span class="s1">shape </span><span class="s4">== </span><span class="s1">y_hat</span><span class="s4">.</span><span class="s1">shape</span>
    <span class="s1">bagging_classifier</span><span class="s4">.</span><span class="s1">predict_log_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
    <span class="s1">bagging_classifier</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s2"># Verify that exceptions can be raised by wrapper classifier</span>
    <span class="s1">classifier </span><span class="s4">= </span><span class="s1">DecisionTreeClassifier</span><span class="s4">()</span>
    <span class="s1">pipeline </span><span class="s4">= </span><span class="s1">make_pipeline</span><span class="s4">(</span><span class="s1">classifier</span><span class="s4">)</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">ValueError</span><span class="s4">):</span>
        <span class="s1">pipeline</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">bagging_classifier </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">pipeline</span><span class="s4">)</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">ValueError</span><span class="s4">):</span>
        <span class="s1">bagging_classifier</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_bagging_small_max_features</span><span class="s4">():</span>
    <span class="s2"># Check that Bagging estimator can accept low fractional max_features</span>

    <span class="s1">X </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([[</span><span class="s5">1</span><span class="s4">, </span><span class="s5">2</span><span class="s4">], [</span><span class="s5">3</span><span class="s4">, </span><span class="s5">4</span><span class="s4">]])</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s5">1</span><span class="s4">, </span><span class="s5">0</span><span class="s4">])</span>

    <span class="s1">bagging </span><span class="s4">= </span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">LogisticRegression</span><span class="s4">(), </span><span class="s1">max_features</span><span class="s4">=</span><span class="s5">0.3</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>
    <span class="s1">bagging</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_bagging_get_estimators_indices</span><span class="s4">():</span>
    <span class="s2"># Check that Bagging estimator can generate sample indices properly</span>
    <span class="s2"># Non-regression test for:</span>
    <span class="s2"># https://github.com/scikit-learn/scikit-learn/issues/16436</span>

    <span class="s1">rng </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">random</span><span class="s4">.</span><span class="s1">RandomState</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">randn</span><span class="s4">(</span><span class="s5">13</span><span class="s4">, </span><span class="s5">4</span><span class="s4">)</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">arange</span><span class="s4">(</span><span class="s5">13</span><span class="s4">)</span>

    <span class="s3">class </span><span class="s1">MyEstimator</span><span class="s4">(</span><span class="s1">DecisionTreeRegressor</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;An estimator which stores y indices information at fit.&quot;&quot;&quot;</span>

        <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">):</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_sample_indices </span><span class="s4">= </span><span class="s1">y</span>

    <span class="s1">clf </span><span class="s4">= </span><span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">=</span><span class="s1">MyEstimator</span><span class="s4">(), </span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">1</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s5">0</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

    <span class="s1">assert_array_equal</span><span class="s4">(</span><span class="s1">clf</span><span class="s4">.</span><span class="s1">estimators_</span><span class="s4">[</span><span class="s5">0</span><span class="s4">].</span><span class="s1">_sample_indices</span><span class="s4">, </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">estimators_samples_</span><span class="s4">[</span><span class="s5">0</span><span class="s4">])</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span>
    <span class="s6">&quot;bagging, expected_allow_nan&quot;</span><span class="s4">,</span>
    <span class="s4">[</span>
        <span class="s4">(</span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">HistGradientBoostingClassifier</span><span class="s4">(</span><span class="s1">max_iter</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)), </span><span class="s3">True</span><span class="s4">),</span>
        <span class="s4">(</span><span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s1">HistGradientBoostingRegressor</span><span class="s4">(</span><span class="s1">max_iter</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)), </span><span class="s3">True</span><span class="s4">),</span>
        <span class="s4">(</span><span class="s1">BaggingClassifier</span><span class="s4">(</span><span class="s1">LogisticRegression</span><span class="s4">()), </span><span class="s3">False</span><span class="s4">),</span>
        <span class="s4">(</span><span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s1">SVR</span><span class="s4">()), </span><span class="s3">False</span><span class="s4">),</span>
    <span class="s4">],</span>
<span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_bagging_allow_nan_tag</span><span class="s4">(</span><span class="s1">bagging</span><span class="s4">, </span><span class="s1">expected_allow_nan</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Check that bagging inherits allow_nan tag.&quot;&quot;&quot;</span>
    <span class="s3">assert </span><span class="s1">bagging</span><span class="s4">.</span><span class="s1">_get_tags</span><span class="s4">()[</span><span class="s6">&quot;allow_nan&quot;</span><span class="s4">] == </span><span class="s1">expected_allow_nan</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span>
    <span class="s6">&quot;model&quot;</span><span class="s4">,</span>
    <span class="s4">[</span>
        <span class="s1">BaggingClassifier</span><span class="s4">(</span>
            <span class="s1">estimator</span><span class="s4">=</span><span class="s1">RandomForestClassifier</span><span class="s4">(</span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">1</span><span class="s4">), </span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">1</span>
        <span class="s4">),</span>
        <span class="s1">BaggingRegressor</span><span class="s4">(</span>
            <span class="s1">estimator</span><span class="s4">=</span><span class="s1">RandomForestRegressor</span><span class="s4">(</span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">1</span><span class="s4">), </span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">1</span>
        <span class="s4">),</span>
    <span class="s4">],</span>
<span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_bagging_with_metadata_routing</span><span class="s4">(</span><span class="s1">model</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Make sure that metadata routing works with non-default estimator.&quot;&quot;&quot;</span>
    <span class="s3">with </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">config_context</span><span class="s4">(</span><span class="s1">enable_metadata_routing</span><span class="s4">=</span><span class="s3">True</span><span class="s4">):</span>
        <span class="s1">model</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span><span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span>
    <span class="s6">&quot;model&quot;</span><span class="s4">,</span>
    <span class="s4">[</span>
        <span class="s1">BaggingClassifier</span><span class="s4">(</span>
            <span class="s1">estimator</span><span class="s4">=</span><span class="s1">AdaBoostClassifier</span><span class="s4">(</span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">1</span><span class="s4">, </span><span class="s1">algorithm</span><span class="s4">=</span><span class="s6">&quot;SAMME&quot;</span><span class="s4">),</span>
            <span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">1</span><span class="s4">,</span>
        <span class="s4">),</span>
        <span class="s1">BaggingRegressor</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">=</span><span class="s1">AdaBoostRegressor</span><span class="s4">(</span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">1</span><span class="s4">), </span><span class="s1">n_estimators</span><span class="s4">=</span><span class="s5">1</span><span class="s4">),</span>
    <span class="s4">],</span>
<span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_bagging_without_support_metadata_routing</span><span class="s4">(</span><span class="s1">model</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Make sure that we still can use an estimator that does not implement the 
    metadata routing.&quot;&quot;&quot;</span>
    <span class="s1">model</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span><span class="s4">, </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span><span class="s4">)</span>
</pre>
</body>
</html>