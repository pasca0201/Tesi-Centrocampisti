<html>
<head>
<title>test_sgd.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #6aab73;}
.s4 { color: #2aacb8;}
.s5 { color: #7a7e85;}
.s6 { color: #5f826b; font-style: italic;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_sgd.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">pickle</span>
<span class="s0">from </span><span class="s1">unittest</span><span class="s2">.</span><span class="s1">mock </span><span class="s0">import </span><span class="s1">Mock</span>

<span class="s0">import </span><span class="s1">joblib</span>
<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">import </span><span class="s1">scipy</span><span class="s2">.</span><span class="s1">sparse </span><span class="s0">as </span><span class="s1">sp</span>

<span class="s0">from </span><span class="s1">sklearn </span><span class="s0">import </span><span class="s1">datasets</span><span class="s2">, </span><span class="s1">linear_model</span><span class="s2">, </span><span class="s1">metrics</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">base </span><span class="s0">import </span><span class="s1">clone</span><span class="s2">, </span><span class="s1">is_classifier</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">exceptions </span><span class="s0">import </span><span class="s1">ConvergenceWarning</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">kernel_approximation </span><span class="s0">import </span><span class="s1">Nystroem</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">linear_model </span><span class="s0">import </span><span class="s1">_sgd_fast </span><span class="s0">as </span><span class="s1">sgd_fast</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">linear_model </span><span class="s0">import </span><span class="s1">_stochastic_gradient</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">model_selection </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">RandomizedSearchCV</span><span class="s2">,</span>
    <span class="s1">ShuffleSplit</span><span class="s2">,</span>
    <span class="s1">StratifiedShuffleSplit</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">pipeline </span><span class="s0">import </span><span class="s1">make_pipeline</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">preprocessing </span><span class="s0">import </span><span class="s1">LabelEncoder</span><span class="s2">, </span><span class="s1">MinMaxScaler</span><span class="s2">, </span><span class="s1">StandardScaler</span><span class="s2">, </span><span class="s1">scale</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">svm </span><span class="s0">import </span><span class="s1">OneClassSVM</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">_testing </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">assert_allclose</span><span class="s2">,</span>
    <span class="s1">assert_almost_equal</span><span class="s2">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">,</span>
    <span class="s1">assert_array_equal</span><span class="s2">,</span>
    <span class="s1">ignore_warnings</span><span class="s2">,</span>
<span class="s2">)</span>


<span class="s0">def </span><span class="s1">_update_kwargs</span><span class="s2">(</span><span class="s1">kwargs</span><span class="s2">):</span>
    <span class="s0">if </span><span class="s3">&quot;random_state&quot; </span><span class="s0">not in </span><span class="s1">kwargs</span><span class="s2">:</span>
        <span class="s1">kwargs</span><span class="s2">[</span><span class="s3">&quot;random_state&quot;</span><span class="s2">] = </span><span class="s4">42</span>

    <span class="s0">if </span><span class="s3">&quot;tol&quot; </span><span class="s0">not in </span><span class="s1">kwargs</span><span class="s2">:</span>
        <span class="s1">kwargs</span><span class="s2">[</span><span class="s3">&quot;tol&quot;</span><span class="s2">] = </span><span class="s0">None</span>
    <span class="s0">if </span><span class="s3">&quot;max_iter&quot; </span><span class="s0">not in </span><span class="s1">kwargs</span><span class="s2">:</span>
        <span class="s1">kwargs</span><span class="s2">[</span><span class="s3">&quot;max_iter&quot;</span><span class="s2">] = </span><span class="s4">5</span>


<span class="s0">class </span><span class="s1">_SparseSGDClassifier</span><span class="s2">(</span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDClassifier</span><span class="s2">):</span>
    <span class="s0">def </span><span class="s1">fit</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">):</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sp</span><span class="s2">.</span><span class="s1">csr_matrix</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">super</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">):</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sp</span><span class="s2">.</span><span class="s1">csr_matrix</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">super</span><span class="s2">().</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">):</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sp</span><span class="s2">.</span><span class="s1">csr_matrix</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">super</span><span class="s2">().</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">):</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sp</span><span class="s2">.</span><span class="s1">csr_matrix</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">super</span><span class="s2">().</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>


<span class="s0">class </span><span class="s1">_SparseSGDRegressor</span><span class="s2">(</span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDRegressor</span><span class="s2">):</span>
    <span class="s0">def </span><span class="s1">fit</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">):</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sp</span><span class="s2">.</span><span class="s1">csr_matrix</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDRegressor</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">):</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sp</span><span class="s2">.</span><span class="s1">csr_matrix</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDRegressor</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">):</span>
        <span class="s5"># XXX untested as of v0.22</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sp</span><span class="s2">.</span><span class="s1">csr_matrix</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDRegressor</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">)</span>


<span class="s0">class </span><span class="s1">_SparseSGDOneClassSVM</span><span class="s2">(</span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDOneClassSVM</span><span class="s2">):</span>
    <span class="s0">def </span><span class="s1">fit</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">):</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sp</span><span class="s2">.</span><span class="s1">csr_matrix</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDOneClassSVM</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">):</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sp</span><span class="s2">.</span><span class="s1">csr_matrix</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDOneClassSVM</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">):</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">sp</span><span class="s2">.</span><span class="s1">csr_matrix</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDOneClassSVM</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">SGDClassifier</span><span class="s2">(**</span><span class="s1">kwargs</span><span class="s2">):</span>
    <span class="s1">_update_kwargs</span><span class="s2">(</span><span class="s1">kwargs</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDClassifier</span><span class="s2">(**</span><span class="s1">kwargs</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">SGDRegressor</span><span class="s2">(**</span><span class="s1">kwargs</span><span class="s2">):</span>
    <span class="s1">_update_kwargs</span><span class="s2">(</span><span class="s1">kwargs</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDRegressor</span><span class="s2">(**</span><span class="s1">kwargs</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">SGDOneClassSVM</span><span class="s2">(**</span><span class="s1">kwargs</span><span class="s2">):</span>
    <span class="s1">_update_kwargs</span><span class="s2">(</span><span class="s1">kwargs</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDOneClassSVM</span><span class="s2">(**</span><span class="s1">kwargs</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">SparseSGDClassifier</span><span class="s2">(**</span><span class="s1">kwargs</span><span class="s2">):</span>
    <span class="s1">_update_kwargs</span><span class="s2">(</span><span class="s1">kwargs</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">_SparseSGDClassifier</span><span class="s2">(**</span><span class="s1">kwargs</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">SparseSGDRegressor</span><span class="s2">(**</span><span class="s1">kwargs</span><span class="s2">):</span>
    <span class="s1">_update_kwargs</span><span class="s2">(</span><span class="s1">kwargs</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">_SparseSGDRegressor</span><span class="s2">(**</span><span class="s1">kwargs</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">(**</span><span class="s1">kwargs</span><span class="s2">):</span>
    <span class="s1">_update_kwargs</span><span class="s2">(</span><span class="s1">kwargs</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">_SparseSGDOneClassSVM</span><span class="s2">(**</span><span class="s1">kwargs</span><span class="s2">)</span>


<span class="s5"># Test Data</span>

<span class="s5"># test sample 1</span>
<span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[-</span><span class="s4">2</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">], [-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">], [-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">2</span><span class="s2">], [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">], [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">], [</span><span class="s4">2</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]])</span>
<span class="s1">Y </span><span class="s2">= [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]</span>
<span class="s1">T </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">], [</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">], [</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]])</span>
<span class="s1">true_result </span><span class="s2">= [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]</span>

<span class="s5"># test sample 2; string class labels</span>
<span class="s1">X2 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span>
    <span class="s2">[</span>
        <span class="s2">[-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">],</span>
        <span class="s2">[-</span><span class="s4">0.75</span><span class="s2">, </span><span class="s4">0.5</span><span class="s2">],</span>
        <span class="s2">[-</span><span class="s4">1.5</span><span class="s2">, </span><span class="s4">1.5</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">0.75</span><span class="s2">, </span><span class="s4">0.5</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">1.5</span><span class="s2">, </span><span class="s4">1.5</span><span class="s2">],</span>
        <span class="s2">[-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">0</span><span class="s2">, -</span><span class="s4">0.5</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">],</span>
    <span class="s2">]</span>
<span class="s2">)</span>
<span class="s1">Y2 </span><span class="s2">= [</span><span class="s3">&quot;one&quot;</span><span class="s2">] * </span><span class="s4">3 </span><span class="s2">+ [</span><span class="s3">&quot;two&quot;</span><span class="s2">] * </span><span class="s4">3 </span><span class="s2">+ [</span><span class="s3">&quot;three&quot;</span><span class="s2">] * </span><span class="s4">3</span>
<span class="s1">T2 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[-</span><span class="s4">1.5</span><span class="s2">, </span><span class="s4">0.5</span><span class="s2">], [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">], [</span><span class="s4">0</span><span class="s2">, -</span><span class="s4">2</span><span class="s2">]])</span>
<span class="s1">true_result2 </span><span class="s2">= [</span><span class="s3">&quot;one&quot;</span><span class="s2">, </span><span class="s3">&quot;two&quot;</span><span class="s2">, </span><span class="s3">&quot;three&quot;</span><span class="s2">]</span>

<span class="s5"># test sample 3</span>
<span class="s1">X3 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span>
    <span class="s2">[</span>
        <span class="s2">[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">],</span>
    <span class="s2">]</span>
<span class="s2">)</span>
<span class="s1">Y3 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">])</span>

<span class="s5"># test sample 4 - two more or less redundant feature groups</span>
<span class="s1">X4 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span>
    <span class="s2">[</span>
        <span class="s2">[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">0.9</span><span class="s2">, </span><span class="s4">0.8</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">0.84</span><span class="s2">, </span><span class="s4">0.98</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">0.96</span><span class="s2">, </span><span class="s4">0.88</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">0.91</span><span class="s2">, </span><span class="s4">0.99</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0.89</span><span class="s2">, </span><span class="s4">0.91</span><span class="s2">, </span><span class="s4">1</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0.79</span><span class="s2">, </span><span class="s4">0.84</span><span class="s2">, </span><span class="s4">1</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0.91</span><span class="s2">, </span><span class="s4">0.95</span><span class="s2">, </span><span class="s4">1</span><span class="s2">],</span>
        <span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">0.93</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">],</span>
    <span class="s2">]</span>
<span class="s2">)</span>
<span class="s1">Y4 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">])</span>

<span class="s1">iris </span><span class="s2">= </span><span class="s1">datasets</span><span class="s2">.</span><span class="s1">load_iris</span><span class="s2">()</span>

<span class="s5"># test sample 5 - test sample 1 as binary classification problem</span>
<span class="s1">X5 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[-</span><span class="s4">2</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">], [-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">], [-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">2</span><span class="s2">], [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">], [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">], [</span><span class="s4">2</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]])</span>
<span class="s1">Y5 </span><span class="s2">= [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]</span>
<span class="s1">true_result5 </span><span class="s2">= [</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]</span>


<span class="s5">###############################################################################</span>
<span class="s5"># Common Test Case to classification and regression</span>


<span class="s5"># a simple implementation of ASGD to use for testing</span>
<span class="s5"># uses squared loss to find the gradient</span>
<span class="s0">def </span><span class="s1">asgd</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">eta</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">weight_init</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">intercept_init</span><span class="s2">=</span><span class="s4">0.0</span><span class="s2">):</span>
    <span class="s0">if </span><span class="s1">weight_init </span><span class="s0">is None</span><span class="s2">:</span>
        <span class="s1">weights </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">weights </span><span class="s2">= </span><span class="s1">weight_init</span>

    <span class="s1">average_weights </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s1">intercept </span><span class="s2">= </span><span class="s1">intercept_init</span>
    <span class="s1">average_intercept </span><span class="s2">= </span><span class="s4">0.0</span>
    <span class="s1">decay </span><span class="s2">= </span><span class="s4">1.0</span>

    <span class="s5"># sparse data has a fixed decay of .01</span>
    <span class="s0">if </span><span class="s1">klass </span><span class="s0">in </span><span class="s2">(</span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">):</span>
        <span class="s1">decay </span><span class="s2">= </span><span class="s4">0.01</span>

    <span class="s0">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">entry </span><span class="s0">in </span><span class="s1">enumerate</span><span class="s2">(</span><span class="s1">X</span><span class="s2">):</span>
        <span class="s1">p </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">entry</span><span class="s2">, </span><span class="s1">weights</span><span class="s2">)</span>
        <span class="s1">p </span><span class="s2">+= </span><span class="s1">intercept</span>
        <span class="s1">gradient </span><span class="s2">= </span><span class="s1">p </span><span class="s2">- </span><span class="s1">y</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>
        <span class="s1">weights </span><span class="s2">*= </span><span class="s4">1.0 </span><span class="s2">- (</span><span class="s1">eta </span><span class="s2">* </span><span class="s1">alpha</span><span class="s2">)</span>
        <span class="s1">weights </span><span class="s2">+= -(</span><span class="s1">eta </span><span class="s2">* </span><span class="s1">gradient </span><span class="s2">* </span><span class="s1">entry</span><span class="s2">)</span>
        <span class="s1">intercept </span><span class="s2">+= -(</span><span class="s1">eta </span><span class="s2">* </span><span class="s1">gradient</span><span class="s2">) * </span><span class="s1">decay</span>

        <span class="s1">average_weights </span><span class="s2">*= </span><span class="s1">i</span>
        <span class="s1">average_weights </span><span class="s2">+= </span><span class="s1">weights</span>
        <span class="s1">average_weights </span><span class="s2">/= </span><span class="s1">i </span><span class="s2">+ </span><span class="s4">1.0</span>

        <span class="s1">average_intercept </span><span class="s2">*= </span><span class="s1">i</span>
        <span class="s1">average_intercept </span><span class="s2">+= </span><span class="s1">intercept</span>
        <span class="s1">average_intercept </span><span class="s2">/= </span><span class="s1">i </span><span class="s2">+ </span><span class="s4">1.0</span>

    <span class="s0">return </span><span class="s1">average_weights</span><span class="s2">, </span><span class="s1">average_intercept</span>


<span class="s0">def </span><span class="s1">_test_warm_start</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">lr</span><span class="s2">):</span>
    <span class="s5"># Test that explicit warm restart...</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s1">clf2 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.001</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">)</span>
    <span class="s1">clf2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">coef_init</span><span class="s2">=</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">(), </span><span class="s1">intercept_init</span><span class="s2">=</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">())</span>

    <span class="s5"># ... and implicit warm restart are equivalent.</span>
    <span class="s1">clf3 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">warm_start</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s1">lr</span>
    <span class="s2">)</span>
    <span class="s1">clf3</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">clf3</span><span class="s2">.</span><span class="s1">t_ </span><span class="s2">== </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">t_</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf3</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>

    <span class="s1">clf3</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.001</span><span class="s2">)</span>
    <span class="s1">clf3</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">clf3</span><span class="s2">.</span><span class="s1">t_ </span><span class="s2">== </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">t_</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf3</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;lr&quot;</span><span class="s2">, [</span><span class="s3">&quot;constant&quot;</span><span class="s2">, </span><span class="s3">&quot;optimal&quot;</span><span class="s2">, </span><span class="s3">&quot;invscaling&quot;</span><span class="s2">, </span><span class="s3">&quot;adaptive&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_warm_start</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">lr</span><span class="s2">):</span>
    <span class="s1">_test_warm_start</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">lr</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_input_format</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Input format tests.</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s1">Y_ </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">Y</span><span class="s2">)[:, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">newaxis</span><span class="s2">]</span>

    <span class="s1">Y_ </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">c_</span><span class="s2">[</span><span class="s1">Y_</span><span class="s2">, </span><span class="s1">Y_</span><span class="s2">]</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_clone</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Test whether clone works ok.</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">clone</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(</span><span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l2&quot;</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s1">clf2 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l2&quot;</span><span class="s2">)</span>
    <span class="s1">clf2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s1">SGDClassifier</span><span class="s2">,</span>
        <span class="s1">SparseSGDClassifier</span><span class="s2">,</span>
        <span class="s1">SGDRegressor</span><span class="s2">,</span>
        <span class="s1">SparseSGDRegressor</span><span class="s2">,</span>
        <span class="s1">SGDOneClassSVM</span><span class="s2">,</span>
        <span class="s1">SparseSGDOneClassSVM</span><span class="s2">,</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_plain_has_no_average_attr</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">average</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;_average_coef&quot;</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;_average_intercept&quot;</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;_standard_intercept&quot;</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;_standard_coef&quot;</span><span class="s2">)</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">()</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s0">assert not </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;_average_coef&quot;</span><span class="s2">)</span>
    <span class="s0">assert not </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;_average_intercept&quot;</span><span class="s2">)</span>
    <span class="s0">assert not </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;_standard_intercept&quot;</span><span class="s2">)</span>
    <span class="s0">assert not </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;_standard_coef&quot;</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s1">SGDClassifier</span><span class="s2">,</span>
        <span class="s1">SparseSGDClassifier</span><span class="s2">,</span>
        <span class="s1">SGDRegressor</span><span class="s2">,</span>
        <span class="s1">SparseSGDRegressor</span><span class="s2">,</span>
        <span class="s1">SGDOneClassSVM</span><span class="s2">,</span>
        <span class="s1">SparseSGDOneClassSVM</span><span class="s2">,</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_late_onset_averaging_not_reached</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">clf1 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">average</span><span class="s2">=</span><span class="s4">600</span><span class="s2">)</span>
    <span class="s1">clf2 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">()</span>
    <span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s4">100</span><span class="s2">):</span>
        <span class="s0">if </span><span class="s1">is_classifier</span><span class="s2">(</span><span class="s1">clf1</span><span class="s2">):</span>
            <span class="s1">clf1</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">classes</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">Y</span><span class="s2">))</span>
            <span class="s1">clf2</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">classes</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">Y</span><span class="s2">))</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">clf1</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
            <span class="s1">clf2</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">16</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">klass </span><span class="s0">in </span><span class="s2">[</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">]:</span>
        <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">16</span><span class="s2">)</span>
    <span class="s0">elif </span><span class="s1">klass </span><span class="s0">in </span><span class="s2">[</span><span class="s1">SGDOneClassSVM</span><span class="s2">, </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">]:</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">offset_</span><span class="s2">, </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">offset_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_late_onset_averaging_reached</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">eta0 </span><span class="s2">= </span><span class="s4">0.001</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">0.0001</span>
    <span class="s1">Y_encode </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s1">Y_encode</span><span class="s2">[</span><span class="s1">Y_encode </span><span class="s2">== </span><span class="s4">1</span><span class="s2">] = -</span><span class="s4">1.0</span>
    <span class="s1">Y_encode</span><span class="s2">[</span><span class="s1">Y_encode </span><span class="s2">== </span><span class="s4">2</span><span class="s2">] = </span><span class="s4">1.0</span>

    <span class="s1">clf1 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">average</span><span class="s2">=</span><span class="s4">7</span><span class="s2">,</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;squared_error&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s1">eta0</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">2</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf2 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">average</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;squared_error&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s1">eta0</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">clf1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y_encode</span><span class="s2">)</span>
    <span class="s1">clf2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y_encode</span><span class="s2">)</span>

    <span class="s1">average_weights</span><span class="s2">, </span><span class="s1">average_intercept </span><span class="s2">= </span><span class="s1">asgd</span><span class="s2">(</span>
        <span class="s1">klass</span><span class="s2">,</span>
        <span class="s1">X</span><span class="s2">,</span>
        <span class="s1">Y_encode</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">weight_init</span><span class="s2">=</span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">(),</span>
        <span class="s1">intercept_init</span><span class="s2">=</span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">(), </span><span class="s1">average_weights</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">(), </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">16</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">average_intercept</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">16</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_early_stopping</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">[</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target </span><span class="s2">&gt; </span><span class="s4">0</span><span class="s2">]</span>
    <span class="s1">Y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">[</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target </span><span class="s2">&gt; </span><span class="s4">0</span><span class="s2">]</span>
    <span class="s0">for </span><span class="s1">early_stopping </span><span class="s0">in </span><span class="s2">[</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">]:</span>
        <span class="s1">max_iter </span><span class="s2">= </span><span class="s4">1000</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">early_stopping</span><span class="s2">=</span><span class="s1">early_stopping</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s1">max_iter</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span>
            <span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span>
        <span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">&lt; </span><span class="s1">max_iter</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_adaptive_longer_than_constant</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">clf1 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;adaptive&quot;</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">100</span><span class="s2">)</span>
    <span class="s1">clf1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">)</span>
    <span class="s1">clf2 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">100</span><span class="s2">)</span>
    <span class="s1">clf2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">&gt; </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">n_iter_</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_validation_set_not_used_for_training</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">Y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span>
    <span class="s1">validation_fraction </span><span class="s2">= </span><span class="s4">0.4</span>
    <span class="s1">seed </span><span class="s2">= </span><span class="s4">42</span>
    <span class="s1">shuffle </span><span class="s2">= </span><span class="s0">False</span>
    <span class="s1">max_iter </span><span class="s2">= </span><span class="s4">10</span>
    <span class="s1">clf1 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">early_stopping</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">seed</span><span class="s2">),</span>
        <span class="s1">validation_fraction</span><span class="s2">=</span><span class="s1">validation_fraction</span><span class="s2">,</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s1">max_iter</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s1">shuffle</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">== </span><span class="s1">max_iter</span>

    <span class="s1">clf2 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">early_stopping</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">seed</span><span class="s2">),</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s1">max_iter</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s1">shuffle</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s0">if </span><span class="s1">is_classifier</span><span class="s2">(</span><span class="s1">clf2</span><span class="s2">):</span>
        <span class="s1">cv </span><span class="s2">= </span><span class="s1">StratifiedShuffleSplit</span><span class="s2">(</span><span class="s1">test_size</span><span class="s2">=</span><span class="s1">validation_fraction</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">seed</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">cv </span><span class="s2">= </span><span class="s1">ShuffleSplit</span><span class="s2">(</span><span class="s1">test_size</span><span class="s2">=</span><span class="s1">validation_fraction</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">seed</span><span class="s2">)</span>
    <span class="s1">idx_train</span><span class="s2">, </span><span class="s1">idx_val </span><span class="s2">= </span><span class="s1">next</span><span class="s2">(</span><span class="s1">cv</span><span class="s2">.</span><span class="s1">split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">))</span>
    <span class="s1">idx_train </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sort</span><span class="s2">(</span><span class="s1">idx_train</span><span class="s2">)  </span><span class="s5"># remove shuffling</span>
    <span class="s1">clf2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[</span><span class="s1">idx_train</span><span class="s2">], </span><span class="s1">Y</span><span class="s2">[</span><span class="s1">idx_train</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">== </span><span class="s1">max_iter</span>

    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_n_iter_no_change</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">Y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span>
    <span class="s5"># test that n_iter_ increases monotonically with n_iter_no_change</span>
    <span class="s0">for </span><span class="s1">early_stopping </span><span class="s0">in </span><span class="s2">[</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">]:</span>
        <span class="s1">n_iter_list </span><span class="s2">= [</span>
            <span class="s1">klass</span><span class="s2">(</span>
                <span class="s1">early_stopping</span><span class="s2">=</span><span class="s1">early_stopping</span><span class="s2">,</span>
                <span class="s1">n_iter_no_change</span><span class="s2">=</span><span class="s1">n_iter_no_change</span><span class="s2">,</span>
                <span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-4</span><span class="s2">,</span>
                <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">,</span>
            <span class="s2">)</span>
            <span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
            <span class="s2">.</span><span class="s1">n_iter_</span>
            <span class="s0">for </span><span class="s1">n_iter_no_change </span><span class="s0">in </span><span class="s2">[</span><span class="s4">2</span><span class="s2">, </span><span class="s4">3</span><span class="s2">, </span><span class="s4">10</span><span class="s2">]</span>
        <span class="s2">]</span>
        <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">n_iter_list</span><span class="s2">, </span><span class="s1">sorted</span><span class="s2">(</span><span class="s1">n_iter_list</span><span class="s2">))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_not_enough_sample_for_early_stopping</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># test an error is raised if the training or validation set is empty</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">early_stopping</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">validation_fraction</span><span class="s2">=</span><span class="s4">0.99</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X3</span><span class="s2">, </span><span class="s1">Y3</span><span class="s2">)</span>


<span class="s5">###############################################################################</span>
<span class="s5"># Classification Test Case</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_clf</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Check that SGD gives any results :-)</span>

    <span class="s0">for </span><span class="s1">loss </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;hinge&quot;</span><span class="s2">, </span><span class="s3">&quot;squared_hinge&quot;</span><span class="s2">, </span><span class="s3">&quot;log_loss&quot;</span><span class="s2">, </span><span class="s3">&quot;modified_huber&quot;</span><span class="s2">):</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
            <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l2&quot;</span><span class="s2">,</span>
            <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">,</span>
            <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
            <span class="s1">loss</span><span class="s2">=</span><span class="s1">loss</span><span class="s2">,</span>
            <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">10</span><span class="s2">,</span>
            <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s2">)</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
        <span class="s5"># assert_almost_equal(clf.coef_[0], clf.coef_[1], decimal=7)</span>
        <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">T</span><span class="s2">), </span><span class="s1">true_result</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SGDOneClassSVM</span><span class="s2">, </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_provide_coef</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s6">&quot;&quot;&quot;Check that the shape of `coef_init` is validated.&quot;&quot;&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;Provided coef_init does not match dataset&quot;</span><span class="s2">):</span>
        <span class="s1">klass</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">coef_init</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s4">3</span><span class="s2">,)))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass, fit_params&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">(</span><span class="s1">SGDClassifier</span><span class="s2">, {</span><span class="s3">&quot;intercept_init&quot;</span><span class="s2">: </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s4">3</span><span class="s2">,))}),</span>
        <span class="s2">(</span><span class="s1">SparseSGDClassifier</span><span class="s2">, {</span><span class="s3">&quot;intercept_init&quot;</span><span class="s2">: </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s4">3</span><span class="s2">,))}),</span>
        <span class="s2">(</span><span class="s1">SGDOneClassSVM</span><span class="s2">, {</span><span class="s3">&quot;offset_init&quot;</span><span class="s2">: </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s4">3</span><span class="s2">,))}),</span>
        <span class="s2">(</span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">, {</span><span class="s3">&quot;offset_init&quot;</span><span class="s2">: </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s4">3</span><span class="s2">,))}),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_set_intercept_offset</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">fit_params</span><span class="s2">):</span>
    <span class="s6">&quot;&quot;&quot;Check that `intercept_init` or `offset_init` is validated.&quot;&quot;&quot;</span>
    <span class="s1">sgd_estimator </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">()</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;does not match dataset&quot;</span><span class="s2">):</span>
        <span class="s1">sgd_estimator</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, **</span><span class="s1">fit_params</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_sgd_early_stopping_with_partial_fit</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s6">&quot;&quot;&quot;Check that we raise an error for `early_stopping` used with 
    `partial_fit`. 
    &quot;&quot;&quot;</span>
    <span class="s1">err_msg </span><span class="s2">= </span><span class="s3">&quot;early_stopping should be False with partial_fit&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">err_msg</span><span class="s2">):</span>
        <span class="s1">klass</span><span class="s2">(</span><span class="s1">early_stopping</span><span class="s2">=</span><span class="s0">True</span><span class="s2">).</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass, fit_params&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">(</span><span class="s1">SGDClassifier</span><span class="s2">, {</span><span class="s3">&quot;intercept_init&quot;</span><span class="s2">: </span><span class="s4">0</span><span class="s2">}),</span>
        <span class="s2">(</span><span class="s1">SparseSGDClassifier</span><span class="s2">, {</span><span class="s3">&quot;intercept_init&quot;</span><span class="s2">: </span><span class="s4">0</span><span class="s2">}),</span>
        <span class="s2">(</span><span class="s1">SGDOneClassSVM</span><span class="s2">, {</span><span class="s3">&quot;offset_init&quot;</span><span class="s2">: </span><span class="s4">0</span><span class="s2">}),</span>
        <span class="s2">(</span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">, {</span><span class="s3">&quot;offset_init&quot;</span><span class="s2">: </span><span class="s4">0</span><span class="s2">}),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_set_intercept_offset_binary</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">fit_params</span><span class="s2">):</span>
    <span class="s6">&quot;&quot;&quot;Check that we can pass a scaler with binary classification to 
    `intercept_init` or `offset_init`.&quot;&quot;&quot;</span>
    <span class="s1">klass</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X5</span><span class="s2">, </span><span class="s1">Y5</span><span class="s2">, **</span><span class="s1">fit_params</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_average_binary_computed_correctly</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Checks the SGDClassifier correctly computes the average weights</span>
    <span class="s1">eta </span><span class="s2">= </span><span class="s4">0.1</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">2.0</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">20</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s4">10</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">))</span>
    <span class="s1">w </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">)</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;squared_error&quot;</span><span class="s2">,</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s1">eta</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
        <span class="s1">average</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s5"># simple linear function without noise</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">w</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sign</span><span class="s2">(</span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">average_weights</span><span class="s2">, </span><span class="s1">average_intercept </span><span class="s2">= </span><span class="s1">asgd</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">eta</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">)</span>
    <span class="s1">average_weights </span><span class="s2">= </span><span class="s1">average_weights</span><span class="s2">.</span><span class="s1">reshape</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">average_weights</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">14</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">average_intercept</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">14</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_set_intercept_to_intercept</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Checks intercept_ shape consistency for the warm starts</span>
    <span class="s5"># Inconsistent intercept_ shape.</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X5</span><span class="s2">, </span><span class="s1">Y5</span><span class="s2">)</span>
    <span class="s1">klass</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X5</span><span class="s2">, </span><span class="s1">Y5</span><span class="s2">, </span><span class="s1">intercept_init</span><span class="s2">=</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s1">klass</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">intercept_init</span><span class="s2">=</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_at_least_two_labels</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Target must have at least two labels</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s4">9</span><span class="s2">))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_partial_fit_weight_class_balanced</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># partial_fit with class_weight='balanced' not supported&quot;&quot;&quot;</span>
    <span class="s1">regex </span><span class="s2">= (</span>
        <span class="s3">r&quot;class_weight 'balanced' is not supported for &quot;</span>
        <span class="s3">r&quot;partial_fit\. In order to use 'balanced' weights, &quot;</span>
        <span class="s3">r&quot;use compute_class_weight\('balanced', classes=classes, y=y\). &quot;</span>
        <span class="s3">r&quot;In place of y you can use a large enough sample &quot;</span>
        <span class="s3">r&quot;of the full training set target to properly &quot;</span>
        <span class="s3">r&quot;estimate the class frequency distributions\. &quot;</span>
        <span class="s3">r&quot;Pass the resulting weights as the class_weight &quot;</span>
        <span class="s3">r&quot;parameter\.&quot;</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">regex</span><span class="s2">):</span>
        <span class="s1">klass</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">=</span><span class="s3">&quot;balanced&quot;</span><span class="s2">).</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">classes</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">Y</span><span class="s2">))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_multiclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Multi-class test case</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">3</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">([[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">]]).</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">1</span><span class="s2">, </span><span class="s4">3</span><span class="s2">)</span>
    <span class="s1">pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">T2</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">pred</span><span class="s2">, </span><span class="s1">true_result2</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_multiclass_average</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">eta </span><span class="s2">= </span><span class="s4">0.001</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">0.01</span>
    <span class="s5"># Multi-class average test case</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;squared_error&quot;</span><span class="s2">,</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s1">eta</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
        <span class="s1">average</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">np_Y2 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">Y2</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">np_Y2</span><span class="s2">)</span>
    <span class="s1">classes </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">np_Y2</span><span class="s2">)</span>

    <span class="s0">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">cl </span><span class="s0">in </span><span class="s1">enumerate</span><span class="s2">(</span><span class="s1">classes</span><span class="s2">):</span>
        <span class="s1">y_i </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">np_Y2</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>
        <span class="s1">y_i</span><span class="s2">[</span><span class="s1">np_Y2 </span><span class="s2">!= </span><span class="s1">cl</span><span class="s2">] = -</span><span class="s4">1</span>
        <span class="s1">average_coef</span><span class="s2">, </span><span class="s1">average_intercept </span><span class="s2">= </span><span class="s1">asgd</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X2</span><span class="s2">, </span><span class="s1">y_i</span><span class="s2">, </span><span class="s1">eta</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">)</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">average_coef</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">[</span><span class="s1">i</span><span class="s2">], </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">16</span><span class="s2">)</span>
        <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">average_intercept</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">[</span><span class="s1">i</span><span class="s2">], </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">16</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_multiclass_with_init_coef</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Multi-class test case</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">, </span><span class="s1">coef_init</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">)), </span><span class="s1">intercept_init</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s4">3</span><span class="s2">))</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">, (</span><span class="s4">3</span><span class="s2">,)</span>
    <span class="s1">pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">T2</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">pred</span><span class="s2">, </span><span class="s1">true_result2</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_multiclass_njobs</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Multi-class test case with multi-core support</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">, </span><span class="s1">n_jobs</span><span class="s2">=</span><span class="s4">2</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">3</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">([[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">]]).</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">1</span><span class="s2">, </span><span class="s4">3</span><span class="s2">)</span>
    <span class="s1">pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">T2</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">pred</span><span class="s2">, </span><span class="s1">true_result2</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_set_coef_multiclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Checks coef_init and intercept_init shape for multi-class</span>
    <span class="s5"># problems</span>
    <span class="s5"># Provided coef_ does not match dataset</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">()</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">, </span><span class="s1">coef_init</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">)))</span>

    <span class="s5"># Provided coef_ does match dataset</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">, </span><span class="s1">coef_init</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">)))</span>

    <span class="s5"># Provided intercept_ does not match dataset</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">()</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">, </span><span class="s1">intercept_init</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s4">1</span><span class="s2">,)))</span>

    <span class="s5"># Provided intercept_ does match dataset.</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">, </span><span class="s1">intercept_init</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s4">3</span><span class="s2">,)))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_predict_proba_method_access</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Checks that SGDClassifier predict_proba and predict_log_proba methods</span>
    <span class="s5"># can either be accessed or raise an appropriate error message</span>
    <span class="s5"># otherwise. See</span>
    <span class="s5"># https://github.com/scikit-learn/scikit-learn/issues/10938 for more</span>
    <span class="s5"># details.</span>
    <span class="s0">for </span><span class="s1">loss </span><span class="s0">in </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDClassifier</span><span class="s2">.</span><span class="s1">loss_functions</span><span class="s2">:</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">=</span><span class="s1">loss</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">loss </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;log_loss&quot;</span><span class="s2">, </span><span class="s3">&quot;modified_huber&quot;</span><span class="s2">):</span>
            <span class="s0">assert </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">)</span>
            <span class="s0">assert </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;predict_log_proba&quot;</span><span class="s2">)</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">inner_msg </span><span class="s2">= </span><span class="s3">&quot;probability estimates are not available for loss={!r}&quot;</span><span class="s2">.</span><span class="s1">format</span><span class="s2">(</span>
                <span class="s1">loss</span>
            <span class="s2">)</span>
            <span class="s0">assert not </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">)</span>
            <span class="s0">assert not </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;predict_log_proba&quot;</span><span class="s2">)</span>
            <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span>
                <span class="s1">AttributeError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;has no attribute 'predict_proba'&quot;</span>
            <span class="s2">) </span><span class="s0">as </span><span class="s1">exec_info</span><span class="s2">:</span>
                <span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span>

            <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">exec_info</span><span class="s2">.</span><span class="s1">value</span><span class="s2">.</span><span class="s1">__cause__</span><span class="s2">, </span><span class="s1">AttributeError</span><span class="s2">)</span>
            <span class="s0">assert </span><span class="s1">inner_msg </span><span class="s0">in </span><span class="s1">str</span><span class="s2">(</span><span class="s1">exec_info</span><span class="s2">.</span><span class="s1">value</span><span class="s2">.</span><span class="s1">__cause__</span><span class="s2">)</span>

            <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span>
                <span class="s1">AttributeError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;has no attribute 'predict_log_proba'&quot;</span>
            <span class="s2">) </span><span class="s0">as </span><span class="s1">exec_info</span><span class="s2">:</span>
                <span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_log_proba</span>
            <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">exec_info</span><span class="s2">.</span><span class="s1">value</span><span class="s2">.</span><span class="s1">__cause__</span><span class="s2">, </span><span class="s1">AttributeError</span><span class="s2">)</span>
            <span class="s0">assert </span><span class="s1">inner_msg </span><span class="s0">in </span><span class="s1">str</span><span class="s2">(</span><span class="s1">exec_info</span><span class="s2">.</span><span class="s1">value</span><span class="s2">.</span><span class="s1">__cause__</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_proba</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Check SGD.predict_proba</span>

    <span class="s5"># Hinge loss does not allow for conditional prob estimate.</span>
    <span class="s5"># We cannot use the factory here, because it defines predict_proba</span>
    <span class="s5"># anyway.</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;hinge&quot;</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s0">None</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s0">assert not </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">)</span>
    <span class="s0">assert not </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;predict_log_proba&quot;</span><span class="s2">)</span>

    <span class="s5"># log and modified_huber losses can output probability estimates</span>
    <span class="s5"># binary case</span>
    <span class="s0">for </span><span class="s1">loss </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;log_loss&quot;</span><span class="s2">, </span><span class="s3">&quot;modified_huber&quot;</span><span class="s2">]:</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">=</span><span class="s1">loss</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">10</span><span class="s2">)</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
        <span class="s1">p </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">([[</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]])</span>
        <span class="s0">assert </span><span class="s1">p</span><span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">] &gt; </span><span class="s4">0.5</span>
        <span class="s1">p </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">([[-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">]])</span>
        <span class="s0">assert </span><span class="s1">p</span><span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">] &lt; </span><span class="s4">0.5</span>

        <span class="s5"># If predict_proba is 0, we get &quot;RuntimeWarning: divide by zero encountered</span>
        <span class="s5"># in log&quot;. We avoid it here.</span>
        <span class="s0">with </span><span class="s1">np</span><span class="s2">.</span><span class="s1">errstate</span><span class="s2">(</span><span class="s1">divide</span><span class="s2">=</span><span class="s3">&quot;ignore&quot;</span><span class="s2">):</span>
            <span class="s1">p </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_log_proba</span><span class="s2">([[</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]])</span>
            <span class="s0">assert </span><span class="s1">p</span><span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">] &gt; </span><span class="s1">p</span><span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">]</span>
            <span class="s1">p </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_log_proba</span><span class="s2">([[-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">]])</span>
            <span class="s0">assert </span><span class="s1">p</span><span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">] &lt; </span><span class="s1">p</span><span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">]</span>

    <span class="s5"># log loss multiclass probability estimates</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;log_loss&quot;</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">10</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">)</span>

    <span class="s1">d </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">([[</span><span class="s4">0.1</span><span class="s2">, -</span><span class="s4">0.1</span><span class="s2">], [</span><span class="s4">0.3</span><span class="s2">, </span><span class="s4">0.2</span><span class="s2">]])</span>
    <span class="s1">p </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">([[</span><span class="s4">0.1</span><span class="s2">, -</span><span class="s4">0.1</span><span class="s2">], [</span><span class="s4">0.3</span><span class="s2">, </span><span class="s4">0.2</span><span class="s2">]])</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">argmax</span><span class="s2">(</span><span class="s1">p</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">argmax</span><span class="s2">(</span><span class="s1">d</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">))</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">p</span><span class="s2">[</span><span class="s4">0</span><span class="s2">].</span><span class="s1">sum</span><span class="s2">(), </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">p</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] &gt;= </span><span class="s4">0</span><span class="s2">)</span>

    <span class="s1">p </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">([[-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">]])</span>
    <span class="s1">d </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">([[-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">]])</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">argsort</span><span class="s2">(</span><span class="s1">p</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">argsort</span><span class="s2">(</span><span class="s1">d</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]))</span>

    <span class="s1">lp </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_log_proba</span><span class="s2">([[</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]])</span>
    <span class="s1">p </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">([[</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]])</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">log</span><span class="s2">(</span><span class="s1">p</span><span class="s2">), </span><span class="s1">lp</span><span class="s2">)</span>

    <span class="s1">lp </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_log_proba</span><span class="s2">([[-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">]])</span>
    <span class="s1">p </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">([[-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">]])</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">log</span><span class="s2">(</span><span class="s1">p</span><span class="s2">), </span><span class="s1">lp</span><span class="s2">)</span>

    <span class="s5"># Modified Huber multiclass probability estimates; requires a separate</span>
    <span class="s5"># test because the hard zero/one probabilities may destroy the</span>
    <span class="s5"># ordering present in decision_function output.</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;modified_huber&quot;</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">10</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">)</span>
    <span class="s1">d </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">([[</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]])</span>
    <span class="s1">p </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">([[</span><span class="s4">3</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]])</span>
    <span class="s0">if </span><span class="s1">klass </span><span class="s2">!= </span><span class="s1">SparseSGDClassifier</span><span class="s2">:</span>
        <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">argmax</span><span class="s2">(</span><span class="s1">d</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">) == </span><span class="s1">np</span><span class="s2">.</span><span class="s1">argmax</span><span class="s2">(</span><span class="s1">p</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:  </span><span class="s5"># XXX the sparse test gets a different X2 (?)</span>
        <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">argmin</span><span class="s2">(</span><span class="s1">d</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">) == </span><span class="s1">np</span><span class="s2">.</span><span class="s1">argmin</span><span class="s2">(</span><span class="s1">p</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>

    <span class="s5"># the following sample produces decision_function values &lt; -1,</span>
    <span class="s5"># which would cause naive normalization to fail (see comment</span>
    <span class="s5"># in SGDClassifier.predict_proba)</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">d </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">([</span><span class="s1">x</span><span class="s2">])</span>
    <span class="s0">if </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">d </span><span class="s2">&lt; -</span><span class="s4">1</span><span class="s2">):  </span><span class="s5"># XXX not true in sparse test case (why?)</span>
        <span class="s1">p </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">([</span><span class="s1">x</span><span class="s2">])</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">p</span><span class="s2">[</span><span class="s4">0</span><span class="s2">], [</span><span class="s4">1 </span><span class="s2">/ </span><span class="s4">3.0</span><span class="s2">] * </span><span class="s4">3</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_l1</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Test L1 regularization</span>
    <span class="s1">n </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">X4</span><span class="s2">)</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">13</span><span class="s2">)</span>
    <span class="s1">idx </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">n</span><span class="s2">)</span>
    <span class="s1">rng</span><span class="s2">.</span><span class="s1">shuffle</span><span class="s2">(</span><span class="s1">idx</span><span class="s2">)</span>

    <span class="s1">X </span><span class="s2">= </span><span class="s1">X4</span><span class="s2">[</span><span class="s1">idx</span><span class="s2">, :]</span>
    <span class="s1">Y </span><span class="s2">= </span><span class="s1">Y4</span><span class="s2">[</span><span class="s1">idx</span><span class="s2">]</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.2</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">2000</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">:-</span><span class="s4">1</span><span class="s2">], </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s4">4</span><span class="s2">,)))</span>
    <span class="s1">pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">pred</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s5"># test sparsify with dense inputs</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">sparsify</span><span class="s2">()</span>
    <span class="s0">assert </span><span class="s1">sp</span><span class="s2">.</span><span class="s1">issparse</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>
    <span class="s1">pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">pred</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s5"># pickle and unpickle with sparse coef_</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">pickle</span><span class="s2">.</span><span class="s1">loads</span><span class="s2">(</span><span class="s1">pickle</span><span class="s2">.</span><span class="s1">dumps</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">))</span>
    <span class="s0">assert </span><span class="s1">sp</span><span class="s2">.</span><span class="s1">issparse</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>
    <span class="s1">pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">pred</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_class_weights</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Test class weights.</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[-</span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [-</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">], [-</span><span class="s4">0.8</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">], [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">]])</span>
    <span class="s1">y </span><span class="s2">= [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">]</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">([[</span><span class="s4">0.2</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">]]), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">1</span><span class="s2">]))</span>

    <span class="s5"># we give a small weights to class 1</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">={</span><span class="s4">1</span><span class="s2">: </span><span class="s4">0.001</span><span class="s2">})</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s5"># now the hyperplane should rotate clock-wise and</span>
    <span class="s5"># the prediction on this point should shift</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">([[</span><span class="s4">0.2</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">]]), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([-</span><span class="s4">1</span><span class="s2">]))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_equal_class_weight</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Test if equal class weights approx. equals no class weights.</span>
    <span class="s1">X </span><span class="s2">= [[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">], [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">], [</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">], [</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]]</span>
    <span class="s1">y </span><span class="s2">= [</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">X </span><span class="s2">= [[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">], [</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]]</span>
    <span class="s1">y </span><span class="s2">= [</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]</span>
    <span class="s1">clf_weighted </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">={</span><span class="s4">0</span><span class="s2">: </span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">1</span><span class="s2">: </span><span class="s4">0.5</span><span class="s2">})</span>
    <span class="s1">clf_weighted</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s5"># should be similar up to some epsilon due to learning rate schedule</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf_weighted</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">2</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_wrong_class_weight_label</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># ValueError due to not existing class label.</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">={</span><span class="s4">0</span><span class="s2">: </span><span class="s4">0.5</span><span class="s2">})</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_weights_multiplied</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Tests that class_weight and sample_weight are multiplicative</span>
    <span class="s1">class_weights </span><span class="s2">= {</span><span class="s4">1</span><span class="s2">: </span><span class="s4">0.6</span><span class="s2">, </span><span class="s4">2</span><span class="s2">: </span><span class="s4">0.3</span><span class="s2">}</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">sample_weights </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">random_sample</span><span class="s2">(</span><span class="s1">Y4</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>
    <span class="s1">multiplied_together </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">(</span><span class="s1">sample_weights</span><span class="s2">)</span>
    <span class="s1">multiplied_together</span><span class="s2">[</span><span class="s1">Y4 </span><span class="s2">== </span><span class="s4">1</span><span class="s2">] *= </span><span class="s1">class_weights</span><span class="s2">[</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s1">multiplied_together</span><span class="s2">[</span><span class="s1">Y4 </span><span class="s2">== </span><span class="s4">2</span><span class="s2">] *= </span><span class="s1">class_weights</span><span class="s2">[</span><span class="s4">2</span><span class="s2">]</span>

    <span class="s1">clf1 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">=</span><span class="s1">class_weights</span><span class="s2">)</span>
    <span class="s1">clf2 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">)</span>

    <span class="s1">clf1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X4</span><span class="s2">, </span><span class="s1">Y4</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weights</span><span class="s2">)</span>
    <span class="s1">clf2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X4</span><span class="s2">, </span><span class="s1">Y4</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">multiplied_together</span><span class="s2">)</span>

    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_balanced_weight</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Test class weights for imbalanced data&quot;&quot;&quot;</span>
    <span class="s5"># compute reference metrics on iris dataset that is quite balanced by</span>
    <span class="s5"># default</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">scale</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">idx </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">6</span><span class="s2">)</span>
    <span class="s1">rng</span><span class="s2">.</span><span class="s1">shuffle</span><span class="s2">(</span><span class="s1">idx</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[</span><span class="s1">idx</span><span class="s2">]</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">y</span><span class="s2">[</span><span class="s1">idx</span><span class="s2">]</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.0001</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">f1 </span><span class="s2">= </span><span class="s1">metrics</span><span class="s2">.</span><span class="s1">f1_score</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">f1</span><span class="s2">, </span><span class="s4">0.96</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>

    <span class="s5"># make the same prediction using balanced class_weight</span>
    <span class="s1">clf_balanced </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.0001</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">=</span><span class="s3">&quot;balanced&quot;</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span>
    <span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">f1 </span><span class="s2">= </span><span class="s1">metrics</span><span class="s2">.</span><span class="s1">f1_score</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">clf_balanced</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">f1</span><span class="s2">, </span><span class="s4">0.96</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>

    <span class="s5"># Make sure that in the balanced case it does not change anything</span>
    <span class="s5"># to use &quot;balanced&quot;</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf_balanced</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s4">6</span><span class="s2">)</span>

    <span class="s5"># build an very very imbalanced dataset out of iris data</span>
    <span class="s1">X_0 </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[</span><span class="s1">y </span><span class="s2">== </span><span class="s4">0</span><span class="s2">, :]</span>
    <span class="s1">y_0 </span><span class="s2">= </span><span class="s1">y</span><span class="s2">[</span><span class="s1">y </span><span class="s2">== </span><span class="s4">0</span><span class="s2">]</span>

    <span class="s1">X_imbalanced </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">vstack</span><span class="s2">([</span><span class="s1">X</span><span class="s2">] + [</span><span class="s1">X_0</span><span class="s2">] * </span><span class="s4">10</span><span class="s2">)</span>
    <span class="s1">y_imbalanced </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">([</span><span class="s1">y</span><span class="s2">] + [</span><span class="s1">y_0</span><span class="s2">] * </span><span class="s4">10</span><span class="s2">)</span>

    <span class="s5"># fit a model on the imbalanced data without class weight info</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_imbalanced</span><span class="s2">, </span><span class="s1">y_imbalanced</span><span class="s2">)</span>
    <span class="s1">y_pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">metrics</span><span class="s2">.</span><span class="s1">f1_score</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">) &lt; </span><span class="s4">0.96</span>

    <span class="s5"># fit a model with balanced class_weight enabled</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">=</span><span class="s3">&quot;balanced&quot;</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_imbalanced</span><span class="s2">, </span><span class="s1">y_imbalanced</span><span class="s2">)</span>
    <span class="s1">y_pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">metrics</span><span class="s2">.</span><span class="s1">f1_score</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">) &gt; </span><span class="s4">0.96</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sample_weights</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Test weights on individual samples</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[-</span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [-</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">], [-</span><span class="s4">0.8</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">], [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">], [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">]])</span>
    <span class="s1">y </span><span class="s2">= [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">]</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">([[</span><span class="s4">0.2</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">]]), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">1</span><span class="s2">]))</span>

    <span class="s5"># we give a small weights to class 1</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=[</span><span class="s4">0.001</span><span class="s2">] * </span><span class="s4">3 </span><span class="s2">+ [</span><span class="s4">1</span><span class="s2">] * </span><span class="s4">2</span><span class="s2">)</span>

    <span class="s5"># now the hyperplane should rotate clock-wise and</span>
    <span class="s5"># the prediction on this point should shift</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">([[</span><span class="s4">0.2</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">]]), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([-</span><span class="s4">1</span><span class="s2">]))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">, </span><span class="s1">SGDOneClassSVM</span><span class="s2">, </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_wrong_sample_weights</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Test if ValueError is raised if sample_weight has wrong shape</span>
    <span class="s0">if </span><span class="s1">klass </span><span class="s0">in </span><span class="s2">[</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">]:</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s0">elif </span><span class="s1">klass </span><span class="s0">in </span><span class="s2">[</span><span class="s1">SGDOneClassSVM</span><span class="s2">, </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">]:</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">nu</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s5"># provided sample_weight too long</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s4">7</span><span class="s2">))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_partial_fit_exception</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">)</span>
    <span class="s5"># classes was not specified</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X3</span><span class="s2">, </span><span class="s1">Y3</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_partial_fit_binary</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">third </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] // </span><span class="s4">3</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">)</span>
    <span class="s1">classes </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[:</span><span class="s1">third</span><span class="s2">], </span><span class="s1">Y</span><span class="s2">[:</span><span class="s1">third</span><span class="s2">], </span><span class="s1">classes</span><span class="s2">=</span><span class="s1">classes</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">1</span><span class="s2">, </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">1</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">([[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">]]).</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">1</span><span class="s2">,)</span>
    <span class="s1">id1 </span><span class="s2">= </span><span class="s1">id</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">data</span><span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[</span><span class="s1">third</span><span class="s2">:], </span><span class="s1">Y</span><span class="s2">[</span><span class="s1">third</span><span class="s2">:])</span>
    <span class="s1">id2 </span><span class="s2">= </span><span class="s1">id</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">data</span><span class="s2">)</span>
    <span class="s5"># check that coef_ haven't been re-allocated</span>
    <span class="s0">assert </span><span class="s1">id1</span><span class="s2">, </span><span class="s1">id2</span>

    <span class="s1">y_pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">T</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">true_result</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_partial_fit_multiclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">third </span><span class="s2">= </span><span class="s1">X2</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] // </span><span class="s4">3</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">)</span>
    <span class="s1">classes </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">Y2</span><span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">[:</span><span class="s1">third</span><span class="s2">], </span><span class="s1">Y2</span><span class="s2">[:</span><span class="s1">third</span><span class="s2">], </span><span class="s1">classes</span><span class="s2">=</span><span class="s1">classes</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">3</span><span class="s2">, </span><span class="s1">X2</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">3</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">([[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">]]).</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">1</span><span class="s2">, </span><span class="s4">3</span><span class="s2">)</span>
    <span class="s1">id1 </span><span class="s2">= </span><span class="s1">id</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">data</span><span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">[</span><span class="s1">third</span><span class="s2">:], </span><span class="s1">Y2</span><span class="s2">[</span><span class="s1">third</span><span class="s2">:])</span>
    <span class="s1">id2 </span><span class="s2">= </span><span class="s1">id</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">data</span><span class="s2">)</span>
    <span class="s5"># check that coef_ haven't been re-allocated</span>
    <span class="s0">assert </span><span class="s1">id1</span><span class="s2">, </span><span class="s1">id2</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_partial_fit_multiclass_average</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">third </span><span class="s2">= </span><span class="s1">X2</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] // </span><span class="s4">3</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s1">X2</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])</span>
    <span class="s1">classes </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">Y2</span><span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">[:</span><span class="s1">third</span><span class="s2">], </span><span class="s1">Y2</span><span class="s2">[:</span><span class="s1">third</span><span class="s2">], </span><span class="s1">classes</span><span class="s2">=</span><span class="s1">classes</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">3</span><span class="s2">, </span><span class="s1">X2</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">3</span><span class="s2">,)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">[</span><span class="s1">third</span><span class="s2">:], </span><span class="s1">Y2</span><span class="s2">[</span><span class="s1">third</span><span class="s2">:])</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">3</span><span class="s2">, </span><span class="s1">X2</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">3</span><span class="s2">,)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_fit_then_partial_fit</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Partial_fit should work after initial fit in the multiclass case.</span>
    <span class="s5"># Non-regression test for #2496; fit would previously produce a</span>
    <span class="s5"># Fortran-ordered coef_ that subsequent partial_fit couldn't handle.</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">()</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">)  </span><span class="s5"># no exception here</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;lr&quot;</span><span class="s2">, [</span><span class="s3">&quot;constant&quot;</span><span class="s2">, </span><span class="s3">&quot;optimal&quot;</span><span class="s2">, </span><span class="s3">&quot;invscaling&quot;</span><span class="s2">, </span><span class="s3">&quot;adaptive&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_partial_fit_equal_fit_classif</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">lr</span><span class="s2">):</span>
    <span class="s0">for </span><span class="s1">X_</span><span class="s2">, </span><span class="s1">Y_</span><span class="s2">, </span><span class="s1">T_ </span><span class="s0">in </span><span class="s2">((</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">T</span><span class="s2">), (</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">, </span><span class="s1">T2</span><span class="s2">)):</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_</span><span class="s2">, </span><span class="s1">Y_</span><span class="s2">)</span>
        <span class="s1">y_pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">T_</span><span class="s2">)</span>
        <span class="s1">t </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">t_</span>

        <span class="s1">classes </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">Y_</span><span class="s2">)</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
        <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s4">2</span><span class="s2">):</span>
            <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X_</span><span class="s2">, </span><span class="s1">Y_</span><span class="s2">, </span><span class="s1">classes</span><span class="s2">=</span><span class="s1">classes</span><span class="s2">)</span>
        <span class="s1">y_pred2 </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">T_</span><span class="s2">)</span>

        <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">t_ </span><span class="s2">== </span><span class="s1">t</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">y_pred2</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">2</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_regression_losses</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">random_state </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">,</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">,</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;epsilon_insensitive&quot;</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">random_state</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s4">1.0 </span><span class="s2">== </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">) == </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">,</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">,</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;squared_epsilon_insensitive&quot;</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">random_state</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s4">1.0 </span><span class="s2">== </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">) == </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;huber&quot;</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">random_state</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s4">1.0 </span><span class="s2">== </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">) == </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">,</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">,</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;squared_error&quot;</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">random_state</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s4">1.0 </span><span class="s2">== </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">) == </span><span class="s1">Y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_warm_start_multiclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">_test_warm_start</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X2</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">, </span><span class="s3">&quot;optimal&quot;</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SparseSGDClassifier</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_multiple_fit</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Test multiple calls of fit w/ different shaped inputs.</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s3">&quot;coef_&quot;</span><span class="s2">)</span>

    <span class="s5"># Non-regression test: try fitting with a different label set.</span>
    <span class="s1">y </span><span class="s2">= [[</span><span class="s3">&quot;ham&quot;</span><span class="s2">, </span><span class="s3">&quot;spam&quot;</span><span class="s2">][</span><span class="s1">i</span><span class="s2">] </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">LabelEncoder</span><span class="s2">().</span><span class="s1">fit_transform</span><span class="s2">(</span><span class="s1">Y</span><span class="s2">)]</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[:, :-</span><span class="s4">1</span><span class="s2">], </span><span class="s1">y</span><span class="s2">)</span>


<span class="s5">###############################################################################</span>
<span class="s5"># Regression Test Case</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_reg</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Check that SGD gives any results.</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">([[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">], [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">], [</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]], [</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] == </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">[</span><span class="s4">1</span><span class="s2">]</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_averaged_computed_correctly</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Tests the average regressor matches the naive implementation</span>

    <span class="s1">eta </span><span class="s2">= </span><span class="s4">0.001</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">0.01</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">20</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s4">10</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">))</span>
    <span class="s1">w </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">)</span>

    <span class="s5"># simple linear function without noise</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">w</span><span class="s2">)</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;squared_error&quot;</span><span class="s2">,</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s1">eta</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
        <span class="s1">average</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">average_weights</span><span class="s2">, </span><span class="s1">average_intercept </span><span class="s2">= </span><span class="s1">asgd</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">eta</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">average_weights</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">16</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">average_intercept</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">16</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_averaged_partial_fit</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Tests whether the partial fit yields the same average as the fit</span>
    <span class="s1">eta </span><span class="s2">= </span><span class="s4">0.001</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">0.01</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">20</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s4">10</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">))</span>
    <span class="s1">w </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">)</span>

    <span class="s5"># simple linear function without noise</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">w</span><span class="s2">)</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;squared_error&quot;</span><span class="s2">,</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s1">eta</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
        <span class="s1">average</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[: </span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">)][:], </span><span class="s1">y</span><span class="s2">[: </span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">)])</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[</span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">) :][:], </span><span class="s1">y</span><span class="s2">[</span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">) :])</span>
    <span class="s1">average_weights</span><span class="s2">, </span><span class="s1">average_intercept </span><span class="s2">= </span><span class="s1">asgd</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">eta</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">average_weights</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">16</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">[</span><span class="s4">0</span><span class="s2">], </span><span class="s1">average_intercept</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">16</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_average_sparse</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Checks the average weights on data with 0s</span>

    <span class="s1">eta </span><span class="s2">= </span><span class="s4">0.001</span>
    <span class="s1">alpha </span><span class="s2">= </span><span class="s4">0.01</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;squared_error&quot;</span><span class="s2">,</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s1">eta</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
        <span class="s1">average</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">n_samples </span><span class="s2">= </span><span class="s1">Y3</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X3</span><span class="s2">[: </span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">)][:], </span><span class="s1">Y3</span><span class="s2">[: </span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">)])</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X3</span><span class="s2">[</span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">) :][:], </span><span class="s1">Y3</span><span class="s2">[</span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">) :])</span>
    <span class="s1">average_weights</span><span class="s2">, </span><span class="s1">average_intercept </span><span class="s2">= </span><span class="s1">asgd</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X3</span><span class="s2">, </span><span class="s1">Y3</span><span class="s2">, </span><span class="s1">eta</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">average_weights</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">16</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">average_intercept</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">16</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_least_squares_fit</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">xmin</span><span class="s2">, </span><span class="s1">xmax </span><span class="s2">= -</span><span class="s4">5</span><span class="s2">, </span><span class="s4">5</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">100</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(</span><span class="s1">xmin</span><span class="s2">, </span><span class="s1">xmax</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>

    <span class="s5"># simple linear function without noise</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s4">0.5 </span><span class="s2">* </span><span class="s1">X</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">()</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;squared_error&quot;</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">score </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">score </span><span class="s2">&gt; </span><span class="s4">0.99</span>

    <span class="s5"># simple linear function with noise</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s4">0.5 </span><span class="s2">* </span><span class="s1">X</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">() + </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s4">1</span><span class="s2">).</span><span class="s1">ravel</span><span class="s2">()</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;squared_error&quot;</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">score </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">score </span><span class="s2">&gt; </span><span class="s4">0.5</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_epsilon_insensitive</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">xmin</span><span class="s2">, </span><span class="s1">xmax </span><span class="s2">= -</span><span class="s4">5</span><span class="s2">, </span><span class="s4">5</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">100</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(</span><span class="s1">xmin</span><span class="s2">, </span><span class="s1">xmax</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>

    <span class="s5"># simple linear function without noise</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s4">0.5 </span><span class="s2">* </span><span class="s1">X</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">()</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;epsilon_insensitive&quot;</span><span class="s2">,</span>
        <span class="s1">epsilon</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">score </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">score </span><span class="s2">&gt; </span><span class="s4">0.99</span>

    <span class="s5"># simple linear function with noise</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s4">0.5 </span><span class="s2">* </span><span class="s1">X</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">() + </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s4">1</span><span class="s2">).</span><span class="s1">ravel</span><span class="s2">()</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;epsilon_insensitive&quot;</span><span class="s2">,</span>
        <span class="s1">epsilon</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">score </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">score </span><span class="s2">&gt; </span><span class="s4">0.5</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_huber_fit</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">xmin</span><span class="s2">, </span><span class="s1">xmax </span><span class="s2">= -</span><span class="s4">5</span><span class="s2">, </span><span class="s4">5</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">100</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(</span><span class="s1">xmin</span><span class="s2">, </span><span class="s1">xmax</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>

    <span class="s5"># simple linear function without noise</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s4">0.5 </span><span class="s2">* </span><span class="s1">X</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">()</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;huber&quot;</span><span class="s2">, </span><span class="s1">epsilon</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">score </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">score </span><span class="s2">&gt; </span><span class="s4">0.99</span>

    <span class="s5"># simple linear function with noise</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s4">0.5 </span><span class="s2">* </span><span class="s1">X</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">() + </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s4">1</span><span class="s2">).</span><span class="s1">ravel</span><span class="s2">()</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;huber&quot;</span><span class="s2">, </span><span class="s1">epsilon</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">score </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">score </span><span class="s2">&gt; </span><span class="s4">0.5</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_elasticnet_convergence</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Check that the SGD output is consistent with coordinate descent</span>

    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s4">1000</span><span class="s2">, </span><span class="s4">5</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s5"># ground_truth linear model that generate y from X and to which the</span>
    <span class="s5"># models should converge if the regularizer would be set to 0.0</span>
    <span class="s1">ground_truth_coef </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">ground_truth_coef</span><span class="s2">)</span>

    <span class="s5"># XXX: alpha = 0.1 seems to cause convergence problems</span>
    <span class="s0">for </span><span class="s1">alpha </span><span class="s0">in </span><span class="s2">[</span><span class="s4">0.01</span><span class="s2">, </span><span class="s4">0.001</span><span class="s2">]:</span>
        <span class="s0">for </span><span class="s1">l1_ratio </span><span class="s0">in </span><span class="s2">[</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">0.8</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">]:</span>
            <span class="s1">cd </span><span class="s2">= </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">ElasticNet</span><span class="s2">(</span>
                <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">l1_ratio</span><span class="s2">=</span><span class="s1">l1_ratio</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span>
            <span class="s2">)</span>
            <span class="s1">cd</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
            <span class="s1">sgd </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
                <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
                <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">50</span><span class="s2">,</span>
                <span class="s1">alpha</span><span class="s2">=</span><span class="s1">alpha</span><span class="s2">,</span>
                <span class="s1">l1_ratio</span><span class="s2">=</span><span class="s1">l1_ratio</span><span class="s2">,</span>
                <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
            <span class="s2">)</span>
            <span class="s1">sgd</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
            <span class="s1">err_msg </span><span class="s2">= (</span>
                <span class="s3">&quot;cd and sgd did not converge to comparable &quot;</span>
                <span class="s3">&quot;results for alpha=%f and l1_ratio=%f&quot; </span><span class="s2">% (</span><span class="s1">alpha</span><span class="s2">, </span><span class="s1">l1_ratio</span><span class="s2">)</span>
            <span class="s2">)</span>
            <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">cd</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">sgd</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">err_msg</span><span class="s2">=</span><span class="s1">err_msg</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">ignore_warnings</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_partial_fit</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">third </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] // </span><span class="s4">3</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[:</span><span class="s1">third</span><span class="s2">], </span><span class="s1">Y</span><span class="s2">[:</span><span class="s1">third</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">],)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">1</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">([[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">]]).</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">1</span><span class="s2">,)</span>
    <span class="s1">id1 </span><span class="s2">= </span><span class="s1">id</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">data</span><span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[</span><span class="s1">third</span><span class="s2">:], </span><span class="s1">Y</span><span class="s2">[</span><span class="s1">third</span><span class="s2">:])</span>
    <span class="s1">id2 </span><span class="s2">= </span><span class="s1">id</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">data</span><span class="s2">)</span>
    <span class="s5"># check that coef_ haven't been re-allocated</span>
    <span class="s0">assert </span><span class="s1">id1</span><span class="s2">, </span><span class="s1">id2</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;lr&quot;</span><span class="s2">, [</span><span class="s3">&quot;constant&quot;</span><span class="s2">, </span><span class="s3">&quot;optimal&quot;</span><span class="s2">, </span><span class="s3">&quot;invscaling&quot;</span><span class="s2">, </span><span class="s3">&quot;adaptive&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_partial_fit_equal_fit</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">lr</span><span class="s2">):</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s1">y_pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">T</span><span class="s2">)</span>
    <span class="s1">t </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">t_</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s4">2</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s1">y_pred2 </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">T</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">t_ </span><span class="s2">== </span><span class="s1">t</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">y_pred2</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s4">2</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SparseSGDRegressor</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_loss_function_epsilon</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">epsilon</span><span class="s2">=</span><span class="s4">0.9</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(</span><span class="s1">epsilon</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">loss_functions</span><span class="s2">[</span><span class="s3">&quot;huber&quot;</span><span class="s2">][</span><span class="s4">1</span><span class="s2">] == </span><span class="s4">0.1</span>


<span class="s5">###############################################################################</span>
<span class="s5"># SGD One Class SVM Test Case</span>


<span class="s5"># a simple implementation of ASGD to use for testing SGDOneClassSVM</span>
<span class="s0">def </span><span class="s1">asgd_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">eta</span><span class="s2">, </span><span class="s1">nu</span><span class="s2">, </span><span class="s1">coef_init</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">offset_init</span><span class="s2">=</span><span class="s4">0.0</span><span class="s2">):</span>
    <span class="s0">if </span><span class="s1">coef_init </span><span class="s0">is None</span><span class="s2">:</span>
        <span class="s1">coef </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">coef </span><span class="s2">= </span><span class="s1">coef_init</span>

    <span class="s1">average_coef </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s1">offset </span><span class="s2">= </span><span class="s1">offset_init</span>
    <span class="s1">intercept </span><span class="s2">= </span><span class="s4">1 </span><span class="s2">- </span><span class="s1">offset</span>
    <span class="s1">average_intercept </span><span class="s2">= </span><span class="s4">0.0</span>
    <span class="s1">decay </span><span class="s2">= </span><span class="s4">1.0</span>

    <span class="s5"># sparse data has a fixed decay of .01</span>
    <span class="s0">if </span><span class="s1">klass </span><span class="s2">== </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">:</span>
        <span class="s1">decay </span><span class="s2">= </span><span class="s4">0.01</span>

    <span class="s0">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">entry </span><span class="s0">in </span><span class="s1">enumerate</span><span class="s2">(</span><span class="s1">X</span><span class="s2">):</span>
        <span class="s1">p </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">entry</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">)</span>
        <span class="s1">p </span><span class="s2">+= </span><span class="s1">intercept</span>
        <span class="s0">if </span><span class="s1">p </span><span class="s2">&lt;= </span><span class="s4">1.0</span><span class="s2">:</span>
            <span class="s1">gradient </span><span class="s2">= -</span><span class="s4">1</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">gradient </span><span class="s2">= </span><span class="s4">0</span>
        <span class="s1">coef </span><span class="s2">*= </span><span class="s1">max</span><span class="s2">(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1.0 </span><span class="s2">- (</span><span class="s1">eta </span><span class="s2">* </span><span class="s1">nu </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">))</span>
        <span class="s1">coef </span><span class="s2">+= -(</span><span class="s1">eta </span><span class="s2">* </span><span class="s1">gradient </span><span class="s2">* </span><span class="s1">entry</span><span class="s2">)</span>
        <span class="s1">intercept </span><span class="s2">+= -(</span><span class="s1">eta </span><span class="s2">* (</span><span class="s1">nu </span><span class="s2">+ </span><span class="s1">gradient</span><span class="s2">)) * </span><span class="s1">decay</span>

        <span class="s1">average_coef </span><span class="s2">*= </span><span class="s1">i</span>
        <span class="s1">average_coef </span><span class="s2">+= </span><span class="s1">coef</span>
        <span class="s1">average_coef </span><span class="s2">/= </span><span class="s1">i </span><span class="s2">+ </span><span class="s4">1.0</span>

        <span class="s1">average_intercept </span><span class="s2">*= </span><span class="s1">i</span>
        <span class="s1">average_intercept </span><span class="s2">+= </span><span class="s1">intercept</span>
        <span class="s1">average_intercept </span><span class="s2">/= </span><span class="s1">i </span><span class="s2">+ </span><span class="s4">1.0</span>

    <span class="s0">return </span><span class="s1">average_coef</span><span class="s2">, </span><span class="s4">1 </span><span class="s2">- </span><span class="s1">average_intercept</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDOneClassSVM</span><span class="s2">, </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">_test_warm_start_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">lr</span><span class="s2">):</span>
    <span class="s5"># Test that explicit warm restart...</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">nu</span><span class="s2">=</span><span class="s4">0.5</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">clf2 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">nu</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">)</span>
    <span class="s1">clf2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">coef_init</span><span class="s2">=</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">(), </span><span class="s1">offset_init</span><span class="s2">=</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">offset_</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">())</span>

    <span class="s5"># ... and implicit warm restart are equivalent.</span>
    <span class="s1">clf3 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">nu</span><span class="s2">=</span><span class="s4">0.5</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">warm_start</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">)</span>
    <span class="s1">clf3</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">clf3</span><span class="s2">.</span><span class="s1">t_ </span><span class="s2">== </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">t_</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf3</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>

    <span class="s1">clf3</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(</span><span class="s1">nu</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">)</span>
    <span class="s1">clf3</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">clf3</span><span class="s2">.</span><span class="s1">t_ </span><span class="s2">== </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">t_</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf3</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDOneClassSVM</span><span class="s2">, </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;lr&quot;</span><span class="s2">, [</span><span class="s3">&quot;constant&quot;</span><span class="s2">, </span><span class="s3">&quot;optimal&quot;</span><span class="s2">, </span><span class="s3">&quot;invscaling&quot;</span><span class="s2">, </span><span class="s3">&quot;adaptive&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_warm_start_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">lr</span><span class="s2">):</span>
    <span class="s1">_test_warm_start_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">lr</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDOneClassSVM</span><span class="s2">, </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_clone_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Test whether clone works ok.</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">nu</span><span class="s2">=</span><span class="s4">0.5</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">clone</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(</span><span class="s1">nu</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">clf2 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">nu</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">)</span>
    <span class="s1">clf2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDOneClassSVM</span><span class="s2">, </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_partial_fit_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s1">third </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] // </span><span class="s4">3</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">nu</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[:</span><span class="s1">third</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">],)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">offset_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">1</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">([[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">]]).</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">1</span><span class="s2">,)</span>
    <span class="s1">previous_coefs </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[</span><span class="s1">third</span><span class="s2">:])</span>
    <span class="s5"># check that coef_ haven't been re-allocated</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_ </span><span class="s0">is </span><span class="s1">previous_coefs</span>

    <span class="s5"># raises ValueError if number of features does not match previous data</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[:, </span><span class="s4">1</span><span class="s2">])</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDOneClassSVM</span><span class="s2">, </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;lr&quot;</span><span class="s2">, [</span><span class="s3">&quot;constant&quot;</span><span class="s2">, </span><span class="s3">&quot;optimal&quot;</span><span class="s2">, </span><span class="s3">&quot;invscaling&quot;</span><span class="s2">, </span><span class="s3">&quot;adaptive&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_partial_fit_equal_fit_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">lr</span><span class="s2">):</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">nu</span><span class="s2">=</span><span class="s4">0.05</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">y_scores </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">T</span><span class="s2">)</span>
    <span class="s1">t </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">t_</span>
    <span class="s1">coef </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span>
    <span class="s1">offset </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">offset_</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span><span class="s1">nu</span><span class="s2">=</span><span class="s4">0.05</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s4">2</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">y_scores2 </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">T</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">t_ </span><span class="s2">== </span><span class="s1">t</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">y_scores</span><span class="s2">, </span><span class="s1">y_scores2</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">offset_</span><span class="s2">, </span><span class="s1">offset</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDOneClassSVM</span><span class="s2">, </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_late_onset_averaging_reached_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Test average</span>
    <span class="s1">eta0 </span><span class="s2">= </span><span class="s4">0.001</span>
    <span class="s1">nu </span><span class="s2">= </span><span class="s4">0.05</span>

    <span class="s5"># 2 passes over the training set but average only at second pass</span>
    <span class="s1">clf1 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">average</span><span class="s2">=</span><span class="s4">7</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s1">eta0</span><span class="s2">, </span><span class="s1">nu</span><span class="s2">=</span><span class="s1">nu</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span>
    <span class="s2">)</span>
    <span class="s5"># 1 pass over the training set with no averaging</span>
    <span class="s1">clf2 </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">average</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s1">eta0</span><span class="s2">,</span>
        <span class="s1">nu</span><span class="s2">=</span><span class="s1">nu</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">clf1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">clf2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s5"># Start from clf2 solution, compute averaging using asgd function and</span>
    <span class="s5"># compare with clf1 solution</span>
    <span class="s1">average_coef</span><span class="s2">, </span><span class="s1">average_offset </span><span class="s2">= </span><span class="s1">asgd_oneclass</span><span class="s2">(</span>
        <span class="s1">klass</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">, </span><span class="s1">nu</span><span class="s2">, </span><span class="s1">coef_init</span><span class="s2">=</span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">(), </span><span class="s1">offset_init</span><span class="s2">=</span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">offset_</span>
    <span class="s2">)</span>

    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">(), </span><span class="s1">average_coef</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">())</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">offset_</span><span class="s2">, </span><span class="s1">average_offset</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDOneClassSVM</span><span class="s2">, </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_averaged_computed_correctly_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Tests the average SGD One-Class SVM matches the naive implementation</span>
    <span class="s1">eta </span><span class="s2">= </span><span class="s4">0.001</span>
    <span class="s1">nu </span><span class="s2">= </span><span class="s4">0.05</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">20</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s4">10</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">))</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s1">eta</span><span class="s2">,</span>
        <span class="s1">nu</span><span class="s2">=</span><span class="s1">nu</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
        <span class="s1">average</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">average_coef</span><span class="s2">, </span><span class="s1">average_offset </span><span class="s2">= </span><span class="s1">asgd_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">eta</span><span class="s2">, </span><span class="s1">nu</span><span class="s2">)</span>

    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">average_coef</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">offset_</span><span class="s2">, </span><span class="s1">average_offset</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDOneClassSVM</span><span class="s2">, </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_averaged_partial_fit_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Tests whether the partial fit yields the same average as the fit</span>
    <span class="s1">eta </span><span class="s2">= </span><span class="s4">0.001</span>
    <span class="s1">nu </span><span class="s2">= </span><span class="s4">0.05</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">20</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s4">10</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">))</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s1">eta</span><span class="s2">,</span>
        <span class="s1">nu</span><span class="s2">=</span><span class="s1">nu</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
        <span class="s1">average</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[: </span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">)][:])</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[</span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">) :][:])</span>
    <span class="s1">average_coef</span><span class="s2">, </span><span class="s1">average_offset </span><span class="s2">= </span><span class="s1">asgd_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">eta</span><span class="s2">, </span><span class="s1">nu</span><span class="s2">)</span>

    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">average_coef</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">offset_</span><span class="s2">, </span><span class="s1">average_offset</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;klass&quot;</span><span class="s2">, [</span><span class="s1">SGDOneClassSVM</span><span class="s2">, </span><span class="s1">SparseSGDOneClassSVM</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_average_sparse_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">):</span>
    <span class="s5"># Checks the average coef on data with 0s</span>
    <span class="s1">eta </span><span class="s2">= </span><span class="s4">0.001</span>
    <span class="s1">nu </span><span class="s2">= </span><span class="s4">0.01</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">klass</span><span class="s2">(</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s1">eta</span><span class="s2">,</span>
        <span class="s1">nu</span><span class="s2">=</span><span class="s1">nu</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
        <span class="s1">average</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">n_samples </span><span class="s2">= </span><span class="s1">X3</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X3</span><span class="s2">[: </span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">)])</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">partial_fit</span><span class="s2">(</span><span class="s1">X3</span><span class="s2">[</span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">) :])</span>
    <span class="s1">average_coef</span><span class="s2">, </span><span class="s1">average_offset </span><span class="s2">= </span><span class="s1">asgd_oneclass</span><span class="s2">(</span><span class="s1">klass</span><span class="s2">, </span><span class="s1">X3</span><span class="s2">, </span><span class="s1">eta</span><span class="s2">, </span><span class="s1">nu</span><span class="s2">)</span>

    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">average_coef</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">offset_</span><span class="s2">, </span><span class="s1">average_offset</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_sgd_oneclass</span><span class="s2">():</span>
    <span class="s5"># Test fit, decision_function, predict and score_samples on a toy</span>
    <span class="s5"># dataset</span>
    <span class="s1">X_train </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[-</span><span class="s4">2</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">], [-</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">], [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]])</span>
    <span class="s1">X_test </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[</span><span class="s4">0.5</span><span class="s2">, -</span><span class="s4">2</span><span class="s2">], [</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]])</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">SGDOneClassSVM</span><span class="s2">(</span>
        <span class="s1">nu</span><span class="s2">=</span><span class="s4">0.5</span><span class="s2">, </span><span class="s1">eta0</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">, </span><span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span>
    <span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([-</span><span class="s4">0.125</span><span class="s2">, </span><span class="s4">0.4375</span><span class="s2">]))</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">offset_</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] == -</span><span class="s4">0.5</span>

    <span class="s1">scores </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">score_samples</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">scores</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([-</span><span class="s4">0.9375</span><span class="s2">, </span><span class="s4">0.625</span><span class="s2">]))</span>

    <span class="s1">dec </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">score_samples</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">) - </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">offset_</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">), </span><span class="s1">dec</span><span class="s2">)</span>

    <span class="s1">pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">pred</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]))</span>


<span class="s0">def </span><span class="s1">test_ocsvm_vs_sgdocsvm</span><span class="s2">():</span>
    <span class="s5"># Checks SGDOneClass SVM gives a good approximation of kernelized</span>
    <span class="s5"># One-Class SVM</span>
    <span class="s1">nu </span><span class="s2">= </span><span class="s4">0.05</span>
    <span class="s1">gamma </span><span class="s2">= </span><span class="s4">2.0</span>
    <span class="s1">random_state </span><span class="s2">= </span><span class="s4">42</span>

    <span class="s5"># Generate train and test data</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s4">0.3 </span><span class="s2">* </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s4">500</span><span class="s2">, </span><span class="s4">2</span><span class="s2">)</span>
    <span class="s1">X_train </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">X </span><span class="s2">+ </span><span class="s4">2</span><span class="s2">, </span><span class="s1">X </span><span class="s2">- </span><span class="s4">2</span><span class="s2">]</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s4">0.3 </span><span class="s2">* </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s4">100</span><span class="s2">, </span><span class="s4">2</span><span class="s2">)</span>
    <span class="s1">X_test </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">r_</span><span class="s2">[</span><span class="s1">X </span><span class="s2">+ </span><span class="s4">2</span><span class="s2">, </span><span class="s1">X </span><span class="s2">- </span><span class="s4">2</span><span class="s2">]</span>

    <span class="s5"># One-Class SVM</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">OneClassSVM</span><span class="s2">(</span><span class="s1">gamma</span><span class="s2">=</span><span class="s1">gamma</span><span class="s2">, </span><span class="s1">kernel</span><span class="s2">=</span><span class="s3">&quot;rbf&quot;</span><span class="s2">, </span><span class="s1">nu</span><span class="s2">=</span><span class="s1">nu</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">)</span>
    <span class="s1">y_pred_ocsvm </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>
    <span class="s1">dec_ocsvm </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">)</span>

    <span class="s5"># SGDOneClassSVM using kernel approximation</span>
    <span class="s1">max_iter </span><span class="s2">= </span><span class="s4">15</span>
    <span class="s1">transform </span><span class="s2">= </span><span class="s1">Nystroem</span><span class="s2">(</span><span class="s1">gamma</span><span class="s2">=</span><span class="s1">gamma</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">random_state</span><span class="s2">)</span>
    <span class="s1">clf_sgd </span><span class="s2">= </span><span class="s1">SGDOneClassSVM</span><span class="s2">(</span>
        <span class="s1">nu</span><span class="s2">=</span><span class="s1">nu</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s1">max_iter</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">random_state</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">pipe_sgd </span><span class="s2">= </span><span class="s1">make_pipeline</span><span class="s2">(</span><span class="s1">transform</span><span class="s2">, </span><span class="s1">clf_sgd</span><span class="s2">)</span>
    <span class="s1">pipe_sgd</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">)</span>
    <span class="s1">y_pred_sgdocsvm </span><span class="s2">= </span><span class="s1">pipe_sgd</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>
    <span class="s1">dec_sgdocsvm </span><span class="s2">= </span><span class="s1">pipe_sgd</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">y_pred_sgdocsvm </span><span class="s2">== </span><span class="s1">y_pred_ocsvm</span><span class="s2">) &gt;= </span><span class="s4">0.99</span>
    <span class="s1">corrcoef </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">corrcoef</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">((</span><span class="s1">dec_ocsvm</span><span class="s2">, </span><span class="s1">dec_sgdocsvm</span><span class="s2">)))[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]</span>
    <span class="s0">assert </span><span class="s1">corrcoef </span><span class="s2">&gt;= </span><span class="s4">0.9</span>


<span class="s0">def </span><span class="s1">test_l1_ratio</span><span class="s2">():</span>
    <span class="s5"># Test if l1 ratio extremes match L1 and L2 penalty settings.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">datasets</span><span class="s2">.</span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s4">100</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s4">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">1234</span>
    <span class="s2">)</span>

    <span class="s5"># test if elasticnet with l1_ratio near 1 gives same result as pure l1</span>
    <span class="s1">est_en </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.001</span><span class="s2">,</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">6</span><span class="s2">,</span>
        <span class="s1">l1_ratio</span><span class="s2">=</span><span class="s4">0.9999999999</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">,</span>
    <span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">est_l1 </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.001</span><span class="s2">, </span><span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">6</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s0">None</span>
    <span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">est_en</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">est_l1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>

    <span class="s5"># test if elasticnet with l1_ratio near 0 gives same result as pure l2</span>
    <span class="s1">est_en </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.001</span><span class="s2">,</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">6</span><span class="s2">,</span>
        <span class="s1">l1_ratio</span><span class="s2">=</span><span class="s4">0.0000000001</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">,</span>
    <span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">est_l2 </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.001</span><span class="s2">, </span><span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l2&quot;</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">6</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s0">None</span>
    <span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">est_en</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">est_l2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_underflow_or_overlow</span><span class="s2">():</span>
    <span class="s0">with </span><span class="s1">np</span><span class="s2">.</span><span class="s1">errstate</span><span class="s2">(</span><span class="s1">all</span><span class="s2">=</span><span class="s3">&quot;raise&quot;</span><span class="s2">):</span>
        <span class="s5"># Generate some weird data with hugely unscaled features</span>
        <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
        <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">100</span>
        <span class="s1">n_features </span><span class="s2">= </span><span class="s4">10</span>

        <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">))</span>
        <span class="s1">X</span><span class="s2">[:, :</span><span class="s4">2</span><span class="s2">] *= </span><span class="s4">1e300</span>
        <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">isfinite</span><span class="s2">(</span><span class="s1">X</span><span class="s2">).</span><span class="s1">all</span><span class="s2">()</span>

        <span class="s5"># Use MinMaxScaler to scale the data without introducing a numerical</span>
        <span class="s5"># instability (computing the standard deviation naively is not possible</span>
        <span class="s5"># on this data)</span>
        <span class="s1">X_scaled </span><span class="s2">= </span><span class="s1">MinMaxScaler</span><span class="s2">().</span><span class="s1">fit_transform</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">isfinite</span><span class="s2">(</span><span class="s1">X_scaled</span><span class="s2">).</span><span class="s1">all</span><span class="s2">()</span>

        <span class="s5"># Define a ground truth on the scaled data</span>
        <span class="s1">ground_truth </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">)</span>
        <span class="s1">y </span><span class="s2">= (</span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">X_scaled</span><span class="s2">, </span><span class="s1">ground_truth</span><span class="s2">) &gt; </span><span class="s4">0.0</span><span class="s2">).</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">int32</span><span class="s2">)</span>
        <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">y</span><span class="s2">), [</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">])</span>

        <span class="s1">model </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span><span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;squared_hinge&quot;</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">500</span><span class="s2">)</span>

        <span class="s5"># smoke test: model is stable on scaled data</span>
        <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_scaled</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">isfinite</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">).</span><span class="s1">all</span><span class="s2">()</span>

        <span class="s5"># model is numerically unstable on unscaled data</span>
        <span class="s1">msg_regxp </span><span class="s2">= (</span>
            <span class="s3">r&quot;Floating-point under-/overflow occurred at epoch #.*&quot;</span>
            <span class="s3">&quot; Scaling input data with StandardScaler or MinMaxScaler&quot;</span>
            <span class="s3">&quot; might help.&quot;</span>
        <span class="s2">)</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg_regxp</span><span class="s2">):</span>
            <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_numerical_stability_large_gradient</span><span class="s2">():</span>
    <span class="s5"># Non regression test case for numerical stability on scaled problems</span>
    <span class="s5"># where the gradient can still explode with some losses</span>
    <span class="s1">model </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;squared_hinge&quot;</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">10</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
        <span class="s1">l1_ratio</span><span class="s2">=</span><span class="s4">0.3</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">0.01</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.001</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">np</span><span class="s2">.</span><span class="s1">errstate</span><span class="s2">(</span><span class="s1">all</span><span class="s2">=</span><span class="s3">&quot;raise&quot;</span><span class="s2">):</span>
        <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">isfinite</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">).</span><span class="s1">all</span><span class="s2">()</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;penalty&quot;</span><span class="s2">, [</span><span class="s3">&quot;l2&quot;</span><span class="s2">, </span><span class="s3">&quot;l1&quot;</span><span class="s2">, </span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_large_regularization</span><span class="s2">(</span><span class="s1">penalty</span><span class="s2">):</span>
    <span class="s5"># Non regression tests for numerical stability issues caused by large</span>
    <span class="s5"># regularization parameters</span>
    <span class="s1">model </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">1e5</span><span class="s2">,</span>
        <span class="s1">learning_rate</span><span class="s2">=</span><span class="s3">&quot;constant&quot;</span><span class="s2">,</span>
        <span class="s1">eta0</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">,</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s1">penalty</span><span class="s2">,</span>
        <span class="s1">shuffle</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">6</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">np</span><span class="s2">.</span><span class="s1">errstate</span><span class="s2">(</span><span class="s1">all</span><span class="s2">=</span><span class="s3">&quot;raise&quot;</span><span class="s2">):</span>
        <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros_like</span><span class="s2">(</span><span class="s1">model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">))</span>


<span class="s0">def </span><span class="s1">test_tol_parameter</span><span class="s2">():</span>
    <span class="s5"># Test that the tol parameter behaves as expected</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">StandardScaler</span><span class="s2">().</span><span class="s1">fit_transform</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target </span><span class="s2">== </span><span class="s4">1</span>

    <span class="s5"># With tol is None, the number of iteration should be equal to max_iter</span>
    <span class="s1">max_iter </span><span class="s2">= </span><span class="s4">42</span>
    <span class="s1">model_0 </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span><span class="s1">tol</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s1">max_iter</span><span class="s2">)</span>
    <span class="s1">model_0</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">max_iter </span><span class="s2">== </span><span class="s1">model_0</span><span class="s2">.</span><span class="s1">n_iter_</span>

    <span class="s5"># If tol is not None, the number of iteration should be less than max_iter</span>
    <span class="s1">max_iter </span><span class="s2">= </span><span class="s4">2000</span>
    <span class="s1">model_1 </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span><span class="s1">tol</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s1">max_iter</span><span class="s2">)</span>
    <span class="s1">model_1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">max_iter </span><span class="s2">&gt; </span><span class="s1">model_1</span><span class="s2">.</span><span class="s1">n_iter_</span>
    <span class="s0">assert </span><span class="s1">model_1</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">&gt; </span><span class="s4">5</span>

    <span class="s5"># A larger tol should yield a smaller number of iteration</span>
    <span class="s1">model_2 </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span><span class="s1">tol</span><span class="s2">=</span><span class="s4">0.1</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s1">max_iter</span><span class="s2">)</span>
    <span class="s1">model_2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">model_1</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">&gt; </span><span class="s1">model_2</span><span class="s2">.</span><span class="s1">n_iter_</span>
    <span class="s0">assert </span><span class="s1">model_2</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">&gt; </span><span class="s4">3</span>

    <span class="s5"># Strict tolerance and small max_iter should trigger a warning</span>
    <span class="s1">model_3 </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">3</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">warning_message </span><span class="s2">= (</span>
        <span class="s3">&quot;Maximum number of iteration reached before &quot;</span>
        <span class="s3">&quot;convergence. Consider increasing max_iter to &quot;</span>
        <span class="s3">&quot;improve the fit.&quot;</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">ConvergenceWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">warning_message</span><span class="s2">):</span>
        <span class="s1">model_3</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">model_3</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">== </span><span class="s4">3</span>


<span class="s0">def </span><span class="s1">_test_loss_common</span><span class="s2">(</span><span class="s1">loss_function</span><span class="s2">, </span><span class="s1">cases</span><span class="s2">):</span>
    <span class="s5"># Test the different loss functions</span>
    <span class="s5"># cases is a list of (p, y, expected)</span>
    <span class="s0">for </span><span class="s1">p</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">expected_loss</span><span class="s2">, </span><span class="s1">expected_dloss </span><span class="s0">in </span><span class="s1">cases</span><span class="s2">:</span>
        <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">loss_function</span><span class="s2">.</span><span class="s1">py_loss</span><span class="s2">(</span><span class="s1">p</span><span class="s2">, </span><span class="s1">y</span><span class="s2">), </span><span class="s1">expected_loss</span><span class="s2">)</span>
        <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">loss_function</span><span class="s2">.</span><span class="s1">py_dloss</span><span class="s2">(</span><span class="s1">p</span><span class="s2">, </span><span class="s1">y</span><span class="s2">), </span><span class="s1">expected_dloss</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_loss_hinge</span><span class="s2">():</span>
    <span class="s5"># Test Hinge (hinge / perceptron)</span>
    <span class="s5"># hinge</span>
    <span class="s1">loss </span><span class="s2">= </span><span class="s1">sgd_fast</span><span class="s2">.</span><span class="s1">Hinge</span><span class="s2">(</span><span class="s4">1.0</span><span class="s2">)</span>
    <span class="s1">cases </span><span class="s2">= [</span>
        <span class="s5"># (p, y, expected_loss, expected_dloss)</span>
        <span class="s2">(</span><span class="s4">1.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">2.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.5</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">2.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">3.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">0.5</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">),</span>
    <span class="s2">]</span>
    <span class="s1">_test_loss_common</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">, </span><span class="s1">cases</span><span class="s2">)</span>

    <span class="s5"># perceptron</span>
    <span class="s1">loss </span><span class="s2">= </span><span class="s1">sgd_fast</span><span class="s2">.</span><span class="s1">Hinge</span><span class="s2">(</span><span class="s4">0.0</span><span class="s2">)</span>
    <span class="s1">cases </span><span class="s2">= [</span>
        <span class="s5"># (p, y, expected_loss, expected_dloss)</span>
        <span class="s2">(</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">0.1</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.5</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">2.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.5</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">),</span>
    <span class="s2">]</span>
    <span class="s1">_test_loss_common</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">, </span><span class="s1">cases</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_gradient_squared_hinge</span><span class="s2">():</span>
    <span class="s5"># Test SquaredHinge</span>
    <span class="s1">loss </span><span class="s2">= </span><span class="s1">sgd_fast</span><span class="s2">.</span><span class="s1">SquaredHinge</span><span class="s2">(</span><span class="s4">1.0</span><span class="s2">)</span>
    <span class="s1">cases </span><span class="s2">= [</span>
        <span class="s5"># (p, y, expected_loss, expected_dloss)</span>
        <span class="s2">(</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">2.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">4.0</span><span class="s2">, </span><span class="s4">4.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">4.0</span><span class="s2">, -</span><span class="s4">4.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.25</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.5</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">2.25</span><span class="s2">, </span><span class="s4">3.0</span><span class="s2">),</span>
    <span class="s2">]</span>
    <span class="s1">_test_loss_common</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">, </span><span class="s1">cases</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_loss_log</span><span class="s2">():</span>
    <span class="s5"># Test Log (logistic loss)</span>
    <span class="s1">loss </span><span class="s2">= </span><span class="s1">sgd_fast</span><span class="s2">.</span><span class="s1">Log</span><span class="s2">()</span>
    <span class="s1">cases </span><span class="s2">= [</span>
        <span class="s5"># (p, y, expected_loss, expected_dloss)</span>
        <span class="s2">(</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">log</span><span class="s2">(</span><span class="s4">1.0 </span><span class="s2">+ </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(-</span><span class="s4">1.0</span><span class="s2">)), -</span><span class="s4">1.0 </span><span class="s2">/ (</span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(</span><span class="s4">1.0</span><span class="s2">) + </span><span class="s4">1.0</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">log</span><span class="s2">(</span><span class="s4">1.0 </span><span class="s2">+ </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(</span><span class="s4">1.0</span><span class="s2">)), </span><span class="s4">1.0 </span><span class="s2">/ (</span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(-</span><span class="s4">1.0</span><span class="s2">) + </span><span class="s4">1.0</span><span class="s2">)),</span>
        <span class="s2">(-</span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">log</span><span class="s2">(</span><span class="s4">1.0 </span><span class="s2">+ </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(-</span><span class="s4">1.0</span><span class="s2">)), </span><span class="s4">1.0 </span><span class="s2">/ (</span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(</span><span class="s4">1.0</span><span class="s2">) + </span><span class="s4">1.0</span><span class="s2">)),</span>
        <span class="s2">(-</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">log</span><span class="s2">(</span><span class="s4">1.0 </span><span class="s2">+ </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(</span><span class="s4">1.0</span><span class="s2">)), -</span><span class="s4">1.0 </span><span class="s2">/ (</span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(-</span><span class="s4">1.0</span><span class="s2">) + </span><span class="s4">1.0</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">log</span><span class="s2">(</span><span class="s4">2</span><span class="s2">), -</span><span class="s4">0.5</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">log</span><span class="s2">(</span><span class="s4">2</span><span class="s2">), </span><span class="s4">0.5</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">17.9</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">17.9</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">17.9</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">17.9</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">),</span>
    <span class="s2">]</span>
    <span class="s1">_test_loss_common</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">, </span><span class="s1">cases</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">.</span><span class="s1">py_dloss</span><span class="s2">(</span><span class="s4">18.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(-</span><span class="s4">18.1</span><span class="s2">) * -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">16</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">.</span><span class="s1">py_loss</span><span class="s2">(</span><span class="s4">18.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(-</span><span class="s4">18.1</span><span class="s2">), </span><span class="s4">16</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">.</span><span class="s1">py_dloss</span><span class="s2">(-</span><span class="s4">18.1</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(-</span><span class="s4">18.1</span><span class="s2">) * </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">16</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">.</span><span class="s1">py_loss</span><span class="s2">(-</span><span class="s4">18.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">), </span><span class="s4">18.1</span><span class="s2">, </span><span class="s4">16</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_loss_squared_loss</span><span class="s2">():</span>
    <span class="s5"># Test SquaredLoss</span>
    <span class="s1">loss </span><span class="s2">= </span><span class="s1">sgd_fast</span><span class="s2">.</span><span class="s1">SquaredLoss</span><span class="s2">()</span>
    <span class="s1">cases </span><span class="s2">= [</span>
        <span class="s5"># (p, y, expected_loss, expected_dloss)</span>
        <span class="s2">(</span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.5</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.125</span><span class="s2">, </span><span class="s4">1.5</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">2.5</span><span class="s2">, </span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">10.125</span><span class="s2">, -</span><span class="s4">4.5</span><span class="s2">),</span>
    <span class="s2">]</span>
    <span class="s1">_test_loss_common</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">, </span><span class="s1">cases</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_loss_huber</span><span class="s2">():</span>
    <span class="s5"># Test Huber</span>
    <span class="s1">loss </span><span class="s2">= </span><span class="s1">sgd_fast</span><span class="s2">.</span><span class="s1">Huber</span><span class="s2">(</span><span class="s4">0.1</span><span class="s2">)</span>
    <span class="s1">cases </span><span class="s2">= [</span>
        <span class="s5"># (p, y, expected_loss, expected_dloss)</span>
        <span class="s2">(</span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.005</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">0.005</span><span class="s2">, -</span><span class="s4">0.1</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">3.95</span><span class="s2">, </span><span class="s4">4.0</span><span class="s2">, </span><span class="s4">0.00125</span><span class="s2">, -</span><span class="s4">0.05</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">5.0</span><span class="s2">, </span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">0.295</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">5.0</span><span class="s2">, </span><span class="s4">0.595</span><span class="s2">, -</span><span class="s4">0.1</span><span class="s2">),</span>
    <span class="s2">]</span>
    <span class="s1">_test_loss_common</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">, </span><span class="s1">cases</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_loss_modified_huber</span><span class="s2">():</span>
    <span class="s5"># (p, y, expected_loss, expected_dloss)</span>
    <span class="s1">loss </span><span class="s2">= </span><span class="s1">sgd_fast</span><span class="s2">.</span><span class="s1">ModifiedHuber</span><span class="s2">()</span>
    <span class="s1">cases </span><span class="s2">= [</span>
        <span class="s5"># (p, y, expected_loss, expected_dloss)</span>
        <span class="s2">(</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, -</span><span class="s4">2.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">4.0</span><span class="s2">, -</span><span class="s4">4.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.5</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">2.25</span><span class="s2">, </span><span class="s4">3.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">8</span><span class="s2">, -</span><span class="s4">4.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">3.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">12</span><span class="s2">, -</span><span class="s4">4.0</span><span class="s2">),</span>
    <span class="s2">]</span>
    <span class="s1">_test_loss_common</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">, </span><span class="s1">cases</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_loss_epsilon_insensitive</span><span class="s2">():</span>
    <span class="s5"># Test EpsilonInsensitive</span>
    <span class="s1">loss </span><span class="s2">= </span><span class="s1">sgd_fast</span><span class="s2">.</span><span class="s1">EpsilonInsensitive</span><span class="s2">(</span><span class="s4">0.1</span><span class="s2">)</span>
    <span class="s1">cases </span><span class="s2">= [</span>
        <span class="s5"># (p, y, expected_loss, expected_dloss)</span>
        <span class="s2">(</span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">2.05</span><span class="s2">, -</span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">3.05</span><span class="s2">, </span><span class="s4">3.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">2.2</span><span class="s2">, </span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">2.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">2.9</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">2.2</span><span class="s2">, </span><span class="s4">0.1</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">2.9</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">),</span>
    <span class="s2">]</span>
    <span class="s1">_test_loss_common</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">, </span><span class="s1">cases</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_loss_squared_epsilon_insensitive</span><span class="s2">():</span>
    <span class="s5"># Test SquaredEpsilonInsensitive</span>
    <span class="s1">loss </span><span class="s2">= </span><span class="s1">sgd_fast</span><span class="s2">.</span><span class="s1">SquaredEpsilonInsensitive</span><span class="s2">(</span><span class="s4">0.1</span><span class="s2">)</span>
    <span class="s1">cases </span><span class="s2">= [</span>
        <span class="s5"># (p, y, expected_loss, expected_dloss)</span>
        <span class="s2">(</span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">0.1</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">2.05</span><span class="s2">, -</span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">3.05</span><span class="s2">, </span><span class="s4">3.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.0</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">2.2</span><span class="s2">, </span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">0.01</span><span class="s2">, </span><span class="s4">0.2</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">2.0</span><span class="s2">, -</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">8.41</span><span class="s2">, </span><span class="s4">5.8</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">2.2</span><span class="s2">, </span><span class="s4">0.01</span><span class="s2">, -</span><span class="s4">0.2</span><span class="s2">),</span>
        <span class="s2">(-</span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">8.41</span><span class="s2">, -</span><span class="s4">5.8</span><span class="s2">),</span>
    <span class="s2">]</span>
    <span class="s1">_test_loss_common</span><span class="s2">(</span><span class="s1">loss</span><span class="s2">, </span><span class="s1">cases</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_multi_thread_multi_class_and_early_stopping</span><span class="s2">():</span>
    <span class="s5"># This is a non-regression test for a bad interaction between</span>
    <span class="s5"># early stopping internal attribute and thread-based parallelism.</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">,</span>
        <span class="s1">early_stopping</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">n_iter_no_change</span><span class="s2">=</span><span class="s4">100</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">,</span>
        <span class="s1">n_jobs</span><span class="s2">=</span><span class="s4">2</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">&gt; </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">n_iter_no_change</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">&lt; </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">n_iter_no_change </span><span class="s2">+ </span><span class="s4">20</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">) &gt; </span><span class="s4">0.8</span>


<span class="s0">def </span><span class="s1">test_multi_core_gridsearch_and_early_stopping</span><span class="s2">():</span>
    <span class="s5"># This is a non-regression test for a bad interaction between</span>
    <span class="s5"># early stopping internal attribute and process-based multi-core</span>
    <span class="s5"># parallelism.</span>
    <span class="s1">param_grid </span><span class="s2">= {</span>
        <span class="s3">&quot;alpha&quot;</span><span class="s2">: </span><span class="s1">np</span><span class="s2">.</span><span class="s1">logspace</span><span class="s2">(-</span><span class="s4">4</span><span class="s2">, </span><span class="s4">4</span><span class="s2">, </span><span class="s4">9</span><span class="s2">),</span>
        <span class="s3">&quot;n_iter_no_change&quot;</span><span class="s2">: [</span><span class="s4">5</span><span class="s2">, </span><span class="s4">10</span><span class="s2">, </span><span class="s4">50</span><span class="s2">],</span>
    <span class="s2">}</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span><span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-2</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">early_stopping</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">search </span><span class="s2">= </span><span class="s1">RandomizedSearchCV</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">param_grid</span><span class="s2">, </span><span class="s1">n_iter</span><span class="s2">=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">n_jobs</span><span class="s2">=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">search</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">search</span><span class="s2">.</span><span class="s1">best_score_ </span><span class="s2">&gt; </span><span class="s4">0.8</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;backend&quot;</span><span class="s2">, [</span><span class="s3">&quot;loky&quot;</span><span class="s2">, </span><span class="s3">&quot;multiprocessing&quot;</span><span class="s2">, </span><span class="s3">&quot;threading&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_SGDClassifier_fit_for_all_backends</span><span class="s2">(</span><span class="s1">backend</span><span class="s2">):</span>
    <span class="s5"># This is a non-regression smoke test. In the multi-class case,</span>
    <span class="s5"># SGDClassifier.fit fits each class in a one-versus-all fashion using</span>
    <span class="s5"># joblib.Parallel.  However, each OvA step updates the coef_ attribute of</span>
    <span class="s5"># the estimator in-place. Internally, SGDClassifier calls Parallel using</span>
    <span class="s5"># require='sharedmem'. This test makes sure SGDClassifier.fit works</span>
    <span class="s5"># consistently even when the user asks for a backend that does not provide</span>
    <span class="s5"># sharedmem semantics.</span>

    <span class="s5"># We further test a case where memmapping would have been used if</span>
    <span class="s5"># SGDClassifier.fit was called from a loky or multiprocessing backend. In</span>
    <span class="s5"># this specific case, in-place modification of clf.coef_ would have caused</span>
    <span class="s5"># a segmentation fault when trying to write in a readonly memory mapped</span>
    <span class="s5"># buffer.</span>

    <span class="s1">random_state </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">42</span><span class="s2">)</span>

    <span class="s5"># Create a classification problem with 50000 features and 20 classes. Using</span>
    <span class="s5"># loky or multiprocessing this make the clf.coef_ exceed the threshold</span>
    <span class="s5"># above which memmaping is used in joblib and loky (1MB as of 2018/11/1).</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">sp</span><span class="s2">.</span><span class="s1">random</span><span class="s2">(</span><span class="s4">500</span><span class="s2">, </span><span class="s4">2000</span><span class="s2">, </span><span class="s1">density</span><span class="s2">=</span><span class="s4">0.02</span><span class="s2">, </span><span class="s1">format</span><span class="s2">=</span><span class="s3">&quot;csr&quot;</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">random_state</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">random_state</span><span class="s2">.</span><span class="s1">choice</span><span class="s2">(</span><span class="s4">20</span><span class="s2">, </span><span class="s4">500</span><span class="s2">)</span>

    <span class="s5"># Begin by fitting a SGD classifier sequentially</span>
    <span class="s1">clf_sequential </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">n_jobs</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">clf_sequential</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s5"># Fit a SGDClassifier using the specified backend, and make sure the</span>
    <span class="s5"># coefficients are equal to those obtained using a sequential fit</span>
    <span class="s1">clf_parallel </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">, </span><span class="s1">n_jobs</span><span class="s2">=</span><span class="s4">4</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">joblib</span><span class="s2">.</span><span class="s1">parallel_backend</span><span class="s2">(</span><span class="s1">backend</span><span class="s2">=</span><span class="s1">backend</span><span class="s2">):</span>
        <span class="s1">clf_parallel</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf_sequential</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf_parallel</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;Estimator&quot;</span><span class="s2">, [</span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDRegressor</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_sgd_random_state</span><span class="s2">(</span><span class="s1">Estimator</span><span class="s2">, </span><span class="s1">global_random_seed</span><span class="s2">):</span>
    <span class="s5"># Train the same model on the same data without converging and check that we</span>
    <span class="s5"># get reproducible results by fixing the random seed.</span>
    <span class="s0">if </span><span class="s1">Estimator </span><span class="s2">== </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDRegressor</span><span class="s2">:</span>
        <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">datasets</span><span class="s2">.</span><span class="s1">make_regression</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">datasets</span><span class="s2">.</span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">)</span>

    <span class="s5"># Fitting twice a model with the same hyper-parameters on the same training</span>
    <span class="s5"># set with the same seed leads to the same results deterministically.</span>

    <span class="s1">est </span><span class="s2">= </span><span class="s1">Estimator</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">ConvergenceWarning</span><span class="s2">):</span>
        <span class="s1">coef_same_seed_a </span><span class="s2">= </span><span class="s1">est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">).</span><span class="s1">coef_</span>
        <span class="s0">assert </span><span class="s1">est</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">== </span><span class="s4">1</span>

    <span class="s1">est </span><span class="s2">= </span><span class="s1">Estimator</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">ConvergenceWarning</span><span class="s2">):</span>
        <span class="s1">coef_same_seed_b </span><span class="s2">= </span><span class="s1">est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">).</span><span class="s1">coef_</span>
        <span class="s0">assert </span><span class="s1">est</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">== </span><span class="s4">1</span>

    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">coef_same_seed_a</span><span class="s2">, </span><span class="s1">coef_same_seed_b</span><span class="s2">)</span>

    <span class="s5"># Fitting twice a model with the same hyper-parameters on the same training</span>
    <span class="s5"># set but with different random seed leads to different results after one</span>
    <span class="s5"># epoch because of the random shuffling of the dataset.</span>

    <span class="s1">est </span><span class="s2">= </span><span class="s1">Estimator</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">ConvergenceWarning</span><span class="s2">):</span>
        <span class="s1">coef_other_seed </span><span class="s2">= </span><span class="s1">est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">).</span><span class="s1">coef_</span>
        <span class="s0">assert </span><span class="s1">est</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">== </span><span class="s4">1</span>

    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">abs</span><span class="s2">(</span><span class="s1">coef_same_seed_a </span><span class="s2">- </span><span class="s1">coef_other_seed</span><span class="s2">).</span><span class="s1">max</span><span class="s2">() &gt; </span><span class="s4">1.0</span>


<span class="s0">def </span><span class="s1">test_validation_mask_correctly_subsets</span><span class="s2">(</span><span class="s1">monkeypatch</span><span class="s2">):</span>
    <span class="s6">&quot;&quot;&quot;Test that data passed to validation callback correctly subsets. 
 
    Non-regression test for #23255. 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">Y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]</span>
    <span class="s1">validation_fraction </span><span class="s2">= </span><span class="s4">0.2</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDClassifier</span><span class="s2">(</span>
        <span class="s1">early_stopping</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s4">1e-3</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s4">1000</span><span class="s2">,</span>
        <span class="s1">validation_fraction</span><span class="s2">=</span><span class="s1">validation_fraction</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">mock </span><span class="s2">= </span><span class="s1">Mock</span><span class="s2">(</span><span class="s1">side_effect</span><span class="s2">=</span><span class="s1">_stochastic_gradient</span><span class="s2">.</span><span class="s1">_ValidationScoreCallback</span><span class="s2">)</span>
    <span class="s1">monkeypatch</span><span class="s2">.</span><span class="s1">setattr</span><span class="s2">(</span><span class="s1">_stochastic_gradient</span><span class="s2">, </span><span class="s3">&quot;_ValidationScoreCallback&quot;</span><span class="s2">, </span><span class="s1">mock</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>

    <span class="s1">X_val</span><span class="s2">, </span><span class="s1">y_val </span><span class="s2">= </span><span class="s1">mock</span><span class="s2">.</span><span class="s1">call_args</span><span class="s2">[</span><span class="s4">0</span><span class="s2">][</span><span class="s4">1</span><span class="s2">:</span><span class="s4">3</span><span class="s2">]</span>
    <span class="s0">assert </span><span class="s1">X_val</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] == </span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">* </span><span class="s1">validation_fraction</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">y_val</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] == </span><span class="s1">int</span><span class="s2">(</span><span class="s1">n_samples </span><span class="s2">* </span><span class="s1">validation_fraction</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_sgd_error_on_zero_validation_weight</span><span class="s2">():</span>
    <span class="s5"># Test that SGDClassifier raises error when all the validation samples</span>
    <span class="s5"># have zero sample_weight. Non-regression test for #17229.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">Y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span>
    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros_like</span><span class="s2">(</span><span class="s1">Y</span><span class="s2">)</span>
    <span class="s1">validation_fraction </span><span class="s2">= </span><span class="s4">0.4</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">SGDClassifier</span><span class="s2">(</span>
        <span class="s1">early_stopping</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">validation_fraction</span><span class="s2">=</span><span class="s1">validation_fraction</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span>
    <span class="s2">)</span>

    <span class="s1">error_message </span><span class="s2">= (</span>
        <span class="s3">&quot;The sample weights for validation set are all zero, consider using a&quot;</span>
        <span class="s3">&quot; different random state.&quot;</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">error_message</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;Estimator&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SGDRegressor</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sgd_verbose</span><span class="s2">(</span><span class="s1">Estimator</span><span class="s2">):</span>
    <span class="s6">&quot;&quot;&quot;non-regression test for gh #25249&quot;&quot;&quot;</span>
    <span class="s1">Estimator</span><span class="s2">(</span><span class="s1">verbose</span><span class="s2">=</span><span class="s4">1</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;SGDEstimator&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s1">SGDClassifier</span><span class="s2">,</span>
        <span class="s1">SparseSGDClassifier</span><span class="s2">,</span>
        <span class="s1">SGDRegressor</span><span class="s2">,</span>
        <span class="s1">SparseSGDRegressor</span><span class="s2">,</span>
        <span class="s1">SGDOneClassSVM</span><span class="s2">,</span>
        <span class="s1">SparseSGDOneClassSVM</span><span class="s2">,</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;data_type&quot;</span><span class="s2">, (</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">))</span>
<span class="s0">def </span><span class="s1">test_sgd_dtype_match</span><span class="s2">(</span><span class="s1">SGDEstimator</span><span class="s2">, </span><span class="s1">data_type</span><span class="s2">):</span>
    <span class="s1">_X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">data_type</span><span class="s2">)</span>
    <span class="s1">_Y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">Y</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">data_type</span><span class="s2">)</span>
    <span class="s1">sgd_model </span><span class="s2">= </span><span class="s1">SGDEstimator</span><span class="s2">()</span>
    <span class="s1">sgd_model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">_X</span><span class="s2">, </span><span class="s1">_Y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">sgd_model</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">data_type</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;SGDEstimator&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s1">SGDClassifier</span><span class="s2">,</span>
        <span class="s1">SparseSGDClassifier</span><span class="s2">,</span>
        <span class="s1">SGDRegressor</span><span class="s2">,</span>
        <span class="s1">SparseSGDRegressor</span><span class="s2">,</span>
        <span class="s1">SGDOneClassSVM</span><span class="s2">,</span>
        <span class="s1">SparseSGDOneClassSVM</span><span class="s2">,</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_sgd_numerical_consistency</span><span class="s2">(</span><span class="s1">SGDEstimator</span><span class="s2">):</span>
    <span class="s1">X_64 </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
    <span class="s1">Y_64 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">Y</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>

    <span class="s1">X_32 </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">)</span>
    <span class="s1">Y_32 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">Y</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">)</span>

    <span class="s1">sgd_64 </span><span class="s2">= </span><span class="s1">SGDEstimator</span><span class="s2">(</span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">)</span>
    <span class="s1">sgd_64</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_64</span><span class="s2">, </span><span class="s1">Y_64</span><span class="s2">)</span>

    <span class="s1">sgd_32 </span><span class="s2">= </span><span class="s1">SGDEstimator</span><span class="s2">(</span><span class="s1">max_iter</span><span class="s2">=</span><span class="s4">20</span><span class="s2">)</span>
    <span class="s1">sgd_32</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_32</span><span class="s2">, </span><span class="s1">Y_32</span><span class="s2">)</span>

    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">sgd_64</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">sgd_32</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s5"># TODO(1.6): remove</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;Estimator&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SGDOneClassSVM</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_loss_attribute_deprecation</span><span class="s2">(</span><span class="s1">Estimator</span><span class="s2">):</span>
    <span class="s5"># Check that we raise the proper deprecation warning if accessing</span>
    <span class="s5"># `loss_function_`.</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">], [</span><span class="s4">3</span><span class="s2">, </span><span class="s4">4</span><span class="s2">]])</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">])</span>
    <span class="s1">est </span><span class="s2">= </span><span class="s1">Estimator</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">FutureWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;`loss_function_` was deprecated&quot;</span><span class="s2">):</span>
        <span class="s1">est</span><span class="s2">.</span><span class="s1">loss_function_</span>


<span class="s5"># TODO(1.7): remove</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;Estimator&quot;</span><span class="s2">, [</span><span class="s1">SGDClassifier</span><span class="s2">, </span><span class="s1">SGDRegressor</span><span class="s2">, </span><span class="s1">SGDOneClassSVM</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_passive_aggressive_deprecated_average</span><span class="s2">(</span><span class="s1">Estimator</span><span class="s2">):</span>
    <span class="s1">est </span><span class="s2">= </span><span class="s1">Estimator</span><span class="s2">(</span><span class="s1">average</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">FutureWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;average=0&quot;</span><span class="s2">):</span>
        <span class="s1">est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">)</span>
</pre>
</body>
</html>