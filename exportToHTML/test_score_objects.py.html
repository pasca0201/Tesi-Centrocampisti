<html>
<head>
<title>test_score_objects.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #6aab73;}
.s4 { color: #7a7e85;}
.s5 { color: #5f826b; font-style: italic;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_score_objects.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numbers</span>
<span class="s0">import </span><span class="s1">pickle</span>
<span class="s0">from </span><span class="s1">copy </span><span class="s0">import </span><span class="s1">deepcopy</span>
<span class="s0">from </span><span class="s1">functools </span><span class="s0">import </span><span class="s1">partial</span>
<span class="s0">from </span><span class="s1">unittest</span><span class="s2">.</span><span class="s1">mock </span><span class="s0">import </span><span class="s1">Mock</span>

<span class="s0">import </span><span class="s1">joblib</span>
<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">numpy</span><span class="s2">.</span><span class="s1">testing </span><span class="s0">import </span><span class="s1">assert_allclose</span>

<span class="s0">from </span><span class="s1">sklearn </span><span class="s0">import </span><span class="s1">config_context</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">base </span><span class="s0">import </span><span class="s1">BaseEstimator</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">cluster </span><span class="s0">import </span><span class="s1">KMeans</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">datasets </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">load_diabetes</span><span class="s2">,</span>
    <span class="s1">make_blobs</span><span class="s2">,</span>
    <span class="s1">make_classification</span><span class="s2">,</span>
    <span class="s1">make_multilabel_classification</span><span class="s2">,</span>
    <span class="s1">make_regression</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">linear_model </span><span class="s0">import </span><span class="s1">LogisticRegression</span><span class="s2">, </span><span class="s1">Perceptron</span><span class="s2">, </span><span class="s1">Ridge</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">metrics </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">accuracy_score</span><span class="s2">,</span>
    <span class="s1">average_precision_score</span><span class="s2">,</span>
    <span class="s1">balanced_accuracy_score</span><span class="s2">,</span>
    <span class="s1">brier_score_loss</span><span class="s2">,</span>
    <span class="s1">check_scoring</span><span class="s2">,</span>
    <span class="s1">f1_score</span><span class="s2">,</span>
    <span class="s1">fbeta_score</span><span class="s2">,</span>
    <span class="s1">get_scorer</span><span class="s2">,</span>
    <span class="s1">get_scorer_names</span><span class="s2">,</span>
    <span class="s1">jaccard_score</span><span class="s2">,</span>
    <span class="s1">log_loss</span><span class="s2">,</span>
    <span class="s1">make_scorer</span><span class="s2">,</span>
    <span class="s1">matthews_corrcoef</span><span class="s2">,</span>
    <span class="s1">precision_score</span><span class="s2">,</span>
    <span class="s1">r2_score</span><span class="s2">,</span>
    <span class="s1">recall_score</span><span class="s2">,</span>
    <span class="s1">roc_auc_score</span><span class="s2">,</span>
    <span class="s1">top_k_accuracy_score</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">metrics </span><span class="s0">import </span><span class="s1">cluster </span><span class="s0">as </span><span class="s1">cluster_module</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">metrics</span><span class="s2">.</span><span class="s1">_scorer </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">_check_multimetric_scoring</span><span class="s2">,</span>
    <span class="s1">_MultimetricScorer</span><span class="s2">,</span>
    <span class="s1">_PassthroughScorer</span><span class="s2">,</span>
    <span class="s1">_Scorer</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">model_selection </span><span class="s0">import </span><span class="s1">GridSearchCV</span><span class="s2">, </span><span class="s1">cross_val_score</span><span class="s2">, </span><span class="s1">train_test_split</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">multiclass </span><span class="s0">import </span><span class="s1">OneVsRestClassifier</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">neighbors </span><span class="s0">import </span><span class="s1">KNeighborsClassifier</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">pipeline </span><span class="s0">import </span><span class="s1">make_pipeline</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">svm </span><span class="s0">import </span><span class="s1">LinearSVC</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">tests</span><span class="s2">.</span><span class="s1">metadata_routing_common </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">assert_request_is_empty</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">tree </span><span class="s0">import </span><span class="s1">DecisionTreeClassifier</span><span class="s2">, </span><span class="s1">DecisionTreeRegressor</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">_testing </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">assert_almost_equal</span><span class="s2">,</span>
    <span class="s1">assert_array_equal</span><span class="s2">,</span>
    <span class="s1">ignore_warnings</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">metadata_routing </span><span class="s0">import </span><span class="s1">MetadataRouter</span><span class="s2">, </span><span class="s1">MethodMapping</span>

<span class="s1">REGRESSION_SCORERS </span><span class="s2">= [</span>
    <span class="s3">&quot;d2_absolute_error_score&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;explained_variance&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;r2&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;neg_mean_absolute_error&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;neg_mean_squared_error&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;neg_mean_absolute_percentage_error&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;neg_mean_squared_log_error&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;neg_median_absolute_error&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;neg_root_mean_squared_error&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;neg_root_mean_squared_log_error&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;mean_absolute_error&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;mean_absolute_percentage_error&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;mean_squared_error&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;median_absolute_error&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;max_error&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;neg_mean_poisson_deviance&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;neg_mean_gamma_deviance&quot;</span><span class="s2">,</span>
<span class="s2">]</span>

<span class="s1">CLF_SCORERS </span><span class="s2">= [</span>
    <span class="s3">&quot;accuracy&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;balanced_accuracy&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;top_k_accuracy&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;f1&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;f1_weighted&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;f1_macro&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;f1_micro&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;roc_auc&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;average_precision&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;precision&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;precision_weighted&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;precision_macro&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;precision_micro&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;recall&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;recall_weighted&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;recall_macro&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;recall_micro&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;neg_log_loss&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;neg_brier_score&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;jaccard&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;jaccard_weighted&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;jaccard_macro&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;jaccard_micro&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;roc_auc_ovr&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;roc_auc_ovo&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;roc_auc_ovr_weighted&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;roc_auc_ovo_weighted&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;matthews_corrcoef&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;positive_likelihood_ratio&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;neg_negative_likelihood_ratio&quot;</span><span class="s2">,</span>
<span class="s2">]</span>

<span class="s4"># All supervised cluster scorers (They behave like classification metric)</span>
<span class="s1">CLUSTER_SCORERS </span><span class="s2">= [</span>
    <span class="s3">&quot;adjusted_rand_score&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;rand_score&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;homogeneity_score&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;completeness_score&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;v_measure_score&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;mutual_info_score&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;adjusted_mutual_info_score&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;normalized_mutual_info_score&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;fowlkes_mallows_score&quot;</span><span class="s2">,</span>
<span class="s2">]</span>

<span class="s1">MULTILABEL_ONLY_SCORERS </span><span class="s2">= [</span>
    <span class="s3">&quot;precision_samples&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;recall_samples&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;f1_samples&quot;</span><span class="s2">,</span>
    <span class="s3">&quot;jaccard_samples&quot;</span><span class="s2">,</span>
<span class="s2">]</span>

<span class="s1">REQUIRE_POSITIVE_Y_SCORERS </span><span class="s2">= [</span><span class="s3">&quot;neg_mean_poisson_deviance&quot;</span><span class="s2">, </span><span class="s3">&quot;neg_mean_gamma_deviance&quot;</span><span class="s2">]</span>


<span class="s0">def </span><span class="s1">_require_positive_y</span><span class="s2">(</span><span class="s1">y</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Make targets strictly positive&quot;&quot;&quot;</span>
    <span class="s1">offset </span><span class="s2">= </span><span class="s1">abs</span><span class="s2">(</span><span class="s1">y</span><span class="s2">.</span><span class="s1">min</span><span class="s2">()) + </span><span class="s6">1</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">y </span><span class="s2">+ </span><span class="s1">offset</span>
    <span class="s0">return </span><span class="s1">y</span>


<span class="s0">def </span><span class="s1">_make_estimators</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_ml_train</span><span class="s2">):</span>
    <span class="s4"># Make estimators that make sense to test various scoring methods</span>
    <span class="s1">sensible_regr </span><span class="s2">= </span><span class="s1">DecisionTreeRegressor</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s4"># some of the regressions scorers require strictly positive input.</span>
    <span class="s1">sensible_regr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">_require_positive_y</span><span class="s2">(</span><span class="s1">y_train</span><span class="s2">))</span>
    <span class="s1">sensible_clf </span><span class="s2">= </span><span class="s1">DecisionTreeClassifier</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">sensible_clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>
    <span class="s1">sensible_ml_clf </span><span class="s2">= </span><span class="s1">DecisionTreeClassifier</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">sensible_ml_clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_ml_train</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">dict</span><span class="s2">(</span>
        <span class="s2">[(</span><span class="s1">name</span><span class="s2">, </span><span class="s1">sensible_regr</span><span class="s2">) </span><span class="s0">for </span><span class="s1">name </span><span class="s0">in </span><span class="s1">REGRESSION_SCORERS</span><span class="s2">]</span>
        <span class="s2">+ [(</span><span class="s1">name</span><span class="s2">, </span><span class="s1">sensible_clf</span><span class="s2">) </span><span class="s0">for </span><span class="s1">name </span><span class="s0">in </span><span class="s1">CLF_SCORERS</span><span class="s2">]</span>
        <span class="s2">+ [(</span><span class="s1">name</span><span class="s2">, </span><span class="s1">sensible_clf</span><span class="s2">) </span><span class="s0">for </span><span class="s1">name </span><span class="s0">in </span><span class="s1">CLUSTER_SCORERS</span><span class="s2">]</span>
        <span class="s2">+ [(</span><span class="s1">name</span><span class="s2">, </span><span class="s1">sensible_ml_clf</span><span class="s2">) </span><span class="s0">for </span><span class="s1">name </span><span class="s0">in </span><span class="s1">MULTILABEL_ONLY_SCORERS</span><span class="s2">]</span>
    <span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">fixture</span><span class="s2">(</span><span class="s1">scope</span><span class="s2">=</span><span class="s3">&quot;module&quot;</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">memmap_data_and_estimators</span><span class="s2">(</span><span class="s1">tmp_path_factory</span><span class="s2">):</span>
    <span class="s1">temp_folder </span><span class="s2">= </span><span class="s1">tmp_path_factory</span><span class="s2">.</span><span class="s1">mktemp</span><span class="s2">(</span><span class="s3">&quot;sklearn_test_score_objects&quot;</span><span class="s2">)</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s6">30</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s6">5</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">_</span><span class="s2">, </span><span class="s1">y_ml </span><span class="s2">= </span><span class="s1">make_multilabel_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s6">0</span><span class="s2">], </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">filename </span><span class="s2">= </span><span class="s1">temp_folder </span><span class="s2">/ </span><span class="s3">&quot;test_data.pkl&quot;</span>
    <span class="s1">joblib</span><span class="s2">.</span><span class="s1">dump</span><span class="s2">((</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">y_ml</span><span class="s2">), </span><span class="s1">filename</span><span class="s2">)</span>
    <span class="s1">X_mm</span><span class="s2">, </span><span class="s1">y_mm</span><span class="s2">, </span><span class="s1">y_ml_mm </span><span class="s2">= </span><span class="s1">joblib</span><span class="s2">.</span><span class="s1">load</span><span class="s2">(</span><span class="s1">filename</span><span class="s2">, </span><span class="s1">mmap_mode</span><span class="s2">=</span><span class="s3">&quot;r&quot;</span><span class="s2">)</span>
    <span class="s1">estimators </span><span class="s2">= </span><span class="s1">_make_estimators</span><span class="s2">(</span><span class="s1">X_mm</span><span class="s2">, </span><span class="s1">y_mm</span><span class="s2">, </span><span class="s1">y_ml_mm</span><span class="s2">)</span>

    <span class="s0">yield </span><span class="s1">X_mm</span><span class="s2">, </span><span class="s1">y_mm</span><span class="s2">, </span><span class="s1">y_ml_mm</span><span class="s2">, </span><span class="s1">estimators</span>


<span class="s0">class </span><span class="s1">EstimatorWithFit</span><span class="s2">(</span><span class="s1">BaseEstimator</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Dummy estimator to test scoring validators&quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">fit</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s1">self</span>


<span class="s0">class </span><span class="s1">EstimatorWithFitAndScore</span><span class="s2">:</span>
    <span class="s5">&quot;&quot;&quot;Dummy estimator to test scoring validators&quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">fit</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s1">self</span>

    <span class="s0">def </span><span class="s1">score</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s6">1.0</span>


<span class="s0">class </span><span class="s1">EstimatorWithFitAndPredict</span><span class="s2">:</span>
    <span class="s5">&quot;&quot;&quot;Dummy estimator to test scoring validators&quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">fit</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">):</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">y </span><span class="s2">= </span><span class="s1">y</span>
        <span class="s0">return </span><span class="s1">self</span>

    <span class="s0">def </span><span class="s1">predict</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s1">self</span><span class="s2">.</span><span class="s1">y</span>


<span class="s0">class </span><span class="s1">DummyScorer</span><span class="s2">:</span>
    <span class="s5">&quot;&quot;&quot;Dummy scorer that always returns 1.&quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">__call__</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">est</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s6">1</span>


<span class="s0">def </span><span class="s1">test_all_scorers_repr</span><span class="s2">():</span>
    <span class="s4"># Test that all scorers have a working repr</span>
    <span class="s0">for </span><span class="s1">name </span><span class="s0">in </span><span class="s1">get_scorer_names</span><span class="s2">():</span>
        <span class="s1">repr</span><span class="s2">(</span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">name</span><span class="s2">))</span>


<span class="s0">def </span><span class="s1">check_scoring_validator_for_single_metric_usecases</span><span class="s2">(</span><span class="s1">scoring_validator</span><span class="s2">):</span>
    <span class="s4"># Test all branches of single metric usecases</span>
    <span class="s1">estimator </span><span class="s2">= </span><span class="s1">EstimatorWithFitAndScore</span><span class="s2">()</span>
    <span class="s1">estimator</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">([[</span><span class="s6">1</span><span class="s2">]], [</span><span class="s6">1</span><span class="s2">])</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">scoring_validator</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">, </span><span class="s1">_PassthroughScorer</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">, [[</span><span class="s6">1</span><span class="s2">]], [</span><span class="s6">1</span><span class="s2">]), </span><span class="s6">1.0</span><span class="s2">)</span>

    <span class="s1">estimator </span><span class="s2">= </span><span class="s1">EstimatorWithFitAndPredict</span><span class="s2">()</span>
    <span class="s1">estimator</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">([[</span><span class="s6">1</span><span class="s2">]], [</span><span class="s6">1</span><span class="s2">])</span>
    <span class="s1">pattern </span><span class="s2">= (</span>
        <span class="s3">r&quot;If no scoring is specified, the estimator passed should have&quot;</span>
        <span class="s3">r&quot; a 'score' method\. The estimator .* does not\.&quot;</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">TypeError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">pattern</span><span class="s2">):</span>
        <span class="s1">scoring_validator</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">)</span>

    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">scoring_validator</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">, [[</span><span class="s6">1</span><span class="s2">]], [</span><span class="s6">1</span><span class="s2">]), </span><span class="s6">1.0</span><span class="s2">)</span>

    <span class="s1">estimator </span><span class="s2">= </span><span class="s1">EstimatorWithFit</span><span class="s2">()</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">scoring_validator</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">, </span><span class="s1">_Scorer</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">scorer</span><span class="s2">.</span><span class="s1">_response_method </span><span class="s2">== </span><span class="s3">&quot;predict&quot;</span>

    <span class="s4"># Test the allow_none parameter for check_scoring alone</span>
    <span class="s0">if </span><span class="s1">scoring_validator </span><span class="s0">is </span><span class="s1">check_scoring</span><span class="s2">:</span>
        <span class="s1">estimator </span><span class="s2">= </span><span class="s1">EstimatorWithFit</span><span class="s2">()</span>
        <span class="s1">scorer </span><span class="s2">= </span><span class="s1">scoring_validator</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">, </span><span class="s1">allow_none</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">scorer </span><span class="s0">is None</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;scoring&quot;</span><span class="s2">,</span>
    <span class="s2">(</span>
        <span class="s2">(</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">,),</span>
        <span class="s2">[</span><span class="s3">&quot;precision&quot;</span><span class="s2">],</span>
        <span class="s2">{</span><span class="s3">&quot;acc&quot;</span><span class="s2">: </span><span class="s3">&quot;accuracy&quot;</span><span class="s2">, </span><span class="s3">&quot;precision&quot;</span><span class="s2">: </span><span class="s3">&quot;precision&quot;</span><span class="s2">},</span>
        <span class="s2">(</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">, </span><span class="s3">&quot;precision&quot;</span><span class="s2">),</span>
        <span class="s2">[</span><span class="s3">&quot;precision&quot;</span><span class="s2">, </span><span class="s3">&quot;accuracy&quot;</span><span class="s2">],</span>
        <span class="s2">{</span>
            <span class="s3">&quot;accuracy&quot;</span><span class="s2">: </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">accuracy_score</span><span class="s2">),</span>
            <span class="s3">&quot;precision&quot;</span><span class="s2">: </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">precision_score</span><span class="s2">),</span>
        <span class="s2">},</span>
    <span class="s2">),</span>
    <span class="s1">ids</span><span class="s2">=[</span>
        <span class="s3">&quot;single_tuple&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;single_list&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;dict_str&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;multi_tuple&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;multi_list&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;dict_callable&quot;</span><span class="s2">,</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_check_scoring_and_check_multimetric_scoring</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">):</span>
    <span class="s1">check_scoring_validator_for_single_metric_usecases</span><span class="s2">(</span><span class="s1">check_scoring</span><span class="s2">)</span>
    <span class="s4"># To make sure the check_scoring is correctly applied to the constituent</span>
    <span class="s4"># scorers</span>

    <span class="s1">estimator </span><span class="s2">= </span><span class="s1">LinearSVC</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">estimator</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">([[</span><span class="s6">1</span><span class="s2">], [</span><span class="s6">2</span><span class="s2">], [</span><span class="s6">3</span><span class="s2">]], [</span><span class="s6">1</span><span class="s2">, </span><span class="s6">1</span><span class="s2">, </span><span class="s6">0</span><span class="s2">])</span>

    <span class="s1">scorers </span><span class="s2">= </span><span class="s1">_check_multimetric_scoring</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">scorers</span><span class="s2">, </span><span class="s1">dict</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">sorted</span><span class="s2">(</span><span class="s1">scorers</span><span class="s2">.</span><span class="s1">keys</span><span class="s2">()) == </span><span class="s1">sorted</span><span class="s2">(</span><span class="s1">list</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">))</span>
    <span class="s0">assert </span><span class="s1">all</span><span class="s2">([</span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">, </span><span class="s1">_Scorer</span><span class="s2">) </span><span class="s0">for </span><span class="s1">scorer </span><span class="s0">in </span><span class="s1">list</span><span class="s2">(</span><span class="s1">scorers</span><span class="s2">.</span><span class="s1">values</span><span class="s2">())])</span>
    <span class="s0">assert </span><span class="s1">all</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">.</span><span class="s1">_response_method </span><span class="s2">== </span><span class="s3">&quot;predict&quot; </span><span class="s0">for </span><span class="s1">scorer </span><span class="s0">in </span><span class="s1">scorers</span><span class="s2">.</span><span class="s1">values</span><span class="s2">())</span>

    <span class="s0">if </span><span class="s3">&quot;acc&quot; </span><span class="s0">in </span><span class="s1">scoring</span><span class="s2">:</span>
        <span class="s1">assert_almost_equal</span><span class="s2">(</span>
            <span class="s1">scorers</span><span class="s2">[</span><span class="s3">&quot;acc&quot;</span><span class="s2">](</span><span class="s1">estimator</span><span class="s2">, [[</span><span class="s6">1</span><span class="s2">], [</span><span class="s6">2</span><span class="s2">], [</span><span class="s6">3</span><span class="s2">]], [</span><span class="s6">1</span><span class="s2">, </span><span class="s6">0</span><span class="s2">, </span><span class="s6">0</span><span class="s2">]), </span><span class="s6">2.0 </span><span class="s2">/ </span><span class="s6">3.0</span>
        <span class="s2">)</span>
    <span class="s0">if </span><span class="s3">&quot;accuracy&quot; </span><span class="s0">in </span><span class="s1">scoring</span><span class="s2">:</span>
        <span class="s1">assert_almost_equal</span><span class="s2">(</span>
            <span class="s1">scorers</span><span class="s2">[</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">](</span><span class="s1">estimator</span><span class="s2">, [[</span><span class="s6">1</span><span class="s2">], [</span><span class="s6">2</span><span class="s2">], [</span><span class="s6">3</span><span class="s2">]], [</span><span class="s6">1</span><span class="s2">, </span><span class="s6">0</span><span class="s2">, </span><span class="s6">0</span><span class="s2">]), </span><span class="s6">2.0 </span><span class="s2">/ </span><span class="s6">3.0</span>
        <span class="s2">)</span>
    <span class="s0">if </span><span class="s3">&quot;precision&quot; </span><span class="s0">in </span><span class="s1">scoring</span><span class="s2">:</span>
        <span class="s1">assert_almost_equal</span><span class="s2">(</span>
            <span class="s1">scorers</span><span class="s2">[</span><span class="s3">&quot;precision&quot;</span><span class="s2">](</span><span class="s1">estimator</span><span class="s2">, [[</span><span class="s6">1</span><span class="s2">], [</span><span class="s6">2</span><span class="s2">], [</span><span class="s6">3</span><span class="s2">]], [</span><span class="s6">1</span><span class="s2">, </span><span class="s6">0</span><span class="s2">, </span><span class="s6">0</span><span class="s2">]), </span><span class="s6">0.5</span>
        <span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;scoring, msg&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">(</span>
            <span class="s2">(</span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">precision_score</span><span class="s2">), </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">accuracy_score</span><span class="s2">)),</span>
            <span class="s3">&quot;One or more of the elements were callables&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s2">([</span><span class="s6">5</span><span class="s2">], </span><span class="s3">&quot;Non-string types were found&quot;</span><span class="s2">),</span>
        <span class="s2">((</span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">precision_score</span><span class="s2">),), </span><span class="s3">&quot;One or more of the elements were callables&quot;</span><span class="s2">),</span>
        <span class="s2">((), </span><span class="s3">&quot;Empty list was given&quot;</span><span class="s2">),</span>
        <span class="s2">((</span><span class="s3">&quot;f1&quot;</span><span class="s2">, </span><span class="s3">&quot;f1&quot;</span><span class="s2">), </span><span class="s3">&quot;Duplicate elements were found&quot;</span><span class="s2">),</span>
        <span class="s2">({</span><span class="s6">4</span><span class="s2">: </span><span class="s3">&quot;accuracy&quot;</span><span class="s2">}, </span><span class="s3">&quot;Non-string types were found in the keys&quot;</span><span class="s2">),</span>
        <span class="s2">({}, </span><span class="s3">&quot;An empty dict was passed&quot;</span><span class="s2">),</span>
    <span class="s2">],</span>
    <span class="s1">ids</span><span class="s2">=[</span>
        <span class="s3">&quot;tuple of callables&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;list of int&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;tuple of one callable&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;empty tuple&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;non-unique str&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;non-string key dict&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;empty dict&quot;</span><span class="s2">,</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_check_scoring_and_check_multimetric_scoring_errors</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">, </span><span class="s1">msg</span><span class="s2">):</span>
    <span class="s4"># Make sure it raises errors when scoring parameter is not valid.</span>
    <span class="s4"># More weird corner cases are tested at test_validation.py</span>
    <span class="s1">estimator </span><span class="s2">= </span><span class="s1">EstimatorWithFitAndPredict</span><span class="s2">()</span>
    <span class="s1">estimator</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">([[</span><span class="s6">1</span><span class="s2">]], [</span><span class="s6">1</span><span class="s2">])</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">_check_multimetric_scoring</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scoring</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_check_scoring_gridsearchcv</span><span class="s2">():</span>
    <span class="s4"># test that check_scoring works on GridSearchCV and pipeline.</span>
    <span class="s4"># slightly redundant non-regression test.</span>

    <span class="s1">grid </span><span class="s2">= </span><span class="s1">GridSearchCV</span><span class="s2">(</span><span class="s1">LinearSVC</span><span class="s2">(), </span><span class="s1">param_grid</span><span class="s2">={</span><span class="s3">&quot;C&quot;</span><span class="s2">: [</span><span class="s6">0.1</span><span class="s2">, </span><span class="s6">1</span><span class="s2">]}, </span><span class="s1">cv</span><span class="s2">=</span><span class="s6">3</span><span class="s2">)</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">check_scoring</span><span class="s2">(</span><span class="s1">grid</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s3">&quot;f1&quot;</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">, </span><span class="s1">_Scorer</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">scorer</span><span class="s2">.</span><span class="s1">_response_method </span><span class="s2">== </span><span class="s3">&quot;predict&quot;</span>

    <span class="s1">pipe </span><span class="s2">= </span><span class="s1">make_pipeline</span><span class="s2">(</span><span class="s1">LinearSVC</span><span class="s2">())</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">check_scoring</span><span class="s2">(</span><span class="s1">pipe</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s3">&quot;f1&quot;</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">, </span><span class="s1">_Scorer</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">scorer</span><span class="s2">.</span><span class="s1">_response_method </span><span class="s2">== </span><span class="s3">&quot;predict&quot;</span>

    <span class="s4"># check that cross_val_score definitely calls the scorer</span>
    <span class="s4"># and doesn't make any assumptions about the estimator apart from having a</span>
    <span class="s4"># fit.</span>
    <span class="s1">scores </span><span class="s2">= </span><span class="s1">cross_val_score</span><span class="s2">(</span>
        <span class="s1">EstimatorWithFit</span><span class="s2">(), [[</span><span class="s6">1</span><span class="s2">], [</span><span class="s6">2</span><span class="s2">], [</span><span class="s6">3</span><span class="s2">]], [</span><span class="s6">1</span><span class="s2">, </span><span class="s6">0</span><span class="s2">, </span><span class="s6">1</span><span class="s2">], </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">DummyScorer</span><span class="s2">(), </span><span class="s1">cv</span><span class="s2">=</span><span class="s6">3</span>
    <span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">scores</span><span class="s2">, </span><span class="s6">1</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;scorer_name, metric&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">(</span><span class="s3">&quot;f1&quot;</span><span class="s2">, </span><span class="s1">f1_score</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;f1_weighted&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">f1_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;f1_macro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">f1_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;macro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;f1_micro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">f1_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;micro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;precision&quot;</span><span class="s2">, </span><span class="s1">precision_score</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;precision_weighted&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">precision_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;precision_macro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">precision_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;macro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;precision_micro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">precision_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;micro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;recall&quot;</span><span class="s2">, </span><span class="s1">recall_score</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;recall_weighted&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">recall_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;recall_macro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">recall_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;macro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;recall_micro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">recall_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;micro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;jaccard&quot;</span><span class="s2">, </span><span class="s1">jaccard_score</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;jaccard_weighted&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">jaccard_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;jaccard_macro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">jaccard_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;macro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;jaccard_micro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">jaccard_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;micro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;top_k_accuracy&quot;</span><span class="s2">, </span><span class="s1">top_k_accuracy_score</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;matthews_corrcoef&quot;</span><span class="s2">, </span><span class="s1">matthews_corrcoef</span><span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_classification_binary_scores</span><span class="s2">(</span><span class="s1">scorer_name</span><span class="s2">, </span><span class="s1">metric</span><span class="s2">):</span>
    <span class="s4"># check consistency between score and scorer for scores supporting</span>
    <span class="s4"># binary classification.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_blobs</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">, </span><span class="s1">centers</span><span class="s2">=</span><span class="s6">2</span><span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LinearSVC</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>

    <span class="s1">score </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">scorer_name</span><span class="s2">)(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s1">expected_score </span><span class="s2">= </span><span class="s1">metric</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">))</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">score</span><span class="s2">, </span><span class="s1">expected_score</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;scorer_name, metric&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">(</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">, </span><span class="s1">accuracy_score</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;balanced_accuracy&quot;</span><span class="s2">, </span><span class="s1">balanced_accuracy_score</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;f1_weighted&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">f1_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;f1_macro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">f1_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;macro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;f1_micro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">f1_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;micro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;precision_weighted&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">precision_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;precision_macro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">precision_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;macro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;precision_micro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">precision_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;micro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;recall_weighted&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">recall_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;recall_macro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">recall_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;macro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;recall_micro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">recall_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;micro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;jaccard_weighted&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">jaccard_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;jaccard_macro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">jaccard_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;macro&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;jaccard_micro&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">jaccard_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;micro&quot;</span><span class="s2">)),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_classification_multiclass_scores</span><span class="s2">(</span><span class="s1">scorer_name</span><span class="s2">, </span><span class="s1">metric</span><span class="s2">):</span>
    <span class="s4"># check consistency between score and scorer for scores supporting</span>
    <span class="s4"># multiclass classification.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">=</span><span class="s6">30</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span>
    <span class="s2">)</span>

    <span class="s4"># use `stratify` = y to ensure train and test sets capture all classes</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span>
        <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">, </span><span class="s1">stratify</span><span class="s2">=</span><span class="s1">y</span>
    <span class="s2">)</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">DecisionTreeClassifier</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>
    <span class="s1">score </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">scorer_name</span><span class="s2">)(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s1">expected_score </span><span class="s2">= </span><span class="s1">metric</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">))</span>
    <span class="s0">assert </span><span class="s1">score </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">expected_score</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_custom_scorer_pickling</span><span class="s2">():</span>
    <span class="s4"># test that custom scorer can be pickled</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_blobs</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">, </span><span class="s1">centers</span><span class="s2">=</span><span class="s6">2</span><span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LinearSVC</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>

    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">fbeta_score</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">=</span><span class="s6">2</span><span class="s2">)</span>
    <span class="s1">score1 </span><span class="s2">= </span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s1">unpickled_scorer </span><span class="s2">= </span><span class="s1">pickle</span><span class="s2">.</span><span class="s1">loads</span><span class="s2">(</span><span class="s1">pickle</span><span class="s2">.</span><span class="s1">dumps</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">))</span>
    <span class="s1">score2 </span><span class="s2">= </span><span class="s1">unpickled_scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">score1 </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">score2</span><span class="s2">)</span>

    <span class="s4"># smoke test the repr:</span>
    <span class="s1">repr</span><span class="s2">(</span><span class="s1">fbeta_score</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_regression_scorers</span><span class="s2">():</span>
    <span class="s4"># Test regression scorers.</span>
    <span class="s1">diabetes </span><span class="s2">= </span><span class="s1">load_diabetes</span><span class="s2">()</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">diabetes</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">diabetes</span><span class="s2">.</span><span class="s1">target</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">Ridge</span><span class="s2">()</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>
    <span class="s1">score1 </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;r2&quot;</span><span class="s2">)(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s1">score2 </span><span class="s2">= </span><span class="s1">r2_score</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">))</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">score1</span><span class="s2">, </span><span class="s1">score2</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_thresholded_scorers</span><span class="s2">():</span>
    <span class="s4"># Test scorers that take thresholds.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_blobs</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">, </span><span class="s1">centers</span><span class="s2">=</span><span class="s6">2</span><span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>
    <span class="s1">score1 </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">)(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s1">score2 </span><span class="s2">= </span><span class="s1">roc_auc_score</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">))</span>
    <span class="s1">score3 </span><span class="s2">= </span><span class="s1">roc_auc_score</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)[:, </span><span class="s6">1</span><span class="s2">])</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">score1</span><span class="s2">, </span><span class="s1">score2</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">score1</span><span class="s2">, </span><span class="s1">score3</span><span class="s2">)</span>

    <span class="s1">logscore </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;neg_log_loss&quot;</span><span class="s2">)(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s1">logloss </span><span class="s2">= </span><span class="s1">log_loss</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">))</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(-</span><span class="s1">logscore</span><span class="s2">, </span><span class="s1">logloss</span><span class="s2">)</span>

    <span class="s4"># same for an estimator without decision_function</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">DecisionTreeClassifier</span><span class="s2">()</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>
    <span class="s1">score1 </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">)(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s1">score2 </span><span class="s2">= </span><span class="s1">roc_auc_score</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)[:, </span><span class="s6">1</span><span class="s2">])</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">score1</span><span class="s2">, </span><span class="s1">score2</span><span class="s2">)</span>

    <span class="s4"># test with a regressor (no decision_function)</span>
    <span class="s1">reg </span><span class="s2">= </span><span class="s1">DecisionTreeRegressor</span><span class="s2">()</span>
    <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>
    <span class="s1">err_msg </span><span class="s2">= </span><span class="s3">&quot;DecisionTreeRegressor has none of the following attributes&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">AttributeError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">err_msg</span><span class="s2">):</span>
        <span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">)(</span><span class="s1">reg</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>

    <span class="s4"># Test that an exception is raised on more than two classes</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_blobs</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">, </span><span class="s1">centers</span><span class="s2">=</span><span class="s6">3</span><span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;multi_class must be in </span><span class="s0">\\</span><span class="s3">('ovo', 'ovr'</span><span class="s0">\\</span><span class="s3">)&quot;</span><span class="s2">):</span>
        <span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">)(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>

    <span class="s4"># test error is raised with a single class present in model</span>
    <span class="s4"># (predict_proba shape is not suitable for binary auc)</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_blobs</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">, </span><span class="s1">centers</span><span class="s2">=</span><span class="s6">2</span><span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">DecisionTreeClassifier</span><span class="s2">()</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros_like</span><span class="s2">(</span><span class="s1">y_train</span><span class="s2">))</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;need classifier with two classes&quot;</span><span class="s2">):</span>
        <span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">)(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>

    <span class="s4"># for proba scorers</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;need classifier with two classes&quot;</span><span class="s2">):</span>
        <span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;neg_log_loss&quot;</span><span class="s2">)(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_thresholded_scorers_multilabel_indicator_data</span><span class="s2">():</span>
    <span class="s4"># Test that the scorer work with multilabel-indicator format</span>
    <span class="s4"># for multilabel and multi-output multi-class classifier</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_multilabel_classification</span><span class="s2">(</span><span class="s1">allow_unlabeled</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>

    <span class="s4"># Multi-output multi-class predict_proba</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">DecisionTreeClassifier</span><span class="s2">()</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>
    <span class="s1">y_proba </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>
    <span class="s1">score1 </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">)(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s1">score2 </span><span class="s2">= </span><span class="s1">roc_auc_score</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">vstack</span><span class="s2">([</span><span class="s1">p</span><span class="s2">[:, -</span><span class="s6">1</span><span class="s2">] </span><span class="s0">for </span><span class="s1">p </span><span class="s0">in </span><span class="s1">y_proba</span><span class="s2">]).</span><span class="s1">T</span><span class="s2">)</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">score1</span><span class="s2">, </span><span class="s1">score2</span><span class="s2">)</span>

    <span class="s4"># Multilabel predict_proba</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">OneVsRestClassifier</span><span class="s2">(</span><span class="s1">DecisionTreeClassifier</span><span class="s2">())</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>
    <span class="s1">score1 </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">)(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s1">score2 </span><span class="s2">= </span><span class="s1">roc_auc_score</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">))</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">score1</span><span class="s2">, </span><span class="s1">score2</span><span class="s2">)</span>

    <span class="s4"># Multilabel decision function</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">OneVsRestClassifier</span><span class="s2">(</span><span class="s1">LinearSVC</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">))</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>
    <span class="s1">score1 </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">)(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s1">score2 </span><span class="s2">= </span><span class="s1">roc_auc_score</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">))</span>
    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">score1</span><span class="s2">, </span><span class="s1">score2</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_supervised_cluster_scorers</span><span class="s2">():</span>
    <span class="s4"># Test clustering scorers against gold standard labeling.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_blobs</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">, </span><span class="s1">centers</span><span class="s2">=</span><span class="s6">2</span><span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">km </span><span class="s2">= </span><span class="s1">KMeans</span><span class="s2">(</span><span class="s1">n_clusters</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_init</span><span class="s2">=</span><span class="s3">&quot;auto&quot;</span><span class="s2">)</span>
    <span class="s1">km</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">)</span>
    <span class="s0">for </span><span class="s1">name </span><span class="s0">in </span><span class="s1">CLUSTER_SCORERS</span><span class="s2">:</span>
        <span class="s1">score1 </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">name</span><span class="s2">)(</span><span class="s1">km</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
        <span class="s1">score2 </span><span class="s2">= </span><span class="s1">getattr</span><span class="s2">(</span><span class="s1">cluster_module</span><span class="s2">, </span><span class="s1">name</span><span class="s2">)(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">km</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">))</span>
        <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">score1</span><span class="s2">, </span><span class="s1">score2</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">ignore_warnings</span>
<span class="s0">def </span><span class="s1">test_raises_on_score_list</span><span class="s2">():</span>
    <span class="s4"># Test that when a list of scores is returned, we raise proper errors.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_blobs</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">f1_scorer_no_average </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">f1_score</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s0">None</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">DecisionTreeClassifier</span><span class="s2">()</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">cross_val_score</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">f1_scorer_no_average</span><span class="s2">)</span>
    <span class="s1">grid_search </span><span class="s2">= </span><span class="s1">GridSearchCV</span><span class="s2">(</span>
        <span class="s1">clf</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">f1_scorer_no_average</span><span class="s2">, </span><span class="s1">param_grid</span><span class="s2">={</span><span class="s3">&quot;max_depth&quot;</span><span class="s2">: [</span><span class="s6">1</span><span class="s2">, </span><span class="s6">2</span><span class="s2">]}</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">grid_search</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">ignore_warnings</span>
<span class="s0">def </span><span class="s1">test_classification_scorer_sample_weight</span><span class="s2">():</span>
    <span class="s4"># Test that classification scorers support sample_weight or raise sensible</span>
    <span class="s4"># errors</span>

    <span class="s4"># Unlike the metrics invariance test, in the scorer case it's harder</span>
    <span class="s4"># to ensure that, on the classifier output, weighted and unweighted</span>
    <span class="s4"># scores really should be unequal.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">_</span><span class="s2">, </span><span class="s1">y_ml </span><span class="s2">= </span><span class="s1">make_multilabel_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s6">0</span><span class="s2">], </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">split </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">y_ml</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_ml_train</span><span class="s2">, </span><span class="s1">y_ml_test </span><span class="s2">= </span><span class="s1">split</span>

    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones_like</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s1">sample_weight</span><span class="s2">[:</span><span class="s6">10</span><span class="s2">] = </span><span class="s6">0</span>

    <span class="s4"># get sensible estimators for each metric</span>
    <span class="s1">estimator </span><span class="s2">= </span><span class="s1">_make_estimators</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_ml_train</span><span class="s2">)</span>

    <span class="s0">for </span><span class="s1">name </span><span class="s0">in </span><span class="s1">get_scorer_names</span><span class="s2">():</span>
        <span class="s1">scorer </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">name</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">name </span><span class="s0">in </span><span class="s1">REGRESSION_SCORERS</span><span class="s2">:</span>
            <span class="s4"># skip the regression scores</span>
            <span class="s0">continue</span>
        <span class="s0">if </span><span class="s1">name </span><span class="s2">== </span><span class="s3">&quot;top_k_accuracy&quot;</span><span class="s2">:</span>
            <span class="s4"># in the binary case k &gt; 1 will always lead to a perfect score</span>
            <span class="s1">scorer</span><span class="s2">.</span><span class="s1">_kwargs </span><span class="s2">= {</span><span class="s3">&quot;k&quot;</span><span class="s2">: </span><span class="s6">1</span><span class="s2">}</span>
        <span class="s0">if </span><span class="s1">name </span><span class="s0">in </span><span class="s1">MULTILABEL_ONLY_SCORERS</span><span class="s2">:</span>
            <span class="s1">target </span><span class="s2">= </span><span class="s1">y_ml_test</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">target </span><span class="s2">= </span><span class="s1">y_test</span>
        <span class="s0">try</span><span class="s2">:</span>
            <span class="s1">weighted </span><span class="s2">= </span><span class="s1">scorer</span><span class="s2">(</span>
                <span class="s1">estimator</span><span class="s2">[</span><span class="s1">name</span><span class="s2">], </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">target</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span>
            <span class="s2">)</span>
            <span class="s1">ignored </span><span class="s2">= </span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">[</span><span class="s1">name</span><span class="s2">], </span><span class="s1">X_test</span><span class="s2">[</span><span class="s6">10</span><span class="s2">:], </span><span class="s1">target</span><span class="s2">[</span><span class="s6">10</span><span class="s2">:])</span>
            <span class="s1">unweighted </span><span class="s2">= </span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">[</span><span class="s1">name</span><span class="s2">], </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">target</span><span class="s2">)</span>
            <span class="s4"># this should not raise. sample_weight should be ignored if None.</span>
            <span class="s1">_ </span><span class="s2">= </span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">[</span><span class="s1">name</span><span class="s2">], </span><span class="s1">X_test</span><span class="s2">[:</span><span class="s6">10</span><span class="s2">], </span><span class="s1">target</span><span class="s2">[:</span><span class="s6">10</span><span class="s2">], </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">)</span>
            <span class="s0">assert </span><span class="s1">weighted </span><span class="s2">!= </span><span class="s1">unweighted</span><span class="s2">, (</span>
                <span class="s3">f&quot;scorer </span><span class="s0">{</span><span class="s1">name</span><span class="s0">} </span><span class="s3">behaves identically when called with &quot;</span>
                <span class="s3">f&quot;sample weights: </span><span class="s0">{</span><span class="s1">weighted</span><span class="s0">} </span><span class="s3">vs </span><span class="s0">{</span><span class="s1">unweighted</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>
            <span class="s1">assert_almost_equal</span><span class="s2">(</span>
                <span class="s1">weighted</span><span class="s2">,</span>
                <span class="s1">ignored</span><span class="s2">,</span>
                <span class="s1">err_msg</span><span class="s2">=(</span>
                    <span class="s3">f&quot;scorer </span><span class="s0">{</span><span class="s1">name</span><span class="s0">} </span><span class="s3">behaves differently &quot;</span>
                    <span class="s3">&quot;when ignoring samples and setting &quot;</span>
                    <span class="s3">f&quot;sample_weight to 0: </span><span class="s0">{</span><span class="s1">weighted</span><span class="s0">} </span><span class="s3">vs </span><span class="s0">{</span><span class="s1">ignored</span><span class="s0">}</span><span class="s3">&quot;</span>
                <span class="s2">),</span>
            <span class="s2">)</span>

        <span class="s0">except </span><span class="s1">TypeError </span><span class="s0">as </span><span class="s1">e</span><span class="s2">:</span>
            <span class="s0">assert </span><span class="s3">&quot;sample_weight&quot; </span><span class="s0">in </span><span class="s1">str</span><span class="s2">(</span><span class="s1">e</span><span class="s2">), (</span>
                <span class="s3">f&quot;scorer </span><span class="s0">{</span><span class="s1">name</span><span class="s0">} </span><span class="s3">raises unhelpful exception when called &quot;</span>
                <span class="s3">f&quot;with sample weights: </span><span class="s0">{</span><span class="s1">str</span><span class="s2">(</span><span class="s1">e</span><span class="s2">)</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>


<span class="s2">@</span><span class="s1">ignore_warnings</span>
<span class="s0">def </span><span class="s1">test_regression_scorer_sample_weight</span><span class="s2">():</span>
    <span class="s4"># Test that regression scorers support sample_weight or raise sensible</span>
    <span class="s4"># errors</span>

    <span class="s4"># Odd number of test samples req for neg_median_absolute_error</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_regression</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s6">101</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s6">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">_require_positive_y</span><span class="s2">(</span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>

    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones_like</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s4"># Odd number req for neg_median_absolute_error</span>
    <span class="s1">sample_weight</span><span class="s2">[:</span><span class="s6">11</span><span class="s2">] = </span><span class="s6">0</span>

    <span class="s1">reg </span><span class="s2">= </span><span class="s1">DecisionTreeRegressor</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">reg</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>

    <span class="s0">for </span><span class="s1">name </span><span class="s0">in </span><span class="s1">get_scorer_names</span><span class="s2">():</span>
        <span class="s1">scorer </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">name</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">name </span><span class="s0">not in </span><span class="s1">REGRESSION_SCORERS</span><span class="s2">:</span>
            <span class="s4"># skip classification scorers</span>
            <span class="s0">continue</span>
        <span class="s0">try</span><span class="s2">:</span>
            <span class="s1">weighted </span><span class="s2">= </span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>
            <span class="s1">ignored </span><span class="s2">= </span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">[</span><span class="s6">11</span><span class="s2">:], </span><span class="s1">y_test</span><span class="s2">[</span><span class="s6">11</span><span class="s2">:])</span>
            <span class="s1">unweighted </span><span class="s2">= </span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
            <span class="s0">assert </span><span class="s1">weighted </span><span class="s2">!= </span><span class="s1">unweighted</span><span class="s2">, (</span>
                <span class="s3">f&quot;scorer </span><span class="s0">{</span><span class="s1">name</span><span class="s0">} </span><span class="s3">behaves identically when called with &quot;</span>
                <span class="s3">f&quot;sample weights: </span><span class="s0">{</span><span class="s1">weighted</span><span class="s0">} </span><span class="s3">vs </span><span class="s0">{</span><span class="s1">unweighted</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>
            <span class="s1">assert_almost_equal</span><span class="s2">(</span>
                <span class="s1">weighted</span><span class="s2">,</span>
                <span class="s1">ignored</span><span class="s2">,</span>
                <span class="s1">err_msg</span><span class="s2">=(</span>
                    <span class="s3">f&quot;scorer </span><span class="s0">{</span><span class="s1">name</span><span class="s0">} </span><span class="s3">behaves differently &quot;</span>
                    <span class="s3">&quot;when ignoring samples and setting &quot;</span>
                    <span class="s3">f&quot;sample_weight to 0: </span><span class="s0">{</span><span class="s1">weighted</span><span class="s0">} </span><span class="s3">vs </span><span class="s0">{</span><span class="s1">ignored</span><span class="s0">}</span><span class="s3">&quot;</span>
                <span class="s2">),</span>
            <span class="s2">)</span>

        <span class="s0">except </span><span class="s1">TypeError </span><span class="s0">as </span><span class="s1">e</span><span class="s2">:</span>
            <span class="s0">assert </span><span class="s3">&quot;sample_weight&quot; </span><span class="s0">in </span><span class="s1">str</span><span class="s2">(</span><span class="s1">e</span><span class="s2">), (</span>
                <span class="s3">f&quot;scorer </span><span class="s0">{</span><span class="s1">name</span><span class="s0">} </span><span class="s3">raises unhelpful exception when called &quot;</span>
                <span class="s3">f&quot;with sample weights: </span><span class="s0">{</span><span class="s1">str</span><span class="s2">(</span><span class="s1">e</span><span class="s2">)</span><span class="s0">}</span><span class="s3">&quot;</span>
            <span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;name&quot;</span><span class="s2">, </span><span class="s1">get_scorer_names</span><span class="s2">())</span>
<span class="s0">def </span><span class="s1">test_scorer_memmap_input</span><span class="s2">(</span><span class="s1">name</span><span class="s2">, </span><span class="s1">memmap_data_and_estimators</span><span class="s2">):</span>
    <span class="s4"># Non-regression test for #6147: some score functions would</span>
    <span class="s4"># return singleton memmap when computed on memmap data instead of scalar</span>
    <span class="s4"># float values.</span>
    <span class="s1">X_mm</span><span class="s2">, </span><span class="s1">y_mm</span><span class="s2">, </span><span class="s1">y_ml_mm</span><span class="s2">, </span><span class="s1">estimators </span><span class="s2">= </span><span class="s1">memmap_data_and_estimators</span>

    <span class="s0">if </span><span class="s1">name </span><span class="s0">in </span><span class="s1">REQUIRE_POSITIVE_Y_SCORERS</span><span class="s2">:</span>
        <span class="s1">y_mm_1 </span><span class="s2">= </span><span class="s1">_require_positive_y</span><span class="s2">(</span><span class="s1">y_mm</span><span class="s2">)</span>
        <span class="s1">y_ml_mm_1 </span><span class="s2">= </span><span class="s1">_require_positive_y</span><span class="s2">(</span><span class="s1">y_ml_mm</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">y_mm_1</span><span class="s2">, </span><span class="s1">y_ml_mm_1 </span><span class="s2">= </span><span class="s1">y_mm</span><span class="s2">, </span><span class="s1">y_ml_mm</span>

    <span class="s4"># UndefinedMetricWarning for P / R scores</span>
    <span class="s0">with </span><span class="s1">ignore_warnings</span><span class="s2">():</span>
        <span class="s1">scorer</span><span class="s2">, </span><span class="s1">estimator </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">name</span><span class="s2">), </span><span class="s1">estimators</span><span class="s2">[</span><span class="s1">name</span><span class="s2">]</span>
        <span class="s0">if </span><span class="s1">name </span><span class="s0">in </span><span class="s1">MULTILABEL_ONLY_SCORERS</span><span class="s2">:</span>
            <span class="s1">score </span><span class="s2">= </span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">, </span><span class="s1">X_mm</span><span class="s2">, </span><span class="s1">y_ml_mm_1</span><span class="s2">)</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">score </span><span class="s2">= </span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">, </span><span class="s1">X_mm</span><span class="s2">, </span><span class="s1">y_mm_1</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">score</span><span class="s2">, </span><span class="s1">numbers</span><span class="s2">.</span><span class="s1">Number</span><span class="s2">), </span><span class="s1">name</span>


<span class="s0">def </span><span class="s1">test_scoring_is_not_metric</span><span class="s2">():</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;make_scorer&quot;</span><span class="s2">):</span>
        <span class="s1">check_scoring</span><span class="s2">(</span><span class="s1">LogisticRegression</span><span class="s2">(), </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">f1_score</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;make_scorer&quot;</span><span class="s2">):</span>
        <span class="s1">check_scoring</span><span class="s2">(</span><span class="s1">LogisticRegression</span><span class="s2">(), </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">roc_auc_score</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;make_scorer&quot;</span><span class="s2">):</span>
        <span class="s1">check_scoring</span><span class="s2">(</span><span class="s1">Ridge</span><span class="s2">(), </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">r2_score</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;make_scorer&quot;</span><span class="s2">):</span>
        <span class="s1">check_scoring</span><span class="s2">(</span><span class="s1">KMeans</span><span class="s2">(), </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">cluster_module</span><span class="s2">.</span><span class="s1">adjusted_rand_score</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;make_scorer&quot;</span><span class="s2">):</span>
        <span class="s1">check_scoring</span><span class="s2">(</span><span class="s1">KMeans</span><span class="s2">(), </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">cluster_module</span><span class="s2">.</span><span class="s1">rand_score</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s2">(</span>
        <span class="s3">&quot;scorers,expected_predict_count,&quot;</span>
        <span class="s3">&quot;expected_predict_proba_count,expected_decision_func_count&quot;</span>
    <span class="s2">),</span>
    <span class="s2">[</span>
        <span class="s2">(</span>
            <span class="s2">{</span>
                <span class="s3">&quot;a1&quot;</span><span class="s2">: </span><span class="s3">&quot;accuracy&quot;</span><span class="s2">,</span>
                <span class="s3">&quot;a2&quot;</span><span class="s2">: </span><span class="s3">&quot;accuracy&quot;</span><span class="s2">,</span>
                <span class="s3">&quot;ll1&quot;</span><span class="s2">: </span><span class="s3">&quot;neg_log_loss&quot;</span><span class="s2">,</span>
                <span class="s3">&quot;ll2&quot;</span><span class="s2">: </span><span class="s3">&quot;neg_log_loss&quot;</span><span class="s2">,</span>
                <span class="s3">&quot;ra1&quot;</span><span class="s2">: </span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">,</span>
                <span class="s3">&quot;ra2&quot;</span><span class="s2">: </span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">,</span>
            <span class="s2">},</span>
            <span class="s6">1</span><span class="s2">,</span>
            <span class="s6">1</span><span class="s2">,</span>
            <span class="s6">1</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s2">([</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">, </span><span class="s3">&quot;accuracy&quot;</span><span class="s2">], </span><span class="s6">1</span><span class="s2">, </span><span class="s6">0</span><span class="s2">, </span><span class="s6">1</span><span class="s2">),</span>
        <span class="s2">([</span><span class="s3">&quot;neg_log_loss&quot;</span><span class="s2">, </span><span class="s3">&quot;accuracy&quot;</span><span class="s2">], </span><span class="s6">1</span><span class="s2">, </span><span class="s6">1</span><span class="s2">, </span><span class="s6">0</span><span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_multimetric_scorer_calls_method_once</span><span class="s2">(</span>
    <span class="s1">scorers</span><span class="s2">,</span>
    <span class="s1">expected_predict_count</span><span class="s2">,</span>
    <span class="s1">expected_predict_proba_count</span><span class="s2">,</span>
    <span class="s1">expected_decision_func_count</span><span class="s2">,</span>
<span class="s2">):</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[</span><span class="s6">1</span><span class="s2">], [</span><span class="s6">1</span><span class="s2">], [</span><span class="s6">0</span><span class="s2">], [</span><span class="s6">0</span><span class="s2">], [</span><span class="s6">0</span><span class="s2">]]), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s6">0</span><span class="s2">, </span><span class="s6">1</span><span class="s2">, </span><span class="s6">1</span><span class="s2">, </span><span class="s6">1</span><span class="s2">, </span><span class="s6">0</span><span class="s2">])</span>

    <span class="s1">mock_est </span><span class="s2">= </span><span class="s1">Mock</span><span class="s2">()</span>
    <span class="s1">mock_est</span><span class="s2">.</span><span class="s1">_estimator_type </span><span class="s2">= </span><span class="s3">&quot;classifier&quot;</span>
    <span class="s1">fit_func </span><span class="s2">= </span><span class="s1">Mock</span><span class="s2">(</span><span class="s1">return_value</span><span class="s2">=</span><span class="s1">mock_est</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;fit&quot;</span><span class="s2">)</span>
    <span class="s1">fit_func</span><span class="s2">.</span><span class="s1">__name__ </span><span class="s2">= </span><span class="s3">&quot;fit&quot;</span>
    <span class="s1">predict_func </span><span class="s2">= </span><span class="s1">Mock</span><span class="s2">(</span><span class="s1">return_value</span><span class="s2">=</span><span class="s1">y</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;predict&quot;</span><span class="s2">)</span>
    <span class="s1">predict_func</span><span class="s2">.</span><span class="s1">__name__ </span><span class="s2">= </span><span class="s3">&quot;predict&quot;</span>

    <span class="s1">pos_proba </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">rand</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s6">0</span><span class="s2">])</span>
    <span class="s1">proba </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">c_</span><span class="s2">[</span><span class="s6">1 </span><span class="s2">- </span><span class="s1">pos_proba</span><span class="s2">, </span><span class="s1">pos_proba</span><span class="s2">]</span>
    <span class="s1">predict_proba_func </span><span class="s2">= </span><span class="s1">Mock</span><span class="s2">(</span><span class="s1">return_value</span><span class="s2">=</span><span class="s1">proba</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">)</span>
    <span class="s1">predict_proba_func</span><span class="s2">.</span><span class="s1">__name__ </span><span class="s2">= </span><span class="s3">&quot;predict_proba&quot;</span>
    <span class="s1">decision_function_func </span><span class="s2">= </span><span class="s1">Mock</span><span class="s2">(</span><span class="s1">return_value</span><span class="s2">=</span><span class="s1">pos_proba</span><span class="s2">, </span><span class="s1">name</span><span class="s2">=</span><span class="s3">&quot;decision_function&quot;</span><span class="s2">)</span>
    <span class="s1">decision_function_func</span><span class="s2">.</span><span class="s1">__name__ </span><span class="s2">= </span><span class="s3">&quot;decision_function&quot;</span>

    <span class="s1">mock_est</span><span class="s2">.</span><span class="s1">fit </span><span class="s2">= </span><span class="s1">fit_func</span>
    <span class="s1">mock_est</span><span class="s2">.</span><span class="s1">predict </span><span class="s2">= </span><span class="s1">predict_func</span>
    <span class="s1">mock_est</span><span class="s2">.</span><span class="s1">predict_proba </span><span class="s2">= </span><span class="s1">predict_proba_func</span>
    <span class="s1">mock_est</span><span class="s2">.</span><span class="s1">decision_function </span><span class="s2">= </span><span class="s1">decision_function_func</span>
    <span class="s4"># add the classes that would be found during fit</span>
    <span class="s1">mock_est</span><span class="s2">.</span><span class="s1">classes_ </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s6">0</span><span class="s2">, </span><span class="s6">1</span><span class="s2">])</span>

    <span class="s1">scorer_dict </span><span class="s2">= </span><span class="s1">_check_multimetric_scoring</span><span class="s2">(</span><span class="s1">LogisticRegression</span><span class="s2">(), </span><span class="s1">scorers</span><span class="s2">)</span>
    <span class="s1">multi_scorer </span><span class="s2">= </span><span class="s1">_MultimetricScorer</span><span class="s2">(</span><span class="s1">scorers</span><span class="s2">=</span><span class="s1">scorer_dict</span><span class="s2">)</span>
    <span class="s1">results </span><span class="s2">= </span><span class="s1">multi_scorer</span><span class="s2">(</span><span class="s1">mock_est</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">set</span><span class="s2">(</span><span class="s1">scorers</span><span class="s2">) == </span><span class="s1">set</span><span class="s2">(</span><span class="s1">results</span><span class="s2">)  </span><span class="s4"># compare dict keys</span>

    <span class="s0">assert </span><span class="s1">predict_func</span><span class="s2">.</span><span class="s1">call_count </span><span class="s2">== </span><span class="s1">expected_predict_count</span>
    <span class="s0">assert </span><span class="s1">predict_proba_func</span><span class="s2">.</span><span class="s1">call_count </span><span class="s2">== </span><span class="s1">expected_predict_proba_count</span>
    <span class="s0">assert </span><span class="s1">decision_function_func</span><span class="s2">.</span><span class="s1">call_count </span><span class="s2">== </span><span class="s1">expected_decision_func_count</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;scorers&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">([</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">, </span><span class="s3">&quot;neg_log_loss&quot;</span><span class="s2">]),</span>
        <span class="s2">(</span>
            <span class="s2">{</span>
                <span class="s3">&quot;roc_auc&quot;</span><span class="s2">: </span><span class="s1">make_scorer</span><span class="s2">(</span>
                    <span class="s1">roc_auc_score</span><span class="s2">,</span>
                    <span class="s1">response_method</span><span class="s2">=[</span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">, </span><span class="s3">&quot;decision_function&quot;</span><span class="s2">],</span>
                <span class="s2">),</span>
                <span class="s3">&quot;neg_log_loss&quot;</span><span class="s2">: </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">log_loss</span><span class="s2">, </span><span class="s1">response_method</span><span class="s2">=</span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">),</span>
            <span class="s2">}</span>
        <span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_multimetric_scorer_calls_method_once_classifier_no_decision</span><span class="s2">(</span><span class="s1">scorers</span><span class="s2">):</span>
    <span class="s1">predict_proba_call_cnt </span><span class="s2">= </span><span class="s6">0</span>

    <span class="s0">class </span><span class="s1">MockKNeighborsClassifier</span><span class="s2">(</span><span class="s1">KNeighborsClassifier</span><span class="s2">):</span>
        <span class="s0">def </span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">):</span>
            <span class="s0">nonlocal </span><span class="s1">predict_proba_call_cnt</span>
            <span class="s1">predict_proba_call_cnt </span><span class="s2">+= </span><span class="s6">1</span>
            <span class="s0">return </span><span class="s1">super</span><span class="s2">().</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[</span><span class="s6">1</span><span class="s2">], [</span><span class="s6">1</span><span class="s2">], [</span><span class="s6">0</span><span class="s2">], [</span><span class="s6">0</span><span class="s2">], [</span><span class="s6">0</span><span class="s2">]]), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s6">0</span><span class="s2">, </span><span class="s6">1</span><span class="s2">, </span><span class="s6">1</span><span class="s2">, </span><span class="s6">1</span><span class="s2">, </span><span class="s6">0</span><span class="s2">])</span>

    <span class="s4"># no decision function</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">MockKNeighborsClassifier</span><span class="s2">(</span><span class="s1">n_neighbors</span><span class="s2">=</span><span class="s6">1</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">scorer_dict </span><span class="s2">= </span><span class="s1">_check_multimetric_scoring</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">scorers</span><span class="s2">)</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">_MultimetricScorer</span><span class="s2">(</span><span class="s1">scorers</span><span class="s2">=</span><span class="s1">scorer_dict</span><span class="s2">)</span>
    <span class="s1">scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">predict_proba_call_cnt </span><span class="s2">== </span><span class="s6">1</span>


<span class="s0">def </span><span class="s1">test_multimetric_scorer_calls_method_once_regressor_threshold</span><span class="s2">():</span>
    <span class="s1">predict_called_cnt </span><span class="s2">= </span><span class="s6">0</span>

    <span class="s0">class </span><span class="s1">MockDecisionTreeRegressor</span><span class="s2">(</span><span class="s1">DecisionTreeRegressor</span><span class="s2">):</span>
        <span class="s0">def </span><span class="s1">predict</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">):</span>
            <span class="s0">nonlocal </span><span class="s1">predict_called_cnt</span>
            <span class="s1">predict_called_cnt </span><span class="s2">+= </span><span class="s6">1</span>
            <span class="s0">return </span><span class="s1">super</span><span class="s2">().</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[</span><span class="s6">1</span><span class="s2">], [</span><span class="s6">1</span><span class="s2">], [</span><span class="s6">0</span><span class="s2">], [</span><span class="s6">0</span><span class="s2">], [</span><span class="s6">0</span><span class="s2">]]), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s6">0</span><span class="s2">, </span><span class="s6">1</span><span class="s2">, </span><span class="s6">1</span><span class="s2">, </span><span class="s6">1</span><span class="s2">, </span><span class="s6">0</span><span class="s2">])</span>

    <span class="s4"># no decision function</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">MockDecisionTreeRegressor</span><span class="s2">()</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">scorers </span><span class="s2">= {</span><span class="s3">&quot;neg_mse&quot;</span><span class="s2">: </span><span class="s3">&quot;neg_mean_squared_error&quot;</span><span class="s2">, </span><span class="s3">&quot;r2&quot;</span><span class="s2">: </span><span class="s3">&quot;r2&quot;</span><span class="s2">}</span>
    <span class="s1">scorer_dict </span><span class="s2">= </span><span class="s1">_check_multimetric_scoring</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">scorers</span><span class="s2">)</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">_MultimetricScorer</span><span class="s2">(</span><span class="s1">scorers</span><span class="s2">=</span><span class="s1">scorer_dict</span><span class="s2">)</span>
    <span class="s1">scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">predict_called_cnt </span><span class="s2">== </span><span class="s6">1</span>


<span class="s0">def </span><span class="s1">test_multimetric_scorer_sanity_check</span><span class="s2">():</span>
    <span class="s4"># scoring dictionary returned is the same as calling each scorer separately</span>
    <span class="s1">scorers </span><span class="s2">= {</span>
        <span class="s3">&quot;a1&quot;</span><span class="s2">: </span><span class="s3">&quot;accuracy&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;a2&quot;</span><span class="s2">: </span><span class="s3">&quot;accuracy&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;ll1&quot;</span><span class="s2">: </span><span class="s3">&quot;neg_log_loss&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;ll2&quot;</span><span class="s2">: </span><span class="s3">&quot;neg_log_loss&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;ra1&quot;</span><span class="s2">: </span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;ra2&quot;</span><span class="s2">: </span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">,</span>
    <span class="s2">}</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">DecisionTreeClassifier</span><span class="s2">()</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">scorer_dict </span><span class="s2">= </span><span class="s1">_check_multimetric_scoring</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">scorers</span><span class="s2">)</span>
    <span class="s1">multi_scorer </span><span class="s2">= </span><span class="s1">_MultimetricScorer</span><span class="s2">(</span><span class="s1">scorers</span><span class="s2">=</span><span class="s1">scorer_dict</span><span class="s2">)</span>

    <span class="s1">result </span><span class="s2">= </span><span class="s1">multi_scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">separate_scores </span><span class="s2">= {</span>
        <span class="s1">name</span><span class="s2">: </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">name</span><span class="s2">)(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s0">for </span><span class="s1">name </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">, </span><span class="s3">&quot;neg_log_loss&quot;</span><span class="s2">, </span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">]</span>
    <span class="s2">}</span>

    <span class="s0">for </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value </span><span class="s0">in </span><span class="s1">result</span><span class="s2">.</span><span class="s1">items</span><span class="s2">():</span>
        <span class="s1">score_name </span><span class="s2">= </span><span class="s1">scorers</span><span class="s2">[</span><span class="s1">key</span><span class="s2">]</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">value</span><span class="s2">, </span><span class="s1">separate_scores</span><span class="s2">[</span><span class="s1">score_name</span><span class="s2">])</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;raise_exc&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_multimetric_scorer_exception_handling</span><span class="s2">(</span><span class="s1">raise_exc</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Check that the calling of the `_MultimetricScorer` returns 
    exception messages in the result dict for the failing scorers 
    in case of `raise_exc` is `False` and if `raise_exc` is `True`, 
    then the proper exception is raised. 
    &quot;&quot;&quot;</span>
    <span class="s1">scorers </span><span class="s2">= {</span>
        <span class="s3">&quot;failing_1&quot;</span><span class="s2">: </span><span class="s3">&quot;neg_mean_squared_log_error&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;non_failing&quot;</span><span class="s2">: </span><span class="s3">&quot;neg_median_absolute_error&quot;</span><span class="s2">,</span>
        <span class="s3">&quot;failing_2&quot;</span><span class="s2">: </span><span class="s3">&quot;neg_mean_squared_log_error&quot;</span><span class="s2">,</span>
    <span class="s2">}</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s6">50</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s6">2</span><span class="s2">, </span><span class="s1">n_redundant</span><span class="s2">=</span><span class="s6">0</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span>
    <span class="s2">)</span>
    <span class="s1">y </span><span class="s2">*= -</span><span class="s6">1  </span><span class="s4"># neg_mean_squared_log_error fails if y contains negative values</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">DecisionTreeClassifier</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">scorer_dict </span><span class="s2">= </span><span class="s1">_check_multimetric_scoring</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">scorers</span><span class="s2">)</span>
    <span class="s1">multi_scorer </span><span class="s2">= </span><span class="s1">_MultimetricScorer</span><span class="s2">(</span><span class="s1">scorers</span><span class="s2">=</span><span class="s1">scorer_dict</span><span class="s2">, </span><span class="s1">raise_exc</span><span class="s2">=</span><span class="s1">raise_exc</span><span class="s2">)</span>

    <span class="s1">error_msg </span><span class="s2">= (</span>
        <span class="s3">&quot;Mean Squared Logarithmic Error cannot be used when targets contain&quot;</span>
        <span class="s3">&quot; negative values.&quot;</span>
    <span class="s2">)</span>

    <span class="s0">if </span><span class="s1">raise_exc</span><span class="s2">:</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">error_msg</span><span class="s2">):</span>
            <span class="s1">multi_scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">result </span><span class="s2">= </span><span class="s1">multi_scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

        <span class="s1">exception_message_1 </span><span class="s2">= </span><span class="s1">result</span><span class="s2">[</span><span class="s3">&quot;failing_1&quot;</span><span class="s2">]</span>
        <span class="s1">score </span><span class="s2">= </span><span class="s1">result</span><span class="s2">[</span><span class="s3">&quot;non_failing&quot;</span><span class="s2">]</span>
        <span class="s1">exception_message_2 </span><span class="s2">= </span><span class="s1">result</span><span class="s2">[</span><span class="s3">&quot;failing_2&quot;</span><span class="s2">]</span>

        <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">exception_message_1</span><span class="s2">, </span><span class="s1">str</span><span class="s2">) </span><span class="s0">and </span><span class="s1">error_msg </span><span class="s0">in </span><span class="s1">exception_message_1</span>
        <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">score</span><span class="s2">, </span><span class="s1">float</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">exception_message_2</span><span class="s2">, </span><span class="s1">str</span><span class="s2">) </span><span class="s0">and </span><span class="s1">error_msg </span><span class="s0">in </span><span class="s1">exception_message_2</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;scorer_name, metric&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">(</span><span class="s3">&quot;roc_auc_ovr&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">roc_auc_score</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span><span class="s3">&quot;roc_auc_ovo&quot;</span><span class="s2">, </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">roc_auc_score</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovo&quot;</span><span class="s2">)),</span>
        <span class="s2">(</span>
            <span class="s3">&quot;roc_auc_ovr_weighted&quot;</span><span class="s2">,</span>
            <span class="s1">partial</span><span class="s2">(</span><span class="s1">roc_auc_score</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">),</span>
        <span class="s2">),</span>
        <span class="s2">(</span>
            <span class="s3">&quot;roc_auc_ovo_weighted&quot;</span><span class="s2">,</span>
            <span class="s1">partial</span><span class="s2">(</span><span class="s1">roc_auc_score</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovo&quot;</span><span class="s2">, </span><span class="s1">average</span><span class="s2">=</span><span class="s3">&quot;weighted&quot;</span><span class="s2">),</span>
        <span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_multiclass_roc_proba_scorer</span><span class="s2">(</span><span class="s1">scorer_name</span><span class="s2">, </span><span class="s1">metric</span><span class="s2">):</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">scorer_name</span><span class="s2">)</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">=</span><span class="s6">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span>
    <span class="s2">)</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">y_proba </span><span class="s2">= </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">expected_score </span><span class="s2">= </span><span class="s1">metric</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">y_proba</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">) == </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">expected_score</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_multiclass_roc_proba_scorer_label</span><span class="s2">():</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span>
        <span class="s1">roc_auc_score</span><span class="s2">,</span>
        <span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovo&quot;</span><span class="s2">,</span>
        <span class="s1">labels</span><span class="s2">=[</span><span class="s6">0</span><span class="s2">, </span><span class="s6">1</span><span class="s2">, </span><span class="s6">2</span><span class="s2">],</span>
        <span class="s1">response_method</span><span class="s2">=</span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">=</span><span class="s6">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span>
    <span class="s2">)</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">y_proba </span><span class="s2">= </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">y_binary </span><span class="s2">= </span><span class="s1">y </span><span class="s2">== </span><span class="s6">0</span>
    <span class="s1">expected_score </span><span class="s2">= </span><span class="s1">roc_auc_score</span><span class="s2">(</span>
        <span class="s1">y_binary</span><span class="s2">, </span><span class="s1">y_proba</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovo&quot;</span><span class="s2">, </span><span class="s1">labels</span><span class="s2">=[</span><span class="s6">0</span><span class="s2">, </span><span class="s6">1</span><span class="s2">, </span><span class="s6">2</span><span class="s2">]</span>
    <span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_binary</span><span class="s2">) == </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">expected_score</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;scorer_name&quot;</span><span class="s2">,</span>
    <span class="s2">[</span><span class="s3">&quot;roc_auc_ovr&quot;</span><span class="s2">, </span><span class="s3">&quot;roc_auc_ovo&quot;</span><span class="s2">, </span><span class="s3">&quot;roc_auc_ovr_weighted&quot;</span><span class="s2">, </span><span class="s3">&quot;roc_auc_ovo_weighted&quot;</span><span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_multiclass_roc_no_proba_scorer_errors</span><span class="s2">(</span><span class="s1">scorer_name</span><span class="s2">):</span>
    <span class="s4"># Perceptron has no predict_proba</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">scorer_name</span><span class="s2">)</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">=</span><span class="s6">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span>
    <span class="s2">)</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">Perceptron</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Perceptron has none of the following attributes: predict_proba.&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">AttributeError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">scorer</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">fixture</span>
<span class="s0">def </span><span class="s1">string_labeled_classification_problem</span><span class="s2">():</span>
    <span class="s5">&quot;&quot;&quot;Train a classifier on binary problem with string target. 
 
    The classifier is trained on a binary classification problem where the 
    minority class of interest has a string label that is intentionally not the 
    greatest class label using the lexicographic order. In this case, &quot;cancer&quot; 
    is the positive label, and `classifier.classes_` is 
    `[&quot;cancer&quot;, &quot;not cancer&quot;]`. 
 
    In addition, the dataset is imbalanced to better identify problems when 
    using non-symmetric performance metrics such as f1-score, average precision 
    and so on. 
 
    Returns 
    ------- 
    classifier : estimator object 
        Trained classifier on the binary problem. 
    X_test : ndarray of shape (n_samples, n_features) 
        Data to be used as testing set in tests. 
    y_test : ndarray of shape (n_samples,), dtype=object 
        Binary target where labels are strings. 
    y_pred : ndarray of shape (n_samples,), dtype=object 
        Prediction of `classifier` when predicting for `X_test`. 
    y_pred_proba : ndarray of shape (n_samples, 2), dtype=np.float64 
        Probabilities of `classifier` when predicting for `X_test`. 
    y_pred_decision : ndarray of shape (n_samples,), dtype=np.float64 
        Decision function values of `classifier` when predicting on `X_test`. 
    &quot;&quot;&quot;</span>
    <span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">datasets </span><span class="s0">import </span><span class="s1">load_breast_cancer</span>
    <span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils </span><span class="s0">import </span><span class="s1">shuffle</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">load_breast_cancer</span><span class="s2">(</span><span class="s1">return_X_y</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s4"># create an highly imbalanced classification task</span>
    <span class="s1">idx_positive </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">flatnonzero</span><span class="s2">(</span><span class="s1">y </span><span class="s2">== </span><span class="s6">1</span><span class="s2">)</span>
    <span class="s1">idx_negative </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">flatnonzero</span><span class="s2">(</span><span class="s1">y </span><span class="s2">== </span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">idx_selected </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">hstack</span><span class="s2">([</span><span class="s1">idx_negative</span><span class="s2">, </span><span class="s1">idx_positive</span><span class="s2">[:</span><span class="s6">25</span><span class="s2">]])</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[</span><span class="s1">idx_selected</span><span class="s2">], </span><span class="s1">y</span><span class="s2">[</span><span class="s1">idx_selected</span><span class="s2">]</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">shuffle</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">42</span><span class="s2">)</span>
    <span class="s4"># only use 2 features to make the problem even harder</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[:, :</span><span class="s6">2</span><span class="s2">]</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s3">&quot;cancer&quot; </span><span class="s0">if </span><span class="s1">c </span><span class="s2">== </span><span class="s6">1 </span><span class="s0">else </span><span class="s3">&quot;not cancer&quot; </span><span class="s0">for </span><span class="s1">c </span><span class="s0">in </span><span class="s1">y</span><span class="s2">], </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">object</span><span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span>
        <span class="s1">X</span><span class="s2">,</span>
        <span class="s1">y</span><span class="s2">,</span>
        <span class="s1">stratify</span><span class="s2">=</span><span class="s1">y</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">classifier </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>
    <span class="s1">y_pred </span><span class="s2">= </span><span class="s1">classifier</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>
    <span class="s1">y_pred_proba </span><span class="s2">= </span><span class="s1">classifier</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>
    <span class="s1">y_pred_decision </span><span class="s2">= </span><span class="s1">classifier</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>

    <span class="s0">return </span><span class="s1">classifier</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">y_pred_proba</span><span class="s2">, </span><span class="s1">y_pred_decision</span>


<span class="s0">def </span><span class="s1">test_average_precision_pos_label</span><span class="s2">(</span><span class="s1">string_labeled_classification_problem</span><span class="s2">):</span>
    <span class="s4"># check that _Scorer will lead to the right score when passing</span>
    <span class="s4"># `pos_label`. Currently, only `average_precision_score` is defined to</span>
    <span class="s4"># be such a scorer.</span>
    <span class="s2">(</span>
        <span class="s1">clf</span><span class="s2">,</span>
        <span class="s1">X_test</span><span class="s2">,</span>
        <span class="s1">y_test</span><span class="s2">,</span>
        <span class="s1">_</span><span class="s2">,</span>
        <span class="s1">y_pred_proba</span><span class="s2">,</span>
        <span class="s1">y_pred_decision</span><span class="s2">,</span>
    <span class="s2">) = </span><span class="s1">string_labeled_classification_problem</span>

    <span class="s1">pos_label </span><span class="s2">= </span><span class="s3">&quot;cancer&quot;</span>
    <span class="s4"># we need to select the positive column or reverse the decision values</span>
    <span class="s1">y_pred_proba </span><span class="s2">= </span><span class="s1">y_pred_proba</span><span class="s2">[:, </span><span class="s6">0</span><span class="s2">]</span>
    <span class="s1">y_pred_decision </span><span class="s2">= </span><span class="s1">y_pred_decision </span><span class="s2">* -</span><span class="s6">1</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">[</span><span class="s6">0</span><span class="s2">] == </span><span class="s1">pos_label</span>

    <span class="s4"># check that when calling the scoring function, probability estimates and</span>
    <span class="s4"># decision values lead to the same results</span>
    <span class="s1">ap_proba </span><span class="s2">= </span><span class="s1">average_precision_score</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_pred_proba</span><span class="s2">, </span><span class="s1">pos_label</span><span class="s2">=</span><span class="s1">pos_label</span><span class="s2">)</span>
    <span class="s1">ap_decision_function </span><span class="s2">= </span><span class="s1">average_precision_score</span><span class="s2">(</span>
        <span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_pred_decision</span><span class="s2">, </span><span class="s1">pos_label</span><span class="s2">=</span><span class="s1">pos_label</span>
    <span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ap_proba </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">ap_decision_function</span><span class="s2">)</span>

    <span class="s4"># create a scorer which would require to pass a `pos_label`</span>
    <span class="s4"># check that it fails if `pos_label` is not provided</span>
    <span class="s1">average_precision_scorer </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span>
        <span class="s1">average_precision_score</span><span class="s2">,</span>
        <span class="s1">response_method</span><span class="s2">=(</span><span class="s3">&quot;decision_function&quot;</span><span class="s2">, </span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">),</span>
    <span class="s2">)</span>
    <span class="s1">err_msg </span><span class="s2">= </span><span class="s3">&quot;pos_label=1 is not a valid label. It should be one of &quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">err_msg</span><span class="s2">):</span>
        <span class="s1">average_precision_scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>

    <span class="s4"># otherwise, the scorer should give the same results than calling the</span>
    <span class="s4"># scoring function</span>
    <span class="s1">average_precision_scorer </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span>
        <span class="s1">average_precision_score</span><span class="s2">,</span>
        <span class="s1">response_method</span><span class="s2">=(</span><span class="s3">&quot;decision_function&quot;</span><span class="s2">, </span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">),</span>
        <span class="s1">pos_label</span><span class="s2">=</span><span class="s1">pos_label</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">ap_scorer </span><span class="s2">= </span><span class="s1">average_precision_scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">ap_scorer </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">ap_proba</span><span class="s2">)</span>

    <span class="s4"># The above scorer call is using `clf.decision_function`. We will force</span>
    <span class="s4"># it to use `clf.predict_proba`.</span>
    <span class="s1">clf_without_predict_proba </span><span class="s2">= </span><span class="s1">deepcopy</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">_predict_proba</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">X</span><span class="s2">):</span>
        <span class="s0">raise </span><span class="s1">NotImplementedError</span>

    <span class="s1">clf_without_predict_proba</span><span class="s2">.</span><span class="s1">predict_proba </span><span class="s2">= </span><span class="s1">partial</span><span class="s2">(</span>
        <span class="s1">_predict_proba</span><span class="s2">, </span><span class="s1">clf_without_predict_proba</span>
    <span class="s2">)</span>
    <span class="s4"># sanity check</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">NotImplementedError</span><span class="s2">):</span>
        <span class="s1">clf_without_predict_proba</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>

    <span class="s1">ap_scorer </span><span class="s2">= </span><span class="s1">average_precision_scorer</span><span class="s2">(</span><span class="s1">clf_without_predict_proba</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ap_scorer </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">ap_proba</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_brier_score_loss_pos_label</span><span class="s2">(</span><span class="s1">string_labeled_classification_problem</span><span class="s2">):</span>
    <span class="s4"># check that _Scorer leads to the right score when `pos_label` is</span>
    <span class="s4"># provided. Currently only the `brier_score_loss` is defined to be such</span>
    <span class="s4"># a scorer.</span>
    <span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">y_pred_proba</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">= </span><span class="s1">string_labeled_classification_problem</span>

    <span class="s1">pos_label </span><span class="s2">= </span><span class="s3">&quot;cancer&quot;</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">[</span><span class="s6">0</span><span class="s2">] == </span><span class="s1">pos_label</span>

    <span class="s4"># brier score loss is symmetric</span>
    <span class="s1">brier_pos_cancer </span><span class="s2">= </span><span class="s1">brier_score_loss</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_pred_proba</span><span class="s2">[:, </span><span class="s6">0</span><span class="s2">], </span><span class="s1">pos_label</span><span class="s2">=</span><span class="s3">&quot;cancer&quot;</span><span class="s2">)</span>
    <span class="s1">brier_pos_not_cancer </span><span class="s2">= </span><span class="s1">brier_score_loss</span><span class="s2">(</span>
        <span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_pred_proba</span><span class="s2">[:, </span><span class="s6">1</span><span class="s2">], </span><span class="s1">pos_label</span><span class="s2">=</span><span class="s3">&quot;not cancer&quot;</span>
    <span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">brier_pos_cancer </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">brier_pos_not_cancer</span><span class="s2">)</span>

    <span class="s1">brier_scorer </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span>
        <span class="s1">brier_score_loss</span><span class="s2">,</span>
        <span class="s1">response_method</span><span class="s2">=</span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">,</span>
        <span class="s1">pos_label</span><span class="s2">=</span><span class="s1">pos_label</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">brier_scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">) == </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">brier_pos_cancer</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;score_func&quot;</span><span class="s2">, [</span><span class="s1">f1_score</span><span class="s2">, </span><span class="s1">precision_score</span><span class="s2">, </span><span class="s1">recall_score</span><span class="s2">, </span><span class="s1">jaccard_score</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_non_symmetric_metric_pos_label</span><span class="s2">(</span>
    <span class="s1">score_func</span><span class="s2">, </span><span class="s1">string_labeled_classification_problem</span>
<span class="s2">):</span>
    <span class="s4"># check that _Scorer leads to the right score when `pos_label` is</span>
    <span class="s4"># provided. We check for all possible metric supported.</span>
    <span class="s4"># Note: At some point we may end up having &quot;scorer tags&quot;.</span>
    <span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">= </span><span class="s1">string_labeled_classification_problem</span>

    <span class="s1">pos_label </span><span class="s2">= </span><span class="s3">&quot;cancer&quot;</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">[</span><span class="s6">0</span><span class="s2">] == </span><span class="s1">pos_label</span>

    <span class="s1">score_pos_cancer </span><span class="s2">= </span><span class="s1">score_func</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">pos_label</span><span class="s2">=</span><span class="s3">&quot;cancer&quot;</span><span class="s2">)</span>
    <span class="s1">score_pos_not_cancer </span><span class="s2">= </span><span class="s1">score_func</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">pos_label</span><span class="s2">=</span><span class="s3">&quot;not cancer&quot;</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">score_pos_cancer </span><span class="s2">!= </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">score_pos_not_cancer</span><span class="s2">)</span>

    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">score_func</span><span class="s2">, </span><span class="s1">pos_label</span><span class="s2">=</span><span class="s1">pos_label</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">) == </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">score_pos_cancer</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;scorer&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s1">make_scorer</span><span class="s2">(</span>
            <span class="s1">average_precision_score</span><span class="s2">,</span>
            <span class="s1">response_method</span><span class="s2">=(</span><span class="s3">&quot;decision_function&quot;</span><span class="s2">, </span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">),</span>
            <span class="s1">pos_label</span><span class="s2">=</span><span class="s3">&quot;xxx&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">brier_score_loss</span><span class="s2">, </span><span class="s1">response_method</span><span class="s2">=</span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">, </span><span class="s1">pos_label</span><span class="s2">=</span><span class="s3">&quot;xxx&quot;</span><span class="s2">),</span>
        <span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">f1_score</span><span class="s2">, </span><span class="s1">pos_label</span><span class="s2">=</span><span class="s3">&quot;xxx&quot;</span><span class="s2">),</span>
    <span class="s2">],</span>
    <span class="s1">ids</span><span class="s2">=[</span><span class="s3">&quot;non-thresholded scorer&quot;</span><span class="s2">, </span><span class="s3">&quot;probability scorer&quot;</span><span class="s2">, </span><span class="s3">&quot;thresholded scorer&quot;</span><span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_scorer_select_proba_error</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">):</span>
    <span class="s4"># check that we raise the proper error when passing an unknown</span>
    <span class="s4"># pos_label</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s6">2</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">=</span><span class="s6">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span>
    <span class="s2">)</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">scorer</span><span class="s2">.</span><span class="s1">_kwargs</span><span class="s2">[</span><span class="s3">&quot;pos_label&quot;</span><span class="s2">] </span><span class="s0">not in </span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">y</span><span class="s2">).</span><span class="s1">tolist</span><span class="s2">()</span>

    <span class="s1">err_msg </span><span class="s2">= </span><span class="s3">&quot;is not a valid label&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">err_msg</span><span class="s2">):</span>
        <span class="s1">scorer</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_get_scorer_return_copy</span><span class="s2">():</span>
    <span class="s4"># test that get_scorer returns a copy</span>
    <span class="s0">assert </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">) </span><span class="s0">is not </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_scorer_no_op_multiclass_select_proba</span><span class="s2">():</span>
    <span class="s4"># check that calling a _Scorer on a multiclass problem do not raise</span>
    <span class="s4"># even if `y_true` would be binary during the scoring.</span>
    <span class="s4"># `_select_proba_binary` should not be called in this case.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">=</span><span class="s6">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span>
    <span class="s2">)</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">mask_last_class </span><span class="s2">= </span><span class="s1">y </span><span class="s2">== </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">[-</span><span class="s6">1</span><span class="s2">]</span>
    <span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[~</span><span class="s1">mask_last_class</span><span class="s2">], </span><span class="s1">y</span><span class="s2">[~</span><span class="s1">mask_last_class</span><span class="s2">]</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">), </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">[:-</span><span class="s6">1</span><span class="s2">])</span>

    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span>
        <span class="s1">roc_auc_score</span><span class="s2">,</span>
        <span class="s1">response_method</span><span class="s2">=</span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">,</span>
        <span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovo&quot;</span><span class="s2">,</span>
        <span class="s1">labels</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">scorer</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;name&quot;</span><span class="s2">, </span><span class="s1">get_scorer_names</span><span class="s2">())</span>
<span class="s0">def </span><span class="s1">test_scorer_set_score_request_raises</span><span class="s2">(</span><span class="s1">name</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test that set_score_request is only available when feature flag is on.&quot;&quot;&quot;</span>
    <span class="s4"># Make sure they expose the routing methods.</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">name</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">RuntimeError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;This method is only available&quot;</span><span class="s2">):</span>
        <span class="s1">scorer</span><span class="s2">.</span><span class="s1">set_score_request</span><span class="s2">()</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">usefixtures</span><span class="s2">(</span><span class="s3">&quot;enable_slep006&quot;</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;name&quot;</span><span class="s2">, </span><span class="s1">get_scorer_names</span><span class="s2">(), </span><span class="s1">ids</span><span class="s2">=</span><span class="s1">get_scorer_names</span><span class="s2">())</span>
<span class="s0">def </span><span class="s1">test_scorer_metadata_request</span><span class="s2">(</span><span class="s1">name</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Testing metadata requests for scorers. 
 
    This test checks many small things in a large test, to reduce the 
    boilerplate required for each section. 
    &quot;&quot;&quot;</span>
    <span class="s4"># Make sure they expose the routing methods.</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">name</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">, </span><span class="s3">&quot;set_score_request&quot;</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">, </span><span class="s3">&quot;get_metadata_routing&quot;</span><span class="s2">)</span>

    <span class="s4"># Check that by default no metadata is requested.</span>
    <span class="s1">assert_request_is_empty</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">.</span><span class="s1">get_metadata_routing</span><span class="s2">())</span>

    <span class="s1">weighted_scorer </span><span class="s2">= </span><span class="s1">scorer</span><span class="s2">.</span><span class="s1">set_score_request</span><span class="s2">(</span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s4"># set_score_request should mutate the instance, rather than returning a</span>
    <span class="s4"># new instance</span>
    <span class="s0">assert </span><span class="s1">weighted_scorer </span><span class="s0">is </span><span class="s1">scorer</span>

    <span class="s4"># make sure the scorer doesn't request anything on methods other than</span>
    <span class="s4"># `score`, and that the requested value on `score` is correct.</span>
    <span class="s1">assert_request_is_empty</span><span class="s2">(</span><span class="s1">weighted_scorer</span><span class="s2">.</span><span class="s1">get_metadata_routing</span><span class="s2">(), </span><span class="s1">exclude</span><span class="s2">=</span><span class="s3">&quot;score&quot;</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s2">(</span>
        <span class="s1">weighted_scorer</span><span class="s2">.</span><span class="s1">get_metadata_routing</span><span class="s2">().</span><span class="s1">score</span><span class="s2">.</span><span class="s1">requests</span><span class="s2">[</span><span class="s3">&quot;sample_weight&quot;</span><span class="s2">] </span><span class="s0">is True</span>
    <span class="s2">)</span>

    <span class="s4"># make sure putting the scorer in a router doesn't request anything by</span>
    <span class="s4"># default</span>
    <span class="s1">router </span><span class="s2">= </span><span class="s1">MetadataRouter</span><span class="s2">(</span><span class="s1">owner</span><span class="s2">=</span><span class="s3">&quot;test&quot;</span><span class="s2">).</span><span class="s1">add</span><span class="s2">(</span>
        <span class="s1">scorer</span><span class="s2">=</span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">name</span><span class="s2">),</span>
        <span class="s1">method_mapping</span><span class="s2">=</span><span class="s1">MethodMapping</span><span class="s2">().</span><span class="s1">add</span><span class="s2">(</span><span class="s1">caller</span><span class="s2">=</span><span class="s3">&quot;score&quot;</span><span class="s2">, </span><span class="s1">callee</span><span class="s2">=</span><span class="s3">&quot;score&quot;</span><span class="s2">),</span>
    <span class="s2">)</span>
    <span class="s4"># make sure `sample_weight` is refused if passed.</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">TypeError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;got unexpected argument&quot;</span><span class="s2">):</span>
        <span class="s1">router</span><span class="s2">.</span><span class="s1">validate_metadata</span><span class="s2">(</span><span class="s1">params</span><span class="s2">={</span><span class="s3">&quot;sample_weight&quot;</span><span class="s2">: </span><span class="s6">1</span><span class="s2">}, </span><span class="s1">method</span><span class="s2">=</span><span class="s3">&quot;score&quot;</span><span class="s2">)</span>
    <span class="s4"># make sure `sample_weight` is not routed even if passed.</span>
    <span class="s1">routed_params </span><span class="s2">= </span><span class="s1">router</span><span class="s2">.</span><span class="s1">route_params</span><span class="s2">(</span><span class="s1">params</span><span class="s2">={</span><span class="s3">&quot;sample_weight&quot;</span><span class="s2">: </span><span class="s6">1</span><span class="s2">}, </span><span class="s1">caller</span><span class="s2">=</span><span class="s3">&quot;score&quot;</span><span class="s2">)</span>
    <span class="s0">assert not </span><span class="s1">routed_params</span><span class="s2">.</span><span class="s1">scorer</span><span class="s2">.</span><span class="s1">score</span>

    <span class="s4"># make sure putting weighted_scorer in a router requests sample_weight</span>
    <span class="s1">router </span><span class="s2">= </span><span class="s1">MetadataRouter</span><span class="s2">(</span><span class="s1">owner</span><span class="s2">=</span><span class="s3">&quot;test&quot;</span><span class="s2">).</span><span class="s1">add</span><span class="s2">(</span>
        <span class="s1">scorer</span><span class="s2">=</span><span class="s1">weighted_scorer</span><span class="s2">,</span>
        <span class="s1">method_mapping</span><span class="s2">=</span><span class="s1">MethodMapping</span><span class="s2">().</span><span class="s1">add</span><span class="s2">(</span><span class="s1">caller</span><span class="s2">=</span><span class="s3">&quot;score&quot;</span><span class="s2">, </span><span class="s1">callee</span><span class="s2">=</span><span class="s3">&quot;score&quot;</span><span class="s2">),</span>
    <span class="s2">)</span>
    <span class="s1">router</span><span class="s2">.</span><span class="s1">validate_metadata</span><span class="s2">(</span><span class="s1">params</span><span class="s2">={</span><span class="s3">&quot;sample_weight&quot;</span><span class="s2">: </span><span class="s6">1</span><span class="s2">}, </span><span class="s1">method</span><span class="s2">=</span><span class="s3">&quot;score&quot;</span><span class="s2">)</span>
    <span class="s1">routed_params </span><span class="s2">= </span><span class="s1">router</span><span class="s2">.</span><span class="s1">route_params</span><span class="s2">(</span><span class="s1">params</span><span class="s2">={</span><span class="s3">&quot;sample_weight&quot;</span><span class="s2">: </span><span class="s6">1</span><span class="s2">}, </span><span class="s1">caller</span><span class="s2">=</span><span class="s3">&quot;score&quot;</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">list</span><span class="s2">(</span><span class="s1">routed_params</span><span class="s2">.</span><span class="s1">scorer</span><span class="s2">.</span><span class="s1">score</span><span class="s2">.</span><span class="s1">keys</span><span class="s2">()) == [</span><span class="s3">&quot;sample_weight&quot;</span><span class="s2">]</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">usefixtures</span><span class="s2">(</span><span class="s3">&quot;enable_slep006&quot;</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_metadata_kwarg_conflict</span><span class="s2">():</span>
    <span class="s5">&quot;&quot;&quot;This test makes sure the right warning is raised if the user passes 
    some metadata both as a constructor to make_scorer, and during __call__. 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">=</span><span class="s6">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span>
    <span class="s2">)</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span>
        <span class="s1">roc_auc_score</span><span class="s2">,</span>
        <span class="s1">response_method</span><span class="s2">=</span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">,</span>
        <span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovo&quot;</span><span class="s2">,</span>
        <span class="s1">labels</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">UserWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;already set as kwargs&quot;</span><span class="s2">):</span>
        <span class="s1">scorer</span><span class="s2">.</span><span class="s1">set_score_request</span><span class="s2">(</span><span class="s1">labels</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">UserWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;There is an overlap&quot;</span><span class="s2">):</span>
        <span class="s1">scorer</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">labels</span><span class="s2">=</span><span class="s1">lr</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">usefixtures</span><span class="s2">(</span><span class="s3">&quot;enable_slep006&quot;</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_PassthroughScorer_set_score_request</span><span class="s2">():</span>
    <span class="s5">&quot;&quot;&quot;Test that _PassthroughScorer.set_score_request adds the correct metadata request 
    on itself and doesn't change its estimator's routing.&quot;&quot;&quot;</span>
    <span class="s1">est </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">().</span><span class="s1">set_score_request</span><span class="s2">(</span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s3">&quot;estimator_weights&quot;</span><span class="s2">)</span>
    <span class="s4"># make a `_PassthroughScorer` with `check_scoring`:</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">check_scoring</span><span class="s2">(</span><span class="s1">est</span><span class="s2">, </span><span class="s0">None</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s2">(</span>
        <span class="s1">scorer</span><span class="s2">.</span><span class="s1">get_metadata_routing</span><span class="s2">().</span><span class="s1">score</span><span class="s2">.</span><span class="s1">requests</span><span class="s2">[</span><span class="s3">&quot;sample_weight&quot;</span><span class="s2">]</span>
        <span class="s2">== </span><span class="s3">&quot;estimator_weights&quot;</span>
    <span class="s2">)</span>

    <span class="s1">scorer</span><span class="s2">.</span><span class="s1">set_score_request</span><span class="s2">(</span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s3">&quot;scorer_weights&quot;</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s2">(</span>
        <span class="s1">scorer</span><span class="s2">.</span><span class="s1">get_metadata_routing</span><span class="s2">().</span><span class="s1">score</span><span class="s2">.</span><span class="s1">requests</span><span class="s2">[</span><span class="s3">&quot;sample_weight&quot;</span><span class="s2">]</span>
        <span class="s2">== </span><span class="s3">&quot;scorer_weights&quot;</span>
    <span class="s2">)</span>

    <span class="s4"># making sure changing the passthrough object doesn't affect the estimator.</span>
    <span class="s0">assert </span><span class="s2">(</span>
        <span class="s1">est</span><span class="s2">.</span><span class="s1">get_metadata_routing</span><span class="s2">().</span><span class="s1">score</span><span class="s2">.</span><span class="s1">requests</span><span class="s2">[</span><span class="s3">&quot;sample_weight&quot;</span><span class="s2">]</span>
        <span class="s2">== </span><span class="s3">&quot;estimator_weights&quot;</span>
    <span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_PassthroughScorer_set_score_request_raises_without_routing_enabled</span><span class="s2">():</span>
    <span class="s5">&quot;&quot;&quot;Test that _PassthroughScorer.set_score_request raises if metadata routing is 
    disabled.&quot;&quot;&quot;</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">check_scoring</span><span class="s2">(</span><span class="s1">LogisticRegression</span><span class="s2">(), </span><span class="s0">None</span><span class="s2">)</span>
    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;This method is only available when metadata routing is enabled.&quot;</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">RuntimeError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">scorer</span><span class="s2">.</span><span class="s1">set_score_request</span><span class="s2">(</span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s3">&quot;my_weights&quot;</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">usefixtures</span><span class="s2">(</span><span class="s3">&quot;enable_slep006&quot;</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_multimetric_scoring_metadata_routing</span><span class="s2">():</span>
    <span class="s4"># Test that _MultimetricScorer properly routes metadata.</span>
    <span class="s0">def </span><span class="s1">score1</span><span class="s2">(</span><span class="s1">y_true</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s6">1</span>

    <span class="s0">def </span><span class="s1">score2</span><span class="s2">(</span><span class="s1">y_true</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s3">&quot;test&quot;</span><span class="s2">):</span>
        <span class="s4"># make sure sample_weight is not passed</span>
        <span class="s0">assert </span><span class="s1">sample_weight </span><span class="s2">== </span><span class="s3">&quot;test&quot;</span>
        <span class="s0">return </span><span class="s6">1</span>

    <span class="s0">def </span><span class="s1">score3</span><span class="s2">(</span><span class="s1">y_true</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">):</span>
        <span class="s4"># make sure sample_weight is passed</span>
        <span class="s0">assert </span><span class="s1">sample_weight </span><span class="s0">is not None</span>
        <span class="s0">return </span><span class="s6">1</span>

    <span class="s1">scorers </span><span class="s2">= {</span>
        <span class="s3">&quot;score1&quot;</span><span class="s2">: </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">score1</span><span class="s2">),</span>
        <span class="s3">&quot;score2&quot;</span><span class="s2">: </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">score2</span><span class="s2">).</span><span class="s1">set_score_request</span><span class="s2">(</span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s0">False</span><span class="s2">),</span>
        <span class="s3">&quot;score3&quot;</span><span class="s2">: </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">score3</span><span class="s2">).</span><span class="s1">set_score_request</span><span class="s2">(</span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s0">True</span><span class="s2">),</span>
    <span class="s2">}</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s6">50</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s6">2</span><span class="s2">, </span><span class="s1">n_redundant</span><span class="s2">=</span><span class="s6">0</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span>
    <span class="s2">)</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">DecisionTreeClassifier</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">scorer_dict </span><span class="s2">= </span><span class="s1">_check_multimetric_scoring</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">scorers</span><span class="s2">)</span>
    <span class="s1">multi_scorer </span><span class="s2">= </span><span class="s1">_MultimetricScorer</span><span class="s2">(</span><span class="s1">scorers</span><span class="s2">=</span><span class="s1">scorer_dict</span><span class="s2">)</span>
    <span class="s4"># this should fail, because metadata routing is not enabled and w/o it we</span>
    <span class="s4"># don't support different metadata for different scorers.</span>
    <span class="s4"># TODO: remove when enable_metadata_routing is deprecated</span>
    <span class="s0">with </span><span class="s1">config_context</span><span class="s2">(</span><span class="s1">enable_metadata_routing</span><span class="s2">=</span><span class="s0">False</span><span class="s2">):</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">TypeError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;got an unexpected keyword argument&quot;</span><span class="s2">):</span>
            <span class="s1">multi_scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s6">1</span><span class="s2">)</span>

    <span class="s4"># This passes since routing is done.</span>
    <span class="s1">multi_scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s6">1</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_kwargs_without_metadata_routing_error</span><span class="s2">():</span>
    <span class="s4"># Test that kwargs are not supported in scorers if metadata routing is not</span>
    <span class="s4"># enabled.</span>
    <span class="s4"># TODO: remove when enable_metadata_routing is deprecated</span>
    <span class="s0">def </span><span class="s1">score</span><span class="s2">(</span><span class="s1">y_true</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">, </span><span class="s1">param</span><span class="s2">=</span><span class="s0">None</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s6">1  </span><span class="s4"># pragma: no cover</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s6">50</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s6">2</span><span class="s2">, </span><span class="s1">n_redundant</span><span class="s2">=</span><span class="s6">0</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span>
    <span class="s2">)</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">DecisionTreeClassifier</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">scorer </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">score</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">config_context</span><span class="s2">(</span><span class="s1">enable_metadata_routing</span><span class="s2">=</span><span class="s0">False</span><span class="s2">):</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span>
            <span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">&quot;is only supported if enable_metadata_routing=True&quot;</span>
        <span class="s2">):</span>
            <span class="s1">scorer</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">param</span><span class="s2">=</span><span class="s3">&quot;blah&quot;</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_get_scorer_multilabel_indicator</span><span class="s2">():</span>
    <span class="s5">&quot;&quot;&quot;Check that our scorer deal with multi-label indicator matrices. 
 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/26817 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">Y </span><span class="s2">= </span><span class="s1">make_multilabel_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s6">72</span><span class="s2">, </span><span class="s1">n_classes</span><span class="s2">=</span><span class="s6">3</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">Y_train</span><span class="s2">, </span><span class="s1">Y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>

    <span class="s1">estimator </span><span class="s2">= </span><span class="s1">KNeighborsClassifier</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">Y_train</span><span class="s2">)</span>

    <span class="s1">score </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;average_precision&quot;</span><span class="s2">)(</span><span class="s1">estimator</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">Y_test</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">score </span><span class="s2">&gt; </span><span class="s6">0.8</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;scorer, expected_repr&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">(</span>
            <span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">),</span>
            <span class="s3">&quot;make_scorer(accuracy_score, response_method='predict')&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s2">(</span>
            <span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;neg_log_loss&quot;</span><span class="s2">),</span>
            <span class="s2">(</span>
                <span class="s3">&quot;make_scorer(log_loss, greater_is_better=False,&quot;</span>
                <span class="s3">&quot; response_method='predict_proba')&quot;</span>
            <span class="s2">),</span>
        <span class="s2">),</span>
        <span class="s2">(</span>
            <span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">),</span>
            <span class="s2">(</span>
                <span class="s3">&quot;make_scorer(roc_auc_score, response_method=&quot;</span>
                <span class="s3">&quot;('decision_function', 'predict_proba'))&quot;</span>
            <span class="s2">),</span>
        <span class="s2">),</span>
        <span class="s2">(</span>
            <span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">fbeta_score</span><span class="s2">, </span><span class="s1">beta</span><span class="s2">=</span><span class="s6">2</span><span class="s2">),</span>
            <span class="s3">&quot;make_scorer(fbeta_score, response_method='predict', beta=2)&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_make_scorer_repr</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">, </span><span class="s1">expected_repr</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Check the representation of the scorer.&quot;&quot;&quot;</span>
    <span class="s0">assert </span><span class="s1">repr</span><span class="s2">(</span><span class="s1">scorer</span><span class="s2">) == </span><span class="s1">expected_repr</span>


<span class="s4"># TODO(1.6): rework this test after the deprecation of `needs_proba` and</span>
<span class="s4"># `needs_threshold`</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*needs_proba.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;params, err_type, err_msg&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s4"># response_method should not be set if needs_* are set</span>
        <span class="s2">(</span>
            <span class="s2">{</span><span class="s3">&quot;response_method&quot;</span><span class="s2">: </span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">, </span><span class="s3">&quot;needs_proba&quot;</span><span class="s2">: </span><span class="s0">True</span><span class="s2">},</span>
            <span class="s1">ValueError</span><span class="s2">,</span>
            <span class="s3">&quot;You cannot set both `response_method`&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s2">(</span>
            <span class="s2">{</span><span class="s3">&quot;response_method&quot;</span><span class="s2">: </span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">, </span><span class="s3">&quot;needs_threshold&quot;</span><span class="s2">: </span><span class="s0">True</span><span class="s2">},</span>
            <span class="s1">ValueError</span><span class="s2">,</span>
            <span class="s3">&quot;You cannot set both `response_method`&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s4"># cannot set both needs_proba and needs_threshold</span>
        <span class="s2">(</span>
            <span class="s2">{</span><span class="s3">&quot;needs_proba&quot;</span><span class="s2">: </span><span class="s0">True</span><span class="s2">, </span><span class="s3">&quot;needs_threshold&quot;</span><span class="s2">: </span><span class="s0">True</span><span class="s2">},</span>
            <span class="s1">ValueError</span><span class="s2">,</span>
            <span class="s3">&quot;You cannot set both `needs_proba` and `needs_threshold`&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_make_scorer_error</span><span class="s2">(</span><span class="s1">params</span><span class="s2">, </span><span class="s1">err_type</span><span class="s2">, </span><span class="s1">err_msg</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Check that `make_scorer` raises errors if the parameter used.&quot;&quot;&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">err_type</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">err_msg</span><span class="s2">):</span>
        <span class="s1">make_scorer</span><span class="s2">(</span><span class="s0">lambda </span><span class="s1">y_true</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">: </span><span class="s6">1</span><span class="s2">, **</span><span class="s1">params</span><span class="s2">)</span>


<span class="s4"># TODO(1.6): remove the following test</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;deprecated_params, new_params, warn_msg&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">(</span>
            <span class="s2">{</span><span class="s3">&quot;needs_proba&quot;</span><span class="s2">: </span><span class="s0">True</span><span class="s2">},</span>
            <span class="s2">{</span><span class="s3">&quot;response_method&quot;</span><span class="s2">: </span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">},</span>
            <span class="s3">&quot;The `needs_threshold` and `needs_proba` parameter are deprecated&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s2">(</span>
            <span class="s2">{</span><span class="s3">&quot;needs_proba&quot;</span><span class="s2">: </span><span class="s0">True</span><span class="s2">, </span><span class="s3">&quot;needs_threshold&quot;</span><span class="s2">: </span><span class="s0">False</span><span class="s2">},</span>
            <span class="s2">{</span><span class="s3">&quot;response_method&quot;</span><span class="s2">: </span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">},</span>
            <span class="s3">&quot;The `needs_threshold` and `needs_proba` parameter are deprecated&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s2">(</span>
            <span class="s2">{</span><span class="s3">&quot;needs_threshold&quot;</span><span class="s2">: </span><span class="s0">True</span><span class="s2">},</span>
            <span class="s2">{</span><span class="s3">&quot;response_method&quot;</span><span class="s2">: (</span><span class="s3">&quot;decision_function&quot;</span><span class="s2">, </span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">)},</span>
            <span class="s3">&quot;The `needs_threshold` and `needs_proba` parameter are deprecated&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s2">(</span>
            <span class="s2">{</span><span class="s3">&quot;needs_threshold&quot;</span><span class="s2">: </span><span class="s0">True</span><span class="s2">, </span><span class="s3">&quot;needs_proba&quot;</span><span class="s2">: </span><span class="s0">False</span><span class="s2">},</span>
            <span class="s2">{</span><span class="s3">&quot;response_method&quot;</span><span class="s2">: (</span><span class="s3">&quot;decision_function&quot;</span><span class="s2">, </span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">)},</span>
            <span class="s3">&quot;The `needs_threshold` and `needs_proba` parameter are deprecated&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s2">(</span>
            <span class="s2">{</span><span class="s3">&quot;needs_threshold&quot;</span><span class="s2">: </span><span class="s0">False</span><span class="s2">, </span><span class="s3">&quot;needs_proba&quot;</span><span class="s2">: </span><span class="s0">False</span><span class="s2">},</span>
            <span class="s2">{</span><span class="s3">&quot;response_method&quot;</span><span class="s2">: </span><span class="s3">&quot;predict&quot;</span><span class="s2">},</span>
            <span class="s3">&quot;The `needs_threshold` and `needs_proba` parameter are deprecated&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_make_scorer_deprecation</span><span class="s2">(</span><span class="s1">deprecated_params</span><span class="s2">, </span><span class="s1">new_params</span><span class="s2">, </span><span class="s1">warn_msg</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Check that we raise a deprecation warning when using `needs_proba` or 
    `needs_threshold`.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s6">150</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s6">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">classifier </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s4"># check deprecation of needs_proba</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">FutureWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">warn_msg</span><span class="s2">):</span>
        <span class="s1">deprecated_roc_auc_scorer </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">roc_auc_score</span><span class="s2">, **</span><span class="s1">deprecated_params</span><span class="s2">)</span>
    <span class="s1">roc_auc_scorer </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">roc_auc_score</span><span class="s2">, **</span><span class="s1">new_params</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">deprecated_roc_auc_scorer</span><span class="s2">(</span><span class="s1">classifier</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">) == </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span>
        <span class="s1">roc_auc_scorer</span><span class="s2">(</span><span class="s1">classifier</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;pass_estimator&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_get_scorer_multimetric</span><span class="s2">(</span><span class="s1">pass_estimator</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Check that check_scoring is compatible with multi-metric configurations.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s6">150</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s6">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">pass_estimator</span><span class="s2">:</span>
        <span class="s1">check_scoring_ </span><span class="s2">= </span><span class="s1">check_scoring</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">check_scoring_ </span><span class="s2">= </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">check_scoring</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>

    <span class="s1">y_pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>
    <span class="s1">y_proba </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>

    <span class="s1">expected_results </span><span class="s2">= {</span>
        <span class="s3">&quot;r2&quot;</span><span class="s2">: </span><span class="s1">r2_score</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">),</span>
        <span class="s3">&quot;roc_auc&quot;</span><span class="s2">: </span><span class="s1">roc_auc_score</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_proba</span><span class="s2">[:, </span><span class="s6">1</span><span class="s2">]),</span>
        <span class="s3">&quot;accuracy&quot;</span><span class="s2">: </span><span class="s1">accuracy_score</span><span class="s2">(</span><span class="s1">y_test</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">),</span>
    <span class="s2">}</span>

    <span class="s0">for </span><span class="s1">container </span><span class="s0">in </span><span class="s2">[</span><span class="s1">set</span><span class="s2">, </span><span class="s1">list</span><span class="s2">, </span><span class="s1">tuple</span><span class="s2">]:</span>
        <span class="s1">scoring </span><span class="s2">= </span><span class="s1">check_scoring_</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">container</span><span class="s2">([</span><span class="s3">&quot;r2&quot;</span><span class="s2">, </span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">, </span><span class="s3">&quot;accuracy&quot;</span><span class="s2">]))</span>
        <span class="s1">result </span><span class="s2">= </span><span class="s1">scoring</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>

        <span class="s0">assert </span><span class="s1">result</span><span class="s2">.</span><span class="s1">keys</span><span class="s2">() == </span><span class="s1">expected_results</span><span class="s2">.</span><span class="s1">keys</span><span class="s2">()</span>
        <span class="s0">for </span><span class="s1">name </span><span class="s0">in </span><span class="s1">result</span><span class="s2">:</span>
            <span class="s0">assert </span><span class="s1">result</span><span class="s2">[</span><span class="s1">name</span><span class="s2">] == </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">expected_results</span><span class="s2">[</span><span class="s1">name</span><span class="s2">])</span>

    <span class="s0">def </span><span class="s1">double_accuracy</span><span class="s2">(</span><span class="s1">y_true</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s6">2 </span><span class="s2">* </span><span class="s1">accuracy_score</span><span class="s2">(</span><span class="s1">y_true</span><span class="s2">, </span><span class="s1">y_pred</span><span class="s2">)</span>

    <span class="s1">custom_scorer </span><span class="s2">= </span><span class="s1">make_scorer</span><span class="s2">(</span><span class="s1">double_accuracy</span><span class="s2">, </span><span class="s1">response_method</span><span class="s2">=</span><span class="s3">&quot;predict&quot;</span><span class="s2">)</span>

    <span class="s4"># dict with different names</span>
    <span class="s1">dict_scoring </span><span class="s2">= </span><span class="s1">check_scoring_</span><span class="s2">(</span>
        <span class="s1">scoring</span><span class="s2">={</span>
            <span class="s3">&quot;my_r2&quot;</span><span class="s2">: </span><span class="s3">&quot;r2&quot;</span><span class="s2">,</span>
            <span class="s3">&quot;my_roc_auc&quot;</span><span class="s2">: </span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">,</span>
            <span class="s3">&quot;double_accuracy&quot;</span><span class="s2">: </span><span class="s1">custom_scorer</span><span class="s2">,</span>
        <span class="s2">}</span>
    <span class="s2">)</span>
    <span class="s1">dict_result </span><span class="s2">= </span><span class="s1">dict_scoring</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">len</span><span class="s2">(</span><span class="s1">dict_result</span><span class="s2">) == </span><span class="s6">3</span>
    <span class="s0">assert </span><span class="s1">dict_result</span><span class="s2">[</span><span class="s3">&quot;my_r2&quot;</span><span class="s2">] == </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">expected_results</span><span class="s2">[</span><span class="s3">&quot;r2&quot;</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">dict_result</span><span class="s2">[</span><span class="s3">&quot;my_roc_auc&quot;</span><span class="s2">] == </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">expected_results</span><span class="s2">[</span><span class="s3">&quot;roc_auc&quot;</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">dict_result</span><span class="s2">[</span><span class="s3">&quot;double_accuracy&quot;</span><span class="s2">] == </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span>
        <span class="s6">2 </span><span class="s2">* </span><span class="s1">expected_results</span><span class="s2">[</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">]</span>
    <span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_multimetric_scorer_repr</span><span class="s2">():</span>
    <span class="s5">&quot;&quot;&quot;Check repr for multimetric scorer&quot;&quot;&quot;</span>
    <span class="s1">multi_metric_scorer </span><span class="s2">= </span><span class="s1">check_scoring</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">=[</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">, </span><span class="s3">&quot;r2&quot;</span><span class="s2">])</span>

    <span class="s0">assert </span><span class="s1">str</span><span class="s2">(</span><span class="s1">multi_metric_scorer</span><span class="s2">) == </span><span class="s3">'MultiMetricScorer(&quot;accuracy&quot;, &quot;r2&quot;)'</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;enable_metadata_routing&quot;</span><span class="s2">, [</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_metadata_routing_multimetric_metadata_routing</span><span class="s2">(</span><span class="s1">enable_metadata_routing</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Test multimetric scorer works with and without metadata routing enabled when 
    there is no actual metadata to pass. 
 
    Non-regression test for https://github.com/scikit-learn/scikit-learn/issues/28256 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s6">50</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s6">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s6">0</span><span class="s2">)</span>
    <span class="s1">estimator </span><span class="s2">= </span><span class="s1">EstimatorWithFitAndPredict</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">multimetric_scorer </span><span class="s2">= </span><span class="s1">_MultimetricScorer</span><span class="s2">(</span><span class="s1">scorers</span><span class="s2">={</span><span class="s3">&quot;acc&quot;</span><span class="s2">: </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">)})</span>
    <span class="s0">with </span><span class="s1">config_context</span><span class="s2">(</span><span class="s1">enable_metadata_routing</span><span class="s2">=</span><span class="s1">enable_metadata_routing</span><span class="s2">):</span>
        <span class="s1">multimetric_scorer</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
</pre>
</body>
</html>