<html>
<head>
<title>test_monotonic_contraints.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #2aacb8;}
.s4 { color: #7a7e85;}
.s5 { color: #5f826b; font-style: italic;}
.s6 { color: #6aab73;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_monotonic_contraints.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">re</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>

<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">ensemble </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">HistGradientBoostingClassifier</span><span class="s2">,</span>
    <span class="s1">HistGradientBoostingRegressor</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">ensemble</span><span class="s2">.</span><span class="s1">_hist_gradient_boosting</span><span class="s2">.</span><span class="s1">common </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">G_H_DTYPE</span><span class="s2">,</span>
    <span class="s1">X_BINNED_DTYPE</span><span class="s2">,</span>
    <span class="s1">MonotonicConstraint</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">ensemble</span><span class="s2">.</span><span class="s1">_hist_gradient_boosting</span><span class="s2">.</span><span class="s1">grower </span><span class="s0">import </span><span class="s1">TreeGrower</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">ensemble</span><span class="s2">.</span><span class="s1">_hist_gradient_boosting</span><span class="s2">.</span><span class="s1">histogram </span><span class="s0">import </span><span class="s1">HistogramBuilder</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">ensemble</span><span class="s2">.</span><span class="s1">_hist_gradient_boosting</span><span class="s2">.</span><span class="s1">splitting </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">Splitter</span><span class="s2">,</span>
    <span class="s1">compute_node_value</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">_openmp_helpers </span><span class="s0">import </span><span class="s1">_openmp_effective_n_threads</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">_testing </span><span class="s0">import </span><span class="s1">_convert_container</span>

<span class="s1">n_threads </span><span class="s2">= </span><span class="s1">_openmp_effective_n_threads</span><span class="s2">()</span>


<span class="s0">def </span><span class="s1">is_increasing</span><span class="s2">(</span><span class="s1">a</span><span class="s2">):</span>
    <span class="s0">return </span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">diff</span><span class="s2">(</span><span class="s1">a</span><span class="s2">) &gt;= </span><span class="s3">0.0</span><span class="s2">).</span><span class="s1">all</span><span class="s2">()</span>


<span class="s0">def </span><span class="s1">is_decreasing</span><span class="s2">(</span><span class="s1">a</span><span class="s2">):</span>
    <span class="s0">return </span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">diff</span><span class="s2">(</span><span class="s1">a</span><span class="s2">) &lt;= </span><span class="s3">0.0</span><span class="s2">).</span><span class="s1">all</span><span class="s2">()</span>


<span class="s0">def </span><span class="s1">assert_leaves_values_monotonic</span><span class="s2">(</span><span class="s1">predictor</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">):</span>
    <span class="s4"># make sure leaves values (from left to right) are either all increasing</span>
    <span class="s4"># or all decreasing (or neither) depending on the monotonic constraint.</span>
    <span class="s1">nodes </span><span class="s2">= </span><span class="s1">predictor</span><span class="s2">.</span><span class="s1">nodes</span>

    <span class="s0">def </span><span class="s1">get_leaves_values</span><span class="s2">():</span>
        <span class="s5">&quot;&quot;&quot;get leaves values from left to right&quot;&quot;&quot;</span>
        <span class="s1">values </span><span class="s2">= []</span>

        <span class="s0">def </span><span class="s1">depth_first_collect_leaf_values</span><span class="s2">(</span><span class="s1">node_idx</span><span class="s2">):</span>
            <span class="s1">node </span><span class="s2">= </span><span class="s1">nodes</span><span class="s2">[</span><span class="s1">node_idx</span><span class="s2">]</span>
            <span class="s0">if </span><span class="s1">node</span><span class="s2">[</span><span class="s6">&quot;is_leaf&quot;</span><span class="s2">]:</span>
                <span class="s1">values</span><span class="s2">.</span><span class="s1">append</span><span class="s2">(</span><span class="s1">node</span><span class="s2">[</span><span class="s6">&quot;value&quot;</span><span class="s2">])</span>
                <span class="s0">return</span>
            <span class="s1">depth_first_collect_leaf_values</span><span class="s2">(</span><span class="s1">node</span><span class="s2">[</span><span class="s6">&quot;left&quot;</span><span class="s2">])</span>
            <span class="s1">depth_first_collect_leaf_values</span><span class="s2">(</span><span class="s1">node</span><span class="s2">[</span><span class="s6">&quot;right&quot;</span><span class="s2">])</span>

        <span class="s1">depth_first_collect_leaf_values</span><span class="s2">(</span><span class="s3">0</span><span class="s2">)  </span><span class="s4"># start at root (0)</span>
        <span class="s0">return </span><span class="s1">values</span>

    <span class="s1">values </span><span class="s2">= </span><span class="s1">get_leaves_values</span><span class="s2">()</span>

    <span class="s0">if </span><span class="s1">monotonic_cst </span><span class="s2">== </span><span class="s1">MonotonicConstraint</span><span class="s2">.</span><span class="s1">NO_CST</span><span class="s2">:</span>
        <span class="s4"># some increasing, some decreasing</span>
        <span class="s0">assert not </span><span class="s1">is_increasing</span><span class="s2">(</span><span class="s1">values</span><span class="s2">) </span><span class="s0">and not </span><span class="s1">is_decreasing</span><span class="s2">(</span><span class="s1">values</span><span class="s2">)</span>
    <span class="s0">elif </span><span class="s1">monotonic_cst </span><span class="s2">== </span><span class="s1">MonotonicConstraint</span><span class="s2">.</span><span class="s1">POS</span><span class="s2">:</span>
        <span class="s4"># all increasing</span>
        <span class="s0">assert </span><span class="s1">is_increasing</span><span class="s2">(</span><span class="s1">values</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:  </span><span class="s4"># NEG</span>
        <span class="s4"># all decreasing</span>
        <span class="s0">assert </span><span class="s1">is_decreasing</span><span class="s2">(</span><span class="s1">values</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">assert_children_values_monotonic</span><span class="s2">(</span><span class="s1">predictor</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">):</span>
    <span class="s4"># Make sure siblings values respect the monotonic constraints. Left should</span>
    <span class="s4"># be lower (resp greater) than right child if constraint is POS (resp.</span>
    <span class="s4"># NEG).</span>
    <span class="s4"># Note that this property alone isn't enough to ensure full monotonicity,</span>
    <span class="s4"># since we also need to guanrantee that all the descendents of the left</span>
    <span class="s4"># child won't be greater (resp. lower) than the right child, or its</span>
    <span class="s4"># descendents. That's why we need to bound the predicted values (this is</span>
    <span class="s4"># tested in assert_children_values_bounded)</span>
    <span class="s1">nodes </span><span class="s2">= </span><span class="s1">predictor</span><span class="s2">.</span><span class="s1">nodes</span>
    <span class="s1">left_lower </span><span class="s2">= []</span>
    <span class="s1">left_greater </span><span class="s2">= []</span>
    <span class="s0">for </span><span class="s1">node </span><span class="s0">in </span><span class="s1">nodes</span><span class="s2">:</span>
        <span class="s0">if </span><span class="s1">node</span><span class="s2">[</span><span class="s6">&quot;is_leaf&quot;</span><span class="s2">]:</span>
            <span class="s0">continue</span>

        <span class="s1">left_idx </span><span class="s2">= </span><span class="s1">node</span><span class="s2">[</span><span class="s6">&quot;left&quot;</span><span class="s2">]</span>
        <span class="s1">right_idx </span><span class="s2">= </span><span class="s1">node</span><span class="s2">[</span><span class="s6">&quot;right&quot;</span><span class="s2">]</span>

        <span class="s0">if </span><span class="s1">nodes</span><span class="s2">[</span><span class="s1">left_idx</span><span class="s2">][</span><span class="s6">&quot;value&quot;</span><span class="s2">] &lt; </span><span class="s1">nodes</span><span class="s2">[</span><span class="s1">right_idx</span><span class="s2">][</span><span class="s6">&quot;value&quot;</span><span class="s2">]:</span>
            <span class="s1">left_lower</span><span class="s2">.</span><span class="s1">append</span><span class="s2">(</span><span class="s1">node</span><span class="s2">)</span>
        <span class="s0">elif </span><span class="s1">nodes</span><span class="s2">[</span><span class="s1">left_idx</span><span class="s2">][</span><span class="s6">&quot;value&quot;</span><span class="s2">] &gt; </span><span class="s1">nodes</span><span class="s2">[</span><span class="s1">right_idx</span><span class="s2">][</span><span class="s6">&quot;value&quot;</span><span class="s2">]:</span>
            <span class="s1">left_greater</span><span class="s2">.</span><span class="s1">append</span><span class="s2">(</span><span class="s1">node</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">monotonic_cst </span><span class="s2">== </span><span class="s1">MonotonicConstraint</span><span class="s2">.</span><span class="s1">NO_CST</span><span class="s2">:</span>
        <span class="s0">assert </span><span class="s1">left_lower </span><span class="s0">and </span><span class="s1">left_greater</span>
    <span class="s0">elif </span><span class="s1">monotonic_cst </span><span class="s2">== </span><span class="s1">MonotonicConstraint</span><span class="s2">.</span><span class="s1">POS</span><span class="s2">:</span>
        <span class="s0">assert </span><span class="s1">left_lower </span><span class="s0">and not </span><span class="s1">left_greater</span>
    <span class="s0">else</span><span class="s2">:  </span><span class="s4"># NEG</span>
        <span class="s0">assert not </span><span class="s1">left_lower </span><span class="s0">and </span><span class="s1">left_greater</span>


<span class="s0">def </span><span class="s1">assert_children_values_bounded</span><span class="s2">(</span><span class="s1">grower</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">):</span>
    <span class="s4"># Make sure that the values of the children of a node are bounded by the</span>
    <span class="s4"># middle value between that node and its sibling (if there is a monotonic</span>
    <span class="s4"># constraint).</span>
    <span class="s4"># As a bonus, we also check that the siblings values are properly ordered</span>
    <span class="s4"># which is slightly redundant with assert_children_values_monotonic (but</span>
    <span class="s4"># this check is done on the grower nodes whereas</span>
    <span class="s4"># assert_children_values_monotonic is done on the predictor nodes)</span>

    <span class="s0">if </span><span class="s1">monotonic_cst </span><span class="s2">== </span><span class="s1">MonotonicConstraint</span><span class="s2">.</span><span class="s1">NO_CST</span><span class="s2">:</span>
        <span class="s0">return</span>

    <span class="s0">def </span><span class="s1">recursively_check_children_node_values</span><span class="s2">(</span><span class="s1">node</span><span class="s2">, </span><span class="s1">right_sibling</span><span class="s2">=</span><span class="s0">None</span><span class="s2">):</span>
        <span class="s0">if </span><span class="s1">node</span><span class="s2">.</span><span class="s1">is_leaf</span><span class="s2">:</span>
            <span class="s0">return</span>
        <span class="s0">if </span><span class="s1">right_sibling </span><span class="s0">is not None</span><span class="s2">:</span>
            <span class="s1">middle </span><span class="s2">= (</span><span class="s1">node</span><span class="s2">.</span><span class="s1">value </span><span class="s2">+ </span><span class="s1">right_sibling</span><span class="s2">.</span><span class="s1">value</span><span class="s2">) / </span><span class="s3">2</span>
            <span class="s0">if </span><span class="s1">monotonic_cst </span><span class="s2">== </span><span class="s1">MonotonicConstraint</span><span class="s2">.</span><span class="s1">POS</span><span class="s2">:</span>
                <span class="s0">assert </span><span class="s1">node</span><span class="s2">.</span><span class="s1">left_child</span><span class="s2">.</span><span class="s1">value </span><span class="s2">&lt;= </span><span class="s1">node</span><span class="s2">.</span><span class="s1">right_child</span><span class="s2">.</span><span class="s1">value </span><span class="s2">&lt;= </span><span class="s1">middle</span>
                <span class="s0">if not </span><span class="s1">right_sibling</span><span class="s2">.</span><span class="s1">is_leaf</span><span class="s2">:</span>
                    <span class="s0">assert </span><span class="s2">(</span>
                        <span class="s1">middle</span>
                        <span class="s2">&lt;= </span><span class="s1">right_sibling</span><span class="s2">.</span><span class="s1">left_child</span><span class="s2">.</span><span class="s1">value</span>
                        <span class="s2">&lt;= </span><span class="s1">right_sibling</span><span class="s2">.</span><span class="s1">right_child</span><span class="s2">.</span><span class="s1">value</span>
                    <span class="s2">)</span>
            <span class="s0">else</span><span class="s2">:  </span><span class="s4"># NEG</span>
                <span class="s0">assert </span><span class="s1">node</span><span class="s2">.</span><span class="s1">left_child</span><span class="s2">.</span><span class="s1">value </span><span class="s2">&gt;= </span><span class="s1">node</span><span class="s2">.</span><span class="s1">right_child</span><span class="s2">.</span><span class="s1">value </span><span class="s2">&gt;= </span><span class="s1">middle</span>
                <span class="s0">if not </span><span class="s1">right_sibling</span><span class="s2">.</span><span class="s1">is_leaf</span><span class="s2">:</span>
                    <span class="s0">assert </span><span class="s2">(</span>
                        <span class="s1">middle</span>
                        <span class="s2">&gt;= </span><span class="s1">right_sibling</span><span class="s2">.</span><span class="s1">left_child</span><span class="s2">.</span><span class="s1">value</span>
                        <span class="s2">&gt;= </span><span class="s1">right_sibling</span><span class="s2">.</span><span class="s1">right_child</span><span class="s2">.</span><span class="s1">value</span>
                    <span class="s2">)</span>

        <span class="s1">recursively_check_children_node_values</span><span class="s2">(</span>
            <span class="s1">node</span><span class="s2">.</span><span class="s1">left_child</span><span class="s2">, </span><span class="s1">right_sibling</span><span class="s2">=</span><span class="s1">node</span><span class="s2">.</span><span class="s1">right_child</span>
        <span class="s2">)</span>
        <span class="s1">recursively_check_children_node_values</span><span class="s2">(</span><span class="s1">node</span><span class="s2">.</span><span class="s1">right_child</span><span class="s2">)</span>

    <span class="s1">recursively_check_children_node_values</span><span class="s2">(</span><span class="s1">grower</span><span class="s2">.</span><span class="s1">root</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s6">&quot;seed&quot;</span><span class="s2">, </span><span class="s1">range</span><span class="s2">(</span><span class="s3">3</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s6">&quot;monotonic_cst&quot;</span><span class="s2">,</span>
    <span class="s2">(</span>
        <span class="s1">MonotonicConstraint</span><span class="s2">.</span><span class="s1">NO_CST</span><span class="s2">,</span>
        <span class="s1">MonotonicConstraint</span><span class="s2">.</span><span class="s1">POS</span><span class="s2">,</span>
        <span class="s1">MonotonicConstraint</span><span class="s2">.</span><span class="s1">NEG</span><span class="s2">,</span>
    <span class="s2">),</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_nodes_values</span><span class="s2">(</span><span class="s1">monotonic_cst</span><span class="s2">, </span><span class="s1">seed</span><span class="s2">):</span>
    <span class="s4"># Build a single tree with only one feature, and make sure the nodes</span>
    <span class="s4"># values respect the monotonic constraints.</span>

    <span class="s4"># Considering the following tree with a monotonic POS constraint, we</span>
    <span class="s4"># should have:</span>
    <span class="s4">#</span>
    <span class="s4">#       root</span>
    <span class="s4">#      /    \</span>
    <span class="s4">#     5     10    # middle = 7.5</span>
    <span class="s4">#    / \   / \</span>
    <span class="s4">#   a  b  c  d</span>
    <span class="s4">#</span>
    <span class="s4"># a &lt;= b and c &lt;= d  (assert_children_values_monotonic)</span>
    <span class="s4"># a, b &lt;= middle &lt;= c, d (assert_children_values_bounded)</span>
    <span class="s4"># a &lt;= b &lt;= c &lt;= d (assert_leaves_values_monotonic)</span>
    <span class="s4">#</span>
    <span class="s4"># The last one is a consequence of the others, but can't hurt to check</span>

    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">seed</span><span class="s2">)</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s3">1000</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s3">1</span>
    <span class="s1">X_binned </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randint</span><span class="s2">(</span><span class="s3">0</span><span class="s2">, </span><span class="s3">255</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">), </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">uint8</span><span class="s2">)</span>
    <span class="s1">X_binned </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asfortranarray</span><span class="s2">(</span><span class="s1">X_binned</span><span class="s2">)</span>

    <span class="s1">gradients </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">).</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">G_H_DTYPE</span><span class="s2">)</span>
    <span class="s1">hessians </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">=</span><span class="s3">1</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">G_H_DTYPE</span><span class="s2">)</span>

    <span class="s1">grower </span><span class="s2">= </span><span class="s1">TreeGrower</span><span class="s2">(</span>
        <span class="s1">X_binned</span><span class="s2">, </span><span class="s1">gradients</span><span class="s2">, </span><span class="s1">hessians</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">=[</span><span class="s1">monotonic_cst</span><span class="s2">], </span><span class="s1">shrinkage</span><span class="s2">=</span><span class="s3">0.1</span>
    <span class="s2">)</span>
    <span class="s1">grower</span><span class="s2">.</span><span class="s1">grow</span><span class="s2">()</span>

    <span class="s4"># grow() will shrink the leaves values at the very end. For our comparison</span>
    <span class="s4"># tests, we need to revert the shrinkage of the leaves, else we would</span>
    <span class="s4"># compare the value of a leaf (shrunk) with a node (not shrunk) and the</span>
    <span class="s4"># test would not be correct.</span>
    <span class="s0">for </span><span class="s1">leave </span><span class="s0">in </span><span class="s1">grower</span><span class="s2">.</span><span class="s1">finalized_leaves</span><span class="s2">:</span>
        <span class="s1">leave</span><span class="s2">.</span><span class="s1">value </span><span class="s2">/= </span><span class="s1">grower</span><span class="s2">.</span><span class="s1">shrinkage</span>

    <span class="s4"># We pass undefined binning_thresholds because we won't use predict anyway</span>
    <span class="s1">predictor </span><span class="s2">= </span><span class="s1">grower</span><span class="s2">.</span><span class="s1">make_predictor</span><span class="s2">(</span>
        <span class="s1">binning_thresholds</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s1">X_binned</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s3">1</span><span class="s2">], </span><span class="s1">X_binned</span><span class="s2">.</span><span class="s1">max</span><span class="s2">() + </span><span class="s3">1</span><span class="s2">))</span>
    <span class="s2">)</span>

    <span class="s4"># The consistency of the bounds can only be checked on the tree grower</span>
    <span class="s4"># as the node bounds are not copied into the predictor tree. The</span>
    <span class="s4"># consistency checks on the values of node children and leaves can be</span>
    <span class="s4"># done either on the grower tree or on the predictor tree. We only</span>
    <span class="s4"># do those checks on the predictor tree as the latter is derived from</span>
    <span class="s4"># the former.</span>
    <span class="s1">assert_children_values_monotonic</span><span class="s2">(</span><span class="s1">predictor</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">)</span>
    <span class="s1">assert_children_values_bounded</span><span class="s2">(</span><span class="s1">grower</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">)</span>
    <span class="s1">assert_leaves_values_monotonic</span><span class="s2">(</span><span class="s1">predictor</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s6">&quot;use_feature_names&quot;</span><span class="s2">, (</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">))</span>
<span class="s0">def </span><span class="s1">test_predictions</span><span class="s2">(</span><span class="s1">global_random_seed</span><span class="s2">, </span><span class="s1">use_feature_names</span><span class="s2">):</span>
    <span class="s4"># Train a model with a POS constraint on the first non-categorical feature</span>
    <span class="s4"># and a NEG constraint on the second non-categorical feature, and make sure</span>
    <span class="s4"># the constraints are respected by checking the predictions.</span>
    <span class="s4"># test adapted from lightgbm's test_monotone_constraint(), itself inspired</span>
    <span class="s4"># by https://xgboost.readthedocs.io/en/latest/tutorials/monotonic.html</span>

    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">global_random_seed</span><span class="s2">)</span>

    <span class="s1">n_samples </span><span class="s2">= </span><span class="s3">1000</span>
    <span class="s1">f_0 </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">rand</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)  </span><span class="s4"># positive correlation with y</span>
    <span class="s1">f_1 </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">rand</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)  </span><span class="s4"># negative correlation with y</span>

    <span class="s4"># extra categorical features, no correlation with y,</span>
    <span class="s4"># to check the correctness of monotonicity constraint remapping, see issue #28898</span>
    <span class="s1">f_a </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randint</span><span class="s2">(</span><span class="s1">low</span><span class="s2">=</span><span class="s3">0</span><span class="s2">, </span><span class="s1">high</span><span class="s2">=</span><span class="s3">9</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">f_b </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randint</span><span class="s2">(</span><span class="s1">low</span><span class="s2">=</span><span class="s3">0</span><span class="s2">, </span><span class="s1">high</span><span class="s2">=</span><span class="s3">9</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">f_c </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randint</span><span class="s2">(</span><span class="s1">low</span><span class="s2">=</span><span class="s3">0</span><span class="s2">, </span><span class="s1">high</span><span class="s2">=</span><span class="s3">9</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">)</span>

    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">c_</span><span class="s2">[</span><span class="s1">f_a</span><span class="s2">, </span><span class="s1">f_0</span><span class="s2">, </span><span class="s1">f_b</span><span class="s2">, </span><span class="s1">f_1</span><span class="s2">, </span><span class="s1">f_c</span><span class="s2">]</span>
    <span class="s1">columns_name </span><span class="s2">= [</span><span class="s6">&quot;f_a&quot;</span><span class="s2">, </span><span class="s6">&quot;f_0&quot;</span><span class="s2">, </span><span class="s6">&quot;f_b&quot;</span><span class="s2">, </span><span class="s6">&quot;f_1&quot;</span><span class="s2">, </span><span class="s6">&quot;f_c&quot;</span><span class="s2">]</span>
    <span class="s1">constructor_name </span><span class="s2">= </span><span class="s6">&quot;dataframe&quot; </span><span class="s0">if </span><span class="s1">use_feature_names </span><span class="s0">else </span><span class="s6">&quot;array&quot;</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">_convert_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">constructor_name</span><span class="s2">, </span><span class="s1">columns_name</span><span class="s2">=</span><span class="s1">columns_name</span><span class="s2">)</span>

    <span class="s1">noise </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">loc</span><span class="s2">=</span><span class="s3">0.0</span><span class="s2">, </span><span class="s1">scale</span><span class="s2">=</span><span class="s3">0.01</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s3">5 </span><span class="s2">* </span><span class="s1">f_0 </span><span class="s2">+ </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sin</span><span class="s2">(</span><span class="s3">10 </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">pi </span><span class="s2">* </span><span class="s1">f_0</span><span class="s2">) - </span><span class="s3">5 </span><span class="s2">* </span><span class="s1">f_1 </span><span class="s2">- </span><span class="s1">np</span><span class="s2">.</span><span class="s1">cos</span><span class="s2">(</span><span class="s3">10 </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">pi </span><span class="s2">* </span><span class="s1">f_1</span><span class="s2">) + </span><span class="s1">noise</span>

    <span class="s0">if </span><span class="s1">use_feature_names</span><span class="s2">:</span>
        <span class="s1">monotonic_cst </span><span class="s2">= {</span><span class="s6">&quot;f_0&quot;</span><span class="s2">: +</span><span class="s3">1</span><span class="s2">, </span><span class="s6">&quot;f_1&quot;</span><span class="s2">: -</span><span class="s3">1</span><span class="s2">}</span>
        <span class="s1">categorical_features </span><span class="s2">= [</span><span class="s6">&quot;f_a&quot;</span><span class="s2">, </span><span class="s6">&quot;f_b&quot;</span><span class="s2">, </span><span class="s6">&quot;f_c&quot;</span><span class="s2">]</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">monotonic_cst </span><span class="s2">= [</span><span class="s3">0</span><span class="s2">, +</span><span class="s3">1</span><span class="s2">, </span><span class="s3">0</span><span class="s2">, -</span><span class="s3">1</span><span class="s2">, </span><span class="s3">0</span><span class="s2">]</span>
        <span class="s1">categorical_features </span><span class="s2">= [</span><span class="s3">0</span><span class="s2">, </span><span class="s3">2</span><span class="s2">, </span><span class="s3">4</span><span class="s2">]</span>

    <span class="s1">gbdt </span><span class="s2">= </span><span class="s1">HistGradientBoostingRegressor</span><span class="s2">(</span>
        <span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">, </span><span class="s1">categorical_features</span><span class="s2">=</span><span class="s1">categorical_features</span>
    <span class="s2">)</span>
    <span class="s1">gbdt</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">linspace </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(</span><span class="s3">0</span><span class="s2">, </span><span class="s3">1</span><span class="s2">, </span><span class="s3">100</span><span class="s2">)</span>
    <span class="s1">sin </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sin</span><span class="s2">(</span><span class="s1">linspace</span><span class="s2">)</span>
    <span class="s1">constant </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">full_like</span><span class="s2">(</span><span class="s1">linspace</span><span class="s2">, </span><span class="s1">fill_value</span><span class="s2">=</span><span class="s3">0.5</span><span class="s2">)</span>

    <span class="s4"># We now assert the predictions properly respect the constraints, on each</span>
    <span class="s4"># feature. When testing for a feature we need to set the other one to a</span>
    <span class="s4"># constant, because the monotonic constraints are only a &quot;all else being</span>
    <span class="s4"># equal&quot; type of constraints:</span>
    <span class="s4"># a constraint on the first feature only means that</span>
    <span class="s4"># x0 &lt; x0' =&gt; f(x0, x1) &lt; f(x0', x1)</span>
    <span class="s4"># while x1 stays constant.</span>
    <span class="s4"># The constraint does not guanrantee that</span>
    <span class="s4"># x0 &lt; x0' =&gt; f(x0, x1) &lt; f(x0', x1')</span>

    <span class="s4"># First non-categorical feature (POS)</span>
    <span class="s4"># assert pred is all increasing when f_0 is all increasing</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">c_</span><span class="s2">[</span><span class="s1">constant</span><span class="s2">, </span><span class="s1">linspace</span><span class="s2">, </span><span class="s1">constant</span><span class="s2">, </span><span class="s1">constant</span><span class="s2">, </span><span class="s1">constant</span><span class="s2">]</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">_convert_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">constructor_name</span><span class="s2">, </span><span class="s1">columns_name</span><span class="s2">=</span><span class="s1">columns_name</span><span class="s2">)</span>
    <span class="s1">pred </span><span class="s2">= </span><span class="s1">gbdt</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">is_increasing</span><span class="s2">(</span><span class="s1">pred</span><span class="s2">)</span>
    <span class="s4"># assert pred actually follows the variations of f_0</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">c_</span><span class="s2">[</span><span class="s1">constant</span><span class="s2">, </span><span class="s1">sin</span><span class="s2">, </span><span class="s1">constant</span><span class="s2">, </span><span class="s1">constant</span><span class="s2">, </span><span class="s1">constant</span><span class="s2">]</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">_convert_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">constructor_name</span><span class="s2">, </span><span class="s1">columns_name</span><span class="s2">=</span><span class="s1">columns_name</span><span class="s2">)</span>
    <span class="s1">pred </span><span class="s2">= </span><span class="s1">gbdt</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">((</span><span class="s1">np</span><span class="s2">.</span><span class="s1">diff</span><span class="s2">(</span><span class="s1">pred</span><span class="s2">) &gt;= </span><span class="s3">0</span><span class="s2">) == (</span><span class="s1">np</span><span class="s2">.</span><span class="s1">diff</span><span class="s2">(</span><span class="s1">sin</span><span class="s2">) &gt;= </span><span class="s3">0</span><span class="s2">))</span>

    <span class="s4"># Second non-categorical feature (NEG)</span>
    <span class="s4"># assert pred is all decreasing when f_1 is all increasing</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">c_</span><span class="s2">[</span><span class="s1">constant</span><span class="s2">, </span><span class="s1">constant</span><span class="s2">, </span><span class="s1">constant</span><span class="s2">, </span><span class="s1">linspace</span><span class="s2">, </span><span class="s1">constant</span><span class="s2">]</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">_convert_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">constructor_name</span><span class="s2">, </span><span class="s1">columns_name</span><span class="s2">=</span><span class="s1">columns_name</span><span class="s2">)</span>
    <span class="s1">pred </span><span class="s2">= </span><span class="s1">gbdt</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">is_decreasing</span><span class="s2">(</span><span class="s1">pred</span><span class="s2">)</span>
    <span class="s4"># assert pred actually follows the inverse variations of f_1</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">c_</span><span class="s2">[</span><span class="s1">constant</span><span class="s2">, </span><span class="s1">constant</span><span class="s2">, </span><span class="s1">constant</span><span class="s2">, </span><span class="s1">sin</span><span class="s2">, </span><span class="s1">constant</span><span class="s2">]</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">_convert_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">constructor_name</span><span class="s2">, </span><span class="s1">columns_name</span><span class="s2">=</span><span class="s1">columns_name</span><span class="s2">)</span>
    <span class="s1">pred </span><span class="s2">= </span><span class="s1">gbdt</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s2">((</span><span class="s1">np</span><span class="s2">.</span><span class="s1">diff</span><span class="s2">(</span><span class="s1">pred</span><span class="s2">) &lt;= </span><span class="s3">0</span><span class="s2">) == (</span><span class="s1">np</span><span class="s2">.</span><span class="s1">diff</span><span class="s2">(</span><span class="s1">sin</span><span class="s2">) &gt;= </span><span class="s3">0</span><span class="s2">)).</span><span class="s1">all</span><span class="s2">()</span>


<span class="s0">def </span><span class="s1">test_input_error</span><span class="s2">():</span>
    <span class="s1">X </span><span class="s2">= [[</span><span class="s3">1</span><span class="s2">, </span><span class="s3">2</span><span class="s2">], [</span><span class="s3">2</span><span class="s2">, </span><span class="s3">3</span><span class="s2">], [</span><span class="s3">3</span><span class="s2">, </span><span class="s3">4</span><span class="s2">]]</span>
    <span class="s1">y </span><span class="s2">= [</span><span class="s3">0</span><span class="s2">, </span><span class="s3">1</span><span class="s2">, </span><span class="s3">2</span><span class="s2">]</span>

    <span class="s1">gbdt </span><span class="s2">= </span><span class="s1">HistGradientBoostingRegressor</span><span class="s2">(</span><span class="s1">monotonic_cst</span><span class="s2">=[</span><span class="s3">1</span><span class="s2">, </span><span class="s3">0</span><span class="s2">, -</span><span class="s3">1</span><span class="s2">])</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span>
        <span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">re</span><span class="s2">.</span><span class="s1">escape</span><span class="s2">(</span><span class="s6">&quot;monotonic_cst has shape (3,) but the input data&quot;</span><span class="s2">)</span>
    <span class="s2">):</span>
        <span class="s1">gbdt</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">for </span><span class="s1">monotonic_cst </span><span class="s0">in </span><span class="s2">([</span><span class="s3">1</span><span class="s2">, </span><span class="s3">3</span><span class="s2">], [</span><span class="s3">1</span><span class="s2">, -</span><span class="s3">3</span><span class="s2">], [</span><span class="s3">0.3</span><span class="s2">, -</span><span class="s3">0.7</span><span class="s2">]):</span>
        <span class="s1">gbdt </span><span class="s2">= </span><span class="s1">HistGradientBoostingRegressor</span><span class="s2">(</span><span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">)</span>
        <span class="s1">expected_msg </span><span class="s2">= </span><span class="s1">re</span><span class="s2">.</span><span class="s1">escape</span><span class="s2">(</span>
            <span class="s6">&quot;must be an array-like of -1, 0 or 1. Observed values:&quot;</span>
        <span class="s2">)</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">expected_msg</span><span class="s2">):</span>
            <span class="s1">gbdt</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">gbdt </span><span class="s2">= </span><span class="s1">HistGradientBoostingClassifier</span><span class="s2">(</span><span class="s1">monotonic_cst</span><span class="s2">=[</span><span class="s3">0</span><span class="s2">, </span><span class="s3">1</span><span class="s2">])</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span>
        <span class="s1">ValueError</span><span class="s2">,</span>
        <span class="s1">match</span><span class="s2">=</span><span class="s6">&quot;monotonic constraints are not supported for multiclass classification&quot;</span><span class="s2">,</span>
    <span class="s2">):</span>
        <span class="s1">gbdt</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_input_error_related_to_feature_names</span><span class="s2">():</span>
    <span class="s1">pd </span><span class="s2">= </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">importorskip</span><span class="s2">(</span><span class="s6">&quot;pandas&quot;</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">pd</span><span class="s2">.</span><span class="s1">DataFrame</span><span class="s2">({</span><span class="s6">&quot;a&quot;</span><span class="s2">: [</span><span class="s3">0</span><span class="s2">, </span><span class="s3">1</span><span class="s2">, </span><span class="s3">2</span><span class="s2">], </span><span class="s6">&quot;b&quot;</span><span class="s2">: [</span><span class="s3">0</span><span class="s2">, </span><span class="s3">1</span><span class="s2">, </span><span class="s3">2</span><span class="s2">]})</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s3">0</span><span class="s2">, </span><span class="s3">1</span><span class="s2">, </span><span class="s3">0</span><span class="s2">])</span>

    <span class="s1">monotonic_cst </span><span class="s2">= {</span><span class="s6">&quot;d&quot;</span><span class="s2">: </span><span class="s3">1</span><span class="s2">, </span><span class="s6">&quot;a&quot;</span><span class="s2">: </span><span class="s3">1</span><span class="s2">, </span><span class="s6">&quot;c&quot;</span><span class="s2">: -</span><span class="s3">1</span><span class="s2">}</span>
    <span class="s1">gbdt </span><span class="s2">= </span><span class="s1">HistGradientBoostingRegressor</span><span class="s2">(</span><span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">)</span>
    <span class="s1">expected_msg </span><span class="s2">= </span><span class="s1">re</span><span class="s2">.</span><span class="s1">escape</span><span class="s2">(</span>
        <span class="s6">&quot;monotonic_cst contains 2 unexpected feature names: ['c', 'd'].&quot;</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">expected_msg</span><span class="s2">):</span>
        <span class="s1">gbdt</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">monotonic_cst </span><span class="s2">= {</span><span class="s1">k</span><span class="s2">: </span><span class="s3">1 </span><span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s6">&quot;abcdefghijklmnopqrstuvwxyz&quot;</span><span class="s2">}</span>
    <span class="s1">gbdt </span><span class="s2">= </span><span class="s1">HistGradientBoostingRegressor</span><span class="s2">(</span><span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">)</span>
    <span class="s1">expected_msg </span><span class="s2">= </span><span class="s1">re</span><span class="s2">.</span><span class="s1">escape</span><span class="s2">(</span>
        <span class="s6">&quot;monotonic_cst contains 24 unexpected feature names: &quot;</span>
        <span class="s6">&quot;['c', 'd', 'e', 'f', 'g', '...'].&quot;</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">expected_msg</span><span class="s2">):</span>
        <span class="s1">gbdt</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">monotonic_cst </span><span class="s2">= {</span><span class="s6">&quot;a&quot;</span><span class="s2">: </span><span class="s3">1</span><span class="s2">}</span>
    <span class="s1">gbdt </span><span class="s2">= </span><span class="s1">HistGradientBoostingRegressor</span><span class="s2">(</span><span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">)</span>
    <span class="s1">expected_msg </span><span class="s2">= </span><span class="s1">re</span><span class="s2">.</span><span class="s1">escape</span><span class="s2">(</span>
        <span class="s6">&quot;HistGradientBoostingRegressor was not fitted on data with feature &quot;</span>
        <span class="s6">&quot;names. Pass monotonic_cst as an integer array instead.&quot;</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">expected_msg</span><span class="s2">):</span>
        <span class="s1">gbdt</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">values</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">monotonic_cst </span><span class="s2">= {</span><span class="s6">&quot;b&quot;</span><span class="s2">: -</span><span class="s3">1</span><span class="s2">, </span><span class="s6">&quot;a&quot;</span><span class="s2">: </span><span class="s6">&quot;+&quot;</span><span class="s2">}</span>
    <span class="s1">gbdt </span><span class="s2">= </span><span class="s1">HistGradientBoostingRegressor</span><span class="s2">(</span><span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">)</span>
    <span class="s1">expected_msg </span><span class="s2">= </span><span class="s1">re</span><span class="s2">.</span><span class="s1">escape</span><span class="s2">(</span><span class="s6">&quot;monotonic_cst['a'] must be either -1, 0 or 1. Got '+'.&quot;</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">expected_msg</span><span class="s2">):</span>
        <span class="s1">gbdt</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_bounded_value_min_gain_to_split</span><span class="s2">():</span>
    <span class="s4"># The purpose of this test is to show that when computing the gain at a</span>
    <span class="s4"># given split, the value of the current node should be properly bounded to</span>
    <span class="s4"># respect the monotonic constraints, because it strongly interacts with</span>
    <span class="s4"># min_gain_to_split. We build a simple example where gradients are [1, 1,</span>
    <span class="s4"># 100, 1, 1] (hessians are all ones). The best split happens on the 3rd</span>
    <span class="s4"># bin, and depending on whether the value of the node is bounded or not,</span>
    <span class="s4"># the min_gain_to_split constraint is or isn't satisfied.</span>
    <span class="s1">l2_regularization </span><span class="s2">= </span><span class="s3">0</span>
    <span class="s1">min_hessian_to_split </span><span class="s2">= </span><span class="s3">0</span>
    <span class="s1">min_samples_leaf </span><span class="s2">= </span><span class="s3">1</span>
    <span class="s1">n_bins </span><span class="s2">= </span><span class="s1">n_samples </span><span class="s2">= </span><span class="s3">5</span>
    <span class="s1">X_binned </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s3">1</span><span class="s2">, </span><span class="s3">1</span><span class="s2">).</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">X_BINNED_DTYPE</span><span class="s2">)</span>
    <span class="s1">sample_indices </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">uint32</span><span class="s2">)</span>
    <span class="s1">all_hessians </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">G_H_DTYPE</span><span class="s2">)</span>
    <span class="s1">all_gradients </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s3">1</span><span class="s2">, </span><span class="s3">1</span><span class="s2">, </span><span class="s3">100</span><span class="s2">, </span><span class="s3">1</span><span class="s2">, </span><span class="s3">1</span><span class="s2">], </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">G_H_DTYPE</span><span class="s2">)</span>
    <span class="s1">sum_gradients </span><span class="s2">= </span><span class="s1">all_gradients</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">()</span>
    <span class="s1">sum_hessians </span><span class="s2">= </span><span class="s1">all_hessians</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">()</span>
    <span class="s1">hessians_are_constant </span><span class="s2">= </span><span class="s0">False</span>

    <span class="s1">builder </span><span class="s2">= </span><span class="s1">HistogramBuilder</span><span class="s2">(</span>
        <span class="s1">X_binned</span><span class="s2">, </span><span class="s1">n_bins</span><span class="s2">, </span><span class="s1">all_gradients</span><span class="s2">, </span><span class="s1">all_hessians</span><span class="s2">, </span><span class="s1">hessians_are_constant</span><span class="s2">, </span><span class="s1">n_threads</span>
    <span class="s2">)</span>
    <span class="s1">n_bins_non_missing </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s1">n_bins </span><span class="s2">- </span><span class="s3">1</span><span class="s2">] * </span><span class="s1">X_binned</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s3">1</span><span class="s2">], </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">uint32</span><span class="s2">)</span>
    <span class="s1">has_missing_values </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s0">False</span><span class="s2">] * </span><span class="s1">X_binned</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s3">1</span><span class="s2">], </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">uint8</span><span class="s2">)</span>
    <span class="s1">monotonic_cst </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span>
        <span class="s2">[</span><span class="s1">MonotonicConstraint</span><span class="s2">.</span><span class="s1">NO_CST</span><span class="s2">] * </span><span class="s1">X_binned</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s3">1</span><span class="s2">], </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">int8</span>
    <span class="s2">)</span>
    <span class="s1">is_categorical </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros_like</span><span class="s2">(</span><span class="s1">monotonic_cst</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">uint8</span><span class="s2">)</span>
    <span class="s1">missing_values_bin_idx </span><span class="s2">= </span><span class="s1">n_bins </span><span class="s2">- </span><span class="s3">1</span>
    <span class="s1">children_lower_bound</span><span class="s2">, </span><span class="s1">children_upper_bound </span><span class="s2">= -</span><span class="s1">np</span><span class="s2">.</span><span class="s1">inf</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">inf</span>

    <span class="s1">min_gain_to_split </span><span class="s2">= </span><span class="s3">2000</span>
    <span class="s1">splitter </span><span class="s2">= </span><span class="s1">Splitter</span><span class="s2">(</span>
        <span class="s1">X_binned</span><span class="s2">,</span>
        <span class="s1">n_bins_non_missing</span><span class="s2">,</span>
        <span class="s1">missing_values_bin_idx</span><span class="s2">,</span>
        <span class="s1">has_missing_values</span><span class="s2">,</span>
        <span class="s1">is_categorical</span><span class="s2">,</span>
        <span class="s1">monotonic_cst</span><span class="s2">,</span>
        <span class="s1">l2_regularization</span><span class="s2">,</span>
        <span class="s1">min_hessian_to_split</span><span class="s2">,</span>
        <span class="s1">min_samples_leaf</span><span class="s2">,</span>
        <span class="s1">min_gain_to_split</span><span class="s2">,</span>
        <span class="s1">hessians_are_constant</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">histograms </span><span class="s2">= </span><span class="s1">builder</span><span class="s2">.</span><span class="s1">compute_histograms_brute</span><span class="s2">(</span><span class="s1">sample_indices</span><span class="s2">)</span>

    <span class="s4"># Since the gradient array is [1, 1, 100, 1, 1]</span>
    <span class="s4"># the max possible gain happens on the 3rd bin (or equivalently in the 2nd)</span>
    <span class="s4"># and is equal to about 1307, which less than min_gain_to_split = 2000, so</span>
    <span class="s4"># the node is considered unsplittable (gain = -1)</span>
    <span class="s1">current_lower_bound</span><span class="s2">, </span><span class="s1">current_upper_bound </span><span class="s2">= -</span><span class="s1">np</span><span class="s2">.</span><span class="s1">inf</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">inf</span>
    <span class="s1">value </span><span class="s2">= </span><span class="s1">compute_node_value</span><span class="s2">(</span>
        <span class="s1">sum_gradients</span><span class="s2">,</span>
        <span class="s1">sum_hessians</span><span class="s2">,</span>
        <span class="s1">current_lower_bound</span><span class="s2">,</span>
        <span class="s1">current_upper_bound</span><span class="s2">,</span>
        <span class="s1">l2_regularization</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s4"># the unbounded value is equal to -sum_gradients / sum_hessians</span>
    <span class="s0">assert </span><span class="s1">value </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(-</span><span class="s3">104 </span><span class="s2">/ </span><span class="s3">5</span><span class="s2">)</span>
    <span class="s1">split_info </span><span class="s2">= </span><span class="s1">splitter</span><span class="s2">.</span><span class="s1">find_node_split</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">,</span>
        <span class="s1">histograms</span><span class="s2">,</span>
        <span class="s1">sum_gradients</span><span class="s2">,</span>
        <span class="s1">sum_hessians</span><span class="s2">,</span>
        <span class="s1">value</span><span class="s2">,</span>
        <span class="s1">lower_bound</span><span class="s2">=</span><span class="s1">children_lower_bound</span><span class="s2">,</span>
        <span class="s1">upper_bound</span><span class="s2">=</span><span class="s1">children_upper_bound</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">split_info</span><span class="s2">.</span><span class="s1">gain </span><span class="s2">== -</span><span class="s3">1  </span><span class="s4"># min_gain_to_split not respected</span>

    <span class="s4"># here again the max possible gain is on the 3rd bin but we now cap the</span>
    <span class="s4"># value of the node into [-10, inf].</span>
    <span class="s4"># This means the gain is now about 2430 which is more than the</span>
    <span class="s4"># min_gain_to_split constraint.</span>
    <span class="s1">current_lower_bound</span><span class="s2">, </span><span class="s1">current_upper_bound </span><span class="s2">= -</span><span class="s3">10</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">inf</span>
    <span class="s1">value </span><span class="s2">= </span><span class="s1">compute_node_value</span><span class="s2">(</span>
        <span class="s1">sum_gradients</span><span class="s2">,</span>
        <span class="s1">sum_hessians</span><span class="s2">,</span>
        <span class="s1">current_lower_bound</span><span class="s2">,</span>
        <span class="s1">current_upper_bound</span><span class="s2">,</span>
        <span class="s1">l2_regularization</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">value </span><span class="s2">== -</span><span class="s3">10</span>
    <span class="s1">split_info </span><span class="s2">= </span><span class="s1">splitter</span><span class="s2">.</span><span class="s1">find_node_split</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">,</span>
        <span class="s1">histograms</span><span class="s2">,</span>
        <span class="s1">sum_gradients</span><span class="s2">,</span>
        <span class="s1">sum_hessians</span><span class="s2">,</span>
        <span class="s1">value</span><span class="s2">,</span>
        <span class="s1">lower_bound</span><span class="s2">=</span><span class="s1">children_lower_bound</span><span class="s2">,</span>
        <span class="s1">upper_bound</span><span class="s2">=</span><span class="s1">children_upper_bound</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">split_info</span><span class="s2">.</span><span class="s1">gain </span><span class="s2">&gt; </span><span class="s1">min_gain_to_split</span>
</pre>
</body>
</html>