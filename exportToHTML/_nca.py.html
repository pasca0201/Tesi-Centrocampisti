<html>
<head>
<title>_nca.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_nca.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Neighborhood Component Analysis 
&quot;&quot;&quot;</span>

<span class="s2"># Authors: William de Vazelhes &lt;wdevazelhes@gmail.com&gt;</span>
<span class="s2">#          John Chiotellis &lt;ioannis.chiotellis@in.tum.de&gt;</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">sys</span>
<span class="s3">import </span><span class="s1">time</span>
<span class="s3">from </span><span class="s1">numbers </span><span class="s3">import </span><span class="s1">Integral</span><span class="s4">, </span><span class="s1">Real</span>
<span class="s3">from </span><span class="s1">warnings </span><span class="s3">import </span><span class="s1">warn</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy</span><span class="s4">.</span><span class="s1">optimize </span><span class="s3">import </span><span class="s1">minimize</span>

<span class="s3">from </span><span class="s4">..</span><span class="s1">base </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">BaseEstimator</span><span class="s4">,</span>
    <span class="s1">ClassNamePrefixFeaturesOutMixin</span><span class="s4">,</span>
    <span class="s1">TransformerMixin</span><span class="s4">,</span>
    <span class="s1">_fit_context</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">decomposition </span><span class="s3">import </span><span class="s1">PCA</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">exceptions </span><span class="s3">import </span><span class="s1">ConvergenceWarning</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">metrics </span><span class="s3">import </span><span class="s1">pairwise_distances</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">preprocessing </span><span class="s3">import </span><span class="s1">LabelEncoder</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_param_validation </span><span class="s3">import </span><span class="s1">Interval</span><span class="s4">, </span><span class="s1">StrOptions</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">extmath </span><span class="s3">import </span><span class="s1">softmax</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">multiclass </span><span class="s3">import </span><span class="s1">check_classification_targets</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">random </span><span class="s3">import </span><span class="s1">check_random_state</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">validation </span><span class="s3">import </span><span class="s1">check_array</span><span class="s4">, </span><span class="s1">check_is_fitted</span>


<span class="s3">class </span><span class="s1">NeighborhoodComponentsAnalysis</span><span class="s4">(</span>
    <span class="s1">ClassNamePrefixFeaturesOutMixin</span><span class="s4">, </span><span class="s1">TransformerMixin</span><span class="s4">, </span><span class="s1">BaseEstimator</span>
<span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Neighborhood Components Analysis. 
 
    Neighborhood Component Analysis (NCA) is a machine learning algorithm for 
    metric learning. It learns a linear transformation in a supervised fashion 
    to improve the classification accuracy of a stochastic nearest neighbors 
    rule in the transformed space. 
 
    Read more in the :ref:`User Guide &lt;nca&gt;`. 
 
    Parameters 
    ---------- 
    n_components : int, default=None 
        Preferred dimensionality of the projected space. 
        If None it will be set to `n_features`. 
 
    init : {'auto', 'pca', 'lda', 'identity', 'random'} or ndarray of shape \ 
            (n_features_a, n_features_b), default='auto' 
        Initialization of the linear transformation. Possible options are 
        `'auto'`, `'pca'`, `'lda'`, `'identity'`, `'random'`, and a numpy 
        array of shape `(n_features_a, n_features_b)`. 
 
        - `'auto'` 
            Depending on `n_components`, the most reasonable initialization 
            is chosen. If `n_components &lt;= min(n_features, n_classes - 1)` 
            we use `'lda'`, as it uses labels information. If not, but 
            `n_components &lt; min(n_features, n_samples)`, we use `'pca'`, as 
            it projects data in meaningful directions (those of higher 
            variance). Otherwise, we just use `'identity'`. 
 
        - `'pca'` 
            `n_components` principal components of the inputs passed 
            to :meth:`fit` will be used to initialize the transformation. 
            (See :class:`~sklearn.decomposition.PCA`) 
 
        - `'lda'` 
            `min(n_components, n_classes)` most discriminative 
            components of the inputs passed to :meth:`fit` will be used to 
            initialize the transformation. (If `n_components &gt; n_classes`, 
            the rest of the components will be zero.) (See 
            :class:`~sklearn.discriminant_analysis.LinearDiscriminantAnalysis`) 
 
        - `'identity'` 
            If `n_components` is strictly smaller than the 
            dimensionality of the inputs passed to :meth:`fit`, the identity 
            matrix will be truncated to the first `n_components` rows. 
 
        - `'random'` 
            The initial transformation will be a random array of shape 
            `(n_components, n_features)`. Each value is sampled from the 
            standard normal distribution. 
 
        - numpy array 
            `n_features_b` must match the dimensionality of the inputs passed 
            to :meth:`fit` and n_features_a must be less than or equal to that. 
            If `n_components` is not `None`, `n_features_a` must match it. 
 
    warm_start : bool, default=False 
        If `True` and :meth:`fit` has been called before, the solution of the 
        previous call to :meth:`fit` is used as the initial linear 
        transformation (`n_components` and `init` will be ignored). 
 
    max_iter : int, default=50 
        Maximum number of iterations in the optimization. 
 
    tol : float, default=1e-5 
        Convergence tolerance for the optimization. 
 
    callback : callable, default=None 
        If not `None`, this function is called after every iteration of the 
        optimizer, taking as arguments the current solution (flattened 
        transformation matrix) and the number of iterations. This might be 
        useful in case one wants to examine or store the transformation 
        found after each iteration. 
 
    verbose : int, default=0 
        If 0, no progress messages will be printed. 
        If 1, progress messages will be printed to stdout. 
        If &gt; 1, progress messages will be printed and the `disp` 
        parameter of :func:`scipy.optimize.minimize` will be set to 
        `verbose - 2`. 
 
    random_state : int or numpy.RandomState, default=None 
        A pseudo random number generator object or a seed for it if int. If 
        `init='random'`, `random_state` is used to initialize the random 
        transformation. If `init='pca'`, `random_state` is passed as an 
        argument to PCA when initializing the transformation. Pass an int 
        for reproducible results across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    Attributes 
    ---------- 
    components_ : ndarray of shape (n_components, n_features) 
        The linear transformation learned during fitting. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    n_iter_ : int 
        Counts the number of iterations performed by the optimizer. 
 
    random_state_ : numpy.RandomState 
        Pseudo random number generator object used during initialization. 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    See Also 
    -------- 
    sklearn.discriminant_analysis.LinearDiscriminantAnalysis : Linear 
        Discriminant Analysis. 
    sklearn.decomposition.PCA : Principal component analysis (PCA). 
 
    References 
    ---------- 
    .. [1] J. Goldberger, G. Hinton, S. Roweis, R. Salakhutdinov. 
           &quot;Neighbourhood Components Analysis&quot;. Advances in Neural Information 
           Processing Systems. 17, 513-520, 2005. 
           http://www.cs.nyu.edu/~roweis/papers/ncanips.pdf 
 
    .. [2] Wikipedia entry on Neighborhood Components Analysis 
           https://en.wikipedia.org/wiki/Neighbourhood_components_analysis 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.neighbors import NeighborhoodComponentsAnalysis 
    &gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier 
    &gt;&gt;&gt; from sklearn.datasets import load_iris 
    &gt;&gt;&gt; from sklearn.model_selection import train_test_split 
    &gt;&gt;&gt; X, y = load_iris(return_X_y=True) 
    &gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(X, y, 
    ... stratify=y, test_size=0.7, random_state=42) 
    &gt;&gt;&gt; nca = NeighborhoodComponentsAnalysis(random_state=42) 
    &gt;&gt;&gt; nca.fit(X_train, y_train) 
    NeighborhoodComponentsAnalysis(...) 
    &gt;&gt;&gt; knn = KNeighborsClassifier(n_neighbors=3) 
    &gt;&gt;&gt; knn.fit(X_train, y_train) 
    KNeighborsClassifier(...) 
    &gt;&gt;&gt; print(knn.score(X_test, y_test)) 
    0.933333... 
    &gt;&gt;&gt; knn.fit(nca.transform(X_train), y_train) 
    KNeighborsClassifier(...) 
    &gt;&gt;&gt; print(knn.score(nca.transform(X_test), y_test)) 
    0.961904... 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s5">&quot;n_components&quot;</span><span class="s4">: [</span>
            <span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">),</span>
            <span class="s3">None</span><span class="s4">,</span>
        <span class="s4">],</span>
        <span class="s5">&quot;init&quot;</span><span class="s4">: [</span>
            <span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;auto&quot;</span><span class="s4">, </span><span class="s5">&quot;pca&quot;</span><span class="s4">, </span><span class="s5">&quot;lda&quot;</span><span class="s4">, </span><span class="s5">&quot;identity&quot;</span><span class="s4">, </span><span class="s5">&quot;random&quot;</span><span class="s4">}),</span>
            <span class="s1">np</span><span class="s4">.</span><span class="s1">ndarray</span><span class="s4">,</span>
        <span class="s4">],</span>
        <span class="s5">&quot;warm_start&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;max_iter&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;tol&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;callback&quot;</span><span class="s4">: [</span><span class="s1">callable</span><span class="s4">, </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;verbose&quot;</span><span class="s4">: [</span><span class="s5">&quot;verbose&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;random_state&quot;</span><span class="s4">: [</span><span class="s5">&quot;random_state&quot;</span><span class="s4">],</span>
    <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">n_components</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s4">*,</span>
        <span class="s1">init</span><span class="s4">=</span><span class="s5">&quot;auto&quot;</span><span class="s4">,</span>
        <span class="s1">warm_start</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">50</span><span class="s4">,</span>
        <span class="s1">tol</span><span class="s4">=</span><span class="s6">1e-5</span><span class="s4">,</span>
        <span class="s1">callback</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_components </span><span class="s4">= </span><span class="s1">n_components</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">init </span><span class="s4">= </span><span class="s1">init</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">warm_start </span><span class="s4">= </span><span class="s1">warm_start</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">max_iter </span><span class="s4">= </span><span class="s1">max_iter</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">tol </span><span class="s4">= </span><span class="s1">tol</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">callback </span><span class="s4">= </span><span class="s1">callback</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">verbose </span><span class="s4">= </span><span class="s1">verbose</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">random_state </span><span class="s4">= </span><span class="s1">random_state</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Fit the model according to the given training data. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            The training samples. 
 
        y : array-like of shape (n_samples,) 
            The corresponding training labels. 
 
        Returns 
        ------- 
        self : object 
            Fitted estimator. 
        &quot;&quot;&quot;</span>
        <span class="s2"># Validate the inputs X and y, and converts y to numerical classes.</span>
        <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">ensure_min_samples</span><span class="s4">=</span><span class="s6">2</span><span class="s4">)</span>
        <span class="s1">check_classification_targets</span><span class="s4">(</span><span class="s1">y</span><span class="s4">)</span>
        <span class="s1">y </span><span class="s4">= </span><span class="s1">LabelEncoder</span><span class="s4">().</span><span class="s1">fit_transform</span><span class="s4">(</span><span class="s1">y</span><span class="s4">)</span>

        <span class="s2"># Check the preferred dimensionality of the projected space</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components </span><span class="s3">is not None and </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components </span><span class="s4">&gt; </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]:</span>
            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                <span class="s5">&quot;The preferred dimensionality of the &quot;</span>
                <span class="s5">f&quot;projected space `n_components` (</span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components</span><span class="s3">}</span><span class="s5">) cannot &quot;</span>
                <span class="s5">&quot;be greater than the given data &quot;</span>
                <span class="s5">f&quot;dimensionality (</span><span class="s3">{</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]</span><span class="s3">}</span><span class="s5">)!&quot;</span>
            <span class="s4">)</span>
        <span class="s2"># If warm_start is enabled, check that the inputs are consistent</span>
        <span class="s3">if </span><span class="s4">(</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">warm_start</span>
            <span class="s3">and </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;components_&quot;</span><span class="s4">)</span>
            <span class="s3">and </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">] != </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]</span>
        <span class="s4">):</span>
            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                <span class="s5">f&quot;The new inputs dimensionality (</span><span class="s3">{</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]</span><span class="s3">}</span><span class="s5">) does not &quot;</span>
                <span class="s5">&quot;match the input dimensionality of the &quot;</span>
                <span class="s5">f&quot;previously learned transformation (</span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]</span><span class="s3">}</span><span class="s5">).&quot;</span>
            <span class="s4">)</span>
        <span class="s2"># Check how the linear transformation should be initialized</span>
        <span class="s1">init </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">init</span>
        <span class="s3">if </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">init</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ndarray</span><span class="s4">):</span>
            <span class="s1">init </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">init</span><span class="s4">)</span>
            <span class="s2"># Assert that init.shape[1] = X.shape[1]</span>
            <span class="s3">if </span><span class="s1">init</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">] != </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]:</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                    <span class="s5">f&quot;The input dimensionality (</span><span class="s3">{</span><span class="s1">init</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]</span><span class="s3">}</span><span class="s5">) of the given &quot;</span>
                    <span class="s5">&quot;linear transformation `init` must match the &quot;</span>
                    <span class="s5">f&quot;dimensionality of the given inputs `X` (</span><span class="s3">{</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]</span><span class="s3">}</span><span class="s5">).&quot;</span>
                <span class="s4">)</span>
            <span class="s2"># Assert that init.shape[0] &lt;= init.shape[1]</span>
            <span class="s3">if </span><span class="s1">init</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">] &gt; </span><span class="s1">init</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]:</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                    <span class="s5">f&quot;The output dimensionality (</span><span class="s3">{</span><span class="s1">init</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span><span class="s3">}</span><span class="s5">) of the given &quot;</span>
                    <span class="s5">&quot;linear transformation `init` cannot be &quot;</span>
                    <span class="s5">f&quot;greater than its input dimensionality (</span><span class="s3">{</span><span class="s1">init</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]</span><span class="s3">}</span><span class="s5">).&quot;</span>
                <span class="s4">)</span>
            <span class="s2"># Assert that self.n_components = init.shape[0]</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components </span><span class="s3">is not None and </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components </span><span class="s4">!= </span><span class="s1">init</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]:</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                    <span class="s5">&quot;The preferred dimensionality of the &quot;</span>
                    <span class="s5">f&quot;projected space `n_components` (</span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components</span><span class="s3">}</span><span class="s5">) does&quot;</span>
                    <span class="s5">&quot; not match the output dimensionality of &quot;</span>
                    <span class="s5">&quot;the given linear transformation &quot;</span>
                    <span class="s5">f&quot;`init` (</span><span class="s3">{</span><span class="s1">init</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span><span class="s3">}</span><span class="s5">)!&quot;</span>
                <span class="s4">)</span>

        <span class="s2"># Initialize the random generator</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">random_state_ </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>

        <span class="s2"># Measure the total training time</span>
        <span class="s1">t_train </span><span class="s4">= </span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">()</span>

        <span class="s2"># Compute a mask that stays fixed during optimization:</span>
        <span class="s1">same_class_mask </span><span class="s4">= </span><span class="s1">y</span><span class="s4">[:, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">newaxis</span><span class="s4">] == </span><span class="s1">y</span><span class="s4">[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">newaxis</span><span class="s4">, :]</span>
        <span class="s2"># (n_samples, n_samples)</span>

        <span class="s2"># Initialize the transformation</span>
        <span class="s1">transformation </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ravel</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">_initialize</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">init</span><span class="s4">))</span>

        <span class="s2"># Create a dictionary of parameters to be passed to the optimizer</span>
        <span class="s1">disp </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose </span><span class="s4">- </span><span class="s6">2 </span><span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose </span><span class="s4">&gt; </span><span class="s6">1 </span><span class="s3">else </span><span class="s4">-</span><span class="s6">1</span>
        <span class="s1">optimizer_params </span><span class="s4">= {</span>
            <span class="s5">&quot;method&quot;</span><span class="s4">: </span><span class="s5">&quot;L-BFGS-B&quot;</span><span class="s4">,</span>
            <span class="s5">&quot;fun&quot;</span><span class="s4">: </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_loss_grad_lbfgs</span><span class="s4">,</span>
            <span class="s5">&quot;args&quot;</span><span class="s4">: (</span><span class="s1">X</span><span class="s4">, </span><span class="s1">same_class_mask</span><span class="s4">, -</span><span class="s6">1.0</span><span class="s4">),</span>
            <span class="s5">&quot;jac&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">,</span>
            <span class="s5">&quot;x0&quot;</span><span class="s4">: </span><span class="s1">transformation</span><span class="s4">,</span>
            <span class="s5">&quot;tol&quot;</span><span class="s4">: </span><span class="s1">self</span><span class="s4">.</span><span class="s1">tol</span><span class="s4">,</span>
            <span class="s5">&quot;options&quot;</span><span class="s4">: </span><span class="s1">dict</span><span class="s4">(</span><span class="s1">maxiter</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">max_iter</span><span class="s4">, </span><span class="s1">disp</span><span class="s4">=</span><span class="s1">disp</span><span class="s4">),</span>
            <span class="s5">&quot;callback&quot;</span><span class="s4">: </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_callback</span><span class="s4">,</span>
        <span class="s4">}</span>

        <span class="s2"># Call the optimizer</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter_ </span><span class="s4">= </span><span class="s6">0</span>
        <span class="s1">opt_result </span><span class="s4">= </span><span class="s1">minimize</span><span class="s4">(**</span><span class="s1">optimizer_params</span><span class="s4">)</span>

        <span class="s2"># Reshape the solution found by the optimizer</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">components_ </span><span class="s4">= </span><span class="s1">opt_result</span><span class="s4">.</span><span class="s1">x</span><span class="s4">.</span><span class="s1">reshape</span><span class="s4">(-</span><span class="s6">1</span><span class="s4">, </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">])</span>

        <span class="s2"># Stop timer</span>
        <span class="s1">t_train </span><span class="s4">= </span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">() - </span><span class="s1">t_train</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">:</span>
            <span class="s1">cls_name </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span>

            <span class="s2"># Warn the user if the algorithm did not converge</span>
            <span class="s3">if not </span><span class="s1">opt_result</span><span class="s4">.</span><span class="s1">success</span><span class="s4">:</span>
                <span class="s1">warn</span><span class="s4">(</span>
                    <span class="s5">&quot;[{}] NCA did not converge: {}&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span>
                        <span class="s1">cls_name</span><span class="s4">, </span><span class="s1">opt_result</span><span class="s4">.</span><span class="s1">message</span>
                    <span class="s4">),</span>
                    <span class="s1">ConvergenceWarning</span><span class="s4">,</span>
                <span class="s4">)</span>

            <span class="s1">print</span><span class="s4">(</span><span class="s5">&quot;[{}] Training took {:8.2f}s.&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span><span class="s1">cls_name</span><span class="s4">, </span><span class="s1">t_train</span><span class="s4">))</span>

        <span class="s3">return </span><span class="s1">self</span>

    <span class="s3">def </span><span class="s1">transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Apply the learned transformation to the given data. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Data samples. 
 
        Returns 
        ------- 
        X_embedded: ndarray of shape (n_samples, n_components) 
            The data samples transformed. 
 
        Raises 
        ------ 
        NotFittedError 
            If :meth:`fit` has not been called before. 
        &quot;&quot;&quot;</span>

        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">reset</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>

        <span class="s3">return </span><span class="s1">np</span><span class="s4">.</span><span class="s1">dot</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">.</span><span class="s1">T</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_initialize</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">init</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Initialize the transformation. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            The training samples. 
 
        y : array-like of shape (n_samples,) 
            The training labels. 
 
        init : str or ndarray of shape (n_features_a, n_features_b) 
            The validated initialization of the linear transformation. 
 
        Returns 
        ------- 
        transformation : ndarray of shape (n_components, n_features) 
            The initialized linear transformation. 
 
        &quot;&quot;&quot;</span>

        <span class="s1">transformation </span><span class="s4">= </span><span class="s1">init</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">warm_start </span><span class="s3">and </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;components_&quot;</span><span class="s4">):</span>
            <span class="s1">transformation </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span>
        <span class="s3">elif </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">init</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ndarray</span><span class="s4">):</span>
            <span class="s3">pass</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_features </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span>
            <span class="s1">n_components </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components </span><span class="s3">or </span><span class="s1">n_features</span>
            <span class="s3">if </span><span class="s1">init </span><span class="s4">== </span><span class="s5">&quot;auto&quot;</span><span class="s4">:</span>
                <span class="s1">n_classes </span><span class="s4">= </span><span class="s1">len</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">unique</span><span class="s4">(</span><span class="s1">y</span><span class="s4">))</span>
                <span class="s3">if </span><span class="s1">n_components </span><span class="s4">&lt;= </span><span class="s1">min</span><span class="s4">(</span><span class="s1">n_features</span><span class="s4">, </span><span class="s1">n_classes </span><span class="s4">- </span><span class="s6">1</span><span class="s4">):</span>
                    <span class="s1">init </span><span class="s4">= </span><span class="s5">&quot;lda&quot;</span>
                <span class="s3">elif </span><span class="s1">n_components </span><span class="s4">&lt; </span><span class="s1">min</span><span class="s4">(</span><span class="s1">n_features</span><span class="s4">, </span><span class="s1">n_samples</span><span class="s4">):</span>
                    <span class="s1">init </span><span class="s4">= </span><span class="s5">&quot;pca&quot;</span>
                <span class="s3">else</span><span class="s4">:</span>
                    <span class="s1">init </span><span class="s4">= </span><span class="s5">&quot;identity&quot;</span>
            <span class="s3">if </span><span class="s1">init </span><span class="s4">== </span><span class="s5">&quot;identity&quot;</span><span class="s4">:</span>
                <span class="s1">transformation </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">eye</span><span class="s4">(</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">])</span>
            <span class="s3">elif </span><span class="s1">init </span><span class="s4">== </span><span class="s5">&quot;random&quot;</span><span class="s4">:</span>
                <span class="s1">transformation </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state_</span><span class="s4">.</span><span class="s1">standard_normal</span><span class="s4">(</span>
                    <span class="s1">size</span><span class="s4">=(</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">])</span>
                <span class="s4">)</span>
            <span class="s3">elif </span><span class="s1">init </span><span class="s3">in </span><span class="s4">{</span><span class="s5">&quot;pca&quot;</span><span class="s4">, </span><span class="s5">&quot;lda&quot;</span><span class="s4">}:</span>
                <span class="s1">init_time </span><span class="s4">= </span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">()</span>
                <span class="s3">if </span><span class="s1">init </span><span class="s4">== </span><span class="s5">&quot;pca&quot;</span><span class="s4">:</span>
                    <span class="s1">pca </span><span class="s4">= </span><span class="s1">PCA</span><span class="s4">(</span>
                        <span class="s1">n_components</span><span class="s4">=</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state_</span>
                    <span class="s4">)</span>
                    <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">:</span>
                        <span class="s1">print</span><span class="s4">(</span><span class="s5">&quot;Finding principal components... &quot;</span><span class="s4">, </span><span class="s1">end</span><span class="s4">=</span><span class="s5">&quot;&quot;</span><span class="s4">)</span>
                        <span class="s1">sys</span><span class="s4">.</span><span class="s1">stdout</span><span class="s4">.</span><span class="s1">flush</span><span class="s4">()</span>
                    <span class="s1">pca</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
                    <span class="s1">transformation </span><span class="s4">= </span><span class="s1">pca</span><span class="s4">.</span><span class="s1">components_</span>
                <span class="s3">elif </span><span class="s1">init </span><span class="s4">== </span><span class="s5">&quot;lda&quot;</span><span class="s4">:</span>
                    <span class="s3">from </span><span class="s4">..</span><span class="s1">discriminant_analysis </span><span class="s3">import </span><span class="s1">LinearDiscriminantAnalysis</span>

                    <span class="s1">lda </span><span class="s4">= </span><span class="s1">LinearDiscriminantAnalysis</span><span class="s4">(</span><span class="s1">n_components</span><span class="s4">=</span><span class="s1">n_components</span><span class="s4">)</span>
                    <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">:</span>
                        <span class="s1">print</span><span class="s4">(</span><span class="s5">&quot;Finding most discriminative components... &quot;</span><span class="s4">, </span><span class="s1">end</span><span class="s4">=</span><span class="s5">&quot;&quot;</span><span class="s4">)</span>
                        <span class="s1">sys</span><span class="s4">.</span><span class="s1">stdout</span><span class="s4">.</span><span class="s1">flush</span><span class="s4">()</span>
                    <span class="s1">lda</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
                    <span class="s1">transformation </span><span class="s4">= </span><span class="s1">lda</span><span class="s4">.</span><span class="s1">scalings_</span><span class="s4">.</span><span class="s1">T</span><span class="s4">[:</span><span class="s1">n_components</span><span class="s4">]</span>
                <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">:</span>
                    <span class="s1">print</span><span class="s4">(</span><span class="s5">&quot;done in {:5.2f}s&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">() - </span><span class="s1">init_time</span><span class="s4">))</span>
        <span class="s3">return </span><span class="s1">transformation</span>

    <span class="s3">def </span><span class="s1">_callback</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">transformation</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Called after each iteration of the optimizer. 
 
        Parameters 
        ---------- 
        transformation : ndarray of shape (n_components * n_features,) 
            The solution computed by the optimizer in this iteration. 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">callback </span><span class="s3">is not None</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">callback</span><span class="s4">(</span><span class="s1">transformation</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter_</span><span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter_ </span><span class="s4">+= </span><span class="s6">1</span>

    <span class="s3">def </span><span class="s1">_loss_grad_lbfgs</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">transformation</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">same_class_mask</span><span class="s4">, </span><span class="s1">sign</span><span class="s4">=</span><span class="s6">1.0</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Compute the loss and the loss gradient w.r.t. `transformation`. 
 
        Parameters 
        ---------- 
        transformation : ndarray of shape (n_components * n_features,) 
            The raveled linear transformation on which to compute loss and 
            evaluate gradient. 
 
        X : ndarray of shape (n_samples, n_features) 
            The training samples. 
 
        same_class_mask : ndarray of shape (n_samples, n_samples) 
            A mask where `mask[i, j] == 1` if `X[i]` and `X[j]` belong 
            to the same class, and `0` otherwise. 
 
        Returns 
        ------- 
        loss : float 
            The loss computed for the given transformation. 
 
        gradient : ndarray of shape (n_components * n_features,) 
            The new (flattened) gradient of the loss. 
        &quot;&quot;&quot;</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter_ </span><span class="s4">== </span><span class="s6">0</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter_ </span><span class="s4">+= </span><span class="s6">1</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">:</span>
                <span class="s1">header_fields </span><span class="s4">= [</span><span class="s5">&quot;Iteration&quot;</span><span class="s4">, </span><span class="s5">&quot;Objective Value&quot;</span><span class="s4">, </span><span class="s5">&quot;Time(s)&quot;</span><span class="s4">]</span>
                <span class="s1">header_fmt </span><span class="s4">= </span><span class="s5">&quot;{:&gt;10} {:&gt;20} {:&gt;10}&quot;</span>
                <span class="s1">header </span><span class="s4">= </span><span class="s1">header_fmt</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(*</span><span class="s1">header_fields</span><span class="s4">)</span>
                <span class="s1">cls_name </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span>
                <span class="s1">print</span><span class="s4">(</span><span class="s5">&quot;[{}]&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span><span class="s1">cls_name</span><span class="s4">))</span>
                <span class="s1">print</span><span class="s4">(</span>
                    <span class="s5">&quot;[{}] {}</span><span class="s3">\n</span><span class="s5">[{}] {}&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span>
                        <span class="s1">cls_name</span><span class="s4">, </span><span class="s1">header</span><span class="s4">, </span><span class="s1">cls_name</span><span class="s4">, </span><span class="s5">&quot;-&quot; </span><span class="s4">* </span><span class="s1">len</span><span class="s4">(</span><span class="s1">header</span><span class="s4">)</span>
                    <span class="s4">)</span>
                <span class="s4">)</span>

        <span class="s1">t_funcall </span><span class="s4">= </span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">()</span>

        <span class="s1">transformation </span><span class="s4">= </span><span class="s1">transformation</span><span class="s4">.</span><span class="s1">reshape</span><span class="s4">(-</span><span class="s6">1</span><span class="s4">, </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">])</span>
        <span class="s1">X_embedded </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">dot</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">transformation</span><span class="s4">.</span><span class="s1">T</span><span class="s4">)  </span><span class="s2"># (n_samples, n_components)</span>

        <span class="s2"># Compute softmax distances</span>
        <span class="s1">p_ij </span><span class="s4">= </span><span class="s1">pairwise_distances</span><span class="s4">(</span><span class="s1">X_embedded</span><span class="s4">, </span><span class="s1">squared</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
        <span class="s1">np</span><span class="s4">.</span><span class="s1">fill_diagonal</span><span class="s4">(</span><span class="s1">p_ij</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span><span class="s4">)</span>
        <span class="s1">p_ij </span><span class="s4">= </span><span class="s1">softmax</span><span class="s4">(-</span><span class="s1">p_ij</span><span class="s4">)  </span><span class="s2"># (n_samples, n_samples)</span>

        <span class="s2"># Compute loss</span>
        <span class="s1">masked_p_ij </span><span class="s4">= </span><span class="s1">p_ij </span><span class="s4">* </span><span class="s1">same_class_mask</span>
        <span class="s1">p </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">masked_p_ij</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">keepdims</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)  </span><span class="s2"># (n_samples, 1)</span>
        <span class="s1">loss </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">p</span><span class="s4">)</span>

        <span class="s2"># Compute gradient of loss w.r.t. `transform`</span>
        <span class="s1">weighted_p_ij </span><span class="s4">= </span><span class="s1">masked_p_ij </span><span class="s4">- </span><span class="s1">p_ij </span><span class="s4">* </span><span class="s1">p</span>
        <span class="s1">weighted_p_ij_sym </span><span class="s4">= </span><span class="s1">weighted_p_ij </span><span class="s4">+ </span><span class="s1">weighted_p_ij</span><span class="s4">.</span><span class="s1">T</span>
        <span class="s1">np</span><span class="s4">.</span><span class="s1">fill_diagonal</span><span class="s4">(</span><span class="s1">weighted_p_ij_sym</span><span class="s4">, -</span><span class="s1">weighted_p_ij</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">0</span><span class="s4">))</span>
        <span class="s1">gradient </span><span class="s4">= </span><span class="s6">2 </span><span class="s4">* </span><span class="s1">X_embedded</span><span class="s4">.</span><span class="s1">T</span><span class="s4">.</span><span class="s1">dot</span><span class="s4">(</span><span class="s1">weighted_p_ij_sym</span><span class="s4">).</span><span class="s1">dot</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s2"># time complexity of the gradient: O(n_components x n_samples x (</span>
        <span class="s2"># n_samples + n_features))</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">:</span>
            <span class="s1">t_funcall </span><span class="s4">= </span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">() - </span><span class="s1">t_funcall</span>
            <span class="s1">values_fmt </span><span class="s4">= </span><span class="s5">&quot;[{}] {:&gt;10} {:&gt;20.6e} {:&gt;10.2f}&quot;</span>
            <span class="s1">print</span><span class="s4">(</span>
                <span class="s1">values_fmt</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span>
                    <span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter_</span><span class="s4">, </span><span class="s1">loss</span><span class="s4">, </span><span class="s1">t_funcall</span>
                <span class="s4">)</span>
            <span class="s4">)</span>
            <span class="s1">sys</span><span class="s4">.</span><span class="s1">stdout</span><span class="s4">.</span><span class="s1">flush</span><span class="s4">()</span>

        <span class="s3">return </span><span class="s1">sign </span><span class="s4">* </span><span class="s1">loss</span><span class="s4">, </span><span class="s1">sign </span><span class="s4">* </span><span class="s1">gradient</span><span class="s4">.</span><span class="s1">ravel</span><span class="s4">()</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span><span class="s5">&quot;requires_y&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">}</span>

    <span class="s4">@</span><span class="s1">property</span>
    <span class="s3">def </span><span class="s1">_n_features_out</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Number of transformed output features.&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>
</pre>
</body>
</html>