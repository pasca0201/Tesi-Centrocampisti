<html>
<head>
<title>_hypotests.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #6aab73;}
.s4 { color: #2aacb8;}
.s5 { color: #5f826b; font-style: italic;}
.s6 { color: #7a7e85;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_hypotests.py</font>
</center></td></tr></table>
<pre><span class="s0">from </span><span class="s1">collections </span><span class="s0">import </span><span class="s1">namedtuple</span>
<span class="s0">from </span><span class="s1">dataclasses </span><span class="s0">import </span><span class="s1">dataclass</span>
<span class="s0">from </span><span class="s1">math </span><span class="s0">import </span><span class="s1">comb</span>
<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">warnings</span>
<span class="s0">from </span><span class="s1">itertools </span><span class="s0">import </span><span class="s1">combinations</span>
<span class="s0">import </span><span class="s1">scipy</span><span class="s2">.</span><span class="s1">stats</span>
<span class="s0">from </span><span class="s1">scipy</span><span class="s2">.</span><span class="s1">optimize </span><span class="s0">import </span><span class="s1">shgo</span>
<span class="s0">from </span><span class="s2">. </span><span class="s0">import </span><span class="s1">distributions</span>
<span class="s0">from </span><span class="s2">.</span><span class="s1">_common </span><span class="s0">import </span><span class="s1">ConfidenceInterval</span>
<span class="s0">from </span><span class="s2">.</span><span class="s1">_continuous_distns </span><span class="s0">import </span><span class="s1">norm</span>
<span class="s0">from </span><span class="s1">scipy</span><span class="s2">.</span><span class="s1">special </span><span class="s0">import </span><span class="s1">gamma</span><span class="s2">, </span><span class="s1">kv</span><span class="s2">, </span><span class="s1">gammaln</span>
<span class="s0">from </span><span class="s1">scipy</span><span class="s2">.</span><span class="s1">fft </span><span class="s0">import </span><span class="s1">ifft</span>
<span class="s0">from </span><span class="s2">.</span><span class="s1">_stats_pythran </span><span class="s0">import </span><span class="s1">_a_ij_Aij_Dij2</span>
<span class="s0">from </span><span class="s2">.</span><span class="s1">_stats_pythran </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">_concordant_pairs </span><span class="s0">as </span><span class="s1">_P</span><span class="s2">, </span><span class="s1">_discordant_pairs </span><span class="s0">as </span><span class="s1">_Q</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s2">.</span><span class="s1">_axis_nan_policy </span><span class="s0">import </span><span class="s1">_axis_nan_policy_factory</span>
<span class="s0">from </span><span class="s1">scipy</span><span class="s2">.</span><span class="s1">stats </span><span class="s0">import </span><span class="s1">_stats_py</span>

<span class="s1">__all__ </span><span class="s2">= [</span><span class="s3">'epps_singleton_2samp'</span><span class="s2">, </span><span class="s3">'cramervonmises'</span><span class="s2">, </span><span class="s3">'somersd'</span><span class="s2">,</span>
           <span class="s3">'barnard_exact'</span><span class="s2">, </span><span class="s3">'boschloo_exact'</span><span class="s2">, </span><span class="s3">'cramervonmises_2samp'</span><span class="s2">,</span>
           <span class="s3">'tukey_hsd'</span><span class="s2">, </span><span class="s3">'poisson_means_test'</span><span class="s2">]</span>

<span class="s1">Epps_Singleton_2sampResult </span><span class="s2">= </span><span class="s1">namedtuple</span><span class="s2">(</span><span class="s3">'Epps_Singleton_2sampResult'</span><span class="s2">,</span>
                                        <span class="s2">(</span><span class="s3">'statistic'</span><span class="s2">, </span><span class="s3">'pvalue'</span><span class="s2">))</span>


<span class="s2">@</span><span class="s1">_axis_nan_policy_factory</span><span class="s2">(</span><span class="s1">Epps_Singleton_2sampResult</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">too_small</span><span class="s2">=</span><span class="s4">4</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">epps_singleton_2samp</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">t</span><span class="s2">=(</span><span class="s4">0.4</span><span class="s2">, </span><span class="s4">0.8</span><span class="s2">)):</span>
    <span class="s5">&quot;&quot;&quot;Compute the Epps-Singleton (ES) test statistic. 
 
    Test the null hypothesis that two samples have the same underlying 
    probability distribution. 
 
    Parameters 
    ---------- 
    x, y : array-like 
        The two samples of observations to be tested. Input must not have more 
        than one dimension. Samples can have different lengths, but both 
        must have at least five observations. 
    t : array-like, optional 
        The points (t1, ..., tn) where the empirical characteristic function is 
        to be evaluated. It should be positive distinct numbers. The default 
        value (0.4, 0.8) is proposed in [1]_. Input must not have more than 
        one dimension. 
 
    Returns 
    ------- 
    statistic : float 
        The test statistic. 
    pvalue : float 
        The associated p-value based on the asymptotic chi2-distribution. 
 
    See Also 
    -------- 
    ks_2samp, anderson_ksamp 
 
    Notes 
    ----- 
    Testing whether two samples are generated by the same underlying 
    distribution is a classical question in statistics. A widely used test is 
    the Kolmogorov-Smirnov (KS) test which relies on the empirical 
    distribution function. Epps and Singleton introduce a test based on the 
    empirical characteristic function in [1]_. 
 
    One advantage of the ES test compared to the KS test is that is does 
    not assume a continuous distribution. In [1]_, the authors conclude 
    that the test also has a higher power than the KS test in many 
    examples. They recommend the use of the ES test for discrete samples as 
    well as continuous samples with at least 25 observations each, whereas 
    `anderson_ksamp` is recommended for smaller sample sizes in the 
    continuous case. 
 
    The p-value is computed from the asymptotic distribution of the test 
    statistic which follows a `chi2` distribution. If the sample size of both 
    `x` and `y` is below 25, the small sample correction proposed in [1]_ is 
    applied to the test statistic. 
 
    The default values of `t` are determined in [1]_ by considering 
    various distributions and finding good values that lead to a high power 
    of the test in general. Table III in [1]_ gives the optimal values for 
    the distributions tested in that study. The values of `t` are scaled by 
    the semi-interquartile range in the implementation, see [1]_. 
 
    References 
    ---------- 
    .. [1] T. W. Epps and K. J. Singleton, &quot;An omnibus test for the two-sample 
       problem using the empirical characteristic function&quot;, Journal of 
       Statistical Computation and Simulation 26, p. 177--203, 1986. 
 
    .. [2] S. J. Goerg and J. Kaiser, &quot;Nonparametric testing of distributions 
       - the Epps-Singleton two-sample test using the empirical characteristic 
       function&quot;, The Stata Journal 9(3), p. 454--465, 2009. 
 
    &quot;&quot;&quot;</span>
    <span class="s6"># x and y are converted to arrays by the decorator</span>
    <span class="s1">t </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">t</span><span class="s2">)</span>
    <span class="s6"># check if x and y are valid inputs</span>
    <span class="s1">nx</span><span class="s2">, </span><span class="s1">ny </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">x</span><span class="s2">), </span><span class="s1">len</span><span class="s2">(</span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s2">(</span><span class="s1">nx </span><span class="s2">&lt; </span><span class="s4">5</span><span class="s2">) </span><span class="s0">or </span><span class="s2">(</span><span class="s1">ny </span><span class="s2">&lt; </span><span class="s4">5</span><span class="s2">):</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">'x and y should have at least 5 elements, but len(x) '</span>
                         <span class="s3">f'= </span><span class="s0">{</span><span class="s1">nx</span><span class="s0">} </span><span class="s3">and len(y) = </span><span class="s0">{</span><span class="s1">ny</span><span class="s0">}</span><span class="s3">.'</span><span class="s2">)</span>
    <span class="s0">if not </span><span class="s1">np</span><span class="s2">.</span><span class="s1">isfinite</span><span class="s2">(</span><span class="s1">x</span><span class="s2">).</span><span class="s1">all</span><span class="s2">():</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">'x must not contain nonfinite values.'</span><span class="s2">)</span>
    <span class="s0">if not </span><span class="s1">np</span><span class="s2">.</span><span class="s1">isfinite</span><span class="s2">(</span><span class="s1">y</span><span class="s2">).</span><span class="s1">all</span><span class="s2">():</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">'y must not contain nonfinite values.'</span><span class="s2">)</span>
    <span class="s1">n </span><span class="s2">= </span><span class="s1">nx </span><span class="s2">+ </span><span class="s1">ny</span>

    <span class="s6"># check if t is valid</span>
    <span class="s0">if </span><span class="s1">t</span><span class="s2">.</span><span class="s1">ndim </span><span class="s2">&gt; </span><span class="s4">1</span><span class="s2">:</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">f't must be 1d, but t.ndim equals </span><span class="s0">{</span><span class="s1">t</span><span class="s2">.</span><span class="s1">ndim</span><span class="s0">}</span><span class="s3">.'</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">np</span><span class="s2">.</span><span class="s1">less_equal</span><span class="s2">(</span><span class="s1">t</span><span class="s2">, </span><span class="s4">0</span><span class="s2">).</span><span class="s1">any</span><span class="s2">():</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">'t must contain positive elements only.'</span><span class="s2">)</span>

    <span class="s6"># rescale t with semi-iqr as proposed in [1]; import iqr here to avoid</span>
    <span class="s6"># circular import</span>
    <span class="s0">from </span><span class="s1">scipy</span><span class="s2">.</span><span class="s1">stats </span><span class="s0">import </span><span class="s1">iqr</span>
    <span class="s1">sigma </span><span class="s2">= </span><span class="s1">iqr</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">hstack</span><span class="s2">((</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">))) / </span><span class="s4">2</span>
    <span class="s1">ts </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">reshape</span><span class="s2">(</span><span class="s1">t</span><span class="s2">, (-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)) / </span><span class="s1">sigma</span>

    <span class="s6"># covariance estimation of ES test</span>
    <span class="s1">gx </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">vstack</span><span class="s2">((</span><span class="s1">np</span><span class="s2">.</span><span class="s1">cos</span><span class="s2">(</span><span class="s1">ts</span><span class="s2">*</span><span class="s1">x</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sin</span><span class="s2">(</span><span class="s1">ts</span><span class="s2">*</span><span class="s1">x</span><span class="s2">))).</span><span class="s1">T  </span><span class="s6"># shape = (nx, 2*len(t))</span>
    <span class="s1">gy </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">vstack</span><span class="s2">((</span><span class="s1">np</span><span class="s2">.</span><span class="s1">cos</span><span class="s2">(</span><span class="s1">ts</span><span class="s2">*</span><span class="s1">y</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sin</span><span class="s2">(</span><span class="s1">ts</span><span class="s2">*</span><span class="s1">y</span><span class="s2">))).</span><span class="s1">T</span>
    <span class="s1">cov_x </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">cov</span><span class="s2">(</span><span class="s1">gx</span><span class="s2">.</span><span class="s1">T</span><span class="s2">, </span><span class="s1">bias</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)  </span><span class="s6"># the test uses biased cov-estimate</span>
    <span class="s1">cov_y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">cov</span><span class="s2">(</span><span class="s1">gy</span><span class="s2">.</span><span class="s1">T</span><span class="s2">, </span><span class="s1">bias</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s1">est_cov </span><span class="s2">= (</span><span class="s1">n</span><span class="s2">/</span><span class="s1">nx</span><span class="s2">)*</span><span class="s1">cov_x </span><span class="s2">+ (</span><span class="s1">n</span><span class="s2">/</span><span class="s1">ny</span><span class="s2">)*</span><span class="s1">cov_y</span>
    <span class="s1">est_cov_inv </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">pinv</span><span class="s2">(</span><span class="s1">est_cov</span><span class="s2">)</span>
    <span class="s1">r </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linalg</span><span class="s2">.</span><span class="s1">matrix_rank</span><span class="s2">(</span><span class="s1">est_cov_inv</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">r </span><span class="s2">&lt; </span><span class="s4">2</span><span class="s2">*</span><span class="s1">len</span><span class="s2">(</span><span class="s1">t</span><span class="s2">):</span>
        <span class="s1">warnings</span><span class="s2">.</span><span class="s1">warn</span><span class="s2">(</span><span class="s3">'Estimated covariance matrix does not have full rank. '</span>
                      <span class="s3">'This indicates a bad choice of the input t and the '</span>
                      <span class="s3">'test might not be consistent.'</span><span class="s2">, </span><span class="s6"># see p. 183 in [1]_</span>
                      <span class="s1">stacklevel</span><span class="s2">=</span><span class="s4">2</span><span class="s2">)</span>

    <span class="s6"># compute test statistic w distributed asympt. as chisquare with df=r</span>
    <span class="s1">g_diff </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">gx</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">) - </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">gy</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">w </span><span class="s2">= </span><span class="s1">n</span><span class="s2">*</span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">g_diff</span><span class="s2">.</span><span class="s1">T</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">est_cov_inv</span><span class="s2">, </span><span class="s1">g_diff</span><span class="s2">))</span>

    <span class="s6"># apply small-sample correction</span>
    <span class="s0">if </span><span class="s2">(</span><span class="s1">max</span><span class="s2">(</span><span class="s1">nx</span><span class="s2">, </span><span class="s1">ny</span><span class="s2">) &lt; </span><span class="s4">25</span><span class="s2">):</span>
        <span class="s1">corr </span><span class="s2">= </span><span class="s4">1.0</span><span class="s2">/(</span><span class="s4">1.0 </span><span class="s2">+ </span><span class="s1">n</span><span class="s2">**(-</span><span class="s4">0.45</span><span class="s2">) + </span><span class="s4">10.1</span><span class="s2">*(</span><span class="s1">nx</span><span class="s2">**(-</span><span class="s4">1.7</span><span class="s2">) + </span><span class="s1">ny</span><span class="s2">**(-</span><span class="s4">1.7</span><span class="s2">)))</span>
        <span class="s1">w </span><span class="s2">= </span><span class="s1">corr </span><span class="s2">* </span><span class="s1">w</span>

    <span class="s1">chi2 </span><span class="s2">= </span><span class="s1">_stats_py</span><span class="s2">.</span><span class="s1">_SimpleChi2</span><span class="s2">(</span><span class="s1">r</span><span class="s2">)</span>
    <span class="s1">p </span><span class="s2">= </span><span class="s1">_stats_py</span><span class="s2">.</span><span class="s1">_get_pvalue</span><span class="s2">(</span><span class="s1">w</span><span class="s2">, </span><span class="s1">chi2</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">=</span><span class="s3">'greater'</span><span class="s2">, </span><span class="s1">symmetric</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">xp</span><span class="s2">=</span><span class="s1">np</span><span class="s2">)</span>

    <span class="s0">return </span><span class="s1">Epps_Singleton_2sampResult</span><span class="s2">(</span><span class="s1">w</span><span class="s2">, </span><span class="s1">p</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">poisson_means_test</span><span class="s2">(</span><span class="s1">k1</span><span class="s2">, </span><span class="s1">n1</span><span class="s2">, </span><span class="s1">k2</span><span class="s2">, </span><span class="s1">n2</span><span class="s2">, *, </span><span class="s1">diff</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">=</span><span class="s3">'two-sided'</span><span class="s2">):</span>
    <span class="s5">r&quot;&quot;&quot; 
    Performs the Poisson means test, AKA the &quot;E-test&quot;. 
 
    This is a test of the null hypothesis that the difference between means of 
    two Poisson distributions is `diff`. The samples are provided as the 
    number of events `k1` and `k2` observed within measurement intervals 
    (e.g. of time, space, number of observations) of sizes `n1` and `n2`. 
 
    Parameters 
    ---------- 
    k1 : int 
        Number of events observed from distribution 1. 
    n1: float 
        Size of sample from distribution 1. 
    k2 : int 
        Number of events observed from distribution 2. 
    n2 : float 
        Size of sample from distribution 2. 
    diff : float, default=0 
        The hypothesized difference in means between the distributions 
        underlying the samples. 
    alternative : {'two-sided', 'less', 'greater'}, optional 
        Defines the alternative hypothesis. 
        The following options are available (default is 'two-sided'): 
 
          * 'two-sided': the difference between distribution means is not 
            equal to `diff` 
          * 'less': the difference between distribution means is less than 
            `diff` 
          * 'greater': the difference between distribution means is greater 
            than `diff` 
 
    Returns 
    ------- 
    statistic : float 
        The test statistic (see [1]_ equation 3.3). 
    pvalue : float 
        The probability of achieving such an extreme value of the test 
        statistic under the null hypothesis. 
 
    Notes 
    ----- 
 
    Let: 
 
    .. math:: X_1 \sim \mbox{Poisson}(\mathtt{n1}\lambda_1) 
 
    be a random variable independent of 
 
    .. math:: X_2  \sim \mbox{Poisson}(\mathtt{n2}\lambda_2) 
 
    and let ``k1`` and ``k2`` be the observed values of :math:`X_1` 
    and :math:`X_2`, respectively. Then `poisson_means_test` uses the number 
    of observed events ``k1`` and ``k2`` from samples of size ``n1`` and 
    ``n2``, respectively, to test the null hypothesis that 
 
    .. math:: 
       H_0: \lambda_1 - \lambda_2 = \mathtt{diff} 
 
    A benefit of the E-test is that it has good power for small sample sizes, 
    which can reduce sampling costs [1]_. It has been evaluated and determined 
    to be more powerful than the comparable C-test, sometimes referred to as 
    the Poisson exact test. 
 
    References 
    ---------- 
    .. [1]  Krishnamoorthy, K., &amp; Thomson, J. (2004). A more powerful test for 
       comparing two Poisson means. Journal of Statistical Planning and 
       Inference, 119(1), 23-35. 
 
    .. [2]  Przyborowski, J., &amp; Wilenski, H. (1940). Homogeneity of results in 
       testing samples from Poisson series: With an application to testing 
       clover seed for dodder. Biometrika, 31(3/4), 313-323. 
 
    Examples 
    -------- 
 
    Suppose that a gardener wishes to test the number of dodder (weed) seeds 
    in a sack of clover seeds that they buy from a seed company. It has 
    previously been established that the number of dodder seeds in clover 
    follows the Poisson distribution. 
 
    A 100 gram sample is drawn from the sack before being shipped to the 
    gardener. The sample is analyzed, and it is found to contain no dodder 
    seeds; that is, `k1` is 0. However, upon arrival, the gardener draws 
    another 100 gram sample from the sack. This time, three dodder seeds are 
    found in the sample; that is, `k2` is 3. The gardener would like to 
    know if the difference is significant and not due to chance. The 
    null hypothesis is that the difference between the two samples is merely 
    due to chance, or that :math:`\lambda_1 - \lambda_2 = \mathtt{diff}` 
    where :math:`\mathtt{diff} = 0`. The alternative hypothesis is that the 
    difference is not due to chance, or :math:`\lambda_1 - \lambda_2 \ne 0`. 
    The gardener selects a significance level of 5% to reject the null 
    hypothesis in favor of the alternative [2]_. 
 
    &gt;&gt;&gt; import scipy.stats as stats 
    &gt;&gt;&gt; res = stats.poisson_means_test(0, 100, 3, 100) 
    &gt;&gt;&gt; res.statistic, res.pvalue 
    (-1.7320508075688772, 0.08837900929018157) 
 
    The p-value is .088, indicating a near 9% chance of observing a value of 
    the test statistic under the null hypothesis. This exceeds 5%, so the 
    gardener does not reject the null hypothesis as the difference cannot be 
    regarded as significant at this level. 
    &quot;&quot;&quot;</span>

    <span class="s1">_poisson_means_test_iv</span><span class="s2">(</span><span class="s1">k1</span><span class="s2">, </span><span class="s1">n1</span><span class="s2">, </span><span class="s1">k2</span><span class="s2">, </span><span class="s1">n2</span><span class="s2">, </span><span class="s1">diff</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">)</span>

    <span class="s6"># &quot;for a given k_1 and k_2, an estimate of \lambda_2 is given by&quot; [1] (3.4)</span>
    <span class="s1">lmbd_hat2 </span><span class="s2">= ((</span><span class="s1">k1 </span><span class="s2">+ </span><span class="s1">k2</span><span class="s2">) / (</span><span class="s1">n1 </span><span class="s2">+ </span><span class="s1">n2</span><span class="s2">) - </span><span class="s1">diff </span><span class="s2">* </span><span class="s1">n1 </span><span class="s2">/ (</span><span class="s1">n1 </span><span class="s2">+ </span><span class="s1">n2</span><span class="s2">))</span>

    <span class="s6"># &quot;\hat{\lambda_{2k}} may be less than or equal to zero ... and in this</span>
    <span class="s6"># case the null hypothesis cannot be rejected ... [and] it is not necessary</span>
    <span class="s6"># to compute the p-value&quot;. [1] page 26 below eq. (3.6).</span>
    <span class="s0">if </span><span class="s1">lmbd_hat2 </span><span class="s2">&lt;= </span><span class="s4">0</span><span class="s2">:</span>
        <span class="s0">return </span><span class="s1">_stats_py</span><span class="s2">.</span><span class="s1">SignificanceResult</span><span class="s2">(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>

    <span class="s6"># The unbiased variance estimate [1] (3.2)</span>
    <span class="s1">var </span><span class="s2">= </span><span class="s1">k1 </span><span class="s2">/ (</span><span class="s1">n1 </span><span class="s2">** </span><span class="s4">2</span><span class="s2">) + </span><span class="s1">k2 </span><span class="s2">/ (</span><span class="s1">n2 </span><span class="s2">** </span><span class="s4">2</span><span class="s2">)</span>

    <span class="s6"># The _observed_ pivot statistic from the input. It follows the</span>
    <span class="s6"># unnumbered equation following equation (3.3) This is used later in</span>
    <span class="s6"># comparison with the computed pivot statistics in an indicator function.</span>
    <span class="s1">t_k1k2 </span><span class="s2">= (</span><span class="s1">k1 </span><span class="s2">/ </span><span class="s1">n1 </span><span class="s2">- </span><span class="s1">k2 </span><span class="s2">/ </span><span class="s1">n2 </span><span class="s2">- </span><span class="s1">diff</span><span class="s2">) / </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sqrt</span><span class="s2">(</span><span class="s1">var</span><span class="s2">)</span>

    <span class="s6"># Equation (3.5) of [1] is lengthy, so it is broken into several parts,</span>
    <span class="s6"># beginning here. Note that the probability mass function of poisson is</span>
    <span class="s6"># exp^(-\mu)*\mu^k/k!, so and this is called with shape \mu, here noted</span>
    <span class="s6"># here as nlmbd_hat*. The strategy for evaluating the double summation in</span>
    <span class="s6"># (3.5) is to create two arrays of the values of the two products inside</span>
    <span class="s6"># the summation and then broadcast them together into a matrix, and then</span>
    <span class="s6"># sum across the entire matrix.</span>

    <span class="s6"># Compute constants (as seen in the first and second separated products in</span>
    <span class="s6"># (3.5).). (This is the shape (\mu) parameter of the poisson distribution.)</span>
    <span class="s1">nlmbd_hat1 </span><span class="s2">= </span><span class="s1">n1 </span><span class="s2">* (</span><span class="s1">lmbd_hat2 </span><span class="s2">+ </span><span class="s1">diff</span><span class="s2">)</span>
    <span class="s1">nlmbd_hat2 </span><span class="s2">= </span><span class="s1">n2 </span><span class="s2">* </span><span class="s1">lmbd_hat2</span>

    <span class="s6"># Determine summation bounds for tail ends of distribution rather than</span>
    <span class="s6"># summing to infinity. `x1*` is for the outer sum and `x2*` is the inner</span>
    <span class="s6"># sum.</span>
    <span class="s1">x1_lb</span><span class="s2">, </span><span class="s1">x1_ub </span><span class="s2">= </span><span class="s1">distributions</span><span class="s2">.</span><span class="s1">poisson</span><span class="s2">.</span><span class="s1">ppf</span><span class="s2">([</span><span class="s4">1e-10</span><span class="s2">, </span><span class="s4">1 </span><span class="s2">- </span><span class="s4">1e-16</span><span class="s2">], </span><span class="s1">nlmbd_hat1</span><span class="s2">)</span>
    <span class="s1">x2_lb</span><span class="s2">, </span><span class="s1">x2_ub </span><span class="s2">= </span><span class="s1">distributions</span><span class="s2">.</span><span class="s1">poisson</span><span class="s2">.</span><span class="s1">ppf</span><span class="s2">([</span><span class="s4">1e-10</span><span class="s2">, </span><span class="s4">1 </span><span class="s2">- </span><span class="s4">1e-16</span><span class="s2">], </span><span class="s1">nlmbd_hat2</span><span class="s2">)</span>

    <span class="s6"># Construct arrays to function as the x_1 and x_2 counters on the summation</span>
    <span class="s6"># in (3.5). `x1` is in columns and `x2` is in rows to allow for</span>
    <span class="s6"># broadcasting.</span>
    <span class="s1">x1 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">x1_lb</span><span class="s2">, </span><span class="s1">x1_ub </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">x2 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">x2_lb</span><span class="s2">, </span><span class="s1">x2_ub </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">)[:, </span><span class="s0">None</span><span class="s2">]</span>

    <span class="s6"># These are the two products in equation (3.5) with `prob_x1` being the</span>
    <span class="s6"># first (left side) and `prob_x2` being the second (right side). (To</span>
    <span class="s6"># make as clear as possible: the 1st contains a &quot;+ d&quot; term, the 2nd does</span>
    <span class="s6"># not.)</span>
    <span class="s1">prob_x1 </span><span class="s2">= </span><span class="s1">distributions</span><span class="s2">.</span><span class="s1">poisson</span><span class="s2">.</span><span class="s1">pmf</span><span class="s2">(</span><span class="s1">x1</span><span class="s2">, </span><span class="s1">nlmbd_hat1</span><span class="s2">)</span>
    <span class="s1">prob_x2 </span><span class="s2">= </span><span class="s1">distributions</span><span class="s2">.</span><span class="s1">poisson</span><span class="s2">.</span><span class="s1">pmf</span><span class="s2">(</span><span class="s1">x2</span><span class="s2">, </span><span class="s1">nlmbd_hat2</span><span class="s2">)</span>

    <span class="s6"># compute constants for use in the &quot;pivot statistic&quot; per the</span>
    <span class="s6"># unnumbered equation following (3.3).</span>
    <span class="s1">lmbd_x1 </span><span class="s2">= </span><span class="s1">x1 </span><span class="s2">/ </span><span class="s1">n1</span>
    <span class="s1">lmbd_x2 </span><span class="s2">= </span><span class="s1">x2 </span><span class="s2">/ </span><span class="s1">n2</span>
    <span class="s1">lmbds_diff </span><span class="s2">= </span><span class="s1">lmbd_x1 </span><span class="s2">- </span><span class="s1">lmbd_x2 </span><span class="s2">- </span><span class="s1">diff</span>
    <span class="s1">var_x1x2 </span><span class="s2">= </span><span class="s1">lmbd_x1 </span><span class="s2">/ </span><span class="s1">n1 </span><span class="s2">+ </span><span class="s1">lmbd_x2 </span><span class="s2">/ </span><span class="s1">n2</span>

    <span class="s6"># This is the 'pivot statistic' for use in the indicator of the summation</span>
    <span class="s6"># (left side of &quot;I[.]&quot;).</span>
    <span class="s0">with </span><span class="s1">np</span><span class="s2">.</span><span class="s1">errstate</span><span class="s2">(</span><span class="s1">invalid</span><span class="s2">=</span><span class="s3">'ignore'</span><span class="s2">, </span><span class="s1">divide</span><span class="s2">=</span><span class="s3">'ignore'</span><span class="s2">):</span>
        <span class="s1">t_x1x2 </span><span class="s2">= </span><span class="s1">lmbds_diff </span><span class="s2">/ </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sqrt</span><span class="s2">(</span><span class="s1">var_x1x2</span><span class="s2">)</span>

    <span class="s6"># `[indicator]` implements the &quot;I[.] ... the indicator function&quot; per</span>
    <span class="s6"># the paragraph following equation (3.5).</span>
    <span class="s0">if </span><span class="s1">alternative </span><span class="s2">== </span><span class="s3">'two-sided'</span><span class="s2">:</span>
        <span class="s1">indicator </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">abs</span><span class="s2">(</span><span class="s1">t_x1x2</span><span class="s2">) &gt;= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">abs</span><span class="s2">(</span><span class="s1">t_k1k2</span><span class="s2">)</span>
    <span class="s0">elif </span><span class="s1">alternative </span><span class="s2">== </span><span class="s3">'less'</span><span class="s2">:</span>
        <span class="s1">indicator </span><span class="s2">= </span><span class="s1">t_x1x2 </span><span class="s2">&lt;= </span><span class="s1">t_k1k2</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">indicator </span><span class="s2">= </span><span class="s1">t_x1x2 </span><span class="s2">&gt;= </span><span class="s1">t_k1k2</span>

    <span class="s6"># Multiply all combinations of the products together, exclude terms</span>
    <span class="s6"># based on the `indicator` and then sum. (3.5)</span>
    <span class="s1">pvalue </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">((</span><span class="s1">prob_x1 </span><span class="s2">* </span><span class="s1">prob_x2</span><span class="s2">)[</span><span class="s1">indicator</span><span class="s2">])</span>
    <span class="s0">return </span><span class="s1">_stats_py</span><span class="s2">.</span><span class="s1">SignificanceResult</span><span class="s2">(</span><span class="s1">t_k1k2</span><span class="s2">, </span><span class="s1">pvalue</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">_poisson_means_test_iv</span><span class="s2">(</span><span class="s1">k1</span><span class="s2">, </span><span class="s1">n1</span><span class="s2">, </span><span class="s1">k2</span><span class="s2">, </span><span class="s1">n2</span><span class="s2">, </span><span class="s1">diff</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">):</span>
    <span class="s6"># &quot;&quot;&quot;check for valid types and values of input to `poisson_mean_test`.&quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">k1 </span><span class="s2">!= </span><span class="s1">int</span><span class="s2">(</span><span class="s1">k1</span><span class="s2">) </span><span class="s0">or </span><span class="s1">k2 </span><span class="s2">!= </span><span class="s1">int</span><span class="s2">(</span><span class="s1">k2</span><span class="s2">):</span>
        <span class="s0">raise </span><span class="s1">TypeError</span><span class="s2">(</span><span class="s3">'`k1` and `k2` must be integers.'</span><span class="s2">)</span>

    <span class="s1">count_err </span><span class="s2">= </span><span class="s3">'`k1` and `k2` must be greater than or equal to 0.'</span>
    <span class="s0">if </span><span class="s1">k1 </span><span class="s2">&lt; </span><span class="s4">0 </span><span class="s0">or </span><span class="s1">k2 </span><span class="s2">&lt; </span><span class="s4">0</span><span class="s2">:</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s1">count_err</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">n1 </span><span class="s2">&lt;= </span><span class="s4">0 </span><span class="s0">or </span><span class="s1">n2 </span><span class="s2">&lt;= </span><span class="s4">0</span><span class="s2">:</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">'`n1` and `n2` must be greater than 0.'</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">diff </span><span class="s2">&lt; </span><span class="s4">0</span><span class="s2">:</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">'diff must be greater than or equal to 0.'</span><span class="s2">)</span>

    <span class="s1">alternatives </span><span class="s2">= {</span><span class="s3">'two-sided'</span><span class="s2">, </span><span class="s3">'less'</span><span class="s2">, </span><span class="s3">'greater'</span><span class="s2">}</span>
    <span class="s0">if </span><span class="s1">alternative</span><span class="s2">.</span><span class="s1">lower</span><span class="s2">() </span><span class="s0">not in </span><span class="s1">alternatives</span><span class="s2">:</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">f&quot;Alternative must be one of '</span><span class="s0">{</span><span class="s1">alternatives</span><span class="s0">}</span><span class="s3">'.&quot;</span><span class="s2">)</span>


<span class="s0">class </span><span class="s1">CramerVonMisesResult</span><span class="s2">:</span>
    <span class="s0">def </span><span class="s1">__init__</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">statistic</span><span class="s2">, </span><span class="s1">pvalue</span><span class="s2">):</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">statistic </span><span class="s2">= </span><span class="s1">statistic</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">pvalue </span><span class="s2">= </span><span class="s1">pvalue</span>

    <span class="s0">def </span><span class="s1">__repr__</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s2">(</span><span class="s3">f&quot;</span><span class="s0">{</span><span class="s1">self</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__name__</span><span class="s0">}</span><span class="s3">(statistic=</span><span class="s0">{</span><span class="s1">self</span><span class="s2">.</span><span class="s1">statistic</span><span class="s0">}</span><span class="s3">, &quot;</span>
                <span class="s3">f&quot;pvalue=</span><span class="s0">{</span><span class="s1">self</span><span class="s2">.</span><span class="s1">pvalue</span><span class="s0">}</span><span class="s3">)&quot;</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">_psi1_mod</span><span class="s2">(</span><span class="s1">x</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot; 
    psi1 is defined in equation 1.10 in Csörgő, S. and Faraway, J. (1996). 
    This implements a modified version by excluding the term V(x) / 12 
    (here: _cdf_cvm_inf(x) / 12) to avoid evaluating _cdf_cvm_inf(x) 
    twice in _cdf_cvm. 
 
    Implementation based on MAPLE code of Julian Faraway and R code of the 
    function pCvM in the package goftest (v1.1.1), permission granted 
    by Adrian Baddeley. Main difference in the implementation: the code 
    here keeps adding terms of the series until the terms are small enough. 
    &quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">_ed2</span><span class="s2">(</span><span class="s1">y</span><span class="s2">):</span>
        <span class="s1">z </span><span class="s2">= </span><span class="s1">y</span><span class="s2">**</span><span class="s4">2 </span><span class="s2">/ </span><span class="s4">4</span>
        <span class="s1">b </span><span class="s2">= </span><span class="s1">kv</span><span class="s2">(</span><span class="s4">1</span><span class="s2">/</span><span class="s4">4</span><span class="s2">, </span><span class="s1">z</span><span class="s2">) + </span><span class="s1">kv</span><span class="s2">(</span><span class="s4">3</span><span class="s2">/</span><span class="s4">4</span><span class="s2">, </span><span class="s1">z</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(-</span><span class="s1">z</span><span class="s2">) * (</span><span class="s1">y</span><span class="s2">/</span><span class="s4">2</span><span class="s2">)**(</span><span class="s4">3</span><span class="s2">/</span><span class="s4">2</span><span class="s2">) * </span><span class="s1">b </span><span class="s2">/ </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sqrt</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">pi</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">_ed3</span><span class="s2">(</span><span class="s1">y</span><span class="s2">):</span>
        <span class="s1">z </span><span class="s2">= </span><span class="s1">y</span><span class="s2">**</span><span class="s4">2 </span><span class="s2">/ </span><span class="s4">4</span>
        <span class="s1">c </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(-</span><span class="s1">z</span><span class="s2">) / </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sqrt</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">pi</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">c </span><span class="s2">* (</span><span class="s1">y</span><span class="s2">/</span><span class="s4">2</span><span class="s2">)**(</span><span class="s4">5</span><span class="s2">/</span><span class="s4">2</span><span class="s2">) * (</span><span class="s4">2</span><span class="s2">*</span><span class="s1">kv</span><span class="s2">(</span><span class="s4">1</span><span class="s2">/</span><span class="s4">4</span><span class="s2">, </span><span class="s1">z</span><span class="s2">) + </span><span class="s4">3</span><span class="s2">*</span><span class="s1">kv</span><span class="s2">(</span><span class="s4">3</span><span class="s2">/</span><span class="s4">4</span><span class="s2">, </span><span class="s1">z</span><span class="s2">) - </span><span class="s1">kv</span><span class="s2">(</span><span class="s4">5</span><span class="s2">/</span><span class="s4">4</span><span class="s2">, </span><span class="s1">z</span><span class="s2">))</span>

    <span class="s0">def </span><span class="s1">_Ak</span><span class="s2">(</span><span class="s1">k</span><span class="s2">, </span><span class="s1">x</span><span class="s2">):</span>
        <span class="s1">m </span><span class="s2">= </span><span class="s4">2</span><span class="s2">*</span><span class="s1">k </span><span class="s2">+ </span><span class="s4">1</span>
        <span class="s1">sx </span><span class="s2">= </span><span class="s4">2 </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sqrt</span><span class="s2">(</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s1">y1 </span><span class="s2">= </span><span class="s1">x</span><span class="s2">**(</span><span class="s4">3</span><span class="s2">/</span><span class="s4">4</span><span class="s2">)</span>
        <span class="s1">y2 </span><span class="s2">= </span><span class="s1">x</span><span class="s2">**(</span><span class="s4">5</span><span class="s2">/</span><span class="s4">4</span><span class="s2">)</span>

        <span class="s1">e1 </span><span class="s2">= </span><span class="s1">m </span><span class="s2">* </span><span class="s1">gamma</span><span class="s2">(</span><span class="s1">k </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">/</span><span class="s4">2</span><span class="s2">) * </span><span class="s1">_ed2</span><span class="s2">((</span><span class="s4">4 </span><span class="s2">* </span><span class="s1">k </span><span class="s2">+ </span><span class="s4">3</span><span class="s2">)/</span><span class="s1">sx</span><span class="s2">) / (</span><span class="s4">9 </span><span class="s2">* </span><span class="s1">y1</span><span class="s2">)</span>
        <span class="s1">e2 </span><span class="s2">= </span><span class="s1">gamma</span><span class="s2">(</span><span class="s1">k </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">/</span><span class="s4">2</span><span class="s2">) * </span><span class="s1">_ed3</span><span class="s2">((</span><span class="s4">4 </span><span class="s2">* </span><span class="s1">k </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">) / </span><span class="s1">sx</span><span class="s2">) / (</span><span class="s4">72 </span><span class="s2">* </span><span class="s1">y2</span><span class="s2">)</span>
        <span class="s1">e3 </span><span class="s2">= </span><span class="s4">2 </span><span class="s2">* (</span><span class="s1">m </span><span class="s2">+ </span><span class="s4">2</span><span class="s2">) * </span><span class="s1">gamma</span><span class="s2">(</span><span class="s1">k </span><span class="s2">+ </span><span class="s4">3</span><span class="s2">/</span><span class="s4">2</span><span class="s2">) * </span><span class="s1">_ed3</span><span class="s2">((</span><span class="s4">4 </span><span class="s2">* </span><span class="s1">k </span><span class="s2">+ </span><span class="s4">5</span><span class="s2">) / </span><span class="s1">sx</span><span class="s2">) / (</span><span class="s4">12 </span><span class="s2">* </span><span class="s1">y2</span><span class="s2">)</span>
        <span class="s1">e4 </span><span class="s2">= </span><span class="s4">7 </span><span class="s2">* </span><span class="s1">m </span><span class="s2">* </span><span class="s1">gamma</span><span class="s2">(</span><span class="s1">k </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">/</span><span class="s4">2</span><span class="s2">) * </span><span class="s1">_ed2</span><span class="s2">((</span><span class="s4">4 </span><span class="s2">* </span><span class="s1">k </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">) / </span><span class="s1">sx</span><span class="s2">) / (</span><span class="s4">144 </span><span class="s2">* </span><span class="s1">y1</span><span class="s2">)</span>
        <span class="s1">e5 </span><span class="s2">= </span><span class="s4">7 </span><span class="s2">* </span><span class="s1">m </span><span class="s2">* </span><span class="s1">gamma</span><span class="s2">(</span><span class="s1">k </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">/</span><span class="s4">2</span><span class="s2">) * </span><span class="s1">_ed2</span><span class="s2">((</span><span class="s4">4 </span><span class="s2">* </span><span class="s1">k </span><span class="s2">+ </span><span class="s4">5</span><span class="s2">) / </span><span class="s1">sx</span><span class="s2">) / (</span><span class="s4">144 </span><span class="s2">* </span><span class="s1">y1</span><span class="s2">)</span>

        <span class="s0">return </span><span class="s1">e1 </span><span class="s2">+ </span><span class="s1">e2 </span><span class="s2">+ </span><span class="s1">e3 </span><span class="s2">+ </span><span class="s1">e4 </span><span class="s2">+ </span><span class="s1">e5</span>

    <span class="s1">x </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s1">tot </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros_like</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s3">'float'</span><span class="s2">)</span>
    <span class="s1">cond </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones_like</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s3">'bool'</span><span class="s2">)</span>
    <span class="s1">k </span><span class="s2">= </span><span class="s4">0</span>
    <span class="s0">while </span><span class="s1">np</span><span class="s2">.</span><span class="s1">any</span><span class="s2">(</span><span class="s1">cond</span><span class="s2">):</span>
        <span class="s1">z </span><span class="s2">= -</span><span class="s1">_Ak</span><span class="s2">(</span><span class="s1">k</span><span class="s2">, </span><span class="s1">x</span><span class="s2">[</span><span class="s1">cond</span><span class="s2">]) / (</span><span class="s1">np</span><span class="s2">.</span><span class="s1">pi </span><span class="s2">* </span><span class="s1">gamma</span><span class="s2">(</span><span class="s1">k </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">))</span>
        <span class="s1">tot</span><span class="s2">[</span><span class="s1">cond</span><span class="s2">] = </span><span class="s1">tot</span><span class="s2">[</span><span class="s1">cond</span><span class="s2">] + </span><span class="s1">z</span>
        <span class="s1">cond</span><span class="s2">[</span><span class="s1">cond</span><span class="s2">] = </span><span class="s1">np</span><span class="s2">.</span><span class="s1">abs</span><span class="s2">(</span><span class="s1">z</span><span class="s2">) &gt;= </span><span class="s4">1e-7</span>
        <span class="s1">k </span><span class="s2">+= </span><span class="s4">1</span>

    <span class="s0">return </span><span class="s1">tot</span>


<span class="s0">def </span><span class="s1">_cdf_cvm_inf</span><span class="s2">(</span><span class="s1">x</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot; 
    Calculate the cdf of the Cramér-von Mises statistic (infinite sample size). 
 
    See equation 1.2 in Csörgő, S. and Faraway, J. (1996). 
 
    Implementation based on MAPLE code of Julian Faraway and R code of the 
    function pCvM in the package goftest (v1.1.1), permission granted 
    by Adrian Baddeley. Main difference in the implementation: the code 
    here keeps adding terms of the series until the terms are small enough. 
 
    The function is not expected to be accurate for large values of x, say 
    x &gt; 4, when the cdf is very close to 1. 
    &quot;&quot;&quot;</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">x</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">term</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">k</span><span class="s2">):</span>
        <span class="s6"># this expression can be found in [2], second line of (1.3)</span>
        <span class="s1">u </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(</span><span class="s1">gammaln</span><span class="s2">(</span><span class="s1">k </span><span class="s2">+ </span><span class="s4">0.5</span><span class="s2">) - </span><span class="s1">gammaln</span><span class="s2">(</span><span class="s1">k</span><span class="s2">+</span><span class="s4">1</span><span class="s2">)) / (</span><span class="s1">np</span><span class="s2">.</span><span class="s1">pi</span><span class="s2">**</span><span class="s4">1.5 </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sqrt</span><span class="s2">(</span><span class="s1">x</span><span class="s2">))</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s4">4</span><span class="s2">*</span><span class="s1">k </span><span class="s2">+ </span><span class="s4">1</span>
        <span class="s1">q </span><span class="s2">= </span><span class="s1">y</span><span class="s2">**</span><span class="s4">2 </span><span class="s2">/ (</span><span class="s4">16</span><span class="s2">*</span><span class="s1">x</span><span class="s2">)</span>
        <span class="s1">b </span><span class="s2">= </span><span class="s1">kv</span><span class="s2">(</span><span class="s4">0.25</span><span class="s2">, </span><span class="s1">q</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">u </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sqrt</span><span class="s2">(</span><span class="s1">y</span><span class="s2">) * </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(-</span><span class="s1">q</span><span class="s2">) * </span><span class="s1">b</span>

    <span class="s1">tot </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros_like</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s3">'float'</span><span class="s2">)</span>
    <span class="s1">cond </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones_like</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s3">'bool'</span><span class="s2">)</span>
    <span class="s1">k </span><span class="s2">= </span><span class="s4">0</span>
    <span class="s0">while </span><span class="s1">np</span><span class="s2">.</span><span class="s1">any</span><span class="s2">(</span><span class="s1">cond</span><span class="s2">):</span>
        <span class="s1">z </span><span class="s2">= </span><span class="s1">term</span><span class="s2">(</span><span class="s1">x</span><span class="s2">[</span><span class="s1">cond</span><span class="s2">], </span><span class="s1">k</span><span class="s2">)</span>
        <span class="s1">tot</span><span class="s2">[</span><span class="s1">cond</span><span class="s2">] = </span><span class="s1">tot</span><span class="s2">[</span><span class="s1">cond</span><span class="s2">] + </span><span class="s1">z</span>
        <span class="s1">cond</span><span class="s2">[</span><span class="s1">cond</span><span class="s2">] = </span><span class="s1">np</span><span class="s2">.</span><span class="s1">abs</span><span class="s2">(</span><span class="s1">z</span><span class="s2">) &gt;= </span><span class="s4">1e-7</span>
        <span class="s1">k </span><span class="s2">+= </span><span class="s4">1</span>

    <span class="s0">return </span><span class="s1">tot</span>


<span class="s0">def </span><span class="s1">_cdf_cvm</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">n</span><span class="s2">=</span><span class="s0">None</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot; 
    Calculate the cdf of the Cramér-von Mises statistic for a finite sample 
    size n. If N is None, use the asymptotic cdf (n=inf). 
 
    See equation 1.8 in Csörgő, S. and Faraway, J. (1996) for finite samples, 
    1.2 for the asymptotic cdf. 
 
    The function is not expected to be accurate for large values of x, say 
    x &gt; 2, when the cdf is very close to 1 and it might return values &gt; 1 
    in that case, e.g. _cdf_cvm(2.0, 12) = 1.0000027556716846. Moreover, it 
    is not accurate for small values of n, especially close to the bounds of 
    the distribution's domain, [1/(12*n), n/3], where the value jumps to 0 
    and 1, respectively. These are limitations of the approximation by Csörgő 
    and Faraway (1996) implemented in this function. 
    &quot;&quot;&quot;</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">n </span><span class="s0">is None</span><span class="s2">:</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">_cdf_cvm_inf</span><span class="s2">(</span><span class="s1">x</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s6"># support of the test statistic is [12/n, n/3], see 1.1 in [2]</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros_like</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s3">'float'</span><span class="s2">)</span>
        <span class="s1">sup </span><span class="s2">= (</span><span class="s4">1.</span><span class="s2">/(</span><span class="s4">12</span><span class="s2">*</span><span class="s1">n</span><span class="s2">) &lt; </span><span class="s1">x</span><span class="s2">) &amp; (</span><span class="s1">x </span><span class="s2">&lt; </span><span class="s1">n</span><span class="s2">/</span><span class="s4">3.</span><span class="s2">)</span>
        <span class="s6"># note: _psi1_mod does not include the term _cdf_cvm_inf(x) / 12</span>
        <span class="s6"># therefore, we need to add it here</span>
        <span class="s1">y</span><span class="s2">[</span><span class="s1">sup</span><span class="s2">] = </span><span class="s1">_cdf_cvm_inf</span><span class="s2">(</span><span class="s1">x</span><span class="s2">[</span><span class="s1">sup</span><span class="s2">]) * (</span><span class="s4">1 </span><span class="s2">+ </span><span class="s4">1.</span><span class="s2">/(</span><span class="s4">12</span><span class="s2">*</span><span class="s1">n</span><span class="s2">)) + </span><span class="s1">_psi1_mod</span><span class="s2">(</span><span class="s1">x</span><span class="s2">[</span><span class="s1">sup</span><span class="s2">]) / </span><span class="s1">n</span>
        <span class="s1">y</span><span class="s2">[</span><span class="s1">x </span><span class="s2">&gt;= </span><span class="s1">n</span><span class="s2">/</span><span class="s4">3</span><span class="s2">] = </span><span class="s4">1</span>

    <span class="s0">if </span><span class="s1">y</span><span class="s2">.</span><span class="s1">ndim </span><span class="s2">== </span><span class="s4">0</span><span class="s2">:</span>
        <span class="s0">return </span><span class="s1">y</span><span class="s2">[()]</span>
    <span class="s0">return </span><span class="s1">y</span>


<span class="s0">def </span><span class="s1">_cvm_result_to_tuple</span><span class="s2">(</span><span class="s1">res</span><span class="s2">):</span>
    <span class="s0">return </span><span class="s1">res</span><span class="s2">.</span><span class="s1">statistic</span><span class="s2">, </span><span class="s1">res</span><span class="s2">.</span><span class="s1">pvalue</span>


<span class="s2">@</span><span class="s1">_axis_nan_policy_factory</span><span class="s2">(</span><span class="s1">CramerVonMisesResult</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">too_small</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
                          <span class="s1">result_to_tuple</span><span class="s2">=</span><span class="s1">_cvm_result_to_tuple</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">cramervonmises</span><span class="s2">(</span><span class="s1">rvs</span><span class="s2">, </span><span class="s1">cdf</span><span class="s2">, </span><span class="s1">args</span><span class="s2">=()):</span>
    <span class="s5">&quot;&quot;&quot;Perform the one-sample Cramér-von Mises test for goodness of fit. 
 
    This performs a test of the goodness of fit of a cumulative distribution 
    function (cdf) :math:`F` compared to the empirical distribution function 
    :math:`F_n` of observed random variates :math:`X_1, ..., X_n` that are 
    assumed to be independent and identically distributed ([1]_). 
    The null hypothesis is that the :math:`X_i` have cumulative distribution 
    :math:`F`. 
 
    Parameters 
    ---------- 
    rvs : array_like 
        A 1-D array of observed values of the random variables :math:`X_i`. 
        The sample must contain at least two observations. 
    cdf : str or callable 
        The cumulative distribution function :math:`F` to test the 
        observations against. If a string, it should be the name of a 
        distribution in `scipy.stats`. If a callable, that callable is used 
        to calculate the cdf: ``cdf(x, *args) -&gt; float``. 
    args : tuple, optional 
        Distribution parameters. These are assumed to be known; see Notes. 
 
    Returns 
    ------- 
    res : object with attributes 
        statistic : float 
            Cramér-von Mises statistic. 
        pvalue : float 
            The p-value. 
 
    See Also 
    -------- 
    kstest, cramervonmises_2samp 
 
    Notes 
    ----- 
    .. versionadded:: 1.6.0 
 
    The p-value relies on the approximation given by equation 1.8 in [2]_. 
    It is important to keep in mind that the p-value is only accurate if 
    one tests a simple hypothesis, i.e. the parameters of the reference 
    distribution are known. If the parameters are estimated from the data 
    (composite hypothesis), the computed p-value is not reliable. 
 
    References 
    ---------- 
    .. [1] Cramér-von Mises criterion, Wikipedia, 
           https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93von_Mises_criterion 
    .. [2] Csörgő, S. and Faraway, J. (1996). The Exact and Asymptotic 
           Distribution of Cramér-von Mises Statistics. Journal of the 
           Royal Statistical Society, pp. 221-234. 
 
    Examples 
    -------- 
 
    Suppose we wish to test whether data generated by ``scipy.stats.norm.rvs`` 
    were, in fact, drawn from the standard normal distribution. We choose a 
    significance level of ``alpha=0.05``. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy import stats 
    &gt;&gt;&gt; rng = np.random.default_rng(165417232101553420507139617764912913465) 
    &gt;&gt;&gt; x = stats.norm.rvs(size=500, random_state=rng) 
    &gt;&gt;&gt; res = stats.cramervonmises(x, 'norm') 
    &gt;&gt;&gt; res.statistic, res.pvalue 
    (0.1072085112565724, 0.5508482238203407) 
 
    The p-value exceeds our chosen significance level, so we do not 
    reject the null hypothesis that the observed sample is drawn from the 
    standard normal distribution. 
 
    Now suppose we wish to check whether the same samples shifted by 2.1 is 
    consistent with being drawn from a normal distribution with a mean of 2. 
 
    &gt;&gt;&gt; y = x + 2.1 
    &gt;&gt;&gt; res = stats.cramervonmises(y, 'norm', args=(2,)) 
    &gt;&gt;&gt; res.statistic, res.pvalue 
    (0.8364446265294695, 0.00596286797008283) 
 
    Here we have used the `args` keyword to specify the mean (``loc``) 
    of the normal distribution to test the data against. This is equivalent 
    to the following, in which we create a frozen normal distribution with 
    mean 2.1, then pass its ``cdf`` method as an argument. 
 
    &gt;&gt;&gt; frozen_dist = stats.norm(loc=2) 
    &gt;&gt;&gt; res = stats.cramervonmises(y, frozen_dist.cdf) 
    &gt;&gt;&gt; res.statistic, res.pvalue 
    (0.8364446265294695, 0.00596286797008283) 
 
    In either case, we would reject the null hypothesis that the observed 
    sample is drawn from a normal distribution with a mean of 2 (and default 
    variance of 1) because the p-value is less than our chosen 
    significance level. 
 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">isinstance</span><span class="s2">(</span><span class="s1">cdf</span><span class="s2">, </span><span class="s1">str</span><span class="s2">):</span>
        <span class="s1">cdf </span><span class="s2">= </span><span class="s1">getattr</span><span class="s2">(</span><span class="s1">distributions</span><span class="s2">, </span><span class="s1">cdf</span><span class="s2">).</span><span class="s1">cdf</span>

    <span class="s1">vals </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sort</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">rvs</span><span class="s2">))</span>

    <span class="s0">if </span><span class="s1">vals</span><span class="s2">.</span><span class="s1">size </span><span class="s2">&lt;= </span><span class="s4">1</span><span class="s2">:</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">'The sample must contain at least two observations.'</span><span class="s2">)</span>

    <span class="s1">n </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">vals</span><span class="s2">)</span>
    <span class="s1">cdfvals </span><span class="s2">= </span><span class="s1">cdf</span><span class="s2">(</span><span class="s1">vals</span><span class="s2">, *</span><span class="s1">args</span><span class="s2">)</span>

    <span class="s1">u </span><span class="s2">= (</span><span class="s4">2</span><span class="s2">*</span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">n</span><span class="s2">+</span><span class="s4">1</span><span class="s2">) - </span><span class="s4">1</span><span class="s2">)/(</span><span class="s4">2</span><span class="s2">*</span><span class="s1">n</span><span class="s2">)</span>
    <span class="s1">w </span><span class="s2">= </span><span class="s4">1</span><span class="s2">/(</span><span class="s4">12</span><span class="s2">*</span><span class="s1">n</span><span class="s2">) + </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">((</span><span class="s1">u </span><span class="s2">- </span><span class="s1">cdfvals</span><span class="s2">)**</span><span class="s4">2</span><span class="s2">)</span>

    <span class="s6"># avoid small negative values that can occur due to the approximation</span>
    <span class="s1">p </span><span class="s2">= </span><span class="s1">max</span><span class="s2">(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1. </span><span class="s2">- </span><span class="s1">_cdf_cvm</span><span class="s2">(</span><span class="s1">w</span><span class="s2">, </span><span class="s1">n</span><span class="s2">))</span>

    <span class="s0">return </span><span class="s1">CramerVonMisesResult</span><span class="s2">(</span><span class="s1">statistic</span><span class="s2">=</span><span class="s1">w</span><span class="s2">, </span><span class="s1">pvalue</span><span class="s2">=</span><span class="s1">p</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">_get_wilcoxon_distr</span><span class="s2">(</span><span class="s1">n</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot; 
    Distribution of probability of the Wilcoxon ranksum statistic r_plus (sum 
    of ranks of positive differences). 
    Returns an array with the probabilities of all the possible ranks 
    r = 0, ..., n*(n+1)/2 
    &quot;&quot;&quot;</span>
    <span class="s1">c </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
    <span class="s0">for </span><span class="s1">k </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">n </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">):</span>
        <span class="s1">prev_c </span><span class="s2">= </span><span class="s1">c</span>
        <span class="s1">c </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s1">k </span><span class="s2">* (</span><span class="s1">k </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">) // </span><span class="s4">2 </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
        <span class="s1">m </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">prev_c</span><span class="s2">)</span>
        <span class="s1">c</span><span class="s2">[:</span><span class="s1">m</span><span class="s2">] = </span><span class="s1">prev_c </span><span class="s2">* </span><span class="s4">0.5</span>
        <span class="s1">c</span><span class="s2">[-</span><span class="s1">m</span><span class="s2">:] += </span><span class="s1">prev_c </span><span class="s2">* </span><span class="s4">0.5</span>
    <span class="s0">return </span><span class="s1">c</span>


<span class="s0">def </span><span class="s1">_get_wilcoxon_distr2</span><span class="s2">(</span><span class="s1">n</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot; 
    Distribution of probability of the Wilcoxon ranksum statistic r_plus (sum 
    of ranks of positive differences). 
    Returns an array with the probabilities of all the possible ranks 
    r = 0, ..., n*(n+1)/2 
    This is a slower reference function 
    References 
    ---------- 
    .. [1] 1. Harris T, Hardin JW. Exact Wilcoxon Signed-Rank and Wilcoxon 
        Mann-Whitney Ranksum Tests. The Stata Journal. 2013;13(2):337-343. 
    &quot;&quot;&quot;</span>
    <span class="s1">ai </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">n</span><span class="s2">+</span><span class="s4">1</span><span class="s2">)[:, </span><span class="s0">None</span><span class="s2">]</span>
    <span class="s1">t </span><span class="s2">= </span><span class="s1">n</span><span class="s2">*(</span><span class="s1">n</span><span class="s2">+</span><span class="s4">1</span><span class="s2">)/</span><span class="s4">2</span>
    <span class="s1">q </span><span class="s2">= </span><span class="s4">2</span><span class="s2">*</span><span class="s1">t</span>
    <span class="s1">j </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">q</span><span class="s2">)</span>
    <span class="s1">theta </span><span class="s2">= </span><span class="s4">2</span><span class="s2">*</span><span class="s1">np</span><span class="s2">.</span><span class="s1">pi</span><span class="s2">/</span><span class="s1">q</span><span class="s2">*</span><span class="s1">j</span>
    <span class="s1">phi_sp </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">prod</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">cos</span><span class="s2">(</span><span class="s1">theta</span><span class="s2">*</span><span class="s1">ai</span><span class="s2">), </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">phi_s </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(</span><span class="s4">1j</span><span class="s2">*</span><span class="s1">theta</span><span class="s2">*</span><span class="s1">t</span><span class="s2">) * </span><span class="s1">phi_sp</span>
    <span class="s1">p </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">real</span><span class="s2">(</span><span class="s1">ifft</span><span class="s2">(</span><span class="s1">phi_s</span><span class="s2">))</span>
    <span class="s1">res </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s1">int</span><span class="s2">(</span><span class="s1">t</span><span class="s2">)+</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">res</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">:] = </span><span class="s1">p</span><span class="s2">[::</span><span class="s4">2</span><span class="s2">]</span>
    <span class="s1">res</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] /= </span><span class="s4">2</span>
    <span class="s1">res</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">] = </span><span class="s1">res</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]</span>
    <span class="s0">return </span><span class="s1">res</span>


<span class="s0">def </span><span class="s1">_tau_b</span><span class="s2">(</span><span class="s1">A</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Calculate Kendall's tau-b and p-value from contingency table.&quot;&quot;&quot;</span>
    <span class="s6"># See [2] 2.2 and 4.2</span>

    <span class="s6"># contingency table must be truly 2D</span>
    <span class="s0">if </span><span class="s1">A</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] == </span><span class="s4">1 </span><span class="s0">or </span><span class="s1">A</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">] == </span><span class="s4">1</span><span class="s2">:</span>
        <span class="s0">return </span><span class="s1">np</span><span class="s2">.</span><span class="s1">nan</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">nan</span>

    <span class="s1">NA </span><span class="s2">= </span><span class="s1">A</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">()</span>
    <span class="s1">PA </span><span class="s2">= </span><span class="s1">_P</span><span class="s2">(</span><span class="s1">A</span><span class="s2">)</span>
    <span class="s1">QA </span><span class="s2">= </span><span class="s1">_Q</span><span class="s2">(</span><span class="s1">A</span><span class="s2">)</span>
    <span class="s1">Sri2 </span><span class="s2">= (</span><span class="s1">A</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)**</span><span class="s4">2</span><span class="s2">).</span><span class="s1">sum</span><span class="s2">()</span>
    <span class="s1">Scj2 </span><span class="s2">= (</span><span class="s1">A</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)**</span><span class="s4">2</span><span class="s2">).</span><span class="s1">sum</span><span class="s2">()</span>
    <span class="s1">denominator </span><span class="s2">= (</span><span class="s1">NA</span><span class="s2">**</span><span class="s4">2 </span><span class="s2">- </span><span class="s1">Sri2</span><span class="s2">)*(</span><span class="s1">NA</span><span class="s2">**</span><span class="s4">2 </span><span class="s2">- </span><span class="s1">Scj2</span><span class="s2">)</span>

    <span class="s1">tau </span><span class="s2">= (</span><span class="s1">PA</span><span class="s2">-</span><span class="s1">QA</span><span class="s2">)/(</span><span class="s1">denominator</span><span class="s2">)**</span><span class="s4">0.5</span>

    <span class="s1">numerator </span><span class="s2">= </span><span class="s4">4</span><span class="s2">*(</span><span class="s1">_a_ij_Aij_Dij2</span><span class="s2">(</span><span class="s1">A</span><span class="s2">) - (</span><span class="s1">PA </span><span class="s2">- </span><span class="s1">QA</span><span class="s2">)**</span><span class="s4">2 </span><span class="s2">/ </span><span class="s1">NA</span><span class="s2">)</span>
    <span class="s1">s02_tau_b </span><span class="s2">= </span><span class="s1">numerator</span><span class="s2">/</span><span class="s1">denominator</span>
    <span class="s0">if </span><span class="s1">s02_tau_b </span><span class="s2">== </span><span class="s4">0</span><span class="s2">:  </span><span class="s6"># Avoid divide by zero</span>
        <span class="s0">return </span><span class="s1">tau</span><span class="s2">, </span><span class="s4">0</span>
    <span class="s1">Z </span><span class="s2">= </span><span class="s1">tau</span><span class="s2">/</span><span class="s1">s02_tau_b</span><span class="s2">**</span><span class="s4">0.5</span>
    <span class="s1">p </span><span class="s2">= </span><span class="s4">2</span><span class="s2">*</span><span class="s1">norm</span><span class="s2">.</span><span class="s1">sf</span><span class="s2">(</span><span class="s1">abs</span><span class="s2">(</span><span class="s1">Z</span><span class="s2">))  </span><span class="s6"># 2-sided p-value</span>

    <span class="s0">return </span><span class="s1">tau</span><span class="s2">, </span><span class="s1">p</span>


<span class="s0">def </span><span class="s1">_somers_d</span><span class="s2">(</span><span class="s1">A</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">=</span><span class="s3">'two-sided'</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Calculate Somers' D and p-value from contingency table.&quot;&quot;&quot;</span>
    <span class="s6"># See [3] page 1740</span>

    <span class="s6"># contingency table must be truly 2D</span>
    <span class="s0">if </span><span class="s1">A</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] &lt;= </span><span class="s4">1 </span><span class="s0">or </span><span class="s1">A</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">] &lt;= </span><span class="s4">1</span><span class="s2">:</span>
        <span class="s0">return </span><span class="s1">np</span><span class="s2">.</span><span class="s1">nan</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">nan</span>

    <span class="s1">NA </span><span class="s2">= </span><span class="s1">A</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">()</span>
    <span class="s1">NA2 </span><span class="s2">= </span><span class="s1">NA</span><span class="s2">**</span><span class="s4">2</span>
    <span class="s1">PA </span><span class="s2">= </span><span class="s1">_P</span><span class="s2">(</span><span class="s1">A</span><span class="s2">)</span>
    <span class="s1">QA </span><span class="s2">= </span><span class="s1">_Q</span><span class="s2">(</span><span class="s1">A</span><span class="s2">)</span>
    <span class="s1">Sri2 </span><span class="s2">= (</span><span class="s1">A</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)**</span><span class="s4">2</span><span class="s2">).</span><span class="s1">sum</span><span class="s2">()</span>

    <span class="s1">d </span><span class="s2">= (</span><span class="s1">PA </span><span class="s2">- </span><span class="s1">QA</span><span class="s2">)/(</span><span class="s1">NA2 </span><span class="s2">- </span><span class="s1">Sri2</span><span class="s2">)</span>

    <span class="s1">S </span><span class="s2">= </span><span class="s1">_a_ij_Aij_Dij2</span><span class="s2">(</span><span class="s1">A</span><span class="s2">) - (</span><span class="s1">PA</span><span class="s2">-</span><span class="s1">QA</span><span class="s2">)**</span><span class="s4">2</span><span class="s2">/</span><span class="s1">NA</span>

    <span class="s0">with </span><span class="s1">np</span><span class="s2">.</span><span class="s1">errstate</span><span class="s2">(</span><span class="s1">divide</span><span class="s2">=</span><span class="s3">'ignore'</span><span class="s2">):</span>
        <span class="s1">Z </span><span class="s2">= (</span><span class="s1">PA </span><span class="s2">- </span><span class="s1">QA</span><span class="s2">)/(</span><span class="s4">4</span><span class="s2">*(</span><span class="s1">S</span><span class="s2">))**</span><span class="s4">0.5</span>

    <span class="s1">norm </span><span class="s2">= </span><span class="s1">_stats_py</span><span class="s2">.</span><span class="s1">_SimpleNormal</span><span class="s2">()</span>
    <span class="s1">p </span><span class="s2">= </span><span class="s1">_stats_py</span><span class="s2">.</span><span class="s1">_get_pvalue</span><span class="s2">(</span><span class="s1">Z</span><span class="s2">, </span><span class="s1">norm</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">, </span><span class="s1">xp</span><span class="s2">=</span><span class="s1">np</span><span class="s2">)</span>

    <span class="s0">return </span><span class="s1">d</span><span class="s2">, </span><span class="s1">p</span>


<span class="s2">@</span><span class="s1">dataclass</span>
<span class="s0">class </span><span class="s1">SomersDResult</span><span class="s2">:</span>
    <span class="s1">statistic</span><span class="s2">: </span><span class="s1">float</span>
    <span class="s1">pvalue</span><span class="s2">: </span><span class="s1">float</span>
    <span class="s1">table</span><span class="s2">: </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ndarray</span>


<span class="s0">def </span><span class="s1">somersd</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">=</span><span class="s3">'two-sided'</span><span class="s2">):</span>
    <span class="s5">r&quot;&quot;&quot;Calculates Somers' D, an asymmetric measure of ordinal association. 
 
    Like Kendall's :math:`\tau`, Somers' :math:`D` is a measure of the 
    correspondence between two rankings. Both statistics consider the 
    difference between the number of concordant and discordant pairs in two 
    rankings :math:`X` and :math:`Y`, and both are normalized such that values 
    close  to 1 indicate strong agreement and values close to -1 indicate 
    strong disagreement. They differ in how they are normalized. To show the 
    relationship, Somers' :math:`D` can be defined in terms of Kendall's 
    :math:`\tau_a`: 
 
    .. math:: 
        D(Y|X) = \frac{\tau_a(X, Y)}{\tau_a(X, X)} 
 
    Suppose the first ranking :math:`X` has :math:`r` distinct ranks and the 
    second ranking :math:`Y` has :math:`s` distinct ranks. These two lists of 
    :math:`n` rankings can also be viewed as an :math:`r \times s` contingency 
    table in which element :math:`i, j` is the number of rank pairs with rank 
    :math:`i` in ranking :math:`X` and rank :math:`j` in ranking :math:`Y`. 
    Accordingly, `somersd` also allows the input data to be supplied as a 
    single, 2D contingency table instead of as two separate, 1D rankings. 
 
    Note that the definition of Somers' :math:`D` is asymmetric: in general, 
    :math:`D(Y|X) \neq D(X|Y)`. ``somersd(x, y)`` calculates Somers' 
    :math:`D(Y|X)`: the &quot;row&quot; variable :math:`X` is treated as an independent 
    variable, and the &quot;column&quot; variable :math:`Y` is dependent. For Somers' 
    :math:`D(X|Y)`, swap the input lists or transpose the input table. 
 
    Parameters 
    ---------- 
    x : array_like 
        1D array of rankings, treated as the (row) independent variable. 
        Alternatively, a 2D contingency table. 
    y : array_like, optional 
        If `x` is a 1D array of rankings, `y` is a 1D array of rankings of the 
        same length, treated as the (column) dependent variable. 
        If `x` is 2D, `y` is ignored. 
    alternative : {'two-sided', 'less', 'greater'}, optional 
        Defines the alternative hypothesis. Default is 'two-sided'. 
        The following options are available: 
        * 'two-sided': the rank correlation is nonzero 
        * 'less': the rank correlation is negative (less than zero) 
        * 'greater':  the rank correlation is positive (greater than zero) 
 
    Returns 
    ------- 
    res : SomersDResult 
        A `SomersDResult` object with the following fields: 
 
            statistic : float 
               The Somers' :math:`D` statistic. 
            pvalue : float 
               The p-value for a hypothesis test whose null 
               hypothesis is an absence of association, :math:`D=0`. 
               See notes for more information. 
            table : 2D array 
               The contingency table formed from rankings `x` and `y` (or the 
               provided contingency table, if `x` is a 2D array) 
 
    See Also 
    -------- 
    kendalltau : Calculates Kendall's tau, another correlation measure. 
    weightedtau : Computes a weighted version of Kendall's tau. 
    spearmanr : Calculates a Spearman rank-order correlation coefficient. 
    pearsonr : Calculates a Pearson correlation coefficient. 
 
    Notes 
    ----- 
    This function follows the contingency table approach of [2]_ and 
    [3]_. *p*-values are computed based on an asymptotic approximation of 
    the test statistic distribution under the null hypothesis :math:`D=0`. 
 
    Theoretically, hypothesis tests based on Kendall's :math:`tau` and Somers' 
    :math:`D` should be identical. 
    However, the *p*-values returned by `kendalltau` are based 
    on the null hypothesis of *independence* between :math:`X` and :math:`Y` 
    (i.e. the population from which pairs in :math:`X` and :math:`Y` are 
    sampled contains equal numbers of all possible pairs), which is more 
    specific than the null hypothesis :math:`D=0` used here. If the null 
    hypothesis of independence is desired, it is acceptable to use the 
    *p*-value returned by `kendalltau` with the statistic returned by 
    `somersd` and vice versa. For more information, see [2]_. 
 
    Contingency tables are formatted according to the convention used by 
    SAS and R: the first ranking supplied (``x``) is the &quot;row&quot; variable, and 
    the second ranking supplied (``y``) is the &quot;column&quot; variable. This is 
    opposite the convention of Somers' original paper [1]_. 
 
    References 
    ---------- 
    .. [1] Robert H. Somers, &quot;A New Asymmetric Measure of Association for 
           Ordinal Variables&quot;, *American Sociological Review*, Vol. 27, No. 6, 
           pp. 799--811, 1962. 
 
    .. [2] Morton B. Brown and Jacqueline K. Benedetti, &quot;Sampling Behavior of 
           Tests for Correlation in Two-Way Contingency Tables&quot;, *Journal of 
           the American Statistical Association* Vol. 72, No. 358, pp. 
           309--315, 1977. 
 
    .. [3] SAS Institute, Inc., &quot;The FREQ Procedure (Book Excerpt)&quot;, 
           *SAS/STAT 9.2 User's Guide, Second Edition*, SAS Publishing, 2009. 
 
    .. [4] Laerd Statistics, &quot;Somers' d using SPSS Statistics&quot;, *SPSS 
           Statistics Tutorials and Statistical Guides*, 
           https://statistics.laerd.com/spss-tutorials/somers-d-using-spss-statistics.php, 
           Accessed July 31, 2020. 
 
    Examples 
    -------- 
    We calculate Somers' D for the example given in [4]_, in which a hotel 
    chain owner seeks to determine the association between hotel room 
    cleanliness and customer satisfaction. The independent variable, hotel 
    room cleanliness, is ranked on an ordinal scale: &quot;below average (1)&quot;, 
    &quot;average (2)&quot;, or &quot;above average (3)&quot;. The dependent variable, customer 
    satisfaction, is ranked on a second scale: &quot;very dissatisfied (1)&quot;, 
    &quot;moderately dissatisfied (2)&quot;, &quot;neither dissatisfied nor satisfied (3)&quot;, 
    &quot;moderately satisfied (4)&quot;, or &quot;very satisfied (5)&quot;. 189 customers 
    respond to the survey, and the results are cast into a contingency table 
    with the hotel room cleanliness as the &quot;row&quot; variable and customer 
    satisfaction as the &quot;column&quot; variable. 
 
    +-----+-----+-----+-----+-----+-----+ 
    |     | (1) | (2) | (3) | (4) | (5) | 
    +=====+=====+=====+=====+=====+=====+ 
    | (1) | 27  | 25  | 14  | 7   | 0   | 
    +-----+-----+-----+-----+-----+-----+ 
    | (2) | 7   | 14  | 18  | 35  | 12  | 
    +-----+-----+-----+-----+-----+-----+ 
    | (3) | 1   | 3   | 2   | 7   | 17  | 
    +-----+-----+-----+-----+-----+-----+ 
 
    For example, 27 customers assigned their room a cleanliness ranking of 
    &quot;below average (1)&quot; and a corresponding satisfaction of &quot;very 
    dissatisfied (1)&quot;. We perform the analysis as follows. 
 
    &gt;&gt;&gt; from scipy.stats import somersd 
    &gt;&gt;&gt; table = [[27, 25, 14, 7, 0], [7, 14, 18, 35, 12], [1, 3, 2, 7, 17]] 
    &gt;&gt;&gt; res = somersd(table) 
    &gt;&gt;&gt; res.statistic 
    0.6032766111513396 
    &gt;&gt;&gt; res.pvalue 
    1.0007091191074533e-27 
 
    The value of the Somers' D statistic is approximately 0.6, indicating 
    a positive correlation between room cleanliness and customer satisfaction 
    in the sample. 
    The *p*-value is very small, indicating a very small probability of 
    observing such an extreme value of the statistic under the null 
    hypothesis that the statistic of the entire population (from which 
    our sample of 189 customers is drawn) is zero. This supports the 
    alternative hypothesis that the true value of Somers' D for the population 
    is nonzero. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">x</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">x</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">x</span><span class="s2">.</span><span class="s1">ndim </span><span class="s2">== </span><span class="s4">1</span><span class="s2">:</span>
        <span class="s0">if </span><span class="s1">x</span><span class="s2">.</span><span class="s1">size </span><span class="s2">!= </span><span class="s1">y</span><span class="s2">.</span><span class="s1">size</span><span class="s2">:</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;Rankings must be of equal length.&quot;</span><span class="s2">)</span>
        <span class="s1">table </span><span class="s2">= </span><span class="s1">scipy</span><span class="s2">.</span><span class="s1">stats</span><span class="s2">.</span><span class="s1">contingency</span><span class="s2">.</span><span class="s1">crosstab</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)[</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s0">elif </span><span class="s1">x</span><span class="s2">.</span><span class="s1">ndim </span><span class="s2">== </span><span class="s4">2</span><span class="s2">:</span>
        <span class="s0">if </span><span class="s1">np</span><span class="s2">.</span><span class="s1">any</span><span class="s2">(</span><span class="s1">x </span><span class="s2">&lt; </span><span class="s4">0</span><span class="s2">):</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;All elements of the contingency table must be &quot;</span>
                             <span class="s3">&quot;non-negative.&quot;</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">np</span><span class="s2">.</span><span class="s1">any</span><span class="s2">(</span><span class="s1">x </span><span class="s2">!= </span><span class="s1">x</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">int</span><span class="s2">)):</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;All elements of the contingency table must be &quot;</span>
                             <span class="s3">&quot;integer.&quot;</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">x</span><span class="s2">.</span><span class="s1">nonzero</span><span class="s2">()[</span><span class="s4">0</span><span class="s2">].</span><span class="s1">size </span><span class="s2">&lt; </span><span class="s4">2</span><span class="s2">:</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;At least two elements of the contingency table &quot;</span>
                             <span class="s3">&quot;must be nonzero.&quot;</span><span class="s2">)</span>
        <span class="s1">table </span><span class="s2">= </span><span class="s1">x</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;x must be either a 1D or 2D array&quot;</span><span class="s2">)</span>
    <span class="s6"># The table type is converted to a float to avoid an integer overflow</span>
    <span class="s1">d</span><span class="s2">, </span><span class="s1">p </span><span class="s2">= </span><span class="s1">_somers_d</span><span class="s2">(</span><span class="s1">table</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">float</span><span class="s2">), </span><span class="s1">alternative</span><span class="s2">)</span>

    <span class="s6"># add alias for consistency with other correlation functions</span>
    <span class="s1">res </span><span class="s2">= </span><span class="s1">SomersDResult</span><span class="s2">(</span><span class="s1">d</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">table</span><span class="s2">)</span>
    <span class="s1">res</span><span class="s2">.</span><span class="s1">correlation </span><span class="s2">= </span><span class="s1">d</span>
    <span class="s0">return </span><span class="s1">res</span>


<span class="s6"># This could be combined with `_all_partitions` in `_resampling.py`</span>
<span class="s0">def </span><span class="s1">_all_partitions</span><span class="s2">(</span><span class="s1">nx</span><span class="s2">, </span><span class="s1">ny</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot; 
    Partition a set of indices into two fixed-length sets in all possible ways 
 
    Partition a set of indices 0 ... nx + ny - 1 into two sets of length nx and 
    ny in all possible ways (ignoring order of elements). 
    &quot;&quot;&quot;</span>
    <span class="s1">z </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">nx</span><span class="s2">+</span><span class="s1">ny</span><span class="s2">)</span>
    <span class="s0">for </span><span class="s1">c </span><span class="s0">in </span><span class="s1">combinations</span><span class="s2">(</span><span class="s1">z</span><span class="s2">, </span><span class="s1">nx</span><span class="s2">):</span>
        <span class="s1">x </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">c</span><span class="s2">)</span>
        <span class="s1">mask </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">nx</span><span class="s2">+</span><span class="s1">ny</span><span class="s2">, </span><span class="s1">bool</span><span class="s2">)</span>
        <span class="s1">mask</span><span class="s2">[</span><span class="s1">x</span><span class="s2">] = </span><span class="s0">False</span>
        <span class="s1">y </span><span class="s2">= </span><span class="s1">z</span><span class="s2">[</span><span class="s1">mask</span><span class="s2">]</span>
        <span class="s0">yield </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span>


<span class="s0">def </span><span class="s1">_compute_log_combinations</span><span class="s2">(</span><span class="s1">n</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Compute all log combination of C(n, k).&quot;&quot;&quot;</span>
    <span class="s1">gammaln_arr </span><span class="s2">= </span><span class="s1">gammaln</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">n </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">) + </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">gammaln</span><span class="s2">(</span><span class="s1">n </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">) - </span><span class="s1">gammaln_arr </span><span class="s2">- </span><span class="s1">gammaln_arr</span><span class="s2">[::-</span><span class="s4">1</span><span class="s2">]</span>


<span class="s2">@</span><span class="s1">dataclass</span>
<span class="s0">class </span><span class="s1">BarnardExactResult</span><span class="s2">:</span>
    <span class="s1">statistic</span><span class="s2">: </span><span class="s1">float</span>
    <span class="s1">pvalue</span><span class="s2">: </span><span class="s1">float</span>


<span class="s0">def </span><span class="s1">barnard_exact</span><span class="s2">(</span><span class="s1">table</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">=</span><span class="s3">&quot;two-sided&quot;</span><span class="s2">, </span><span class="s1">pooled</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">n</span><span class="s2">=</span><span class="s4">32</span><span class="s2">):</span>
    <span class="s5">r&quot;&quot;&quot;Perform a Barnard exact test on a 2x2 contingency table. 
 
    Parameters 
    ---------- 
    table : array_like of ints 
        A 2x2 contingency table.  Elements should be non-negative integers. 
 
    alternative : {'two-sided', 'less', 'greater'}, optional 
        Defines the null and alternative hypotheses. Default is 'two-sided'. 
        Please see explanations in the Notes section below. 
 
    pooled : bool, optional 
        Whether to compute score statistic with pooled variance (as in 
        Student's t-test, for example) or unpooled variance (as in Welch's 
        t-test). Default is ``True``. 
 
    n : int, optional 
        Number of sampling points used in the construction of the sampling 
        method. Note that this argument will automatically be converted to 
        the next higher power of 2 since `scipy.stats.qmc.Sobol` is used to 
        select sample points. Default is 32. Must be positive. In most cases, 
        32 points is enough to reach good precision. More points comes at 
        performance cost. 
 
    Returns 
    ------- 
    ber : BarnardExactResult 
        A result object with the following attributes. 
 
        statistic : float 
            The Wald statistic with pooled or unpooled variance, depending 
            on the user choice of `pooled`. 
 
        pvalue : float 
            P-value, the probability of obtaining a distribution at least as 
            extreme as the one that was actually observed, assuming that the 
            null hypothesis is true. 
 
    See Also 
    -------- 
    chi2_contingency : Chi-square test of independence of variables in a 
        contingency table. 
    fisher_exact : Fisher exact test on a 2x2 contingency table. 
    boschloo_exact : Boschloo's exact test on a 2x2 contingency table, 
        which is an uniformly more powerful alternative to Fisher's exact test. 
 
    Notes 
    ----- 
    Barnard's test is an exact test used in the analysis of contingency 
    tables. It examines the association of two categorical variables, and 
    is a more powerful alternative than Fisher's exact test 
    for 2x2 contingency tables. 
 
    Let's define :math:`X_0` a 2x2 matrix representing the observed sample, 
    where each column stores the binomial experiment, as in the example 
    below. Let's also define :math:`p_1, p_2` the theoretical binomial 
    probabilities for  :math:`x_{11}` and :math:`x_{12}`. When using 
    Barnard exact test, we can assert three different null hypotheses : 
 
    - :math:`H_0 : p_1 \geq p_2` versus :math:`H_1 : p_1 &lt; p_2`, 
      with `alternative` = &quot;less&quot; 
 
    - :math:`H_0 : p_1 \leq p_2` versus :math:`H_1 : p_1 &gt; p_2`, 
      with `alternative` = &quot;greater&quot; 
 
    - :math:`H_0 : p_1 = p_2` versus :math:`H_1 : p_1 \neq p_2`, 
      with `alternative` = &quot;two-sided&quot; (default one) 
 
    In order to compute Barnard's exact test, we are using the Wald 
    statistic [3]_ with pooled or unpooled variance. 
    Under the default assumption that both variances are equal 
    (``pooled = True``), the statistic is computed as: 
 
    .. math:: 
 
        T(X) = \frac{ 
            \hat{p}_1 - \hat{p}_2 
        }{ 
            \sqrt{ 
                \hat{p}(1 - \hat{p}) 
                (\frac{1}{c_1} + 
                \frac{1}{c_2}) 
            } 
        } 
 
    with :math:`\hat{p}_1, \hat{p}_2` and :math:`\hat{p}` the estimator of 
    :math:`p_1, p_2` and :math:`p`, the latter being the combined probability, 
    given the assumption that :math:`p_1 = p_2`. 
 
    If this assumption is invalid (``pooled = False``), the statistic is: 
 
    .. math:: 
 
        T(X) = \frac{ 
            \hat{p}_1 - \hat{p}_2 
        }{ 
            \sqrt{ 
                \frac{\hat{p}_1 (1 - \hat{p}_1)}{c_1} + 
                \frac{\hat{p}_2 (1 - \hat{p}_2)}{c_2} 
            } 
        } 
 
    The p-value is then computed as: 
 
    .. math:: 
 
        \sum 
            \binom{c_1}{x_{11}} 
            \binom{c_2}{x_{12}} 
            \pi^{x_{11} + x_{12}} 
            (1 - \pi)^{t - x_{11} - x_{12}} 
 
    where the sum is over all  2x2 contingency tables :math:`X` such that: 
    * :math:`T(X) \leq T(X_0)` when `alternative` = &quot;less&quot;, 
    * :math:`T(X) \geq T(X_0)` when `alternative` = &quot;greater&quot;, or 
    * :math:`T(X) \geq |T(X_0)|` when `alternative` = &quot;two-sided&quot;. 
    Above, :math:`c_1, c_2` are the sum of the columns 1 and 2, 
    and :math:`t` the total (sum of the 4 sample's element). 
 
    The returned p-value is the maximum p-value taken over the nuisance 
    parameter :math:`\pi`, where :math:`0 \leq \pi \leq 1`. 
 
    This function's complexity is :math:`O(n c_1 c_2)`, where `n` is the 
    number of sample points. 
 
    References 
    ---------- 
    .. [1] Barnard, G. A. &quot;Significance Tests for 2x2 Tables&quot;. *Biometrika*. 
           34.1/2 (1947): 123-138. :doi:`dpgkg3` 
 
    .. [2] Mehta, Cyrus R., and Pralay Senchaudhuri. &quot;Conditional versus 
           unconditional exact tests for comparing two binomials.&quot; 
           *Cytel Software Corporation* 675 (2003): 1-5. 
 
    .. [3] &quot;Wald Test&quot;. *Wikipedia*. https://en.wikipedia.org/wiki/Wald_test 
 
    Examples 
    -------- 
    An example use of Barnard's test is presented in [2]_. 
 
        Consider the following example of a vaccine efficacy study 
        (Chan, 1998). In a randomized clinical trial of 30 subjects, 15 were 
        inoculated with a recombinant DNA influenza vaccine and the 15 were 
        inoculated with a placebo. Twelve of the 15 subjects in the placebo 
        group (80%) eventually became infected with influenza whereas for the 
        vaccine group, only 7 of the 15 subjects (47%) became infected. The 
        data are tabulated as a 2 x 2 table:: 
 
                Vaccine  Placebo 
            Yes     7        12 
            No      8        3 
 
    When working with statistical hypothesis testing, we usually use a 
    threshold probability or significance level upon which we decide 
    to reject the null hypothesis :math:`H_0`. Suppose we choose the common 
    significance level of 5%. 
 
    Our alternative hypothesis is that the vaccine will lower the chance of 
    becoming infected with the virus; that is, the probability :math:`p_1` of 
    catching the virus with the vaccine will be *less than* the probability 
    :math:`p_2` of catching the virus without the vaccine.  Therefore, we call 
    `barnard_exact` with the ``alternative=&quot;less&quot;`` option: 
 
    &gt;&gt;&gt; import scipy.stats as stats 
    &gt;&gt;&gt; res = stats.barnard_exact([[7, 12], [8, 3]], alternative=&quot;less&quot;) 
    &gt;&gt;&gt; res.statistic 
    -1.894 
    &gt;&gt;&gt; res.pvalue 
    0.03407 
 
    Under the null hypothesis that the vaccine will not lower the chance of 
    becoming infected, the probability of obtaining test results at least as 
    extreme as the observed data is approximately 3.4%. Since this p-value is 
    less than our chosen significance level, we have evidence to reject 
    :math:`H_0` in favor of the alternative. 
 
    Suppose we had used Fisher's exact test instead: 
 
    &gt;&gt;&gt; _, pvalue = stats.fisher_exact([[7, 12], [8, 3]], alternative=&quot;less&quot;) 
    &gt;&gt;&gt; pvalue 
    0.0640 
 
    With the same threshold significance of 5%, we would not have been able 
    to reject the null hypothesis in favor of the alternative. As stated in 
    [2]_, Barnard's test is uniformly more powerful than Fisher's exact test 
    because Barnard's test does not condition on any margin. Fisher's test 
    should only be used when both sets of marginals are fixed. 
 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">n </span><span class="s2">&lt;= </span><span class="s4">0</span><span class="s2">:</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
            <span class="s3">&quot;Number of points `n` must be strictly positive, &quot;</span>
            <span class="s3">f&quot;found </span><span class="s0">{</span><span class="s1">n</span><span class="s0">!r}</span><span class="s3">&quot;</span>
        <span class="s2">)</span>

    <span class="s1">table </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">table</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">int64</span><span class="s2">)</span>

    <span class="s0">if not </span><span class="s1">table</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">):</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;The input `table` must be of shape (2, 2).&quot;</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">np</span><span class="s2">.</span><span class="s1">any</span><span class="s2">(</span><span class="s1">table </span><span class="s2">&lt; </span><span class="s4">0</span><span class="s2">):</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;All values in `table` must be nonnegative.&quot;</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s4">0 </span><span class="s0">in </span><span class="s1">table</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">):</span>
        <span class="s6"># If both values in column are zero, the p-value is 1 and</span>
        <span class="s6"># the score's statistic is NaN.</span>
        <span class="s0">return </span><span class="s1">BarnardExactResult</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">nan</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">)</span>

    <span class="s1">total_col_1</span><span class="s2">, </span><span class="s1">total_col_2 </span><span class="s2">= </span><span class="s1">table</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>

    <span class="s1">x1 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">total_col_1 </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">int64</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">x2 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">total_col_2 </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">int64</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">)</span>

    <span class="s6"># We need to calculate the wald statistics for each combination of x1 and</span>
    <span class="s6"># x2.</span>
    <span class="s1">p1</span><span class="s2">, </span><span class="s1">p2 </span><span class="s2">= </span><span class="s1">x1 </span><span class="s2">/ </span><span class="s1">total_col_1</span><span class="s2">, </span><span class="s1">x2 </span><span class="s2">/ </span><span class="s1">total_col_2</span>

    <span class="s0">if </span><span class="s1">pooled</span><span class="s2">:</span>
        <span class="s1">p </span><span class="s2">= (</span><span class="s1">x1 </span><span class="s2">+ </span><span class="s1">x2</span><span class="s2">) / (</span><span class="s1">total_col_1 </span><span class="s2">+ </span><span class="s1">total_col_2</span><span class="s2">)</span>
        <span class="s1">variances </span><span class="s2">= </span><span class="s1">p </span><span class="s2">* (</span><span class="s4">1 </span><span class="s2">- </span><span class="s1">p</span><span class="s2">) * (</span><span class="s4">1 </span><span class="s2">/ </span><span class="s1">total_col_1 </span><span class="s2">+ </span><span class="s4">1 </span><span class="s2">/ </span><span class="s1">total_col_2</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">variances </span><span class="s2">= </span><span class="s1">p1 </span><span class="s2">* (</span><span class="s4">1 </span><span class="s2">- </span><span class="s1">p1</span><span class="s2">) / </span><span class="s1">total_col_1 </span><span class="s2">+ </span><span class="s1">p2 </span><span class="s2">* (</span><span class="s4">1 </span><span class="s2">- </span><span class="s1">p2</span><span class="s2">) / </span><span class="s1">total_col_2</span>

    <span class="s6"># To avoid warning when dividing by 0</span>
    <span class="s0">with </span><span class="s1">np</span><span class="s2">.</span><span class="s1">errstate</span><span class="s2">(</span><span class="s1">divide</span><span class="s2">=</span><span class="s3">&quot;ignore&quot;</span><span class="s2">, </span><span class="s1">invalid</span><span class="s2">=</span><span class="s3">&quot;ignore&quot;</span><span class="s2">):</span>
        <span class="s1">wald_statistic </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">divide</span><span class="s2">((</span><span class="s1">p1 </span><span class="s2">- </span><span class="s1">p2</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sqrt</span><span class="s2">(</span><span class="s1">variances</span><span class="s2">))</span>

    <span class="s1">wald_statistic</span><span class="s2">[</span><span class="s1">p1 </span><span class="s2">== </span><span class="s1">p2</span><span class="s2">] = </span><span class="s4">0  </span><span class="s6"># Removing NaN values</span>

    <span class="s1">wald_stat_obs </span><span class="s2">= </span><span class="s1">wald_statistic</span><span class="s2">[</span><span class="s1">table</span><span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">], </span><span class="s1">table</span><span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]]</span>

    <span class="s0">if </span><span class="s1">alternative </span><span class="s2">== </span><span class="s3">&quot;two-sided&quot;</span><span class="s2">:</span>
        <span class="s1">index_arr </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">abs</span><span class="s2">(</span><span class="s1">wald_statistic</span><span class="s2">) &gt;= </span><span class="s1">abs</span><span class="s2">(</span><span class="s1">wald_stat_obs</span><span class="s2">)</span>
    <span class="s0">elif </span><span class="s1">alternative </span><span class="s2">== </span><span class="s3">&quot;less&quot;</span><span class="s2">:</span>
        <span class="s1">index_arr </span><span class="s2">= </span><span class="s1">wald_statistic </span><span class="s2">&lt;= </span><span class="s1">wald_stat_obs</span>
    <span class="s0">elif </span><span class="s1">alternative </span><span class="s2">== </span><span class="s3">&quot;greater&quot;</span><span class="s2">:</span>
        <span class="s1">index_arr </span><span class="s2">= </span><span class="s1">wald_statistic </span><span class="s2">&gt;= </span><span class="s1">wald_stat_obs</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">msg </span><span class="s2">= (</span>
            <span class="s3">&quot;`alternative` should be one of {'two-sided', 'less', 'greater'},&quot;</span>
            <span class="s3">f&quot; found </span><span class="s0">{</span><span class="s1">alternative</span><span class="s0">!r}</span><span class="s3">&quot;</span>
        <span class="s2">)</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s1">msg</span><span class="s2">)</span>

    <span class="s1">x1_sum_x2 </span><span class="s2">= </span><span class="s1">x1 </span><span class="s2">+ </span><span class="s1">x2</span>

    <span class="s1">x1_log_comb </span><span class="s2">= </span><span class="s1">_compute_log_combinations</span><span class="s2">(</span><span class="s1">total_col_1</span><span class="s2">)</span>
    <span class="s1">x2_log_comb </span><span class="s2">= </span><span class="s1">_compute_log_combinations</span><span class="s2">(</span><span class="s1">total_col_2</span><span class="s2">)</span>
    <span class="s1">x1_sum_x2_log_comb </span><span class="s2">= </span><span class="s1">x1_log_comb</span><span class="s2">[</span><span class="s1">x1</span><span class="s2">] + </span><span class="s1">x2_log_comb</span><span class="s2">[</span><span class="s1">x2</span><span class="s2">]</span>

    <span class="s1">result </span><span class="s2">= </span><span class="s1">shgo</span><span class="s2">(</span>
        <span class="s1">_get_binomial_log_p_value_with_nuisance_param</span><span class="s2">,</span>
        <span class="s1">args</span><span class="s2">=(</span><span class="s1">x1_sum_x2</span><span class="s2">, </span><span class="s1">x1_sum_x2_log_comb</span><span class="s2">, </span><span class="s1">index_arr</span><span class="s2">),</span>
        <span class="s1">bounds</span><span class="s2">=((</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">),),</span>
        <span class="s1">n</span><span class="s2">=</span><span class="s1">n</span><span class="s2">,</span>
        <span class="s1">sampling_method</span><span class="s2">=</span><span class="s3">&quot;sobol&quot;</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s6"># result.fun is the negative log pvalue and therefore needs to be</span>
    <span class="s6"># changed before return</span>
    <span class="s1">p_value </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">clip</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(-</span><span class="s1">result</span><span class="s2">.</span><span class="s1">fun</span><span class="s2">), </span><span class="s1">a_min</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">a_max</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">BarnardExactResult</span><span class="s2">(</span><span class="s1">wald_stat_obs</span><span class="s2">, </span><span class="s1">p_value</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">dataclass</span>
<span class="s0">class </span><span class="s1">BoschlooExactResult</span><span class="s2">:</span>
    <span class="s1">statistic</span><span class="s2">: </span><span class="s1">float</span>
    <span class="s1">pvalue</span><span class="s2">: </span><span class="s1">float</span>


<span class="s0">def </span><span class="s1">boschloo_exact</span><span class="s2">(</span><span class="s1">table</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">=</span><span class="s3">&quot;two-sided&quot;</span><span class="s2">, </span><span class="s1">n</span><span class="s2">=</span><span class="s4">32</span><span class="s2">):</span>
    <span class="s5">r&quot;&quot;&quot;Perform Boschloo's exact test on a 2x2 contingency table. 
 
    Parameters 
    ---------- 
    table : array_like of ints 
        A 2x2 contingency table.  Elements should be non-negative integers. 
 
    alternative : {'two-sided', 'less', 'greater'}, optional 
        Defines the null and alternative hypotheses. Default is 'two-sided'. 
        Please see explanations in the Notes section below. 
 
    n : int, optional 
        Number of sampling points used in the construction of the sampling 
        method. Note that this argument will automatically be converted to 
        the next higher power of 2 since `scipy.stats.qmc.Sobol` is used to 
        select sample points. Default is 32. Must be positive. In most cases, 
        32 points is enough to reach good precision. More points comes at 
        performance cost. 
 
    Returns 
    ------- 
    ber : BoschlooExactResult 
        A result object with the following attributes. 
 
        statistic : float 
            The statistic used in Boschloo's test; that is, the p-value 
            from Fisher's exact test. 
 
        pvalue : float 
            P-value, the probability of obtaining a distribution at least as 
            extreme as the one that was actually observed, assuming that the 
            null hypothesis is true. 
 
    See Also 
    -------- 
    chi2_contingency : Chi-square test of independence of variables in a 
        contingency table. 
    fisher_exact : Fisher exact test on a 2x2 contingency table. 
    barnard_exact : Barnard's exact test, which is a more powerful alternative 
        than Fisher's exact test for 2x2 contingency tables. 
 
    Notes 
    ----- 
    Boschloo's test is an exact test used in the analysis of contingency 
    tables. It examines the association of two categorical variables, and 
    is a uniformly more powerful alternative to Fisher's exact test 
    for 2x2 contingency tables. 
 
    Boschloo's exact test uses the p-value of Fisher's exact test as a 
    statistic, and Boschloo's p-value is the probability under the null 
    hypothesis of observing such an extreme value of this statistic. 
 
    Let's define :math:`X_0` a 2x2 matrix representing the observed sample, 
    where each column stores the binomial experiment, as in the example 
    below. Let's also define :math:`p_1, p_2` the theoretical binomial 
    probabilities for  :math:`x_{11}` and :math:`x_{12}`. When using 
    Boschloo exact test, we can assert three different alternative hypotheses: 
 
    - :math:`H_0 : p_1=p_2` versus :math:`H_1 : p_1 &lt; p_2`, 
      with `alternative` = &quot;less&quot; 
 
    - :math:`H_0 : p_1=p_2` versus :math:`H_1 : p_1 &gt; p_2`, 
      with `alternative` = &quot;greater&quot; 
 
    - :math:`H_0 : p_1=p_2` versus :math:`H_1 : p_1 \neq p_2`, 
      with `alternative` = &quot;two-sided&quot; (default) 
 
    There are multiple conventions for computing a two-sided p-value when the 
    null distribution is asymmetric. Here, we apply the convention that the 
    p-value of a two-sided test is twice the minimum of the p-values of the 
    one-sided tests (clipped to 1.0). Note that `fisher_exact` follows a 
    different convention, so for a given `table`, the statistic reported by 
    `boschloo_exact` may differ from the p-value reported by `fisher_exact` 
    when ``alternative='two-sided'``. 
 
    .. versionadded:: 1.7.0 
 
    References 
    ---------- 
    .. [1] R.D. Boschloo. &quot;Raised conditional level of significance for the 
       2 x 2-table when testing the equality of two probabilities&quot;, 
       Statistica Neerlandica, 24(1), 1970 
 
    .. [2] &quot;Boschloo's test&quot;, Wikipedia, 
       https://en.wikipedia.org/wiki/Boschloo%27s_test 
 
    .. [3] Lise M. Saari et al. &quot;Employee attitudes and job satisfaction&quot;, 
       Human Resource Management, 43(4), 395-407, 2004, 
       :doi:`10.1002/hrm.20032`. 
 
    Examples 
    -------- 
    In the following example, we consider the article &quot;Employee 
    attitudes and job satisfaction&quot; [3]_ 
    which reports the results of a survey from 63 scientists and 117 college 
    professors. Of the 63 scientists, 31 said they were very satisfied with 
    their jobs, whereas 74 of the college professors were very satisfied 
    with their work. Is this significant evidence that college 
    professors are happier with their work than scientists? 
    The following table summarizes the data mentioned above:: 
 
                         college professors   scientists 
        Very Satisfied   74                     31 
        Dissatisfied     43                     32 
 
    When working with statistical hypothesis testing, we usually use a 
    threshold probability or significance level upon which we decide 
    to reject the null hypothesis :math:`H_0`. Suppose we choose the common 
    significance level of 5%. 
 
    Our alternative hypothesis is that college professors are truly more 
    satisfied with their work than scientists. Therefore, we expect 
    :math:`p_1` the proportion of very satisfied college professors to be 
    greater than :math:`p_2`, the proportion of very satisfied scientists. 
    We thus call `boschloo_exact` with the ``alternative=&quot;greater&quot;`` option: 
 
    &gt;&gt;&gt; import scipy.stats as stats 
    &gt;&gt;&gt; res = stats.boschloo_exact([[74, 31], [43, 32]], alternative=&quot;greater&quot;) 
    &gt;&gt;&gt; res.statistic 
    0.0483 
    &gt;&gt;&gt; res.pvalue 
    0.0355 
 
    Under the null hypothesis that scientists are happier in their work than 
    college professors, the probability of obtaining test 
    results at least as extreme as the observed data is approximately 3.55%. 
    Since this p-value is less than our chosen significance level, we have 
    evidence to reject :math:`H_0` in favor of the alternative hypothesis. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">hypergeom </span><span class="s2">= </span><span class="s1">distributions</span><span class="s2">.</span><span class="s1">hypergeom</span>

    <span class="s0">if </span><span class="s1">n </span><span class="s2">&lt;= </span><span class="s4">0</span><span class="s2">:</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span>
            <span class="s3">&quot;Number of points `n` must be strictly positive,&quot;</span>
            <span class="s3">f&quot; found </span><span class="s0">{</span><span class="s1">n</span><span class="s0">!r}</span><span class="s3">&quot;</span>
        <span class="s2">)</span>

    <span class="s1">table </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">table</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">int64</span><span class="s2">)</span>

    <span class="s0">if not </span><span class="s1">table</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">):</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;The input `table` must be of shape (2, 2).&quot;</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">np</span><span class="s2">.</span><span class="s1">any</span><span class="s2">(</span><span class="s1">table </span><span class="s2">&lt; </span><span class="s4">0</span><span class="s2">):</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;All values in `table` must be nonnegative.&quot;</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s4">0 </span><span class="s0">in </span><span class="s1">table</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">):</span>
        <span class="s6"># If both values in column are zero, the p-value is 1 and</span>
        <span class="s6"># the score's statistic is NaN.</span>
        <span class="s0">return </span><span class="s1">BoschlooExactResult</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">nan</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">nan</span><span class="s2">)</span>

    <span class="s1">total_col_1</span><span class="s2">, </span><span class="s1">total_col_2 </span><span class="s2">= </span><span class="s1">table</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">total </span><span class="s2">= </span><span class="s1">total_col_1 </span><span class="s2">+ </span><span class="s1">total_col_2</span>
    <span class="s1">x1 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">total_col_1 </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">int64</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">x2 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">total_col_2 </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">int64</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">x1_sum_x2 </span><span class="s2">= </span><span class="s1">x1 </span><span class="s2">+ </span><span class="s1">x2</span>

    <span class="s0">if </span><span class="s1">alternative </span><span class="s2">== </span><span class="s3">'less'</span><span class="s2">:</span>
        <span class="s1">pvalues </span><span class="s2">= </span><span class="s1">hypergeom</span><span class="s2">.</span><span class="s1">cdf</span><span class="s2">(</span><span class="s1">x1</span><span class="s2">, </span><span class="s1">total</span><span class="s2">, </span><span class="s1">x1_sum_x2</span><span class="s2">, </span><span class="s1">total_col_1</span><span class="s2">).</span><span class="s1">T</span>
    <span class="s0">elif </span><span class="s1">alternative </span><span class="s2">== </span><span class="s3">'greater'</span><span class="s2">:</span>
        <span class="s6"># Same formula as the 'less' case, but with the second column.</span>
        <span class="s1">pvalues </span><span class="s2">= </span><span class="s1">hypergeom</span><span class="s2">.</span><span class="s1">cdf</span><span class="s2">(</span><span class="s1">x2</span><span class="s2">, </span><span class="s1">total</span><span class="s2">, </span><span class="s1">x1_sum_x2</span><span class="s2">, </span><span class="s1">total_col_2</span><span class="s2">).</span><span class="s1">T</span>
    <span class="s0">elif </span><span class="s1">alternative </span><span class="s2">== </span><span class="s3">'two-sided'</span><span class="s2">:</span>
        <span class="s1">boschloo_less </span><span class="s2">= </span><span class="s1">boschloo_exact</span><span class="s2">(</span><span class="s1">table</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">=</span><span class="s3">&quot;less&quot;</span><span class="s2">, </span><span class="s1">n</span><span class="s2">=</span><span class="s1">n</span><span class="s2">)</span>
        <span class="s1">boschloo_greater </span><span class="s2">= </span><span class="s1">boschloo_exact</span><span class="s2">(</span><span class="s1">table</span><span class="s2">, </span><span class="s1">alternative</span><span class="s2">=</span><span class="s3">&quot;greater&quot;</span><span class="s2">, </span><span class="s1">n</span><span class="s2">=</span><span class="s1">n</span><span class="s2">)</span>

        <span class="s1">res </span><span class="s2">= (</span>
            <span class="s1">boschloo_less </span><span class="s0">if </span><span class="s1">boschloo_less</span><span class="s2">.</span><span class="s1">pvalue </span><span class="s2">&lt; </span><span class="s1">boschloo_greater</span><span class="s2">.</span><span class="s1">pvalue</span>
            <span class="s0">else </span><span class="s1">boschloo_greater</span>
        <span class="s2">)</span>

        <span class="s6"># Two-sided p-value is defined as twice the minimum of the one-sided</span>
        <span class="s6"># p-values</span>
        <span class="s1">pvalue </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">clip</span><span class="s2">(</span><span class="s4">2 </span><span class="s2">* </span><span class="s1">res</span><span class="s2">.</span><span class="s1">pvalue</span><span class="s2">, </span><span class="s1">a_min</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">a_max</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">BoschlooExactResult</span><span class="s2">(</span><span class="s1">res</span><span class="s2">.</span><span class="s1">statistic</span><span class="s2">, </span><span class="s1">pvalue</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">msg </span><span class="s2">= (</span>
            <span class="s3">f&quot;`alternative` should be one of </span><span class="s0">{</span><span class="s3">'two-sided'</span><span class="s2">, </span><span class="s3">'less'</span><span class="s2">, </span><span class="s3">'greater'</span><span class="s0">}</span><span class="s3">,&quot;</span>
            <span class="s3">f&quot; found </span><span class="s0">{</span><span class="s1">alternative</span><span class="s0">!r}</span><span class="s3">&quot;</span>
        <span class="s2">)</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s1">msg</span><span class="s2">)</span>

    <span class="s1">fisher_stat </span><span class="s2">= </span><span class="s1">pvalues</span><span class="s2">[</span><span class="s1">table</span><span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">], </span><span class="s1">table</span><span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]]</span>

    <span class="s6"># fisher_stat * (1+1e-13) guards us from small numerical error. It is</span>
    <span class="s6"># equivalent to np.isclose with relative tol of 1e-13 and absolute tol of 0</span>
    <span class="s6"># For more throughout explanations, see gh-14178</span>
    <span class="s1">index_arr </span><span class="s2">= </span><span class="s1">pvalues </span><span class="s2">&lt;= </span><span class="s1">fisher_stat </span><span class="s2">* (</span><span class="s4">1</span><span class="s2">+</span><span class="s4">1e-13</span><span class="s2">)</span>

    <span class="s1">x1</span><span class="s2">, </span><span class="s1">x2</span><span class="s2">, </span><span class="s1">x1_sum_x2 </span><span class="s2">= </span><span class="s1">x1</span><span class="s2">.</span><span class="s1">T</span><span class="s2">, </span><span class="s1">x2</span><span class="s2">.</span><span class="s1">T</span><span class="s2">, </span><span class="s1">x1_sum_x2</span><span class="s2">.</span><span class="s1">T</span>
    <span class="s1">x1_log_comb </span><span class="s2">= </span><span class="s1">_compute_log_combinations</span><span class="s2">(</span><span class="s1">total_col_1</span><span class="s2">)</span>
    <span class="s1">x2_log_comb </span><span class="s2">= </span><span class="s1">_compute_log_combinations</span><span class="s2">(</span><span class="s1">total_col_2</span><span class="s2">)</span>
    <span class="s1">x1_sum_x2_log_comb </span><span class="s2">= </span><span class="s1">x1_log_comb</span><span class="s2">[</span><span class="s1">x1</span><span class="s2">] + </span><span class="s1">x2_log_comb</span><span class="s2">[</span><span class="s1">x2</span><span class="s2">]</span>

    <span class="s1">result </span><span class="s2">= </span><span class="s1">shgo</span><span class="s2">(</span>
        <span class="s1">_get_binomial_log_p_value_with_nuisance_param</span><span class="s2">,</span>
        <span class="s1">args</span><span class="s2">=(</span><span class="s1">x1_sum_x2</span><span class="s2">, </span><span class="s1">x1_sum_x2_log_comb</span><span class="s2">, </span><span class="s1">index_arr</span><span class="s2">),</span>
        <span class="s1">bounds</span><span class="s2">=((</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">),),</span>
        <span class="s1">n</span><span class="s2">=</span><span class="s1">n</span><span class="s2">,</span>
        <span class="s1">sampling_method</span><span class="s2">=</span><span class="s3">&quot;sobol&quot;</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s6"># result.fun is the negative log pvalue and therefore needs to be</span>
    <span class="s6"># changed before return</span>
    <span class="s1">p_value </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">clip</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(-</span><span class="s1">result</span><span class="s2">.</span><span class="s1">fun</span><span class="s2">), </span><span class="s1">a_min</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">a_max</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">BoschlooExactResult</span><span class="s2">(</span><span class="s1">fisher_stat</span><span class="s2">, </span><span class="s1">p_value</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">_get_binomial_log_p_value_with_nuisance_param</span><span class="s2">(</span>
    <span class="s1">nuisance_param</span><span class="s2">, </span><span class="s1">x1_sum_x2</span><span class="s2">, </span><span class="s1">x1_sum_x2_log_comb</span><span class="s2">, </span><span class="s1">index_arr</span>
<span class="s2">):</span>
    <span class="s5">r&quot;&quot;&quot; 
    Compute the log pvalue in respect of a nuisance parameter considering 
    a 2x2 sample space. 
 
    Parameters 
    ---------- 
    nuisance_param : float 
        nuisance parameter used in the computation of the maximisation of 
        the p-value. Must be between 0 and 1 
 
    x1_sum_x2 : ndarray 
        Sum of x1 and x2 inside barnard_exact 
 
    x1_sum_x2_log_comb : ndarray 
        sum of the log combination of x1 and x2 
 
    index_arr : ndarray of boolean 
 
    Returns 
    ------- 
    p_value : float 
        Return the maximum p-value considering every nuisance parameter 
        between 0 and 1 
 
    Notes 
    ----- 
 
    Both Barnard's test and Boschloo's test iterate over a nuisance parameter 
    :math:`\pi \in [0, 1]` to find the maximum p-value. To search this 
    maxima, this function return the negative log pvalue with respect to the 
    nuisance parameter passed in params. This negative log p-value is then 
    used in `shgo` to find the minimum negative pvalue which is our maximum 
    pvalue. 
 
    Also, to compute the different combination used in the 
    p-values' computation formula, this function uses `gammaln` which is 
    more tolerant for large value than `scipy.special.comb`. `gammaln` gives 
    a log combination. For the little precision loss, performances are 
    improved a lot. 
    &quot;&quot;&quot;</span>
    <span class="s1">t1</span><span class="s2">, </span><span class="s1">t2 </span><span class="s2">= </span><span class="s1">x1_sum_x2</span><span class="s2">.</span><span class="s1">shape</span>
    <span class="s1">n </span><span class="s2">= </span><span class="s1">t1 </span><span class="s2">+ </span><span class="s1">t2 </span><span class="s2">- </span><span class="s4">2</span>
    <span class="s0">with </span><span class="s1">np</span><span class="s2">.</span><span class="s1">errstate</span><span class="s2">(</span><span class="s1">divide</span><span class="s2">=</span><span class="s3">&quot;ignore&quot;</span><span class="s2">, </span><span class="s1">invalid</span><span class="s2">=</span><span class="s3">&quot;ignore&quot;</span><span class="s2">):</span>
        <span class="s1">log_nuisance </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">log</span><span class="s2">(</span>
            <span class="s1">nuisance_param</span><span class="s2">,</span>
            <span class="s1">out</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros_like</span><span class="s2">(</span><span class="s1">nuisance_param</span><span class="s2">),</span>
            <span class="s1">where</span><span class="s2">=</span><span class="s1">nuisance_param </span><span class="s2">&gt;= </span><span class="s4">0</span><span class="s2">,</span>
        <span class="s2">)</span>
        <span class="s1">log_1_minus_nuisance </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">log</span><span class="s2">(</span>
            <span class="s4">1 </span><span class="s2">- </span><span class="s1">nuisance_param</span><span class="s2">,</span>
            <span class="s1">out</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros_like</span><span class="s2">(</span><span class="s1">nuisance_param</span><span class="s2">),</span>
            <span class="s1">where</span><span class="s2">=</span><span class="s4">1 </span><span class="s2">- </span><span class="s1">nuisance_param </span><span class="s2">&gt;= </span><span class="s4">0</span><span class="s2">,</span>
        <span class="s2">)</span>

        <span class="s1">nuisance_power_x1_x2 </span><span class="s2">= </span><span class="s1">log_nuisance </span><span class="s2">* </span><span class="s1">x1_sum_x2</span>
        <span class="s1">nuisance_power_x1_x2</span><span class="s2">[(</span><span class="s1">x1_sum_x2 </span><span class="s2">== </span><span class="s4">0</span><span class="s2">)[:, :]] = </span><span class="s4">0</span>

        <span class="s1">nuisance_power_n_minus_x1_x2 </span><span class="s2">= </span><span class="s1">log_1_minus_nuisance </span><span class="s2">* (</span><span class="s1">n </span><span class="s2">- </span><span class="s1">x1_sum_x2</span><span class="s2">)</span>
        <span class="s1">nuisance_power_n_minus_x1_x2</span><span class="s2">[(</span><span class="s1">x1_sum_x2 </span><span class="s2">== </span><span class="s1">n</span><span class="s2">)[:, :]] = </span><span class="s4">0</span>

        <span class="s1">tmp_log_values_arr </span><span class="s2">= (</span>
            <span class="s1">x1_sum_x2_log_comb</span>
            <span class="s2">+ </span><span class="s1">nuisance_power_x1_x2</span>
            <span class="s2">+ </span><span class="s1">nuisance_power_n_minus_x1_x2</span>
        <span class="s2">)</span>

    <span class="s1">tmp_values_from_index </span><span class="s2">= </span><span class="s1">tmp_log_values_arr</span><span class="s2">[</span><span class="s1">index_arr</span><span class="s2">]</span>

    <span class="s6"># To avoid dividing by zero in log function and getting inf value,</span>
    <span class="s6"># values are centered according to the max</span>
    <span class="s1">max_value </span><span class="s2">= </span><span class="s1">tmp_values_from_index</span><span class="s2">.</span><span class="s1">max</span><span class="s2">()</span>

    <span class="s6"># To have better result's precision, the log pvalue is taken here.</span>
    <span class="s6"># Indeed, pvalue is included inside [0, 1] interval. Passing the</span>
    <span class="s6"># pvalue to log makes the interval a lot bigger ([-inf, 0]), and thus</span>
    <span class="s6"># help us to achieve better precision</span>
    <span class="s0">with </span><span class="s1">np</span><span class="s2">.</span><span class="s1">errstate</span><span class="s2">(</span><span class="s1">divide</span><span class="s2">=</span><span class="s3">&quot;ignore&quot;</span><span class="s2">, </span><span class="s1">invalid</span><span class="s2">=</span><span class="s3">&quot;ignore&quot;</span><span class="s2">):</span>
        <span class="s1">log_probs </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(</span><span class="s1">tmp_values_from_index </span><span class="s2">- </span><span class="s1">max_value</span><span class="s2">).</span><span class="s1">sum</span><span class="s2">()</span>
        <span class="s1">log_pvalue </span><span class="s2">= </span><span class="s1">max_value </span><span class="s2">+ </span><span class="s1">np</span><span class="s2">.</span><span class="s1">log</span><span class="s2">(</span>
            <span class="s1">log_probs</span><span class="s2">,</span>
            <span class="s1">out</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">full_like</span><span class="s2">(</span><span class="s1">log_probs</span><span class="s2">, -</span><span class="s1">np</span><span class="s2">.</span><span class="s1">inf</span><span class="s2">),</span>
            <span class="s1">where</span><span class="s2">=</span><span class="s1">log_probs </span><span class="s2">&gt; </span><span class="s4">0</span><span class="s2">,</span>
        <span class="s2">)</span>

    <span class="s6"># Since shgo find the minima, minus log pvalue is returned</span>
    <span class="s0">return </span><span class="s2">-</span><span class="s1">log_pvalue</span>


<span class="s0">def </span><span class="s1">_pval_cvm_2samp_exact</span><span class="s2">(</span><span class="s1">s</span><span class="s2">, </span><span class="s1">m</span><span class="s2">, </span><span class="s1">n</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot; 
    Compute the exact p-value of the Cramer-von Mises two-sample test 
    for a given value s of the test statistic. 
    m and n are the sizes of the samples. 
 
    [1] Y. Xiao, A. Gordon, and A. Yakovlev, &quot;A C++ Program for 
        the Cramér-Von Mises Two-Sample Test&quot;, J. Stat. Soft., 
        vol. 17, no. 8, pp. 1-15, Dec. 2006. 
    [2] T. W. Anderson &quot;On the Distribution of the Two-Sample Cramer-von Mises 
        Criterion,&quot; The Annals of Mathematical Statistics, Ann. Math. Statist. 
        33(3), 1148-1159, (September, 1962) 
    &quot;&quot;&quot;</span>

    <span class="s6"># [1, p. 3]</span>
    <span class="s1">lcm </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">lcm</span><span class="s2">(</span><span class="s1">m</span><span class="s2">, </span><span class="s1">n</span><span class="s2">)</span>
    <span class="s6"># [1, p. 4], below eq. 3</span>
    <span class="s1">a </span><span class="s2">= </span><span class="s1">lcm </span><span class="s2">// </span><span class="s1">m</span>
    <span class="s1">b </span><span class="s2">= </span><span class="s1">lcm </span><span class="s2">// </span><span class="s1">n</span>
    <span class="s6"># Combine Eq. 9 in [2] with Eq. 2 in [1] and solve for $\zeta$</span>
    <span class="s6"># Hint: `s` is $U$ in [2], and $T_2$ in [1] is $T$ in [2]</span>
    <span class="s1">mn </span><span class="s2">= </span><span class="s1">m </span><span class="s2">* </span><span class="s1">n</span>
    <span class="s1">zeta </span><span class="s2">= </span><span class="s1">lcm </span><span class="s2">** </span><span class="s4">2 </span><span class="s2">* (</span><span class="s1">m </span><span class="s2">+ </span><span class="s1">n</span><span class="s2">) * (</span><span class="s4">6 </span><span class="s2">* </span><span class="s1">s </span><span class="s2">- </span><span class="s1">mn </span><span class="s2">* (</span><span class="s4">4 </span><span class="s2">* </span><span class="s1">mn </span><span class="s2">- </span><span class="s4">1</span><span class="s2">)) // (</span><span class="s4">6 </span><span class="s2">* </span><span class="s1">mn </span><span class="s2">** </span><span class="s4">2</span><span class="s2">)</span>

    <span class="s6"># bound maximum value that may appear in `gs` (remember both rows!)</span>
    <span class="s1">zeta_bound </span><span class="s2">= </span><span class="s1">lcm</span><span class="s2">**</span><span class="s4">2 </span><span class="s2">* (</span><span class="s1">m </span><span class="s2">+ </span><span class="s1">n</span><span class="s2">)  </span><span class="s6"># bound elements in row 1</span>
    <span class="s1">combinations </span><span class="s2">= </span><span class="s1">comb</span><span class="s2">(</span><span class="s1">m </span><span class="s2">+ </span><span class="s1">n</span><span class="s2">, </span><span class="s1">m</span><span class="s2">)  </span><span class="s6"># sum of row 2</span>
    <span class="s1">max_gs </span><span class="s2">= </span><span class="s1">max</span><span class="s2">(</span><span class="s1">zeta_bound</span><span class="s2">, </span><span class="s1">combinations</span><span class="s2">)</span>
    <span class="s1">dtype </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">min_scalar_type</span><span class="s2">(</span><span class="s1">max_gs</span><span class="s2">)</span>

    <span class="s6"># the frequency table of $g_{u, v}^+$ defined in [1, p. 6]</span>
    <span class="s1">gs </span><span class="s2">= ([</span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[</span><span class="s4">0</span><span class="s2">], [</span><span class="s4">1</span><span class="s2">]], </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">dtype</span><span class="s2">)]</span>
          <span class="s2">+ [</span><span class="s1">np</span><span class="s2">.</span><span class="s1">empty</span><span class="s2">((</span><span class="s4">2</span><span class="s2">, </span><span class="s4">0</span><span class="s2">), </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">dtype</span><span class="s2">) </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s1">m</span><span class="s2">)])</span>
    <span class="s0">for </span><span class="s1">u </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s1">n </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">):</span>
        <span class="s1">next_gs </span><span class="s2">= []</span>
        <span class="s1">tmp </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">empty</span><span class="s2">((</span><span class="s4">2</span><span class="s2">, </span><span class="s4">0</span><span class="s2">), </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">dtype</span><span class="s2">)</span>
        <span class="s0">for </span><span class="s1">v</span><span class="s2">, </span><span class="s1">g </span><span class="s0">in </span><span class="s1">enumerate</span><span class="s2">(</span><span class="s1">gs</span><span class="s2">):</span>
            <span class="s6"># Calculate g recursively with eq. 11 in [1]. Even though it</span>
            <span class="s6"># doesn't look like it, this also does 12/13 (all of Algorithm 1).</span>
            <span class="s1">vi</span><span class="s2">, </span><span class="s1">i0</span><span class="s2">, </span><span class="s1">i1 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">intersect1d</span><span class="s2">(</span><span class="s1">tmp</span><span class="s2">[</span><span class="s4">0</span><span class="s2">], </span><span class="s1">g</span><span class="s2">[</span><span class="s4">0</span><span class="s2">], </span><span class="s1">return_indices</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
            <span class="s1">tmp </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">([</span>
                <span class="s1">np</span><span class="s2">.</span><span class="s1">stack</span><span class="s2">([</span><span class="s1">vi</span><span class="s2">, </span><span class="s1">tmp</span><span class="s2">[</span><span class="s4">1</span><span class="s2">, </span><span class="s1">i0</span><span class="s2">] + </span><span class="s1">g</span><span class="s2">[</span><span class="s4">1</span><span class="s2">, </span><span class="s1">i1</span><span class="s2">]]),</span>
                <span class="s1">np</span><span class="s2">.</span><span class="s1">delete</span><span class="s2">(</span><span class="s1">tmp</span><span class="s2">, </span><span class="s1">i0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">),</span>
                <span class="s1">np</span><span class="s2">.</span><span class="s1">delete</span><span class="s2">(</span><span class="s1">g</span><span class="s2">, </span><span class="s1">i1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>
            <span class="s2">], </span><span class="s4">1</span><span class="s2">)</span>
            <span class="s1">res </span><span class="s2">= (</span><span class="s1">a </span><span class="s2">* </span><span class="s1">v </span><span class="s2">- </span><span class="s1">b </span><span class="s2">* </span><span class="s1">u</span><span class="s2">) ** </span><span class="s4">2</span>
            <span class="s1">tmp</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] += </span><span class="s1">res</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">dtype</span><span class="s2">)</span>
            <span class="s1">next_gs</span><span class="s2">.</span><span class="s1">append</span><span class="s2">(</span><span class="s1">tmp</span><span class="s2">)</span>
        <span class="s1">gs </span><span class="s2">= </span><span class="s1">next_gs</span>
    <span class="s1">value</span><span class="s2">, </span><span class="s1">freq </span><span class="s2">= </span><span class="s1">gs</span><span class="s2">[</span><span class="s1">m</span><span class="s2">]</span>
    <span class="s0">return </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">freq</span><span class="s2">[</span><span class="s1">value </span><span class="s2">&gt;= </span><span class="s1">zeta</span><span class="s2">]) / </span><span class="s1">combinations</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">_axis_nan_policy_factory</span><span class="s2">(</span><span class="s1">CramerVonMisesResult</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">too_small</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
                          <span class="s1">result_to_tuple</span><span class="s2">=</span><span class="s1">_cvm_result_to_tuple</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">cramervonmises_2samp</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">method</span><span class="s2">=</span><span class="s3">'auto'</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Perform the two-sample Cramér-von Mises test for goodness of fit. 
 
    This is the two-sample version of the Cramér-von Mises test ([1]_): 
    for two independent samples :math:`X_1, ..., X_n` and 
    :math:`Y_1, ..., Y_m`, the null hypothesis is that the samples 
    come from the same (unspecified) continuous distribution. 
 
    Parameters 
    ---------- 
    x : array_like 
        A 1-D array of observed values of the random variables :math:`X_i`. 
        Must contain at least two observations. 
    y : array_like 
        A 1-D array of observed values of the random variables :math:`Y_i`. 
        Must contain at least two observations. 
    method : {'auto', 'asymptotic', 'exact'}, optional 
        The method used to compute the p-value, see Notes for details. 
        The default is 'auto'. 
 
    Returns 
    ------- 
    res : object with attributes 
        statistic : float 
            Cramér-von Mises statistic. 
        pvalue : float 
            The p-value. 
 
    See Also 
    -------- 
    cramervonmises, anderson_ksamp, epps_singleton_2samp, ks_2samp 
 
    Notes 
    ----- 
    .. versionadded:: 1.7.0 
 
    The statistic is computed according to equation 9 in [2]_. The 
    calculation of the p-value depends on the keyword `method`: 
 
    - ``asymptotic``: The p-value is approximated by using the limiting 
      distribution of the test statistic. 
    - ``exact``: The exact p-value is computed by enumerating all 
      possible combinations of the test statistic, see [2]_. 
 
    If ``method='auto'``, the exact approach is used 
    if both samples contain equal to or less than 20 observations, 
    otherwise the asymptotic distribution is used. 
 
    If the underlying distribution is not continuous, the p-value is likely to 
    be conservative (Section 6.2 in [3]_). When ranking the data to compute 
    the test statistic, midranks are used if there are ties. 
 
    References 
    ---------- 
    .. [1] https://en.wikipedia.org/wiki/Cramer-von_Mises_criterion 
    .. [2] Anderson, T.W. (1962). On the distribution of the two-sample 
           Cramer-von-Mises criterion. The Annals of Mathematical 
           Statistics, pp. 1148-1159. 
    .. [3] Conover, W.J., Practical Nonparametric Statistics, 1971. 
 
    Examples 
    -------- 
 
    Suppose we wish to test whether two samples generated by 
    ``scipy.stats.norm.rvs`` have the same distribution. We choose a 
    significance level of alpha=0.05. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy import stats 
    &gt;&gt;&gt; rng = np.random.default_rng() 
    &gt;&gt;&gt; x = stats.norm.rvs(size=100, random_state=rng) 
    &gt;&gt;&gt; y = stats.norm.rvs(size=70, random_state=rng) 
    &gt;&gt;&gt; res = stats.cramervonmises_2samp(x, y) 
    &gt;&gt;&gt; res.statistic, res.pvalue 
    (0.29376470588235293, 0.1412873014573014) 
 
    The p-value exceeds our chosen significance level, so we do not 
    reject the null hypothesis that the observed samples are drawn from the 
    same distribution. 
 
    For small sample sizes, one can compute the exact p-values: 
 
    &gt;&gt;&gt; x = stats.norm.rvs(size=7, random_state=rng) 
    &gt;&gt;&gt; y = stats.t.rvs(df=2, size=6, random_state=rng) 
    &gt;&gt;&gt; res = stats.cramervonmises_2samp(x, y, method='exact') 
    &gt;&gt;&gt; res.statistic, res.pvalue 
    (0.197802197802198, 0.31643356643356646) 
 
    The p-value based on the asymptotic distribution is a good approximation 
    even though the sample size is small. 
 
    &gt;&gt;&gt; res = stats.cramervonmises_2samp(x, y, method='asymptotic') 
    &gt;&gt;&gt; res.statistic, res.pvalue 
    (0.197802197802198, 0.2966041181527128) 
 
    Independent of the method, one would not reject the null hypothesis at the 
    chosen significance level in this example. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">xa </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sort</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">x</span><span class="s2">))</span>
    <span class="s1">ya </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sort</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">y</span><span class="s2">))</span>

    <span class="s0">if </span><span class="s1">xa</span><span class="s2">.</span><span class="s1">size </span><span class="s2">&lt;= </span><span class="s4">1 </span><span class="s0">or </span><span class="s1">ya</span><span class="s2">.</span><span class="s1">size </span><span class="s2">&lt;= </span><span class="s4">1</span><span class="s2">:</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">'x and y must contain at least two observations.'</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">method </span><span class="s0">not in </span><span class="s2">[</span><span class="s3">'auto'</span><span class="s2">, </span><span class="s3">'exact'</span><span class="s2">, </span><span class="s3">'asymptotic'</span><span class="s2">]:</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">'method must be either auto, exact or asymptotic.'</span><span class="s2">)</span>

    <span class="s1">nx </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">xa</span><span class="s2">)</span>
    <span class="s1">ny </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">ya</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">method </span><span class="s2">== </span><span class="s3">'auto'</span><span class="s2">:</span>
        <span class="s0">if </span><span class="s1">max</span><span class="s2">(</span><span class="s1">nx</span><span class="s2">, </span><span class="s1">ny</span><span class="s2">) &gt; </span><span class="s4">20</span><span class="s2">:</span>
            <span class="s1">method </span><span class="s2">= </span><span class="s3">'asymptotic'</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">method </span><span class="s2">= </span><span class="s3">'exact'</span>

    <span class="s6"># get ranks of x and y in the pooled sample</span>
    <span class="s1">z </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">([</span><span class="s1">xa</span><span class="s2">, </span><span class="s1">ya</span><span class="s2">])</span>
    <span class="s6"># in case of ties, use midrank (see [1])</span>
    <span class="s1">r </span><span class="s2">= </span><span class="s1">scipy</span><span class="s2">.</span><span class="s1">stats</span><span class="s2">.</span><span class="s1">rankdata</span><span class="s2">(</span><span class="s1">z</span><span class="s2">, </span><span class="s1">method</span><span class="s2">=</span><span class="s3">'average'</span><span class="s2">)</span>
    <span class="s1">rx </span><span class="s2">= </span><span class="s1">r</span><span class="s2">[:</span><span class="s1">nx</span><span class="s2">]</span>
    <span class="s1">ry </span><span class="s2">= </span><span class="s1">r</span><span class="s2">[</span><span class="s1">nx</span><span class="s2">:]</span>

    <span class="s6"># compute U (eq. 10 in [2])</span>
    <span class="s1">u </span><span class="s2">= </span><span class="s1">nx </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">((</span><span class="s1">rx </span><span class="s2">- </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">nx</span><span class="s2">+</span><span class="s4">1</span><span class="s2">))**</span><span class="s4">2</span><span class="s2">)</span>
    <span class="s1">u </span><span class="s2">+= </span><span class="s1">ny </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">((</span><span class="s1">ry </span><span class="s2">- </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">ny</span><span class="s2">+</span><span class="s4">1</span><span class="s2">))**</span><span class="s4">2</span><span class="s2">)</span>

    <span class="s6"># compute T (eq. 9 in [2])</span>
    <span class="s1">k</span><span class="s2">, </span><span class="s1">N </span><span class="s2">= </span><span class="s1">nx</span><span class="s2">*</span><span class="s1">ny</span><span class="s2">, </span><span class="s1">nx </span><span class="s2">+ </span><span class="s1">ny</span>
    <span class="s1">t </span><span class="s2">= </span><span class="s1">u </span><span class="s2">/ (</span><span class="s1">k</span><span class="s2">*</span><span class="s1">N</span><span class="s2">) - (</span><span class="s4">4</span><span class="s2">*</span><span class="s1">k </span><span class="s2">- </span><span class="s4">1</span><span class="s2">)/(</span><span class="s4">6</span><span class="s2">*</span><span class="s1">N</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">method </span><span class="s2">== </span><span class="s3">'exact'</span><span class="s2">:</span>
        <span class="s1">p </span><span class="s2">= </span><span class="s1">_pval_cvm_2samp_exact</span><span class="s2">(</span><span class="s1">u</span><span class="s2">, </span><span class="s1">nx</span><span class="s2">, </span><span class="s1">ny</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s6"># compute expected value and variance of T (eq. 11 and 14 in [2])</span>
        <span class="s1">et </span><span class="s2">= (</span><span class="s4">1 </span><span class="s2">+ </span><span class="s4">1</span><span class="s2">/</span><span class="s1">N</span><span class="s2">)/</span><span class="s4">6</span>
        <span class="s1">vt </span><span class="s2">= (</span><span class="s1">N</span><span class="s2">+</span><span class="s4">1</span><span class="s2">) * (</span><span class="s4">4</span><span class="s2">*</span><span class="s1">k</span><span class="s2">*</span><span class="s1">N </span><span class="s2">- </span><span class="s4">3</span><span class="s2">*(</span><span class="s1">nx</span><span class="s2">**</span><span class="s4">2 </span><span class="s2">+ </span><span class="s1">ny</span><span class="s2">**</span><span class="s4">2</span><span class="s2">) - </span><span class="s4">2</span><span class="s2">*</span><span class="s1">k</span><span class="s2">)</span>
        <span class="s1">vt </span><span class="s2">= </span><span class="s1">vt </span><span class="s2">/ (</span><span class="s4">45 </span><span class="s2">* </span><span class="s1">N</span><span class="s2">**</span><span class="s4">2 </span><span class="s2">* </span><span class="s4">4 </span><span class="s2">* </span><span class="s1">k</span><span class="s2">)</span>

        <span class="s6"># computed the normalized statistic (eq. 15 in [2])</span>
        <span class="s1">tn </span><span class="s2">= </span><span class="s4">1</span><span class="s2">/</span><span class="s4">6 </span><span class="s2">+ (</span><span class="s1">t </span><span class="s2">- </span><span class="s1">et</span><span class="s2">) / </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sqrt</span><span class="s2">(</span><span class="s4">45 </span><span class="s2">* </span><span class="s1">vt</span><span class="s2">)</span>

        <span class="s6"># approximate distribution of tn with limiting distribution</span>
        <span class="s6"># of the one-sample test statistic</span>
        <span class="s6"># if tn &lt; 0.003, the _cdf_cvm_inf(tn) &lt; 1.28*1e-18, return 1.0 directly</span>
        <span class="s0">if </span><span class="s1">tn </span><span class="s2">&lt; </span><span class="s4">0.003</span><span class="s2">:</span>
            <span class="s1">p </span><span class="s2">= </span><span class="s4">1.0</span>
        <span class="s0">else</span><span class="s2">:</span>
            <span class="s1">p </span><span class="s2">= </span><span class="s1">max</span><span class="s2">(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1. </span><span class="s2">- </span><span class="s1">_cdf_cvm_inf</span><span class="s2">(</span><span class="s1">tn</span><span class="s2">))</span>

    <span class="s0">return </span><span class="s1">CramerVonMisesResult</span><span class="s2">(</span><span class="s1">statistic</span><span class="s2">=</span><span class="s1">t</span><span class="s2">, </span><span class="s1">pvalue</span><span class="s2">=</span><span class="s1">p</span><span class="s2">)</span>


<span class="s0">class </span><span class="s1">TukeyHSDResult</span><span class="s2">:</span>
    <span class="s5">&quot;&quot;&quot;Result of `scipy.stats.tukey_hsd`. 
 
    Attributes 
    ---------- 
    statistic : float ndarray 
        The computed statistic of the test for each comparison. The element 
        at index ``(i, j)`` is the statistic for the comparison between groups 
        ``i`` and ``j``. 
    pvalue : float ndarray 
        The associated p-value from the studentized range distribution. The 
        element at index ``(i, j)`` is the p-value for the comparison 
        between groups ``i`` and ``j``. 
 
    Notes 
    ----- 
    The string representation of this object displays the most recently 
    calculated confidence interval, and if none have been previously 
    calculated, it will evaluate ``confidence_interval()``. 
 
    References 
    ---------- 
    .. [1] NIST/SEMATECH e-Handbook of Statistical Methods, &quot;7.4.7.1. Tukey's 
           Method.&quot; 
           https://www.itl.nist.gov/div898/handbook/prc/section4/prc471.htm, 
           28 November 2020. 
    &quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">__init__</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">statistic</span><span class="s2">, </span><span class="s1">pvalue</span><span class="s2">, </span><span class="s1">_nobs</span><span class="s2">, </span><span class="s1">_ntreatments</span><span class="s2">, </span><span class="s1">_stand_err</span><span class="s2">):</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">statistic </span><span class="s2">= </span><span class="s1">statistic</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">pvalue </span><span class="s2">= </span><span class="s1">pvalue</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_ntreatments </span><span class="s2">= </span><span class="s1">_ntreatments</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_nobs </span><span class="s2">= </span><span class="s1">_nobs</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_stand_err </span><span class="s2">= </span><span class="s1">_stand_err</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_ci </span><span class="s2">= </span><span class="s0">None</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_ci_cl </span><span class="s2">= </span><span class="s0">None</span>

    <span class="s0">def </span><span class="s1">__str__</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
        <span class="s6"># Note: `__str__` prints the confidence intervals from the most</span>
        <span class="s6"># recent call to `confidence_interval`. If it has not been called,</span>
        <span class="s6"># it will be called with the default CL of .95.</span>
        <span class="s0">if </span><span class="s1">self</span><span class="s2">.</span><span class="s1">_ci </span><span class="s0">is None</span><span class="s2">:</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">confidence_interval</span><span class="s2">(</span><span class="s1">confidence_level</span><span class="s2">=</span><span class="s4">.95</span><span class="s2">)</span>
        <span class="s1">s </span><span class="s2">= (</span><span class="s3">&quot;Tukey's HSD Pairwise Group Comparisons&quot;</span>
             <span class="s3">f&quot; (</span><span class="s0">{</span><span class="s1">self</span><span class="s2">.</span><span class="s1">_ci_cl</span><span class="s2">*</span><span class="s4">100</span><span class="s0">:</span><span class="s3">.1f</span><span class="s0">}</span><span class="s3">% Confidence Interval)</span><span class="s0">\n</span><span class="s3">&quot;</span><span class="s2">)</span>
        <span class="s1">s </span><span class="s2">+= </span><span class="s3">&quot;Comparison  Statistic  p-value  Lower CI  Upper CI</span><span class="s0">\n</span><span class="s3">&quot;</span>
        <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s1">self</span><span class="s2">.</span><span class="s1">pvalue</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]):</span>
            <span class="s0">for </span><span class="s1">j </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s1">self</span><span class="s2">.</span><span class="s1">pvalue</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]):</span>
                <span class="s0">if </span><span class="s1">i </span><span class="s2">!= </span><span class="s1">j</span><span class="s2">:</span>
                    <span class="s1">s </span><span class="s2">+= (</span><span class="s3">f&quot; (</span><span class="s0">{</span><span class="s1">i</span><span class="s0">} </span><span class="s3">- </span><span class="s0">{</span><span class="s1">j</span><span class="s0">}</span><span class="s3">) </span><span class="s0">{</span><span class="s1">self</span><span class="s2">.</span><span class="s1">statistic</span><span class="s2">[</span><span class="s1">i</span><span class="s2">, </span><span class="s1">j</span><span class="s2">]</span><span class="s0">:</span><span class="s3">&gt;10.3f</span><span class="s0">}</span><span class="s3">&quot;</span>
                          <span class="s3">f&quot;</span><span class="s0">{</span><span class="s1">self</span><span class="s2">.</span><span class="s1">pvalue</span><span class="s2">[</span><span class="s1">i</span><span class="s2">, </span><span class="s1">j</span><span class="s2">]</span><span class="s0">:</span><span class="s3">&gt;10.3f</span><span class="s0">}</span><span class="s3">&quot;</span>
                          <span class="s3">f&quot;</span><span class="s0">{</span><span class="s1">self</span><span class="s2">.</span><span class="s1">_ci</span><span class="s2">.</span><span class="s1">low</span><span class="s2">[</span><span class="s1">i</span><span class="s2">, </span><span class="s1">j</span><span class="s2">]</span><span class="s0">:</span><span class="s3">&gt;10.3f</span><span class="s0">}</span><span class="s3">&quot;</span>
                          <span class="s3">f&quot;</span><span class="s0">{</span><span class="s1">self</span><span class="s2">.</span><span class="s1">_ci</span><span class="s2">.</span><span class="s1">high</span><span class="s2">[</span><span class="s1">i</span><span class="s2">, </span><span class="s1">j</span><span class="s2">]</span><span class="s0">:</span><span class="s3">&gt;10.3f</span><span class="s0">}\n</span><span class="s3">&quot;</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">s</span>

    <span class="s0">def </span><span class="s1">confidence_interval</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">confidence_level</span><span class="s2">=</span><span class="s4">.95</span><span class="s2">):</span>
        <span class="s5">&quot;&quot;&quot;Compute the confidence interval for the specified confidence level. 
 
        Parameters 
        ---------- 
        confidence_level : float, optional 
            Confidence level for the computed confidence interval 
            of the estimated proportion. Default is .95. 
 
        Returns 
        ------- 
        ci : ``ConfidenceInterval`` object 
            The object has attributes ``low`` and ``high`` that hold the 
            lower and upper bounds of the confidence intervals for each 
            comparison. The high and low values are accessible for each 
            comparison at index ``(i, j)`` between groups ``i`` and ``j``. 
 
        References 
        ---------- 
        .. [1] NIST/SEMATECH e-Handbook of Statistical Methods, &quot;7.4.7.1. 
               Tukey's Method.&quot; 
               https://www.itl.nist.gov/div898/handbook/prc/section4/prc471.htm, 
               28 November 2020. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; from scipy.stats import tukey_hsd 
        &gt;&gt;&gt; group0 = [24.5, 23.5, 26.4, 27.1, 29.9] 
        &gt;&gt;&gt; group1 = [28.4, 34.2, 29.5, 32.2, 30.1] 
        &gt;&gt;&gt; group2 = [26.1, 28.3, 24.3, 26.2, 27.8] 
        &gt;&gt;&gt; result = tukey_hsd(group0, group1, group2) 
        &gt;&gt;&gt; ci = result.confidence_interval() 
        &gt;&gt;&gt; ci.low 
        array([[-3.649159, -8.249159, -3.909159], 
               [ 0.950841, -3.649159,  0.690841], 
               [-3.389159, -7.989159, -3.649159]]) 
        &gt;&gt;&gt; ci.high 
        array([[ 3.649159, -0.950841,  3.389159], 
               [ 8.249159,  3.649159,  7.989159], 
               [ 3.909159, -0.690841,  3.649159]]) 
        &quot;&quot;&quot;</span>
        <span class="s6"># check to see if the supplied confidence level matches that of the</span>
        <span class="s6"># previously computed CI.</span>
        <span class="s0">if </span><span class="s2">(</span><span class="s1">self</span><span class="s2">.</span><span class="s1">_ci </span><span class="s0">is not None and </span><span class="s1">self</span><span class="s2">.</span><span class="s1">_ci_cl </span><span class="s0">is not None and</span>
                <span class="s1">confidence_level </span><span class="s2">== </span><span class="s1">self</span><span class="s2">.</span><span class="s1">_ci_cl</span><span class="s2">):</span>
            <span class="s0">return </span><span class="s1">self</span><span class="s2">.</span><span class="s1">_ci</span>

        <span class="s0">if not </span><span class="s4">0 </span><span class="s2">&lt; </span><span class="s1">confidence_level </span><span class="s2">&lt; </span><span class="s4">1</span><span class="s2">:</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;Confidence level must be between 0 and 1.&quot;</span><span class="s2">)</span>
        <span class="s6"># determine the critical value of the studentized range using the</span>
        <span class="s6"># appropriate confidence level, number of treatments, and degrees</span>
        <span class="s6"># of freedom as determined by the number of data less the number of</span>
        <span class="s6"># treatments. (&quot;Confidence limits for Tukey's method&quot;)[1]. Note that</span>
        <span class="s6"># in the cases of unequal sample sizes there will be a criterion for</span>
        <span class="s6"># each group comparison.</span>
        <span class="s1">params </span><span class="s2">= (</span><span class="s1">confidence_level</span><span class="s2">, </span><span class="s1">self</span><span class="s2">.</span><span class="s1">_nobs</span><span class="s2">, </span><span class="s1">self</span><span class="s2">.</span><span class="s1">_ntreatments </span><span class="s2">- </span><span class="s1">self</span><span class="s2">.</span><span class="s1">_nobs</span><span class="s2">)</span>
        <span class="s1">srd </span><span class="s2">= </span><span class="s1">distributions</span><span class="s2">.</span><span class="s1">studentized_range</span><span class="s2">.</span><span class="s1">ppf</span><span class="s2">(*</span><span class="s1">params</span><span class="s2">)</span>
        <span class="s6"># also called maximum critical value, the Tukey criterion is the</span>
        <span class="s6"># studentized range critical value * the square root of mean square</span>
        <span class="s6"># error over the sample size.</span>
        <span class="s1">tukey_criterion </span><span class="s2">= </span><span class="s1">srd </span><span class="s2">* </span><span class="s1">self</span><span class="s2">.</span><span class="s1">_stand_err</span>
        <span class="s6"># the confidence levels are determined by the</span>
        <span class="s6"># `mean_differences` +- `tukey_criterion`</span>
        <span class="s1">upper_conf </span><span class="s2">= </span><span class="s1">self</span><span class="s2">.</span><span class="s1">statistic </span><span class="s2">+ </span><span class="s1">tukey_criterion</span>
        <span class="s1">lower_conf </span><span class="s2">= </span><span class="s1">self</span><span class="s2">.</span><span class="s1">statistic </span><span class="s2">- </span><span class="s1">tukey_criterion</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_ci </span><span class="s2">= </span><span class="s1">ConfidenceInterval</span><span class="s2">(</span><span class="s1">low</span><span class="s2">=</span><span class="s1">lower_conf</span><span class="s2">, </span><span class="s1">high</span><span class="s2">=</span><span class="s1">upper_conf</span><span class="s2">)</span>
        <span class="s1">self</span><span class="s2">.</span><span class="s1">_ci_cl </span><span class="s2">= </span><span class="s1">confidence_level</span>
        <span class="s0">return </span><span class="s1">self</span><span class="s2">.</span><span class="s1">_ci</span>


<span class="s0">def </span><span class="s1">_tukey_hsd_iv</span><span class="s2">(</span><span class="s1">args</span><span class="s2">):</span>
    <span class="s0">if </span><span class="s2">(</span><span class="s1">len</span><span class="s2">(</span><span class="s1">args</span><span class="s2">)) &lt; </span><span class="s4">2</span><span class="s2">:</span>
        <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;There must be more than 1 treatment.&quot;</span><span class="s2">)</span>
    <span class="s1">args </span><span class="s2">= [</span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">arg</span><span class="s2">) </span><span class="s0">for </span><span class="s1">arg </span><span class="s0">in </span><span class="s1">args</span><span class="s2">]</span>
    <span class="s0">for </span><span class="s1">arg </span><span class="s0">in </span><span class="s1">args</span><span class="s2">:</span>
        <span class="s0">if </span><span class="s1">arg</span><span class="s2">.</span><span class="s1">ndim </span><span class="s2">!= </span><span class="s4">1</span><span class="s2">:</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;Input samples must be one-dimensional.&quot;</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">arg</span><span class="s2">.</span><span class="s1">size </span><span class="s2">&lt;= </span><span class="s4">1</span><span class="s2">:</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;Input sample size must be greater than one.&quot;</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">np</span><span class="s2">.</span><span class="s1">isinf</span><span class="s2">(</span><span class="s1">arg</span><span class="s2">).</span><span class="s1">any</span><span class="s2">():</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">&quot;Input samples must be finite.&quot;</span><span class="s2">)</span>
    <span class="s0">return </span><span class="s1">args</span>


<span class="s0">def </span><span class="s1">tukey_hsd</span><span class="s2">(*</span><span class="s1">args</span><span class="s2">):</span>
    <span class="s5">&quot;&quot;&quot;Perform Tukey's HSD test for equality of means over multiple treatments. 
 
    Tukey's honestly significant difference (HSD) test performs pairwise 
    comparison of means for a set of samples. Whereas ANOVA (e.g. `f_oneway`) 
    assesses whether the true means underlying each sample are identical, 
    Tukey's HSD is a post hoc test used to compare the mean of each sample 
    to the mean of each other sample. 
 
    The null hypothesis is that the distributions underlying the samples all 
    have the same mean. The test statistic, which is computed for every 
    possible pairing of samples, is simply the difference between the sample 
    means. For each pair, the p-value is the probability under the null 
    hypothesis (and other assumptions; see notes) of observing such an extreme 
    value of the statistic, considering that many pairwise comparisons are 
    being performed. Confidence intervals for the difference between each pair 
    of means are also available. 
 
    Parameters 
    ---------- 
    sample1, sample2, ... : array_like 
        The sample measurements for each group. There must be at least 
        two arguments. 
 
    Returns 
    ------- 
    result : `~scipy.stats._result_classes.TukeyHSDResult` instance 
        The return value is an object with the following attributes: 
 
        statistic : float ndarray 
            The computed statistic of the test for each comparison. The element 
            at index ``(i, j)`` is the statistic for the comparison between 
            groups ``i`` and ``j``. 
        pvalue : float ndarray 
            The computed p-value of the test for each comparison. The element 
            at index ``(i, j)`` is the p-value for the comparison between 
            groups ``i`` and ``j``. 
 
        The object has the following methods: 
 
        confidence_interval(confidence_level=0.95): 
            Compute the confidence interval for the specified confidence level. 
 
    See Also 
    -------- 
    dunnett : performs comparison of means against a control group. 
 
    Notes 
    ----- 
    The use of this test relies on several assumptions. 
 
    1. The observations are independent within and among groups. 
    2. The observations within each group are normally distributed. 
    3. The distributions from which the samples are drawn have the same finite 
       variance. 
 
    The original formulation of the test was for samples of equal size [6]_. 
    In case of unequal sample sizes, the test uses the Tukey-Kramer method 
    [4]_. 
 
    References 
    ---------- 
    .. [1] NIST/SEMATECH e-Handbook of Statistical Methods, &quot;7.4.7.1. Tukey's 
           Method.&quot; 
           https://www.itl.nist.gov/div898/handbook/prc/section4/prc471.htm, 
           28 November 2020. 
    .. [2] Abdi, Herve &amp; Williams, Lynne. (2021). &quot;Tukey's Honestly Significant 
           Difference (HSD) Test.&quot; 
           https://personal.utdallas.edu/~herve/abdi-HSD2010-pretty.pdf 
    .. [3] &quot;One-Way ANOVA Using SAS PROC ANOVA &amp; PROC GLM.&quot; SAS 
           Tutorials, 2007, www.stattutorials.com/SAS/TUTORIAL-PROC-GLM.htm. 
    .. [4] Kramer, Clyde Young. &quot;Extension of Multiple Range Tests to Group 
           Means with Unequal Numbers of Replications.&quot; Biometrics, vol. 12, 
           no. 3, 1956, pp. 307-310. JSTOR, www.jstor.org/stable/3001469. 
           Accessed 25 May 2021. 
    .. [5] NIST/SEMATECH e-Handbook of Statistical Methods, &quot;7.4.3.3. 
           The ANOVA table and tests of hypotheses about means&quot; 
           https://www.itl.nist.gov/div898/handbook/prc/section4/prc433.htm, 
           2 June 2021. 
    .. [6] Tukey, John W. &quot;Comparing Individual Means in the Analysis of 
           Variance.&quot; Biometrics, vol. 5, no. 2, 1949, pp. 99-114. JSTOR, 
           www.jstor.org/stable/3001913. Accessed 14 June 2021. 
 
 
    Examples 
    -------- 
    Here are some data comparing the time to relief of three brands of 
    headache medicine, reported in minutes. Data adapted from [3]_. 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from scipy.stats import tukey_hsd 
    &gt;&gt;&gt; group0 = [24.5, 23.5, 26.4, 27.1, 29.9] 
    &gt;&gt;&gt; group1 = [28.4, 34.2, 29.5, 32.2, 30.1] 
    &gt;&gt;&gt; group2 = [26.1, 28.3, 24.3, 26.2, 27.8] 
 
    We would like to see if the means between any of the groups are 
    significantly different. First, visually examine a box and whisker plot. 
 
    &gt;&gt;&gt; import matplotlib.pyplot as plt 
    &gt;&gt;&gt; fig, ax = plt.subplots(1, 1) 
    &gt;&gt;&gt; ax.boxplot([group0, group1, group2]) 
    &gt;&gt;&gt; ax.set_xticklabels([&quot;group0&quot;, &quot;group1&quot;, &quot;group2&quot;]) # doctest: +SKIP 
    &gt;&gt;&gt; ax.set_ylabel(&quot;mean&quot;) # doctest: +SKIP 
    &gt;&gt;&gt; plt.show() 
 
    From the box and whisker plot, we can see overlap in the interquartile 
    ranges group 1 to group 2 and group 3, but we can apply the ``tukey_hsd`` 
    test to determine if the difference between means is significant. We 
    set a significance level of .05 to reject the null hypothesis. 
 
    &gt;&gt;&gt; res = tukey_hsd(group0, group1, group2) 
    &gt;&gt;&gt; print(res) 
    Tukey's HSD Pairwise Group Comparisons (95.0% Confidence Interval) 
    Comparison  Statistic  p-value   Lower CI   Upper CI 
    (0 - 1)     -4.600      0.014     -8.249     -0.951 
    (0 - 2)     -0.260      0.980     -3.909      3.389 
    (1 - 0)      4.600      0.014      0.951      8.249 
    (1 - 2)      4.340      0.020      0.691      7.989 
    (2 - 0)      0.260      0.980     -3.389      3.909 
    (2 - 1)     -4.340      0.020     -7.989     -0.691 
 
    The null hypothesis is that each group has the same mean. The p-value for 
    comparisons between ``group0`` and ``group1`` as well as ``group1`` and 
    ``group2`` do not exceed .05, so we reject the null hypothesis that they 
    have the same means. The p-value of the comparison between ``group0`` 
    and ``group2`` exceeds .05, so we accept the null hypothesis that there 
    is not a significant difference between their means. 
 
    We can also compute the confidence interval associated with our chosen 
    confidence level. 
 
    &gt;&gt;&gt; group0 = [24.5, 23.5, 26.4, 27.1, 29.9] 
    &gt;&gt;&gt; group1 = [28.4, 34.2, 29.5, 32.2, 30.1] 
    &gt;&gt;&gt; group2 = [26.1, 28.3, 24.3, 26.2, 27.8] 
    &gt;&gt;&gt; result = tukey_hsd(group0, group1, group2) 
    &gt;&gt;&gt; conf = res.confidence_interval(confidence_level=.99) 
    &gt;&gt;&gt; for ((i, j), l) in np.ndenumerate(conf.low): 
    ...     # filter out self comparisons 
    ...     if i != j: 
    ...         h = conf.high[i,j] 
    ...         print(f&quot;({i} - {j}) {l:&gt;6.3f} {h:&gt;6.3f}&quot;) 
    (0 - 1) -9.480  0.280 
    (0 - 2) -5.140  4.620 
    (1 - 0) -0.280  9.480 
    (1 - 2) -0.540  9.220 
    (2 - 0) -4.620  5.140 
    (2 - 1) -9.220  0.540 
    &quot;&quot;&quot;</span>
    <span class="s1">args </span><span class="s2">= </span><span class="s1">_tukey_hsd_iv</span><span class="s2">(</span><span class="s1">args</span><span class="s2">)</span>
    <span class="s1">ntreatments </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">args</span><span class="s2">)</span>
    <span class="s1">means </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">([</span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">arg</span><span class="s2">) </span><span class="s0">for </span><span class="s1">arg </span><span class="s0">in </span><span class="s1">args</span><span class="s2">])</span>
    <span class="s1">nsamples_treatments </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">([</span><span class="s1">a</span><span class="s2">.</span><span class="s1">size </span><span class="s0">for </span><span class="s1">a </span><span class="s0">in </span><span class="s1">args</span><span class="s2">])</span>
    <span class="s1">nobs </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">nsamples_treatments</span><span class="s2">)</span>

    <span class="s6"># determine mean square error [5]. Note that this is sometimes called</span>
    <span class="s6"># mean square error within.</span>
    <span class="s1">mse </span><span class="s2">= (</span><span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">([</span><span class="s1">np</span><span class="s2">.</span><span class="s1">var</span><span class="s2">(</span><span class="s1">arg</span><span class="s2">, </span><span class="s1">ddof</span><span class="s2">=</span><span class="s4">1</span><span class="s2">) </span><span class="s0">for </span><span class="s1">arg </span><span class="s0">in </span><span class="s1">args</span><span class="s2">] *</span>
                  <span class="s2">(</span><span class="s1">nsamples_treatments </span><span class="s2">- </span><span class="s4">1</span><span class="s2">)) / (</span><span class="s1">nobs </span><span class="s2">- </span><span class="s1">ntreatments</span><span class="s2">))</span>

    <span class="s6"># The calculation of the standard error differs when treatments differ in</span>
    <span class="s6"># size. See (&quot;Unequal sample sizes&quot;)[1].</span>
    <span class="s0">if </span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">nsamples_treatments</span><span class="s2">).</span><span class="s1">size </span><span class="s2">== </span><span class="s4">1</span><span class="s2">:</span>
        <span class="s6"># all input groups are the same length, so only one value needs to be</span>
        <span class="s6"># calculated [1].</span>
        <span class="s1">normalize </span><span class="s2">= </span><span class="s4">2 </span><span class="s2">/ </span><span class="s1">nsamples_treatments</span><span class="s2">[</span><span class="s4">0</span><span class="s2">]</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s6"># to compare groups of differing sizes, we must compute a variance</span>
        <span class="s6"># value for each individual comparison. Use broadcasting to get the</span>
        <span class="s6"># resulting matrix. [3], verified against [4] (page 308).</span>
        <span class="s1">normalize </span><span class="s2">= </span><span class="s4">1 </span><span class="s2">/ </span><span class="s1">nsamples_treatments </span><span class="s2">+ </span><span class="s4">1 </span><span class="s2">/ </span><span class="s1">nsamples_treatments</span><span class="s2">[</span><span class="s0">None</span><span class="s2">].</span><span class="s1">T</span>

    <span class="s6"># the standard error is used in the computation of the tukey criterion and</span>
    <span class="s6"># finding the p-values.</span>
    <span class="s1">stand_err </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sqrt</span><span class="s2">(</span><span class="s1">normalize </span><span class="s2">* </span><span class="s1">mse </span><span class="s2">/ </span><span class="s4">2</span><span class="s2">)</span>

    <span class="s6"># the mean difference is the test statistic.</span>
    <span class="s1">mean_differences </span><span class="s2">= </span><span class="s1">means</span><span class="s2">[</span><span class="s0">None</span><span class="s2">].</span><span class="s1">T </span><span class="s2">- </span><span class="s1">means</span>

    <span class="s6"># Calculate the t-statistic to use within the survival function of the</span>
    <span class="s6"># studentized range to get the p-value.</span>
    <span class="s1">t_stat </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">abs</span><span class="s2">(</span><span class="s1">mean_differences</span><span class="s2">) / </span><span class="s1">stand_err</span>

    <span class="s1">params </span><span class="s2">= </span><span class="s1">t_stat</span><span class="s2">, </span><span class="s1">ntreatments</span><span class="s2">, </span><span class="s1">nobs </span><span class="s2">- </span><span class="s1">ntreatments</span>
    <span class="s1">pvalues </span><span class="s2">= </span><span class="s1">distributions</span><span class="s2">.</span><span class="s1">studentized_range</span><span class="s2">.</span><span class="s1">sf</span><span class="s2">(*</span><span class="s1">params</span><span class="s2">)</span>

    <span class="s0">return </span><span class="s1">TukeyHSDResult</span><span class="s2">(</span><span class="s1">mean_differences</span><span class="s2">, </span><span class="s1">pvalues</span><span class="s2">, </span><span class="s1">ntreatments</span><span class="s2">,</span>
                          <span class="s1">nobs</span><span class="s2">, </span><span class="s1">stand_err</span><span class="s2">)</span>
</pre>
</body>
</html>