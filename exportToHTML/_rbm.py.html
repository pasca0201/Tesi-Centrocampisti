<html>
<head>
<title>_rbm.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_rbm.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Restricted Boltzmann Machine&quot;&quot;&quot;</span>

<span class="s2"># Authors: Yann N. Dauphin &lt;dauphiya@iro.umontreal.ca&gt;</span>
<span class="s2">#          Vlad Niculae</span>
<span class="s2">#          Gabriel Synnaeve</span>
<span class="s2">#          Lars Buitinck</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">time</span>
<span class="s3">from </span><span class="s1">numbers </span><span class="s3">import </span><span class="s1">Integral</span><span class="s4">, </span><span class="s1">Real</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">import </span><span class="s1">scipy</span><span class="s4">.</span><span class="s1">sparse </span><span class="s3">as </span><span class="s1">sp</span>
<span class="s3">from </span><span class="s1">scipy</span><span class="s4">.</span><span class="s1">special </span><span class="s3">import </span><span class="s1">expit  </span><span class="s2"># logistic function</span>

<span class="s3">from </span><span class="s4">..</span><span class="s1">base </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">BaseEstimator</span><span class="s4">,</span>
    <span class="s1">ClassNamePrefixFeaturesOutMixin</span><span class="s4">,</span>
    <span class="s1">TransformerMixin</span><span class="s4">,</span>
    <span class="s1">_fit_context</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils </span><span class="s3">import </span><span class="s1">check_random_state</span><span class="s4">, </span><span class="s1">gen_even_slices</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_param_validation </span><span class="s3">import </span><span class="s1">Interval</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">extmath </span><span class="s3">import </span><span class="s1">safe_sparse_dot</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">validation </span><span class="s3">import </span><span class="s1">check_is_fitted</span>


<span class="s3">class </span><span class="s1">BernoulliRBM</span><span class="s4">(</span><span class="s1">ClassNamePrefixFeaturesOutMixin</span><span class="s4">, </span><span class="s1">TransformerMixin</span><span class="s4">, </span><span class="s1">BaseEstimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Bernoulli Restricted Boltzmann Machine (RBM). 
 
    A Restricted Boltzmann Machine with binary visible units and 
    binary hidden units. Parameters are estimated using Stochastic Maximum 
    Likelihood (SML), also known as Persistent Contrastive Divergence (PCD) 
    [2]. 
 
    The time complexity of this implementation is ``O(d ** 2)`` assuming 
    d ~ n_features ~ n_components. 
 
    Read more in the :ref:`User Guide &lt;rbm&gt;`. 
 
    Parameters 
    ---------- 
    n_components : int, default=256 
        Number of binary hidden units. 
 
    learning_rate : float, default=0.1 
        The learning rate for weight updates. It is *highly* recommended 
        to tune this hyper-parameter. Reasonable values are in the 
        10**[0., -3.] range. 
 
    batch_size : int, default=10 
        Number of examples per minibatch. 
 
    n_iter : int, default=10 
        Number of iterations/sweeps over the training dataset to perform 
        during training. 
 
    verbose : int, default=0 
        The verbosity level. The default, zero, means silent mode. Range 
        of values is [0, inf]. 
 
    random_state : int, RandomState instance or None, default=None 
        Determines random number generation for: 
 
        - Gibbs sampling from visible and hidden layers. 
 
        - Initializing components, sampling from layers during fit. 
 
        - Corrupting the data when scoring samples. 
 
        Pass an int for reproducible results across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    Attributes 
    ---------- 
    intercept_hidden_ : array-like of shape (n_components,) 
        Biases of the hidden units. 
 
    intercept_visible_ : array-like of shape (n_features,) 
        Biases of the visible units. 
 
    components_ : array-like of shape (n_components, n_features) 
        Weight matrix, where `n_features` is the number of 
        visible units and `n_components` is the number of hidden units. 
 
    h_samples_ : array-like of shape (batch_size, n_components) 
        Hidden Activation sampled from the model distribution, 
        where `batch_size` is the number of examples per minibatch and 
        `n_components` is the number of hidden units. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    See Also 
    -------- 
    sklearn.neural_network.MLPRegressor : Multi-layer Perceptron regressor. 
    sklearn.neural_network.MLPClassifier : Multi-layer Perceptron classifier. 
    sklearn.decomposition.PCA : An unsupervised linear dimensionality 
        reduction model. 
 
    References 
    ---------- 
 
    [1] Hinton, G. E., Osindero, S. and Teh, Y. A fast learning algorithm for 
        deep belief nets. Neural Computation 18, pp 1527-1554. 
        https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf 
 
    [2] Tieleman, T. Training Restricted Boltzmann Machines using 
        Approximations to the Likelihood Gradient. International Conference 
        on Machine Learning (ICML) 2008 
 
    Examples 
    -------- 
 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.neural_network import BernoulliRBM 
    &gt;&gt;&gt; X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]]) 
    &gt;&gt;&gt; model = BernoulliRBM(n_components=2) 
    &gt;&gt;&gt; model.fit(X) 
    BernoulliRBM(n_components=2) 
 
    For a more detailed example usage, see 
    :ref:`sphx_glr_auto_examples_neural_networks_plot_rbm_logistic_classification.py`. 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s5">&quot;n_components&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;learning_rate&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;neither&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;batch_size&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;n_iter&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;verbose&quot;</span><span class="s4">: [</span><span class="s5">&quot;verbose&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;random_state&quot;</span><span class="s4">: [</span><span class="s5">&quot;random_state&quot;</span><span class="s4">],</span>
    <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">n_components</span><span class="s4">=</span><span class="s6">256</span><span class="s4">,</span>
        <span class="s4">*,</span>
        <span class="s1">learning_rate</span><span class="s4">=</span><span class="s6">0.1</span><span class="s4">,</span>
        <span class="s1">batch_size</span><span class="s4">=</span><span class="s6">10</span><span class="s4">,</span>
        <span class="s1">n_iter</span><span class="s4">=</span><span class="s6">10</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_components </span><span class="s4">= </span><span class="s1">n_components</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">learning_rate </span><span class="s4">= </span><span class="s1">learning_rate</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">batch_size </span><span class="s4">= </span><span class="s1">batch_size</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter </span><span class="s4">= </span><span class="s1">n_iter</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">verbose </span><span class="s4">= </span><span class="s1">verbose</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">random_state </span><span class="s4">= </span><span class="s1">random_state</span>

    <span class="s3">def </span><span class="s1">transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Compute the hidden layer activation probabilities, P(h=1|v=X). 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix} of shape (n_samples, n_features) 
            The data to be transformed. 
 
        Returns 
        ------- 
        h : ndarray of shape (n_samples, n_components) 
            Latent representations of the data. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>

        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">, </span><span class="s1">accept_sparse</span><span class="s4">=</span><span class="s5">&quot;csr&quot;</span><span class="s4">, </span><span class="s1">reset</span><span class="s4">=</span><span class="s3">False</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">)</span>
        <span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_mean_hiddens</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_mean_hiddens</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">v</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Computes the probabilities P(h=1|v). 
 
        Parameters 
        ---------- 
        v : ndarray of shape (n_samples, n_features) 
            Values of the visible layer. 
 
        Returns 
        ------- 
        h : ndarray of shape (n_samples, n_components) 
            Corresponding mean field values for the hidden layer. 
        &quot;&quot;&quot;</span>
        <span class="s1">p </span><span class="s4">= </span><span class="s1">safe_sparse_dot</span><span class="s4">(</span><span class="s1">v</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">.</span><span class="s1">T</span><span class="s4">)</span>
        <span class="s1">p </span><span class="s4">+= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">intercept_hidden_</span>
        <span class="s3">return </span><span class="s1">expit</span><span class="s4">(</span><span class="s1">p</span><span class="s4">, </span><span class="s1">out</span><span class="s4">=</span><span class="s1">p</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_sample_hiddens</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">v</span><span class="s4">, </span><span class="s1">rng</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Sample from the distribution P(h|v). 
 
        Parameters 
        ---------- 
        v : ndarray of shape (n_samples, n_features) 
            Values of the visible layer to sample from. 
 
        rng : RandomState instance 
            Random number generator to use. 
 
        Returns 
        ------- 
        h : ndarray of shape (n_samples, n_components) 
            Values of the hidden layer. 
        &quot;&quot;&quot;</span>
        <span class="s1">p </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_mean_hiddens</span><span class="s4">(</span><span class="s1">v</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">uniform</span><span class="s4">(</span><span class="s1">size</span><span class="s4">=</span><span class="s1">p</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">) &lt; </span><span class="s1">p</span>

    <span class="s3">def </span><span class="s1">_sample_visibles</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">h</span><span class="s4">, </span><span class="s1">rng</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Sample from the distribution P(v|h). 
 
        Parameters 
        ---------- 
        h : ndarray of shape (n_samples, n_components) 
            Values of the hidden layer to sample from. 
 
        rng : RandomState instance 
            Random number generator to use. 
 
        Returns 
        ------- 
        v : ndarray of shape (n_samples, n_features) 
            Values of the visible layer. 
        &quot;&quot;&quot;</span>
        <span class="s1">p </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">dot</span><span class="s4">(</span><span class="s1">h</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">)</span>
        <span class="s1">p </span><span class="s4">+= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">intercept_visible_</span>
        <span class="s1">expit</span><span class="s4">(</span><span class="s1">p</span><span class="s4">, </span><span class="s1">out</span><span class="s4">=</span><span class="s1">p</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">uniform</span><span class="s4">(</span><span class="s1">size</span><span class="s4">=</span><span class="s1">p</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">) &lt; </span><span class="s1">p</span>

    <span class="s3">def </span><span class="s1">_free_energy</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">v</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Computes the free energy F(v) = - log sum_h exp(-E(v,h)). 
 
        Parameters 
        ---------- 
        v : ndarray of shape (n_samples, n_features) 
            Values of the visible layer. 
 
        Returns 
        ------- 
        free_energy : ndarray of shape (n_samples,) 
            The value of the free energy. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s4">-</span><span class="s1">safe_sparse_dot</span><span class="s4">(</span><span class="s1">v</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">intercept_visible_</span><span class="s4">) - </span><span class="s1">np</span><span class="s4">.</span><span class="s1">logaddexp</span><span class="s4">(</span>
            <span class="s6">0</span><span class="s4">, </span><span class="s1">safe_sparse_dot</span><span class="s4">(</span><span class="s1">v</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">.</span><span class="s1">T</span><span class="s4">) + </span><span class="s1">self</span><span class="s4">.</span><span class="s1">intercept_hidden_</span>
        <span class="s4">).</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">1</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">gibbs</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">v</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Perform one Gibbs sampling step. 
 
        Parameters 
        ---------- 
        v : ndarray of shape (n_samples, n_features) 
            Values of the visible layer to start from. 
 
        Returns 
        ------- 
        v_new : ndarray of shape (n_samples, n_features) 
            Values of the visible layer after one Gibbs step. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s3">if not </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;random_state_&quot;</span><span class="s4">):</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">random_state_ </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>
        <span class="s1">h_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_sample_hiddens</span><span class="s4">(</span><span class="s1">v</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state_</span><span class="s4">)</span>
        <span class="s1">v_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_sample_visibles</span><span class="s4">(</span><span class="s1">h_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state_</span><span class="s4">)</span>

        <span class="s3">return </span><span class="s1">v_</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">def </span><span class="s1">partial_fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Fit the model to the partial segment of the data X. 
 
        Parameters 
        ---------- 
        X : ndarray of shape (n_samples, n_features) 
            Training data. 
 
        y : array-like of shape (n_samples,) or (n_samples, n_outputs), default=None 
            Target values (None for unsupervised transformations). 
 
        Returns 
        ------- 
        self : BernoulliRBM 
            The fitted model. 
        &quot;&quot;&quot;</span>
        <span class="s1">first_pass </span><span class="s4">= </span><span class="s3">not </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;components_&quot;</span><span class="s4">)</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">, </span><span class="s1">accept_sparse</span><span class="s4">=</span><span class="s5">&quot;csr&quot;</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">reset</span><span class="s4">=</span><span class="s1">first_pass</span>
        <span class="s4">)</span>
        <span class="s3">if not </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;random_state_&quot;</span><span class="s4">):</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">random_state_ </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>
        <span class="s3">if not </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;components_&quot;</span><span class="s4">):</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">components_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">asarray</span><span class="s4">(</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">random_state_</span><span class="s4">.</span><span class="s1">normal</span><span class="s4">(</span><span class="s6">0</span><span class="s4">, </span><span class="s6">0.01</span><span class="s4">, (</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">])),</span>
                <span class="s1">order</span><span class="s4">=</span><span class="s5">&quot;F&quot;</span><span class="s4">,</span>
            <span class="s4">)</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_n_features_out </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>
        <span class="s3">if not </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;intercept_hidden_&quot;</span><span class="s4">):</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">intercept_hidden_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">n_components</span><span class="s4">,</span>
            <span class="s4">)</span>
        <span class="s3">if not </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;intercept_visible_&quot;</span><span class="s4">):</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">intercept_visible_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span>
                <span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">],</span>
            <span class="s4">)</span>
        <span class="s3">if not </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;h_samples_&quot;</span><span class="s4">):</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">h_samples_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">((</span><span class="s1">self</span><span class="s4">.</span><span class="s1">batch_size</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components</span><span class="s4">))</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">_fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state_</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">v_pos</span><span class="s4">, </span><span class="s1">rng</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Inner fit for one mini-batch. 
 
        Adjust the parameters to maximize the likelihood of v using 
        Stochastic Maximum Likelihood (SML). 
 
        Parameters 
        ---------- 
        v_pos : ndarray of shape (n_samples, n_features) 
            The data to use for training. 
 
        rng : RandomState instance 
            Random number generator to use for sampling. 
        &quot;&quot;&quot;</span>
        <span class="s1">h_pos </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_mean_hiddens</span><span class="s4">(</span><span class="s1">v_pos</span><span class="s4">)</span>
        <span class="s1">v_neg </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_sample_visibles</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">h_samples_</span><span class="s4">, </span><span class="s1">rng</span><span class="s4">)</span>
        <span class="s1">h_neg </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_mean_hiddens</span><span class="s4">(</span><span class="s1">v_neg</span><span class="s4">)</span>

        <span class="s1">lr </span><span class="s4">= </span><span class="s1">float</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">learning_rate</span><span class="s4">) / </span><span class="s1">v_pos</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>
        <span class="s1">update </span><span class="s4">= </span><span class="s1">safe_sparse_dot</span><span class="s4">(</span><span class="s1">v_pos</span><span class="s4">.</span><span class="s1">T</span><span class="s4">, </span><span class="s1">h_pos</span><span class="s4">, </span><span class="s1">dense_output</span><span class="s4">=</span><span class="s3">True</span><span class="s4">).</span><span class="s1">T</span>
        <span class="s1">update </span><span class="s4">-= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">dot</span><span class="s4">(</span><span class="s1">h_neg</span><span class="s4">.</span><span class="s1">T</span><span class="s4">, </span><span class="s1">v_neg</span><span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">components_ </span><span class="s4">+= </span><span class="s1">lr </span><span class="s4">* </span><span class="s1">update</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">intercept_hidden_ </span><span class="s4">+= </span><span class="s1">lr </span><span class="s4">* (</span><span class="s1">h_pos</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">0</span><span class="s4">) - </span><span class="s1">h_neg</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">0</span><span class="s4">))</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">intercept_visible_ </span><span class="s4">+= </span><span class="s1">lr </span><span class="s4">* (</span>
            <span class="s1">np</span><span class="s4">.</span><span class="s1">asarray</span><span class="s4">(</span><span class="s1">v_pos</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">0</span><span class="s4">)).</span><span class="s1">squeeze</span><span class="s4">() - </span><span class="s1">v_neg</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">0</span><span class="s4">)</span>
        <span class="s4">)</span>

        <span class="s1">h_neg</span><span class="s4">[</span><span class="s1">rng</span><span class="s4">.</span><span class="s1">uniform</span><span class="s4">(</span><span class="s1">size</span><span class="s4">=</span><span class="s1">h_neg</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">) &lt; </span><span class="s1">h_neg</span><span class="s4">] = </span><span class="s6">1.0  </span><span class="s2"># sample binomial</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">h_samples_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">floor</span><span class="s4">(</span><span class="s1">h_neg</span><span class="s4">, </span><span class="s1">h_neg</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">score_samples</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Compute the pseudo-likelihood of X. 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix} of shape (n_samples, n_features) 
            Values of the visible layer. Must be all-boolean (not checked). 
 
        Returns 
        ------- 
        pseudo_likelihood : ndarray of shape (n_samples,) 
            Value of the pseudo-likelihood (proxy for likelihood). 
 
        Notes 
        ----- 
        This method is not deterministic: it computes a quantity called the 
        free energy on X, then on a randomly corrupted version of X, and 
        returns the log of the logistic function of the difference. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>

        <span class="s1">v </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">accept_sparse</span><span class="s4">=</span><span class="s5">&quot;csr&quot;</span><span class="s4">, </span><span class="s1">reset</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>
        <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>

        <span class="s2"># Randomly corrupt one feature in each sample in v.</span>
        <span class="s1">ind </span><span class="s4">= (</span><span class="s1">np</span><span class="s4">.</span><span class="s1">arange</span><span class="s4">(</span><span class="s1">v</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]), </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">randint</span><span class="s4">(</span><span class="s6">0</span><span class="s4">, </span><span class="s1">v</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">], </span><span class="s1">v</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]))</span>
        <span class="s3">if </span><span class="s1">sp</span><span class="s4">.</span><span class="s1">issparse</span><span class="s4">(</span><span class="s1">v</span><span class="s4">):</span>
            <span class="s1">data </span><span class="s4">= -</span><span class="s6">2 </span><span class="s4">* </span><span class="s1">v</span><span class="s4">[</span><span class="s1">ind</span><span class="s4">] + </span><span class="s6">1</span>
            <span class="s3">if </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">data</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">matrix</span><span class="s4">):  </span><span class="s2"># v is a sparse matrix</span>
                <span class="s1">v_ </span><span class="s4">= </span><span class="s1">v </span><span class="s4">+ </span><span class="s1">sp</span><span class="s4">.</span><span class="s1">csr_matrix</span><span class="s4">((</span><span class="s1">data</span><span class="s4">.</span><span class="s1">A</span><span class="s4">.</span><span class="s1">ravel</span><span class="s4">(), </span><span class="s1">ind</span><span class="s4">), </span><span class="s1">shape</span><span class="s4">=</span><span class="s1">v</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">)</span>
            <span class="s3">else</span><span class="s4">:  </span><span class="s2"># v is a sparse array</span>
                <span class="s1">v_ </span><span class="s4">= </span><span class="s1">v </span><span class="s4">+ </span><span class="s1">sp</span><span class="s4">.</span><span class="s1">csr_array</span><span class="s4">((</span><span class="s1">data</span><span class="s4">.</span><span class="s1">ravel</span><span class="s4">(), </span><span class="s1">ind</span><span class="s4">), </span><span class="s1">shape</span><span class="s4">=</span><span class="s1">v</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">v_ </span><span class="s4">= </span><span class="s1">v</span><span class="s4">.</span><span class="s1">copy</span><span class="s4">()</span>
            <span class="s1">v_</span><span class="s4">[</span><span class="s1">ind</span><span class="s4">] = </span><span class="s6">1 </span><span class="s4">- </span><span class="s1">v_</span><span class="s4">[</span><span class="s1">ind</span><span class="s4">]</span>

        <span class="s1">fe </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_free_energy</span><span class="s4">(</span><span class="s1">v</span><span class="s4">)</span>
        <span class="s1">fe_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_free_energy</span><span class="s4">(</span><span class="s1">v_</span><span class="s4">)</span>
        <span class="s2"># log(expit(x)) = log(1 / (1 + exp(-x)) = -np.logaddexp(0, -x)</span>
        <span class="s3">return </span><span class="s4">-</span><span class="s1">v</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">] * </span><span class="s1">np</span><span class="s4">.</span><span class="s1">logaddexp</span><span class="s4">(</span><span class="s6">0</span><span class="s4">, -(</span><span class="s1">fe_ </span><span class="s4">- </span><span class="s1">fe</span><span class="s4">))</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Fit the model to the data X. 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix} of shape (n_samples, n_features) 
            Training data. 
 
        y : array-like of shape (n_samples,) or (n_samples, n_outputs), default=None 
            Target values (None for unsupervised transformations). 
 
        Returns 
        ------- 
        self : BernoulliRBM 
            The fitted model. 
        &quot;&quot;&quot;</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">accept_sparse</span><span class="s4">=</span><span class="s5">&quot;csr&quot;</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">))</span>
        <span class="s1">n_samples </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>
        <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">components_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">asarray</span><span class="s4">(</span>
            <span class="s1">rng</span><span class="s4">.</span><span class="s1">normal</span><span class="s4">(</span><span class="s6">0</span><span class="s4">, </span><span class="s6">0.01</span><span class="s4">, (</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">])),</span>
            <span class="s1">order</span><span class="s4">=</span><span class="s5">&quot;F&quot;</span><span class="s4">,</span>
            <span class="s1">dtype</span><span class="s4">=</span><span class="s1">X</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_n_features_out </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">intercept_hidden_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">X</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">intercept_visible_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">], </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">X</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">h_samples_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">((</span><span class="s1">self</span><span class="s4">.</span><span class="s1">batch_size</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components</span><span class="s4">), </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">X</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">)</span>

        <span class="s1">n_batches </span><span class="s4">= </span><span class="s1">int</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">ceil</span><span class="s4">(</span><span class="s1">float</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">) / </span><span class="s1">self</span><span class="s4">.</span><span class="s1">batch_size</span><span class="s4">))</span>
        <span class="s1">batch_slices </span><span class="s4">= </span><span class="s1">list</span><span class="s4">(</span>
            <span class="s1">gen_even_slices</span><span class="s4">(</span><span class="s1">n_batches </span><span class="s4">* </span><span class="s1">self</span><span class="s4">.</span><span class="s1">batch_size</span><span class="s4">, </span><span class="s1">n_batches</span><span class="s4">, </span><span class="s1">n_samples</span><span class="s4">=</span><span class="s1">n_samples</span><span class="s4">)</span>
        <span class="s4">)</span>
        <span class="s1">verbose </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span>
        <span class="s1">begin </span><span class="s4">= </span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">()</span>
        <span class="s3">for </span><span class="s1">iteration </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s6">1</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter </span><span class="s4">+ </span><span class="s6">1</span><span class="s4">):</span>
            <span class="s3">for </span><span class="s1">batch_slice </span><span class="s3">in </span><span class="s1">batch_slices</span><span class="s4">:</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">_fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">[</span><span class="s1">batch_slice</span><span class="s4">], </span><span class="s1">rng</span><span class="s4">)</span>

            <span class="s3">if </span><span class="s1">verbose</span><span class="s4">:</span>
                <span class="s1">end </span><span class="s4">= </span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">()</span>
                <span class="s1">print</span><span class="s4">(</span>
                    <span class="s5">&quot;[%s] Iteration %d, pseudo-likelihood = %.2f, time = %.2fs&quot;</span>
                    <span class="s4">% (</span>
                        <span class="s1">type</span><span class="s4">(</span><span class="s1">self</span><span class="s4">).</span><span class="s1">__name__</span><span class="s4">,</span>
                        <span class="s1">iteration</span><span class="s4">,</span>
                        <span class="s1">self</span><span class="s4">.</span><span class="s1">score_samples</span><span class="s4">(</span><span class="s1">X</span><span class="s4">).</span><span class="s1">mean</span><span class="s4">(),</span>
                        <span class="s1">end </span><span class="s4">- </span><span class="s1">begin</span><span class="s4">,</span>
                    <span class="s4">)</span>
                <span class="s4">)</span>
                <span class="s1">begin </span><span class="s4">= </span><span class="s1">end</span>

        <span class="s3">return </span><span class="s1">self</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span>
            <span class="s5">&quot;_xfail_checks&quot;</span><span class="s4">: {</span>
                <span class="s5">&quot;check_methods_subset_invariance&quot;</span><span class="s4">: (</span>
                    <span class="s5">&quot;fails for the decision_function method&quot;</span>
                <span class="s4">),</span>
                <span class="s5">&quot;check_methods_sample_order_invariance&quot;</span><span class="s4">: (</span>
                    <span class="s5">&quot;fails for the score_samples method&quot;</span>
                <span class="s4">),</span>
            <span class="s4">},</span>
            <span class="s5">&quot;preserves_dtype&quot;</span><span class="s4">: [</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">],</span>
        <span class="s4">}</span>
</pre>
</body>
</html>