<html>
<head>
<title>_passive_aggressive.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #7a7e85;}
.s1 { color: #bcbec4;}
.s2 { color: #cf8e6d;}
.s3 { color: #bcbec4;}
.s4 { color: #5f826b; font-style: italic;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_passive_aggressive.py</font>
</center></td></tr></table>
<pre><span class="s0"># Authors: Rob Zinkov, Mathieu Blondel</span>
<span class="s0"># License: BSD 3 clause</span>
<span class="s2">from </span><span class="s1">numbers </span><span class="s2">import </span><span class="s1">Real</span>

<span class="s2">from </span><span class="s3">..</span><span class="s1">base </span><span class="s2">import </span><span class="s1">_fit_context</span>
<span class="s2">from </span><span class="s3">..</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">_param_validation </span><span class="s2">import </span><span class="s1">Interval</span><span class="s3">, </span><span class="s1">StrOptions</span>
<span class="s2">from </span><span class="s3">.</span><span class="s1">_stochastic_gradient </span><span class="s2">import </span><span class="s1">DEFAULT_EPSILON</span><span class="s3">, </span><span class="s1">BaseSGDClassifier</span><span class="s3">, </span><span class="s1">BaseSGDRegressor</span>


<span class="s2">class </span><span class="s1">PassiveAggressiveClassifier</span><span class="s3">(</span><span class="s1">BaseSGDClassifier</span><span class="s3">):</span>
    <span class="s4">&quot;&quot;&quot;Passive Aggressive Classifier. 
 
    Read more in the :ref:`User Guide &lt;passive_aggressive&gt;`. 
 
    Parameters 
    ---------- 
    C : float, default=1.0 
        Maximum step size (regularization). Defaults to 1.0. 
 
    fit_intercept : bool, default=True 
        Whether the intercept should be estimated or not. If False, the 
        data is assumed to be already centered. 
 
    max_iter : int, default=1000 
        The maximum number of passes over the training data (aka epochs). 
        It only impacts the behavior in the ``fit`` method, and not the 
        :meth:`~sklearn.linear_model.PassiveAggressiveClassifier.partial_fit` method. 
 
        .. versionadded:: 0.19 
 
    tol : float or None, default=1e-3 
        The stopping criterion. If it is not None, the iterations will stop 
        when (loss &gt; previous_loss - tol). 
 
        .. versionadded:: 0.19 
 
    early_stopping : bool, default=False 
        Whether to use early stopping to terminate training when validation 
        score is not improving. If set to True, it will automatically set aside 
        a stratified fraction of training data as validation and terminate 
        training when validation score is not improving by at least `tol` for 
        `n_iter_no_change` consecutive epochs. 
 
        .. versionadded:: 0.20 
 
    validation_fraction : float, default=0.1 
        The proportion of training data to set aside as validation set for 
        early stopping. Must be between 0 and 1. 
        Only used if early_stopping is True. 
 
        .. versionadded:: 0.20 
 
    n_iter_no_change : int, default=5 
        Number of iterations with no improvement to wait before early stopping. 
 
        .. versionadded:: 0.20 
 
    shuffle : bool, default=True 
        Whether or not the training data should be shuffled after each epoch. 
 
    verbose : int, default=0 
        The verbosity level. 
 
    loss : str, default=&quot;hinge&quot; 
        The loss function to be used: 
        hinge: equivalent to PA-I in the reference paper. 
        squared_hinge: equivalent to PA-II in the reference paper. 
 
    n_jobs : int or None, default=None 
        The number of CPUs to use to do the OVA (One Versus All, for 
        multi-class problems) computation. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    random_state : int, RandomState instance, default=None 
        Used to shuffle the training data, when ``shuffle`` is set to 
        ``True``. Pass an int for reproducible output across multiple 
        function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    warm_start : bool, default=False 
        When set to True, reuse the solution of the previous call to fit as 
        initialization, otherwise, just erase the previous solution. 
        See :term:`the Glossary &lt;warm_start&gt;`. 
 
        Repeatedly calling fit or partial_fit when warm_start is True can 
        result in a different solution than when calling fit a single time 
        because of the way the data is shuffled. 
 
    class_weight : dict, {class_label: weight} or &quot;balanced&quot; or None, \ 
            default=None 
        Preset for the class_weight fit parameter. 
 
        Weights associated with classes. If not given, all classes 
        are supposed to have weight one. 
 
        The &quot;balanced&quot; mode uses the values of y to automatically adjust 
        weights inversely proportional to class frequencies in the input data 
        as ``n_samples / (n_classes * np.bincount(y))``. 
 
        .. versionadded:: 0.17 
           parameter *class_weight* to automatically weight samples. 
 
    average : bool or int, default=False 
        When set to True, computes the averaged SGD weights and stores the 
        result in the ``coef_`` attribute. If set to an int greater than 1, 
        averaging will begin once the total number of samples seen reaches 
        average. So average=10 will begin averaging after seeing 10 samples. 
 
        .. versionadded:: 0.19 
           parameter *average* to use weights averaging in SGD. 
 
    Attributes 
    ---------- 
    coef_ : ndarray of shape (1, n_features) if n_classes == 2 else \ 
            (n_classes, n_features) 
        Weights assigned to the features. 
 
    intercept_ : ndarray of shape (1,) if n_classes == 2 else (n_classes,) 
        Constants in decision function. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    n_iter_ : int 
        The actual number of iterations to reach the stopping criterion. 
        For multiclass fits, it is the maximum over every binary fit. 
 
    classes_ : ndarray of shape (n_classes,) 
        The unique classes labels. 
 
    t_ : int 
        Number of weight updates performed during training. 
        Same as ``(n_iter_ * n_samples + 1)``. 
 
    loss_function_ : callable 
        Loss function used by the algorithm. 
 
         .. deprecated:: 1.4 
            Attribute `loss_function_` was deprecated in version 1.4 and will be 
            removed in 1.6. 
 
    See Also 
    -------- 
    SGDClassifier : Incrementally trained logistic regression. 
    Perceptron : Linear perceptron classifier. 
 
    References 
    ---------- 
    Online Passive-Aggressive Algorithms 
    &lt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&gt; 
    K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006) 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.linear_model import PassiveAggressiveClassifier 
    &gt;&gt;&gt; from sklearn.datasets import make_classification 
    &gt;&gt;&gt; X, y = make_classification(n_features=4, random_state=0) 
    &gt;&gt;&gt; clf = PassiveAggressiveClassifier(max_iter=1000, random_state=0, 
    ... tol=1e-3) 
    &gt;&gt;&gt; clf.fit(X, y) 
    PassiveAggressiveClassifier(random_state=0) 
    &gt;&gt;&gt; print(clf.coef_) 
    [[0.26642044 0.45070924 0.67251877 0.64185414]] 
    &gt;&gt;&gt; print(clf.intercept_) 
    [1.84127814] 
    &gt;&gt;&gt; print(clf.predict([[0, 0, 0, 0]])) 
    [1] 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s3">: </span><span class="s1">dict </span><span class="s3">= {</span>
        <span class="s3">**</span><span class="s1">BaseSGDClassifier</span><span class="s3">.</span><span class="s1">_parameter_constraints</span><span class="s3">,</span>
        <span class="s5">&quot;loss&quot;</span><span class="s3">: [</span><span class="s1">StrOptions</span><span class="s3">({</span><span class="s5">&quot;hinge&quot;</span><span class="s3">, </span><span class="s5">&quot;squared_hinge&quot;</span><span class="s3">})],</span>
        <span class="s5">&quot;C&quot;</span><span class="s3">: [</span><span class="s1">Interval</span><span class="s3">(</span><span class="s1">Real</span><span class="s3">, </span><span class="s6">0</span><span class="s3">, </span><span class="s2">None</span><span class="s3">, </span><span class="s1">closed</span><span class="s3">=</span><span class="s5">&quot;right&quot;</span><span class="s3">)],</span>
    <span class="s3">}</span>

    <span class="s2">def </span><span class="s1">__init__</span><span class="s3">(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s3">*,</span>
        <span class="s1">C</span><span class="s3">=</span><span class="s6">1.0</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
        <span class="s1">max_iter</span><span class="s3">=</span><span class="s6">1000</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s6">1e-3</span><span class="s3">,</span>
        <span class="s1">early_stopping</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
        <span class="s1">validation_fraction</span><span class="s3">=</span><span class="s6">0.1</span><span class="s3">,</span>
        <span class="s1">n_iter_no_change</span><span class="s3">=</span><span class="s6">5</span><span class="s3">,</span>
        <span class="s1">shuffle</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
        <span class="s1">verbose</span><span class="s3">=</span><span class="s6">0</span><span class="s3">,</span>
        <span class="s1">loss</span><span class="s3">=</span><span class="s5">&quot;hinge&quot;</span><span class="s3">,</span>
        <span class="s1">n_jobs</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
        <span class="s1">warm_start</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
        <span class="s1">class_weight</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
        <span class="s1">average</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
    <span class="s3">):</span>
        <span class="s1">super</span><span class="s3">().</span><span class="s1">__init__</span><span class="s3">(</span>
            <span class="s1">penalty</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
            <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
            <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">,</span>
            <span class="s1">tol</span><span class="s3">=</span><span class="s1">tol</span><span class="s3">,</span>
            <span class="s1">early_stopping</span><span class="s3">=</span><span class="s1">early_stopping</span><span class="s3">,</span>
            <span class="s1">validation_fraction</span><span class="s3">=</span><span class="s1">validation_fraction</span><span class="s3">,</span>
            <span class="s1">n_iter_no_change</span><span class="s3">=</span><span class="s1">n_iter_no_change</span><span class="s3">,</span>
            <span class="s1">shuffle</span><span class="s3">=</span><span class="s1">shuffle</span><span class="s3">,</span>
            <span class="s1">verbose</span><span class="s3">=</span><span class="s1">verbose</span><span class="s3">,</span>
            <span class="s1">random_state</span><span class="s3">=</span><span class="s1">random_state</span><span class="s3">,</span>
            <span class="s1">eta0</span><span class="s3">=</span><span class="s6">1.0</span><span class="s3">,</span>
            <span class="s1">warm_start</span><span class="s3">=</span><span class="s1">warm_start</span><span class="s3">,</span>
            <span class="s1">class_weight</span><span class="s3">=</span><span class="s1">class_weight</span><span class="s3">,</span>
            <span class="s1">average</span><span class="s3">=</span><span class="s1">average</span><span class="s3">,</span>
            <span class="s1">n_jobs</span><span class="s3">=</span><span class="s1">n_jobs</span><span class="s3">,</span>
        <span class="s3">)</span>

        <span class="s1">self</span><span class="s3">.</span><span class="s1">C </span><span class="s3">= </span><span class="s1">C</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">loss </span><span class="s3">= </span><span class="s1">loss</span>

    <span class="s3">@</span><span class="s1">_fit_context</span><span class="s3">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s2">def </span><span class="s1">partial_fit</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">classes</span><span class="s3">=</span><span class="s2">None</span><span class="s3">):</span>
        <span class="s4">&quot;&quot;&quot;Fit linear model with Passive Aggressive algorithm. 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix} of shape (n_samples, n_features) 
            Subset of the training data. 
 
        y : array-like of shape (n_samples,) 
            Subset of the target values. 
 
        classes : ndarray of shape (n_classes,) 
            Classes across all calls to partial_fit. 
            Can be obtained by via `np.unique(y_all)`, where y_all is the 
            target vector of the entire dataset. 
            This argument is required for the first call to partial_fit 
            and can be omitted in the subsequent calls. 
            Note that y doesn't need to contain all labels in `classes`. 
 
        Returns 
        ------- 
        self : object 
            Fitted estimator. 
        &quot;&quot;&quot;</span>
        <span class="s2">if not </span><span class="s1">hasattr</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s5">&quot;classes_&quot;</span><span class="s3">):</span>
            <span class="s1">self</span><span class="s3">.</span><span class="s1">_more_validate_params</span><span class="s3">(</span><span class="s1">for_partial_fit</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>

            <span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">class_weight </span><span class="s3">== </span><span class="s5">&quot;balanced&quot;</span><span class="s3">:</span>
                <span class="s2">raise </span><span class="s1">ValueError</span><span class="s3">(</span>
                    <span class="s5">&quot;class_weight 'balanced' is not supported for &quot;</span>
                    <span class="s5">&quot;partial_fit. For 'balanced' weights, use &quot;</span>
                    <span class="s5">&quot;`sklearn.utils.compute_class_weight` with &quot;</span>
                    <span class="s5">&quot;`class_weight='balanced'`. In place of y you &quot;</span>
                    <span class="s5">&quot;can use a large enough subset of the full &quot;</span>
                    <span class="s5">&quot;training set target to properly estimate the &quot;</span>
                    <span class="s5">&quot;class frequency distributions. Pass the &quot;</span>
                    <span class="s5">&quot;resulting weights as the class_weight &quot;</span>
                    <span class="s5">&quot;parameter.&quot;</span>
                <span class="s3">)</span>

        <span class="s1">lr </span><span class="s3">= </span><span class="s5">&quot;pa1&quot; </span><span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">loss </span><span class="s3">== </span><span class="s5">&quot;hinge&quot; </span><span class="s2">else </span><span class="s5">&quot;pa2&quot;</span>
        <span class="s2">return </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_partial_fit</span><span class="s3">(</span>
            <span class="s1">X</span><span class="s3">,</span>
            <span class="s1">y</span><span class="s3">,</span>
            <span class="s1">alpha</span><span class="s3">=</span><span class="s6">1.0</span><span class="s3">,</span>
            <span class="s1">C</span><span class="s3">=</span><span class="s1">self</span><span class="s3">.</span><span class="s1">C</span><span class="s3">,</span>
            <span class="s1">loss</span><span class="s3">=</span><span class="s5">&quot;hinge&quot;</span><span class="s3">,</span>
            <span class="s1">learning_rate</span><span class="s3">=</span><span class="s1">lr</span><span class="s3">,</span>
            <span class="s1">max_iter</span><span class="s3">=</span><span class="s6">1</span><span class="s3">,</span>
            <span class="s1">classes</span><span class="s3">=</span><span class="s1">classes</span><span class="s3">,</span>
            <span class="s1">sample_weight</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
            <span class="s1">coef_init</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
            <span class="s1">intercept_init</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
        <span class="s3">)</span>

    <span class="s3">@</span><span class="s1">_fit_context</span><span class="s3">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s2">def </span><span class="s1">fit</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">coef_init</span><span class="s3">=</span><span class="s2">None</span><span class="s3">, </span><span class="s1">intercept_init</span><span class="s3">=</span><span class="s2">None</span><span class="s3">):</span>
        <span class="s4">&quot;&quot;&quot;Fit linear model with Passive Aggressive algorithm. 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix} of shape (n_samples, n_features) 
            Training data. 
 
        y : array-like of shape (n_samples,) 
            Target values. 
 
        coef_init : ndarray of shape (n_classes, n_features) 
            The initial coefficients to warm-start the optimization. 
 
        intercept_init : ndarray of shape (n_classes,) 
            The initial intercept to warm-start the optimization. 
 
        Returns 
        ------- 
        self : object 
            Fitted estimator. 
        &quot;&quot;&quot;</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">_more_validate_params</span><span class="s3">()</span>

        <span class="s1">lr </span><span class="s3">= </span><span class="s5">&quot;pa1&quot; </span><span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">loss </span><span class="s3">== </span><span class="s5">&quot;hinge&quot; </span><span class="s2">else </span><span class="s5">&quot;pa2&quot;</span>
        <span class="s2">return </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_fit</span><span class="s3">(</span>
            <span class="s1">X</span><span class="s3">,</span>
            <span class="s1">y</span><span class="s3">,</span>
            <span class="s1">alpha</span><span class="s3">=</span><span class="s6">1.0</span><span class="s3">,</span>
            <span class="s1">C</span><span class="s3">=</span><span class="s1">self</span><span class="s3">.</span><span class="s1">C</span><span class="s3">,</span>
            <span class="s1">loss</span><span class="s3">=</span><span class="s5">&quot;hinge&quot;</span><span class="s3">,</span>
            <span class="s1">learning_rate</span><span class="s3">=</span><span class="s1">lr</span><span class="s3">,</span>
            <span class="s1">coef_init</span><span class="s3">=</span><span class="s1">coef_init</span><span class="s3">,</span>
            <span class="s1">intercept_init</span><span class="s3">=</span><span class="s1">intercept_init</span><span class="s3">,</span>
        <span class="s3">)</span>


<span class="s2">class </span><span class="s1">PassiveAggressiveRegressor</span><span class="s3">(</span><span class="s1">BaseSGDRegressor</span><span class="s3">):</span>
    <span class="s4">&quot;&quot;&quot;Passive Aggressive Regressor. 
 
    Read more in the :ref:`User Guide &lt;passive_aggressive&gt;`. 
 
    Parameters 
    ---------- 
 
    C : float, default=1.0 
        Maximum step size (regularization). Defaults to 1.0. 
 
    fit_intercept : bool, default=True 
        Whether the intercept should be estimated or not. If False, the 
        data is assumed to be already centered. Defaults to True. 
 
    max_iter : int, default=1000 
        The maximum number of passes over the training data (aka epochs). 
        It only impacts the behavior in the ``fit`` method, and not the 
        :meth:`~sklearn.linear_model.PassiveAggressiveRegressor.partial_fit` method. 
 
        .. versionadded:: 0.19 
 
    tol : float or None, default=1e-3 
        The stopping criterion. If it is not None, the iterations will stop 
        when (loss &gt; previous_loss - tol). 
 
        .. versionadded:: 0.19 
 
    early_stopping : bool, default=False 
        Whether to use early stopping to terminate training when validation. 
        score is not improving. If set to True, it will automatically set aside 
        a fraction of training data as validation and terminate 
        training when validation score is not improving by at least tol for 
        n_iter_no_change consecutive epochs. 
 
        .. versionadded:: 0.20 
 
    validation_fraction : float, default=0.1 
        The proportion of training data to set aside as validation set for 
        early stopping. Must be between 0 and 1. 
        Only used if early_stopping is True. 
 
        .. versionadded:: 0.20 
 
    n_iter_no_change : int, default=5 
        Number of iterations with no improvement to wait before early stopping. 
 
        .. versionadded:: 0.20 
 
    shuffle : bool, default=True 
        Whether or not the training data should be shuffled after each epoch. 
 
    verbose : int, default=0 
        The verbosity level. 
 
    loss : str, default=&quot;epsilon_insensitive&quot; 
        The loss function to be used: 
        epsilon_insensitive: equivalent to PA-I in the reference paper. 
        squared_epsilon_insensitive: equivalent to PA-II in the reference 
        paper. 
 
    epsilon : float, default=0.1 
        If the difference between the current prediction and the correct label 
        is below this threshold, the model is not updated. 
 
    random_state : int, RandomState instance, default=None 
        Used to shuffle the training data, when ``shuffle`` is set to 
        ``True``. Pass an int for reproducible output across multiple 
        function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    warm_start : bool, default=False 
        When set to True, reuse the solution of the previous call to fit as 
        initialization, otherwise, just erase the previous solution. 
        See :term:`the Glossary &lt;warm_start&gt;`. 
 
        Repeatedly calling fit or partial_fit when warm_start is True can 
        result in a different solution than when calling fit a single time 
        because of the way the data is shuffled. 
 
    average : bool or int, default=False 
        When set to True, computes the averaged SGD weights and stores the 
        result in the ``coef_`` attribute. If set to an int greater than 1, 
        averaging will begin once the total number of samples seen reaches 
        average. So average=10 will begin averaging after seeing 10 samples. 
 
        .. versionadded:: 0.19 
           parameter *average* to use weights averaging in SGD. 
 
    Attributes 
    ---------- 
    coef_ : array, shape = [1, n_features] if n_classes == 2 else [n_classes,\ 
            n_features] 
        Weights assigned to the features. 
 
    intercept_ : array, shape = [1] if n_classes == 2 else [n_classes] 
        Constants in decision function. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    n_iter_ : int 
        The actual number of iterations to reach the stopping criterion. 
 
    t_ : int 
        Number of weight updates performed during training. 
        Same as ``(n_iter_ * n_samples + 1)``. 
 
    See Also 
    -------- 
    SGDRegressor : Linear model fitted by minimizing a regularized 
        empirical loss with SGD. 
 
    References 
    ---------- 
    Online Passive-Aggressive Algorithms 
    &lt;http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf&gt; 
    K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006). 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.linear_model import PassiveAggressiveRegressor 
    &gt;&gt;&gt; from sklearn.datasets import make_regression 
 
    &gt;&gt;&gt; X, y = make_regression(n_features=4, random_state=0) 
    &gt;&gt;&gt; regr = PassiveAggressiveRegressor(max_iter=100, random_state=0, 
    ... tol=1e-3) 
    &gt;&gt;&gt; regr.fit(X, y) 
    PassiveAggressiveRegressor(max_iter=100, random_state=0) 
    &gt;&gt;&gt; print(regr.coef_) 
    [20.48736655 34.18818427 67.59122734 87.94731329] 
    &gt;&gt;&gt; print(regr.intercept_) 
    [-0.02306214] 
    &gt;&gt;&gt; print(regr.predict([[0, 0, 0, 0]])) 
    [-0.02306214] 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s3">: </span><span class="s1">dict </span><span class="s3">= {</span>
        <span class="s3">**</span><span class="s1">BaseSGDRegressor</span><span class="s3">.</span><span class="s1">_parameter_constraints</span><span class="s3">,</span>
        <span class="s5">&quot;loss&quot;</span><span class="s3">: [</span><span class="s1">StrOptions</span><span class="s3">({</span><span class="s5">&quot;epsilon_insensitive&quot;</span><span class="s3">, </span><span class="s5">&quot;squared_epsilon_insensitive&quot;</span><span class="s3">})],</span>
        <span class="s5">&quot;C&quot;</span><span class="s3">: [</span><span class="s1">Interval</span><span class="s3">(</span><span class="s1">Real</span><span class="s3">, </span><span class="s6">0</span><span class="s3">, </span><span class="s2">None</span><span class="s3">, </span><span class="s1">closed</span><span class="s3">=</span><span class="s5">&quot;right&quot;</span><span class="s3">)],</span>
        <span class="s5">&quot;epsilon&quot;</span><span class="s3">: [</span><span class="s1">Interval</span><span class="s3">(</span><span class="s1">Real</span><span class="s3">, </span><span class="s6">0</span><span class="s3">, </span><span class="s2">None</span><span class="s3">, </span><span class="s1">closed</span><span class="s3">=</span><span class="s5">&quot;left&quot;</span><span class="s3">)],</span>
    <span class="s3">}</span>

    <span class="s2">def </span><span class="s1">__init__</span><span class="s3">(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s3">*,</span>
        <span class="s1">C</span><span class="s3">=</span><span class="s6">1.0</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
        <span class="s1">max_iter</span><span class="s3">=</span><span class="s6">1000</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s6">1e-3</span><span class="s3">,</span>
        <span class="s1">early_stopping</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
        <span class="s1">validation_fraction</span><span class="s3">=</span><span class="s6">0.1</span><span class="s3">,</span>
        <span class="s1">n_iter_no_change</span><span class="s3">=</span><span class="s6">5</span><span class="s3">,</span>
        <span class="s1">shuffle</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
        <span class="s1">verbose</span><span class="s3">=</span><span class="s6">0</span><span class="s3">,</span>
        <span class="s1">loss</span><span class="s3">=</span><span class="s5">&quot;epsilon_insensitive&quot;</span><span class="s3">,</span>
        <span class="s1">epsilon</span><span class="s3">=</span><span class="s1">DEFAULT_EPSILON</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
        <span class="s1">warm_start</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
        <span class="s1">average</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
    <span class="s3">):</span>
        <span class="s1">super</span><span class="s3">().</span><span class="s1">__init__</span><span class="s3">(</span>
            <span class="s1">penalty</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
            <span class="s1">l1_ratio</span><span class="s3">=</span><span class="s6">0</span><span class="s3">,</span>
            <span class="s1">epsilon</span><span class="s3">=</span><span class="s1">epsilon</span><span class="s3">,</span>
            <span class="s1">eta0</span><span class="s3">=</span><span class="s6">1.0</span><span class="s3">,</span>
            <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
            <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">,</span>
            <span class="s1">tol</span><span class="s3">=</span><span class="s1">tol</span><span class="s3">,</span>
            <span class="s1">early_stopping</span><span class="s3">=</span><span class="s1">early_stopping</span><span class="s3">,</span>
            <span class="s1">validation_fraction</span><span class="s3">=</span><span class="s1">validation_fraction</span><span class="s3">,</span>
            <span class="s1">n_iter_no_change</span><span class="s3">=</span><span class="s1">n_iter_no_change</span><span class="s3">,</span>
            <span class="s1">shuffle</span><span class="s3">=</span><span class="s1">shuffle</span><span class="s3">,</span>
            <span class="s1">verbose</span><span class="s3">=</span><span class="s1">verbose</span><span class="s3">,</span>
            <span class="s1">random_state</span><span class="s3">=</span><span class="s1">random_state</span><span class="s3">,</span>
            <span class="s1">warm_start</span><span class="s3">=</span><span class="s1">warm_start</span><span class="s3">,</span>
            <span class="s1">average</span><span class="s3">=</span><span class="s1">average</span><span class="s3">,</span>
        <span class="s3">)</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">C </span><span class="s3">= </span><span class="s1">C</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">loss </span><span class="s3">= </span><span class="s1">loss</span>

    <span class="s3">@</span><span class="s1">_fit_context</span><span class="s3">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s2">def </span><span class="s1">partial_fit</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">):</span>
        <span class="s4">&quot;&quot;&quot;Fit linear model with Passive Aggressive algorithm. 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix} of shape (n_samples, n_features) 
            Subset of training data. 
 
        y : numpy array of shape [n_samples] 
            Subset of target values. 
 
        Returns 
        ------- 
        self : object 
            Fitted estimator. 
        &quot;&quot;&quot;</span>
        <span class="s2">if not </span><span class="s1">hasattr</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s5">&quot;coef_&quot;</span><span class="s3">):</span>
            <span class="s1">self</span><span class="s3">.</span><span class="s1">_more_validate_params</span><span class="s3">(</span><span class="s1">for_partial_fit</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>

        <span class="s1">lr </span><span class="s3">= </span><span class="s5">&quot;pa1&quot; </span><span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">loss </span><span class="s3">== </span><span class="s5">&quot;epsilon_insensitive&quot; </span><span class="s2">else </span><span class="s5">&quot;pa2&quot;</span>
        <span class="s2">return </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_partial_fit</span><span class="s3">(</span>
            <span class="s1">X</span><span class="s3">,</span>
            <span class="s1">y</span><span class="s3">,</span>
            <span class="s1">alpha</span><span class="s3">=</span><span class="s6">1.0</span><span class="s3">,</span>
            <span class="s1">C</span><span class="s3">=</span><span class="s1">self</span><span class="s3">.</span><span class="s1">C</span><span class="s3">,</span>
            <span class="s1">loss</span><span class="s3">=</span><span class="s5">&quot;epsilon_insensitive&quot;</span><span class="s3">,</span>
            <span class="s1">learning_rate</span><span class="s3">=</span><span class="s1">lr</span><span class="s3">,</span>
            <span class="s1">max_iter</span><span class="s3">=</span><span class="s6">1</span><span class="s3">,</span>
            <span class="s1">sample_weight</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
            <span class="s1">coef_init</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
            <span class="s1">intercept_init</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
        <span class="s3">)</span>

    <span class="s3">@</span><span class="s1">_fit_context</span><span class="s3">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s2">def </span><span class="s1">fit</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">coef_init</span><span class="s3">=</span><span class="s2">None</span><span class="s3">, </span><span class="s1">intercept_init</span><span class="s3">=</span><span class="s2">None</span><span class="s3">):</span>
        <span class="s4">&quot;&quot;&quot;Fit linear model with Passive Aggressive algorithm. 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix} of shape (n_samples, n_features) 
            Training data. 
 
        y : numpy array of shape [n_samples] 
            Target values. 
 
        coef_init : array, shape = [n_features] 
            The initial coefficients to warm-start the optimization. 
 
        intercept_init : array, shape = [1] 
            The initial intercept to warm-start the optimization. 
 
        Returns 
        ------- 
        self : object 
            Fitted estimator. 
        &quot;&quot;&quot;</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">_more_validate_params</span><span class="s3">()</span>

        <span class="s1">lr </span><span class="s3">= </span><span class="s5">&quot;pa1&quot; </span><span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">loss </span><span class="s3">== </span><span class="s5">&quot;epsilon_insensitive&quot; </span><span class="s2">else </span><span class="s5">&quot;pa2&quot;</span>
        <span class="s2">return </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_fit</span><span class="s3">(</span>
            <span class="s1">X</span><span class="s3">,</span>
            <span class="s1">y</span><span class="s3">,</span>
            <span class="s1">alpha</span><span class="s3">=</span><span class="s6">1.0</span><span class="s3">,</span>
            <span class="s1">C</span><span class="s3">=</span><span class="s1">self</span><span class="s3">.</span><span class="s1">C</span><span class="s3">,</span>
            <span class="s1">loss</span><span class="s3">=</span><span class="s5">&quot;epsilon_insensitive&quot;</span><span class="s3">,</span>
            <span class="s1">learning_rate</span><span class="s3">=</span><span class="s1">lr</span><span class="s3">,</span>
            <span class="s1">coef_init</span><span class="s3">=</span><span class="s1">coef_init</span><span class="s3">,</span>
            <span class="s1">intercept_init</span><span class="s3">=</span><span class="s1">intercept_init</span><span class="s3">,</span>
        <span class="s3">)</span>
</pre>
</body>
</html>