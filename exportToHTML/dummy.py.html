<html>
<head>
<title>dummy.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
dummy.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Dummy estimators that implement simple rules of thumb.&quot;&quot;&quot;</span>

<span class="s2"># Author: Mathieu Blondel &lt;mathieu@mblondel.org&gt;</span>
<span class="s2">#         Arnaud Joly &lt;a.joly@ulg.ac.be&gt;</span>
<span class="s2">#         Maheshakya Wijewardena &lt;maheshakya.10@cse.mrt.ac.lk&gt;</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">warnings</span>
<span class="s3">from </span><span class="s1">numbers </span><span class="s3">import </span><span class="s1">Integral</span><span class="s4">, </span><span class="s1">Real</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">import </span><span class="s1">scipy</span><span class="s4">.</span><span class="s1">sparse </span><span class="s3">as </span><span class="s1">sp</span>

<span class="s3">from </span><span class="s4">.</span><span class="s1">base </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">BaseEstimator</span><span class="s4">,</span>
    <span class="s1">ClassifierMixin</span><span class="s4">,</span>
    <span class="s1">MultiOutputMixin</span><span class="s4">,</span>
    <span class="s1">RegressorMixin</span><span class="s4">,</span>
    <span class="s1">_fit_context</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils </span><span class="s3">import </span><span class="s1">check_random_state</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_param_validation </span><span class="s3">import </span><span class="s1">Interval</span><span class="s4">, </span><span class="s1">StrOptions</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">multiclass </span><span class="s3">import </span><span class="s1">class_distribution</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">random </span><span class="s3">import </span><span class="s1">_random_choice_csc</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">stats </span><span class="s3">import </span><span class="s1">_weighted_percentile</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">validation </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">_check_sample_weight</span><span class="s4">,</span>
    <span class="s1">_num_samples</span><span class="s4">,</span>
    <span class="s1">check_array</span><span class="s4">,</span>
    <span class="s1">check_consistent_length</span><span class="s4">,</span>
    <span class="s1">check_is_fitted</span><span class="s4">,</span>
<span class="s4">)</span>


<span class="s3">class </span><span class="s1">DummyClassifier</span><span class="s4">(</span><span class="s1">MultiOutputMixin</span><span class="s4">, </span><span class="s1">ClassifierMixin</span><span class="s4">, </span><span class="s1">BaseEstimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;DummyClassifier makes predictions that ignore the input features. 
 
    This classifier serves as a simple baseline to compare against other more 
    complex classifiers. 
 
    The specific behavior of the baseline is selected with the `strategy` 
    parameter. 
 
    All strategies make predictions that ignore the input feature values passed 
    as the `X` argument to `fit` and `predict`. The predictions, however, 
    typically depend on values observed in the `y` parameter passed to `fit`. 
 
    Note that the &quot;stratified&quot; and &quot;uniform&quot; strategies lead to 
    non-deterministic predictions that can be rendered deterministic by setting 
    the `random_state` parameter if needed. The other strategies are naturally 
    deterministic and, once fit, always return the same constant prediction 
    for any value of `X`. 
 
    Read more in the :ref:`User Guide &lt;dummy_estimators&gt;`. 
 
    .. versionadded:: 0.13 
 
    Parameters 
    ---------- 
    strategy : {&quot;most_frequent&quot;, &quot;prior&quot;, &quot;stratified&quot;, &quot;uniform&quot;, \ 
            &quot;constant&quot;}, default=&quot;prior&quot; 
        Strategy to use to generate predictions. 
 
        * &quot;most_frequent&quot;: the `predict` method always returns the most 
          frequent class label in the observed `y` argument passed to `fit`. 
          The `predict_proba` method returns the matching one-hot encoded 
          vector. 
        * &quot;prior&quot;: the `predict` method always returns the most frequent 
          class label in the observed `y` argument passed to `fit` (like 
          &quot;most_frequent&quot;). ``predict_proba`` always returns the empirical 
          class distribution of `y` also known as the empirical class prior 
          distribution. 
        * &quot;stratified&quot;: the `predict_proba` method randomly samples one-hot 
          vectors from a multinomial distribution parametrized by the empirical 
          class prior probabilities. 
          The `predict` method returns the class label which got probability 
          one in the one-hot vector of `predict_proba`. 
          Each sampled row of both methods is therefore independent and 
          identically distributed. 
        * &quot;uniform&quot;: generates predictions uniformly at random from the list 
          of unique classes observed in `y`, i.e. each class has equal 
          probability. 
        * &quot;constant&quot;: always predicts a constant label that is provided by 
          the user. This is useful for metrics that evaluate a non-majority 
          class. 
 
          .. versionchanged:: 0.24 
             The default value of `strategy` has changed to &quot;prior&quot; in version 
             0.24. 
 
    random_state : int, RandomState instance or None, default=None 
        Controls the randomness to generate the predictions when 
        ``strategy='stratified'`` or ``strategy='uniform'``. 
        Pass an int for reproducible output across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    constant : int or str or array-like of shape (n_outputs,), default=None 
        The explicit constant as predicted by the &quot;constant&quot; strategy. This 
        parameter is useful only for the &quot;constant&quot; strategy. 
 
    Attributes 
    ---------- 
    classes_ : ndarray of shape (n_classes,) or list of such arrays 
        Unique class labels observed in `y`. For multi-output classification 
        problems, this attribute is a list of arrays as each output has an 
        independent set of possible classes. 
 
    n_classes_ : int or list of int 
        Number of label for each output. 
 
    class_prior_ : ndarray of shape (n_classes,) or list of such arrays 
        Frequency of each class observed in `y`. For multioutput classification 
        problems, this is computed independently for each output. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` has 
        feature names that are all strings. 
 
    n_outputs_ : int 
        Number of outputs. 
 
    sparse_output_ : bool 
        True if the array returned from predict is to be in sparse CSC format. 
        Is automatically set to True if the input `y` is passed in sparse 
        format. 
 
    See Also 
    -------- 
    DummyRegressor : Regressor that makes predictions using simple rules. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.dummy import DummyClassifier 
    &gt;&gt;&gt; X = np.array([-1, 1, 1, 1]) 
    &gt;&gt;&gt; y = np.array([0, 1, 1, 1]) 
    &gt;&gt;&gt; dummy_clf = DummyClassifier(strategy=&quot;most_frequent&quot;) 
    &gt;&gt;&gt; dummy_clf.fit(X, y) 
    DummyClassifier(strategy='most_frequent') 
    &gt;&gt;&gt; dummy_clf.predict(X) 
    array([1, 1, 1, 1]) 
    &gt;&gt;&gt; dummy_clf.score(X, y) 
    0.75 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s5">&quot;strategy&quot;</span><span class="s4">: [</span>
            <span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;most_frequent&quot;</span><span class="s4">, </span><span class="s5">&quot;prior&quot;</span><span class="s4">, </span><span class="s5">&quot;stratified&quot;</span><span class="s4">, </span><span class="s5">&quot;uniform&quot;</span><span class="s4">, </span><span class="s5">&quot;constant&quot;</span><span class="s4">})</span>
        <span class="s4">],</span>
        <span class="s5">&quot;random_state&quot;</span><span class="s4">: [</span><span class="s5">&quot;random_state&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;constant&quot;</span><span class="s4">: [</span><span class="s1">Integral</span><span class="s4">, </span><span class="s1">str</span><span class="s4">, </span><span class="s5">&quot;array-like&quot;</span><span class="s4">, </span><span class="s3">None</span><span class="s4">],</span>
    <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, *, </span><span class="s1">strategy</span><span class="s4">=</span><span class="s5">&quot;prior&quot;</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, </span><span class="s1">constant</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">strategy </span><span class="s4">= </span><span class="s1">strategy</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">random_state </span><span class="s4">= </span><span class="s1">random_state</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">constant </span><span class="s4">= </span><span class="s1">constant</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Fit the baseline classifier. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Training data. 
 
        y : array-like of shape (n_samples,) or (n_samples, n_outputs) 
            Target values. 
 
        sample_weight : array-like of shape (n_samples,), default=None 
            Sample weights. 
 
        Returns 
        ------- 
        self : object 
            Returns the instance itself. 
        &quot;&quot;&quot;</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">cast_to_ndarray</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">strategy</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;uniform&quot; </span><span class="s3">and </span><span class="s1">sp</span><span class="s4">.</span><span class="s1">issparse</span><span class="s4">(</span><span class="s1">y</span><span class="s4">):</span>
            <span class="s1">y </span><span class="s4">= </span><span class="s1">y</span><span class="s4">.</span><span class="s1">toarray</span><span class="s4">()</span>
            <span class="s1">warnings</span><span class="s4">.</span><span class="s1">warn</span><span class="s4">(</span>
                <span class="s4">(</span>
                    <span class="s5">&quot;A local copy of the target data has been converted &quot;</span>
                    <span class="s5">&quot;to a numpy array. Predicting on sparse target data &quot;</span>
                    <span class="s5">&quot;with the uniform strategy would not save memory &quot;</span>
                    <span class="s5">&quot;and would be slower.&quot;</span>
                <span class="s4">),</span>
                <span class="s1">UserWarning</span><span class="s4">,</span>
            <span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">sparse_output_ </span><span class="s4">= </span><span class="s1">sp</span><span class="s4">.</span><span class="s1">issparse</span><span class="s4">(</span><span class="s1">y</span><span class="s4">)</span>

        <span class="s3">if not </span><span class="s1">self</span><span class="s4">.</span><span class="s1">sparse_output_</span><span class="s4">:</span>
            <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">asarray</span><span class="s4">(</span><span class="s1">y</span><span class="s4">)</span>
            <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">atleast_1d</span><span class="s4">(</span><span class="s1">y</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">y</span><span class="s4">.</span><span class="s1">ndim </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
            <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">reshape</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, (-</span><span class="s6">1</span><span class="s4">, </span><span class="s6">1</span><span class="s4">))</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_ </span><span class="s4">= </span><span class="s1">y</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]</span>

        <span class="s1">check_consistent_length</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">sample_weight </span><span class="s3">is not None</span><span class="s4">:</span>
            <span class="s1">sample_weight </span><span class="s4">= </span><span class="s1">_check_sample_weight</span><span class="s4">(</span><span class="s1">sample_weight</span><span class="s4">, </span><span class="s1">X</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;constant&quot;</span><span class="s4">:</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">constant </span><span class="s3">is None</span><span class="s4">:</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                    <span class="s5">&quot;Constant target value has to be specified &quot;</span>
                    <span class="s5">&quot;when the constant strategy is used.&quot;</span>
                <span class="s4">)</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s1">constant </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">reshape</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">atleast_1d</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">constant</span><span class="s4">), (-</span><span class="s6">1</span><span class="s4">, </span><span class="s6">1</span><span class="s4">))</span>
                <span class="s3">if </span><span class="s1">constant</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">] != </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_</span><span class="s4">:</span>
                    <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                        <span class="s5">&quot;Constant target value should have shape (%d, 1).&quot;</span>
                        <span class="s4">% </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_</span>
                    <span class="s4">)</span>

        <span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">classes_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_classes_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">class_prior_</span><span class="s4">) = </span><span class="s1">class_distribution</span><span class="s4">(</span>
            <span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span>
        <span class="s4">)</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;constant&quot;</span><span class="s4">:</span>
            <span class="s3">for </span><span class="s1">k </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_</span><span class="s4">):</span>
                <span class="s3">if not </span><span class="s1">any</span><span class="s4">(</span><span class="s1">constant</span><span class="s4">[</span><span class="s1">k</span><span class="s4">][</span><span class="s6">0</span><span class="s4">] == </span><span class="s1">c </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">self</span><span class="s4">.</span><span class="s1">classes_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">]):</span>
                    <span class="s2"># Checking in case of constant strategy if the constant</span>
                    <span class="s2"># provided by the user is in y.</span>
                    <span class="s1">err_msg </span><span class="s4">= (</span>
                        <span class="s5">&quot;The constant target value must be present in &quot;</span>
                        <span class="s5">&quot;the training data. You provided constant={}. &quot;</span>
                        <span class="s5">&quot;Possible values are: {}.&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span>
                            <span class="s1">self</span><span class="s4">.</span><span class="s1">constant</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">classes_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">].</span><span class="s1">tolist</span><span class="s4">()</span>
                        <span class="s4">)</span>
                    <span class="s4">)</span>
                    <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span><span class="s1">err_msg</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_ </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">n_classes_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_classes_</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">classes_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">classes_</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">class_prior_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">class_prior_</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>

        <span class="s3">return </span><span class="s1">self</span>

    <span class="s3">def </span><span class="s1">predict</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Perform classification on test vectors X. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Test data. 
 
        Returns 
        ------- 
        y : array-like of shape (n_samples,) or (n_samples, n_outputs) 
            Predicted target values for X. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>

        <span class="s2"># numpy random_state expects Python int and not long as size argument</span>
        <span class="s2"># under Windows</span>
        <span class="s1">n_samples </span><span class="s4">= </span><span class="s1">_num_samples</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s1">rs </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>

        <span class="s1">n_classes_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_classes_</span>
        <span class="s1">classes_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">classes_</span>
        <span class="s1">class_prior_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">class_prior_</span>
        <span class="s1">constant </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">constant</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_ </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
            <span class="s2"># Get same type even for self.n_outputs_ == 1</span>
            <span class="s1">n_classes_ </span><span class="s4">= [</span><span class="s1">n_classes_</span><span class="s4">]</span>
            <span class="s1">classes_ </span><span class="s4">= [</span><span class="s1">classes_</span><span class="s4">]</span>
            <span class="s1">class_prior_ </span><span class="s4">= [</span><span class="s1">class_prior_</span><span class="s4">]</span>
            <span class="s1">constant </span><span class="s4">= [</span><span class="s1">constant</span><span class="s4">]</span>
        <span class="s2"># Compute probability only once</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;stratified&quot;</span><span class="s4">:</span>
            <span class="s1">proba </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_ </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
                <span class="s1">proba </span><span class="s4">= [</span><span class="s1">proba</span><span class="s4">]</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">sparse_output_</span><span class="s4">:</span>
            <span class="s1">class_prob </span><span class="s4">= </span><span class="s3">None</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s3">in </span><span class="s4">(</span><span class="s5">&quot;most_frequent&quot;</span><span class="s4">, </span><span class="s5">&quot;prior&quot;</span><span class="s4">):</span>
                <span class="s1">classes_ </span><span class="s4">= [</span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s1">cp</span><span class="s4">.</span><span class="s1">argmax</span><span class="s4">()]) </span><span class="s3">for </span><span class="s1">cp </span><span class="s3">in </span><span class="s1">class_prior_</span><span class="s4">]</span>

            <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;stratified&quot;</span><span class="s4">:</span>
                <span class="s1">class_prob </span><span class="s4">= </span><span class="s1">class_prior_</span>

            <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;uniform&quot;</span><span class="s4">:</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                    <span class="s5">&quot;Sparse target prediction is not &quot;</span>
                    <span class="s5">&quot;supported with the uniform strategy&quot;</span>
                <span class="s4">)</span>

            <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;constant&quot;</span><span class="s4">:</span>
                <span class="s1">classes_ </span><span class="s4">= [</span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s1">c</span><span class="s4">]) </span><span class="s3">for </span><span class="s1">c </span><span class="s3">in </span><span class="s1">constant</span><span class="s4">]</span>

            <span class="s1">y </span><span class="s4">= </span><span class="s1">_random_choice_csc</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">classes_</span><span class="s4">, </span><span class="s1">class_prob</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s3">in </span><span class="s4">(</span><span class="s5">&quot;most_frequent&quot;</span><span class="s4">, </span><span class="s5">&quot;prior&quot;</span><span class="s4">):</span>
                <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">tile</span><span class="s4">(</span>
                    <span class="s4">[</span>
                        <span class="s1">classes_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">][</span><span class="s1">class_prior_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">].</span><span class="s1">argmax</span><span class="s4">()]</span>
                        <span class="s3">for </span><span class="s1">k </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_</span><span class="s4">)</span>
                    <span class="s4">],</span>
                    <span class="s4">[</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s6">1</span><span class="s4">],</span>
                <span class="s4">)</span>

            <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;stratified&quot;</span><span class="s4">:</span>
                <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">vstack</span><span class="s4">(</span>
                    <span class="s4">[</span>
                        <span class="s1">classes_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">][</span><span class="s1">proba</span><span class="s4">[</span><span class="s1">k</span><span class="s4">].</span><span class="s1">argmax</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">1</span><span class="s4">)]</span>
                        <span class="s3">for </span><span class="s1">k </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_</span><span class="s4">)</span>
                    <span class="s4">]</span>
                <span class="s4">).</span><span class="s1">T</span>

            <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;uniform&quot;</span><span class="s4">:</span>
                <span class="s1">ret </span><span class="s4">= [</span>
                    <span class="s1">classes_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">][</span><span class="s1">rs</span><span class="s4">.</span><span class="s1">randint</span><span class="s4">(</span><span class="s1">n_classes_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">], </span><span class="s1">size</span><span class="s4">=</span><span class="s1">n_samples</span><span class="s4">)]</span>
                    <span class="s3">for </span><span class="s1">k </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_</span><span class="s4">)</span>
                <span class="s4">]</span>
                <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">vstack</span><span class="s4">(</span><span class="s1">ret</span><span class="s4">).</span><span class="s1">T</span>

            <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;constant&quot;</span><span class="s4">:</span>
                <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">tile</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">constant</span><span class="s4">, (</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s6">1</span><span class="s4">))</span>

            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_ </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
                <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ravel</span><span class="s4">(</span><span class="s1">y</span><span class="s4">)</span>

        <span class="s3">return </span><span class="s1">y</span>

    <span class="s3">def </span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Return probability estimates for the test vectors X. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Test data. 
 
        Returns 
        ------- 
        P : ndarray of shape (n_samples, n_classes) or list of such arrays 
            Returns the probability of the sample for each class in 
            the model, where classes are ordered arithmetically, for each 
            output. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>

        <span class="s2"># numpy random_state expects Python int and not long as size argument</span>
        <span class="s2"># under Windows</span>
        <span class="s1">n_samples </span><span class="s4">= </span><span class="s1">_num_samples</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s1">rs </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>

        <span class="s1">n_classes_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_classes_</span>
        <span class="s1">classes_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">classes_</span>
        <span class="s1">class_prior_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">class_prior_</span>
        <span class="s1">constant </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">constant</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_ </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
            <span class="s2"># Get same type even for self.n_outputs_ == 1</span>
            <span class="s1">n_classes_ </span><span class="s4">= [</span><span class="s1">n_classes_</span><span class="s4">]</span>
            <span class="s1">classes_ </span><span class="s4">= [</span><span class="s1">classes_</span><span class="s4">]</span>
            <span class="s1">class_prior_ </span><span class="s4">= [</span><span class="s1">class_prior_</span><span class="s4">]</span>
            <span class="s1">constant </span><span class="s4">= [</span><span class="s1">constant</span><span class="s4">]</span>

        <span class="s1">P </span><span class="s4">= []</span>
        <span class="s3">for </span><span class="s1">k </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_</span><span class="s4">):</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;most_frequent&quot;</span><span class="s4">:</span>
                <span class="s1">ind </span><span class="s4">= </span><span class="s1">class_prior_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">].</span><span class="s1">argmax</span><span class="s4">()</span>
                <span class="s1">out </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">((</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_classes_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">]), </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">)</span>
                <span class="s1">out</span><span class="s4">[:, </span><span class="s1">ind</span><span class="s4">] = </span><span class="s6">1.0</span>
            <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;prior&quot;</span><span class="s4">:</span>
                <span class="s1">out </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ones</span><span class="s4">((</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s6">1</span><span class="s4">)) * </span><span class="s1">class_prior_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">]</span>

            <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;stratified&quot;</span><span class="s4">:</span>
                <span class="s1">out </span><span class="s4">= </span><span class="s1">rs</span><span class="s4">.</span><span class="s1">multinomial</span><span class="s4">(</span><span class="s6">1</span><span class="s4">, </span><span class="s1">class_prior_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">], </span><span class="s1">size</span><span class="s4">=</span><span class="s1">n_samples</span><span class="s4">)</span>
                <span class="s1">out </span><span class="s4">= </span><span class="s1">out</span><span class="s4">.</span><span class="s1">astype</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">)</span>

            <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;uniform&quot;</span><span class="s4">:</span>
                <span class="s1">out </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ones</span><span class="s4">((</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_classes_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">]), </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">)</span>
                <span class="s1">out </span><span class="s4">/= </span><span class="s1">n_classes_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">]</span>

            <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_strategy </span><span class="s4">== </span><span class="s5">&quot;constant&quot;</span><span class="s4">:</span>
                <span class="s1">ind </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">where</span><span class="s4">(</span><span class="s1">classes_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">] == </span><span class="s1">constant</span><span class="s4">[</span><span class="s1">k</span><span class="s4">])</span>
                <span class="s1">out </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">((</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_classes_</span><span class="s4">[</span><span class="s1">k</span><span class="s4">]), </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">)</span>
                <span class="s1">out</span><span class="s4">[:, </span><span class="s1">ind</span><span class="s4">] = </span><span class="s6">1.0</span>

            <span class="s1">P</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">out</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_ </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
            <span class="s1">P </span><span class="s4">= </span><span class="s1">P</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>

        <span class="s3">return </span><span class="s1">P</span>

    <span class="s3">def </span><span class="s1">predict_log_proba</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Return log probability estimates for the test vectors X. 
 
        Parameters 
        ---------- 
        X : {array-like, object with finite length or shape} 
            Training data. 
 
        Returns 
        ------- 
        P : ndarray of shape (n_samples, n_classes) or list of such arrays 
            Returns the log probability of the sample for each class in 
            the model, where classes are ordered arithmetically for each 
            output. 
        &quot;&quot;&quot;</span>
        <span class="s1">proba </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_ </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
            <span class="s3">return </span><span class="s1">np</span><span class="s4">.</span><span class="s1">log</span><span class="s4">(</span><span class="s1">proba</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s3">return </span><span class="s4">[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">log</span><span class="s4">(</span><span class="s1">p</span><span class="s4">) </span><span class="s3">for </span><span class="s1">p </span><span class="s3">in </span><span class="s1">proba</span><span class="s4">]</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span>
            <span class="s5">&quot;poor_score&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">,</span>
            <span class="s5">&quot;no_validation&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">,</span>
            <span class="s5">&quot;_xfail_checks&quot;</span><span class="s4">: {</span>
                <span class="s5">&quot;check_methods_subset_invariance&quot;</span><span class="s4">: </span><span class="s5">&quot;fails for the predict method&quot;</span><span class="s4">,</span>
                <span class="s5">&quot;check_methods_sample_order_invariance&quot;</span><span class="s4">: </span><span class="s5">&quot;fails for the predict method&quot;</span><span class="s4">,</span>
            <span class="s4">},</span>
        <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">score</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Return the mean accuracy on the given test data and labels. 
 
        In multi-label classification, this is the subset accuracy 
        which is a harsh metric since you require for each sample that 
        each label set be correctly predicted. 
 
        Parameters 
        ---------- 
        X : None or array-like of shape (n_samples, n_features) 
            Test samples. Passing None as test samples gives the same result 
            as passing real test samples, since DummyClassifier 
            operates independently of the sampled observations. 
 
        y : array-like of shape (n_samples,) or (n_samples, n_outputs) 
            True labels for X. 
 
        sample_weight : array-like of shape (n_samples,), default=None 
            Sample weights. 
 
        Returns 
        ------- 
        score : float 
            Mean accuracy of self.predict(X) w.r.t. y. 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">X </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">X </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span><span class="s1">shape</span><span class="s4">=(</span><span class="s1">len</span><span class="s4">(</span><span class="s1">y</span><span class="s4">), </span><span class="s6">1</span><span class="s4">))</span>
        <span class="s3">return </span><span class="s1">super</span><span class="s4">().</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">)</span>


<span class="s3">class </span><span class="s1">DummyRegressor</span><span class="s4">(</span><span class="s1">MultiOutputMixin</span><span class="s4">, </span><span class="s1">RegressorMixin</span><span class="s4">, </span><span class="s1">BaseEstimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Regressor that makes predictions using simple rules. 
 
    This regressor is useful as a simple baseline to compare with other 
    (real) regressors. Do not use it for real problems. 
 
    Read more in the :ref:`User Guide &lt;dummy_estimators&gt;`. 
 
    .. versionadded:: 0.13 
 
    Parameters 
    ---------- 
    strategy : {&quot;mean&quot;, &quot;median&quot;, &quot;quantile&quot;, &quot;constant&quot;}, default=&quot;mean&quot; 
        Strategy to use to generate predictions. 
 
        * &quot;mean&quot;: always predicts the mean of the training set 
        * &quot;median&quot;: always predicts the median of the training set 
        * &quot;quantile&quot;: always predicts a specified quantile of the training set, 
          provided with the quantile parameter. 
        * &quot;constant&quot;: always predicts a constant value that is provided by 
          the user. 
 
    constant : int or float or array-like of shape (n_outputs,), default=None 
        The explicit constant as predicted by the &quot;constant&quot; strategy. This 
        parameter is useful only for the &quot;constant&quot; strategy. 
 
    quantile : float in [0.0, 1.0], default=None 
        The quantile to predict using the &quot;quantile&quot; strategy. A quantile of 
        0.5 corresponds to the median, while 0.0 to the minimum and 1.0 to the 
        maximum. 
 
    Attributes 
    ---------- 
    constant_ : ndarray of shape (1, n_outputs) 
        Mean or median or quantile of the training targets or constant value 
        given by the user. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` has 
        feature names that are all strings. 
 
    n_outputs_ : int 
        Number of outputs. 
 
    See Also 
    -------- 
    DummyClassifier: Classifier that makes predictions using simple rules. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.dummy import DummyRegressor 
    &gt;&gt;&gt; X = np.array([1.0, 2.0, 3.0, 4.0]) 
    &gt;&gt;&gt; y = np.array([2.0, 3.0, 5.0, 10.0]) 
    &gt;&gt;&gt; dummy_regr = DummyRegressor(strategy=&quot;mean&quot;) 
    &gt;&gt;&gt; dummy_regr.fit(X, y) 
    DummyRegressor() 
    &gt;&gt;&gt; dummy_regr.predict(X) 
    array([5., 5., 5., 5.]) 
    &gt;&gt;&gt; dummy_regr.score(X, y) 
    0.0 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s5">&quot;strategy&quot;</span><span class="s4">: [</span><span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;mean&quot;</span><span class="s4">, </span><span class="s5">&quot;median&quot;</span><span class="s4">, </span><span class="s5">&quot;quantile&quot;</span><span class="s4">, </span><span class="s5">&quot;constant&quot;</span><span class="s4">})],</span>
        <span class="s5">&quot;quantile&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0.0</span><span class="s4">, </span><span class="s6">1.0</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;both&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;constant&quot;</span><span class="s4">: [</span>
            <span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;neither&quot;</span><span class="s4">),</span>
            <span class="s5">&quot;array-like&quot;</span><span class="s4">,</span>
            <span class="s3">None</span><span class="s4">,</span>
        <span class="s4">],</span>
    <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, *, </span><span class="s1">strategy</span><span class="s4">=</span><span class="s5">&quot;mean&quot;</span><span class="s4">, </span><span class="s1">constant</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, </span><span class="s1">quantile</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">strategy </span><span class="s4">= </span><span class="s1">strategy</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">constant </span><span class="s4">= </span><span class="s1">constant</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">quantile </span><span class="s4">= </span><span class="s1">quantile</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Fit the random regressor. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Training data. 
 
        y : array-like of shape (n_samples,) or (n_samples, n_outputs) 
            Target values. 
 
        sample_weight : array-like of shape (n_samples,), default=None 
            Sample weights. 
 
        Returns 
        ------- 
        self : object 
            Fitted estimator. 
        &quot;&quot;&quot;</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">cast_to_ndarray</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>

        <span class="s1">y </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">ensure_2d</span><span class="s4">=</span><span class="s3">False</span><span class="s4">, </span><span class="s1">input_name</span><span class="s4">=</span><span class="s5">&quot;y&quot;</span><span class="s4">)</span>
        <span class="s3">if </span><span class="s1">len</span><span class="s4">(</span><span class="s1">y</span><span class="s4">) == </span><span class="s6">0</span><span class="s4">:</span>
            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span><span class="s5">&quot;y must not be empty.&quot;</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">y</span><span class="s4">.</span><span class="s1">ndim </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
            <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">reshape</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, (-</span><span class="s6">1</span><span class="s4">, </span><span class="s6">1</span><span class="s4">))</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_ </span><span class="s4">= </span><span class="s1">y</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]</span>

        <span class="s1">check_consistent_length</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">sample_weight </span><span class="s3">is not None</span><span class="s4">:</span>
            <span class="s1">sample_weight </span><span class="s4">= </span><span class="s1">_check_sample_weight</span><span class="s4">(</span><span class="s1">sample_weight</span><span class="s4">, </span><span class="s1">X</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">strategy </span><span class="s4">== </span><span class="s5">&quot;mean&quot;</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">constant_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">average</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">=</span><span class="s6">0</span><span class="s4">, </span><span class="s1">weights</span><span class="s4">=</span><span class="s1">sample_weight</span><span class="s4">)</span>

        <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">strategy </span><span class="s4">== </span><span class="s5">&quot;median&quot;</span><span class="s4">:</span>
            <span class="s3">if </span><span class="s1">sample_weight </span><span class="s3">is None</span><span class="s4">:</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">constant_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">median</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">=</span><span class="s6">0</span><span class="s4">)</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">constant_ </span><span class="s4">= [</span>
                    <span class="s1">_weighted_percentile</span><span class="s4">(</span><span class="s1">y</span><span class="s4">[:, </span><span class="s1">k</span><span class="s4">], </span><span class="s1">sample_weight</span><span class="s4">, </span><span class="s1">percentile</span><span class="s4">=</span><span class="s6">50.0</span><span class="s4">)</span>
                    <span class="s3">for </span><span class="s1">k </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_</span><span class="s4">)</span>
                <span class="s4">]</span>

        <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">strategy </span><span class="s4">== </span><span class="s5">&quot;quantile&quot;</span><span class="s4">:</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">quantile </span><span class="s3">is None</span><span class="s4">:</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                    <span class="s5">&quot;When using `strategy='quantile', you have to specify the desired &quot;</span>
                    <span class="s5">&quot;quantile in the range [0, 1].&quot;</span>
                <span class="s4">)</span>
            <span class="s1">percentile </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">quantile </span><span class="s4">* </span><span class="s6">100.0</span>
            <span class="s3">if </span><span class="s1">sample_weight </span><span class="s3">is None</span><span class="s4">:</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">constant_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">percentile</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">=</span><span class="s6">0</span><span class="s4">, </span><span class="s1">q</span><span class="s4">=</span><span class="s1">percentile</span><span class="s4">)</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">constant_ </span><span class="s4">= [</span>
                    <span class="s1">_weighted_percentile</span><span class="s4">(</span><span class="s1">y</span><span class="s4">[:, </span><span class="s1">k</span><span class="s4">], </span><span class="s1">sample_weight</span><span class="s4">, </span><span class="s1">percentile</span><span class="s4">=</span><span class="s1">percentile</span><span class="s4">)</span>
                    <span class="s3">for </span><span class="s1">k </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_</span><span class="s4">)</span>
                <span class="s4">]</span>

        <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">strategy </span><span class="s4">== </span><span class="s5">&quot;constant&quot;</span><span class="s4">:</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">constant </span><span class="s3">is None</span><span class="s4">:</span>
                <span class="s3">raise </span><span class="s1">TypeError</span><span class="s4">(</span>
                    <span class="s5">&quot;Constant target value has to be specified &quot;</span>
                    <span class="s5">&quot;when the constant strategy is used.&quot;</span>
                <span class="s4">)</span>

            <span class="s1">self</span><span class="s4">.</span><span class="s1">constant_ </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">constant</span><span class="s4">,</span>
                <span class="s1">accept_sparse</span><span class="s4">=[</span><span class="s5">&quot;csr&quot;</span><span class="s4">, </span><span class="s5">&quot;csc&quot;</span><span class="s4">, </span><span class="s5">&quot;coo&quot;</span><span class="s4">],</span>
                <span class="s1">ensure_2d</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
                <span class="s1">ensure_min_samples</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
            <span class="s4">)</span>

            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_ </span><span class="s4">!= </span><span class="s6">1 </span><span class="s3">and </span><span class="s1">self</span><span class="s4">.</span><span class="s1">constant_</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">] != </span><span class="s1">y</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]:</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                    <span class="s5">&quot;Constant target value should have shape (%d, 1).&quot; </span><span class="s4">% </span><span class="s1">y</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]</span>
                <span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">constant_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">reshape</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">constant_</span><span class="s4">, (</span><span class="s6">1</span><span class="s4">, -</span><span class="s6">1</span><span class="s4">))</span>
        <span class="s3">return </span><span class="s1">self</span>

    <span class="s3">def </span><span class="s1">predict</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">return_std</span><span class="s4">=</span><span class="s3">False</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Perform classification on test vectors X. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Test data. 
 
        return_std : bool, default=False 
            Whether to return the standard deviation of posterior prediction. 
            All zeros in this case. 
 
            .. versionadded:: 0.20 
 
        Returns 
        ------- 
        y : array-like of shape (n_samples,) or (n_samples, n_outputs) 
            Predicted target values for X. 
 
        y_std : array-like of shape (n_samples,) or (n_samples, n_outputs) 
            Standard deviation of predictive distribution of query points. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s1">n_samples </span><span class="s4">= </span><span class="s1">_num_samples</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

        <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">full</span><span class="s4">(</span>
            <span class="s4">(</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_</span><span class="s4">),</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">constant_</span><span class="s4">,</span>
            <span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">constant_</span><span class="s4">).</span><span class="s1">dtype</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">y_std </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">((</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_</span><span class="s4">))</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_outputs_ </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
            <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ravel</span><span class="s4">(</span><span class="s1">y</span><span class="s4">)</span>
            <span class="s1">y_std </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ravel</span><span class="s4">(</span><span class="s1">y_std</span><span class="s4">)</span>

        <span class="s3">return </span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">y_std</span><span class="s4">) </span><span class="s3">if </span><span class="s1">return_std </span><span class="s3">else </span><span class="s1">y</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span><span class="s5">&quot;poor_score&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">, </span><span class="s5">&quot;no_validation&quot;</span><span class="s4">: </span><span class="s3">True</span><span class="s4">}</span>

    <span class="s3">def </span><span class="s1">score</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Return the coefficient of determination R^2 of the prediction. 
 
        The coefficient R^2 is defined as `(1 - u/v)`, where `u` is the 
        residual sum of squares `((y_true - y_pred) ** 2).sum()` and `v` is the 
        total sum of squares `((y_true - y_true.mean()) ** 2).sum()`. The best 
        possible score is 1.0 and it can be negative (because the model can be 
        arbitrarily worse). A constant model that always predicts the expected 
        value of y, disregarding the input features, would get a R^2 score of 
        0.0. 
 
        Parameters 
        ---------- 
        X : None or array-like of shape (n_samples, n_features) 
            Test samples. Passing None as test samples gives the same result 
            as passing real test samples, since `DummyRegressor` 
            operates independently of the sampled observations. 
 
        y : array-like of shape (n_samples,) or (n_samples, n_outputs) 
            True values for X. 
 
        sample_weight : array-like of shape (n_samples,), default=None 
            Sample weights. 
 
        Returns 
        ------- 
        score : float 
            R^2 of `self.predict(X)` w.r.t. y. 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">X </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">X </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span><span class="s1">shape</span><span class="s4">=(</span><span class="s1">len</span><span class="s4">(</span><span class="s1">y</span><span class="s4">), </span><span class="s6">1</span><span class="s4">))</span>
        <span class="s3">return </span><span class="s1">super</span><span class="s4">().</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">)</span>
</pre>
</body>
</html>