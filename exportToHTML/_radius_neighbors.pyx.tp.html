<html>
<head>
<title>_radius_neighbors.pyx.tp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #bcbec4;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_radius_neighbors.pyx.tp</font>
</center></td></tr></table>
<pre><span class="s0">cimport numpy as cnp</span>
<span class="s0">import numpy as np</span>
<span class="s0">import warnings</span>

<span class="s0">from libcpp.memory cimport shared_ptr, make_shared</span>
<span class="s0">from libcpp.vector cimport vector</span>
<span class="s0">from libcpp.algorithm cimport move</span>
<span class="s0">from cython cimport final</span>
<span class="s0">from cython.operator cimport dereference as deref</span>
<span class="s0">from cython.parallel cimport parallel, prange</span>

<span class="s0">from ...utils._sorting cimport simultaneous_sort</span>
<span class="s0">from ...utils._typedefs cimport intp_t, float64_t</span>
<span class="s0">from ...utils._vector_sentinel cimport vector_to_nd_array</span>

<span class="s0">from numbers import Real</span>
<span class="s0">from scipy.sparse import issparse</span>
<span class="s0">from ...utils import check_array, check_scalar</span>
<span class="s0">from ...utils.fixes import _in_unstable_openblas_configuration</span>
<span class="s0">from ...utils.parallel import _get_threadpool_controller</span>

<span class="s0">cnp.import_array()</span>

<span class="s0">######################</span>

<span class="s0">cdef cnp.ndarray[object, ndim=1] coerce_vectors_to_nd_arrays(</span>
    <span class="s0">shared_ptr[vector_vector_double_intp_t] vecs</span>
<span class="s0">):</span>
    <span class="s0">&quot;&quot;&quot;Coerce a std::vector of std::vector to a ndarray of ndarray.&quot;&quot;&quot;</span>
    <span class="s0">cdef:</span>
        <span class="s0">intp_t n = deref(vecs).size()</span>
        <span class="s0">cnp.ndarray[object, ndim=1] nd_arrays_of_nd_arrays = np.empty(n, dtype=np.ndarray)</span>

    <span class="s0">for i in range(n):</span>
        <span class="s0">nd_arrays_of_nd_arrays[i] = vector_to_nd_array(&amp;(deref(vecs)[i]))</span>

    <span class="s0">return nd_arrays_of_nd_arrays</span>

<span class="s0">#####################</span>
<span class="s0">{{for name_suffix in ['64', '32']}}</span>

<span class="s0">from ._base cimport (</span>
    <span class="s0">BaseDistancesReduction{{name_suffix}},</span>
    <span class="s0">_sqeuclidean_row_norms{{name_suffix}}</span>
<span class="s0">)</span>

<span class="s0">from ._datasets_pair cimport DatasetsPair{{name_suffix}}</span>

<span class="s0">from ._middle_term_computer cimport MiddleTermComputer{{name_suffix}}</span>


<span class="s0">cdef class RadiusNeighbors{{name_suffix}}(BaseDistancesReduction{{name_suffix}}):</span>
    <span class="s0">&quot;&quot;&quot;float{{name_suffix}} implementation of the RadiusNeighbors.&quot;&quot;&quot;</span>

    <span class="s0">@classmethod</span>
    <span class="s0">def compute(</span>
        <span class="s0">cls,</span>
        <span class="s0">X,</span>
        <span class="s0">Y,</span>
        <span class="s0">float64_t radius,</span>
        <span class="s0">str metric=&quot;euclidean&quot;,</span>
        <span class="s0">chunk_size=None,</span>
        <span class="s0">dict metric_kwargs=None,</span>
        <span class="s0">str strategy=None,</span>
        <span class="s0">bint return_distance=False,</span>
        <span class="s0">bint sort_results=False,</span>
    <span class="s0">):</span>
        <span class="s0">&quot;&quot;&quot;Compute the radius-neighbors reduction.</span>

        <span class="s0">This classmethod is responsible for introspecting the arguments</span>
        <span class="s0">values to dispatch to the most appropriate implementation of</span>
        <span class="s0">:class:`RadiusNeighbors{{name_suffix}}`.</span>

        <span class="s0">This allows decoupling the API entirely from the implementation details</span>
        <span class="s0">whilst maintaining RAII: all temporarily allocated datastructures necessary</span>
        <span class="s0">for the concrete implementation are therefore freed when this classmethod</span>
        <span class="s0">returns.</span>

        <span class="s0">No instance should directly be created outside of this class method.</span>
        <span class="s0">&quot;&quot;&quot;</span>
        <span class="s0">if metric in (&quot;euclidean&quot;, &quot;sqeuclidean&quot;):</span>
            <span class="s0"># Specialized implementation of RadiusNeighbors for the Euclidean</span>
            <span class="s0"># distance for the dense-dense and sparse-sparse cases.</span>
            <span class="s0"># This implementation computes the distances by chunk using</span>
            <span class="s0"># a decomposition of the Squared Euclidean distance.</span>
            <span class="s0"># This specialisation has an improved arithmetic intensity for both</span>
            <span class="s0"># the dense and sparse settings, allowing in most case speed-ups of</span>
            <span class="s0"># several orders of magnitude compared to the generic RadiusNeighbors</span>
            <span class="s0"># implementation.</span>
            <span class="s0"># For more information see MiddleTermComputer.</span>
            <span class="s0">use_squared_distances = metric == &quot;sqeuclidean&quot;</span>
            <span class="s0">pda = EuclideanRadiusNeighbors{{name_suffix}}(</span>
                <span class="s0">X=X, Y=Y, radius=radius,</span>
                <span class="s0">use_squared_distances=use_squared_distances,</span>
                <span class="s0">chunk_size=chunk_size,</span>
                <span class="s0">strategy=strategy,</span>
                <span class="s0">sort_results=sort_results,</span>
                <span class="s0">metric_kwargs=metric_kwargs,</span>
            <span class="s0">)</span>
        <span class="s0">else:</span>
             <span class="s0"># Fall back on a generic implementation that handles most scipy</span>
             <span class="s0"># metrics by computing the distances between 2 vectors at a time.</span>
            <span class="s0">pda = RadiusNeighbors{{name_suffix}}(</span>
                <span class="s0">datasets_pair=DatasetsPair{{name_suffix}}.get_for(X, Y, metric, metric_kwargs),</span>
                <span class="s0">radius=radius,</span>
                <span class="s0">chunk_size=chunk_size,</span>
                <span class="s0">strategy=strategy,</span>
                <span class="s0">sort_results=sort_results,</span>
            <span class="s0">)</span>

        <span class="s0"># Limit the number of threads in second level of nested parallelism for BLAS</span>
        <span class="s0"># to avoid threads over-subscription (in GEMM for instance).</span>
        <span class="s0">with _get_threadpool_controller().limit(limits=1, user_api=&quot;blas&quot;):</span>
            <span class="s0">if pda.execute_in_parallel_on_Y:</span>
                <span class="s0">pda._parallel_on_Y()</span>
            <span class="s0">else:</span>
                <span class="s0">pda._parallel_on_X()</span>

        <span class="s0">return pda._finalize_results(return_distance)</span>


    <span class="s0">def __init__(</span>
        <span class="s0">self,</span>
        <span class="s0">DatasetsPair{{name_suffix}} datasets_pair,</span>
        <span class="s0">float64_t radius,</span>
        <span class="s0">chunk_size=None,</span>
        <span class="s0">strategy=None,</span>
        <span class="s0">sort_results=False,</span>
    <span class="s0">):</span>
        <span class="s0">super().__init__(</span>
            <span class="s0">datasets_pair=datasets_pair,</span>
            <span class="s0">chunk_size=chunk_size,</span>
            <span class="s0">strategy=strategy,</span>
        <span class="s0">)</span>

        <span class="s0">self.radius = check_scalar(radius, &quot;radius&quot;, Real, min_val=0)</span>
        <span class="s0">self.r_radius = self.datasets_pair.distance_metric._dist_to_rdist(radius)</span>
        <span class="s0">self.sort_results = sort_results</span>

        <span class="s0"># Allocating pointers to datastructures but not the datastructures themselves.</span>
        <span class="s0"># There are as many pointers as effective threads.</span>
        <span class="s0">#</span>
        <span class="s0"># For the sake of explicitness:</span>
        <span class="s0">#   - when parallelizing on X, the pointers of those heaps are referencing</span>
        <span class="s0">#   self.neigh_distances and self.neigh_indices</span>
        <span class="s0">#   - when parallelizing on Y, the pointers of those heaps are referencing</span>
        <span class="s0">#   std::vectors of std::vectors which are thread-wise-allocated and whose</span>
        <span class="s0">#   content will be merged into self.neigh_distances and self.neigh_indices.</span>
        <span class="s0">self.neigh_distances_chunks = vector[shared_ptr[vector[vector[float64_t]]]](</span>
            <span class="s0">self.chunks_n_threads</span>
        <span class="s0">)</span>
        <span class="s0">self.neigh_indices_chunks = vector[shared_ptr[vector[vector[intp_t]]]](</span>
            <span class="s0">self.chunks_n_threads</span>
        <span class="s0">)</span>

        <span class="s0"># Temporary datastructures which will be coerced to numpy arrays on before</span>
        <span class="s0"># RadiusNeighbors.compute &quot;return&quot; and will be then freed.</span>
        <span class="s0">self.neigh_distances = make_shared[vector[vector[float64_t]]](self.n_samples_X)</span>
        <span class="s0">self.neigh_indices = make_shared[vector[vector[intp_t]]](self.n_samples_X)</span>

    <span class="s0">cdef void _compute_and_reduce_distances_on_chunks(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
        <span class="s0">intp_t Y_start,</span>
        <span class="s0">intp_t Y_end,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t i, j</span>
            <span class="s0">float64_t r_dist_i_j</span>

        <span class="s0">for i in range(X_start, X_end):</span>
            <span class="s0">for j in range(Y_start, Y_end):</span>
                <span class="s0">r_dist_i_j = self.datasets_pair.surrogate_dist(i, j)</span>
                <span class="s0">if r_dist_i_j &lt;= self.r_radius:</span>
                    <span class="s0">deref(self.neigh_distances_chunks[thread_num])[i].push_back(r_dist_i_j)</span>
                    <span class="s0">deref(self.neigh_indices_chunks[thread_num])[i].push_back(j)</span>

    <span class="s0">def _finalize_results(self, bint return_distance=False):</span>
        <span class="s0">if return_distance:</span>
            <span class="s0"># We need to recompute distances because we relied on</span>
            <span class="s0"># surrogate distances for the reduction.</span>
            <span class="s0">self.compute_exact_distances()</span>
            <span class="s0">return (</span>
                <span class="s0">coerce_vectors_to_nd_arrays(self.neigh_distances),</span>
                <span class="s0">coerce_vectors_to_nd_arrays(self.neigh_indices),</span>
            <span class="s0">)</span>

        <span class="s0">return coerce_vectors_to_nd_arrays(self.neigh_indices)</span>

    <span class="s0">cdef void _parallel_on_X_init_chunk(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>

        <span class="s0"># As this strategy is embarrassingly parallel, we can set the</span>
        <span class="s0"># thread vectors' pointers to the main vectors'.</span>
        <span class="s0">self.neigh_distances_chunks[thread_num] = self.neigh_distances</span>
        <span class="s0">self.neigh_indices_chunks[thread_num] = self.neigh_indices</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_X_prange_iter_finalize(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t idx</span>

        <span class="s0"># Sorting neighbors for each query vector of X</span>
        <span class="s0">if self.sort_results:</span>
            <span class="s0">for idx in range(X_start, X_end):</span>
                <span class="s0">simultaneous_sort(</span>
                    <span class="s0">deref(self.neigh_distances)[idx].data(),</span>
                    <span class="s0">deref(self.neigh_indices)[idx].data(),</span>
                    <span class="s0">deref(self.neigh_indices)[idx].size()</span>
                <span class="s0">)</span>

    <span class="s0">cdef void _parallel_on_Y_init(</span>
        <span class="s0">self,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t thread_num</span>
        <span class="s0"># As chunks of X are shared across threads, so must datastructures to avoid race</span>
        <span class="s0"># conditions: each thread has its own vectors of n_samples_X vectors which are</span>
        <span class="s0"># then merged back in the main n_samples_X vectors.</span>
        <span class="s0">for thread_num in range(self.chunks_n_threads):</span>
            <span class="s0">self.neigh_distances_chunks[thread_num] = make_shared[vector[vector[float64_t]]](self.n_samples_X)</span>
            <span class="s0">self.neigh_indices_chunks[thread_num] = make_shared[vector[vector[intp_t]]](self.n_samples_X)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _merge_vectors(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t idx,</span>
        <span class="s0">intp_t num_threads,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t thread_num</span>
            <span class="s0">intp_t idx_n_elements = 0</span>
            <span class="s0">intp_t last_element_idx = deref(self.neigh_indices)[idx].size()</span>

        <span class="s0"># Resizing buffers only once for the given number of elements.</span>
        <span class="s0">for thread_num in range(num_threads):</span>
            <span class="s0">idx_n_elements += deref(self.neigh_distances_chunks[thread_num])[idx].size()</span>

        <span class="s0">deref(self.neigh_distances)[idx].resize(last_element_idx + idx_n_elements)</span>
        <span class="s0">deref(self.neigh_indices)[idx].resize(last_element_idx + idx_n_elements)</span>

        <span class="s0"># Moving the elements by range using the range first element</span>
        <span class="s0"># as the reference for the insertion.</span>
        <span class="s0">for thread_num in range(num_threads):</span>
            <span class="s0">move(</span>
                <span class="s0">deref(self.neigh_distances_chunks[thread_num])[idx].begin(),</span>
                <span class="s0">deref(self.neigh_distances_chunks[thread_num])[idx].end(),</span>
                <span class="s0">deref(self.neigh_distances)[idx].begin() + last_element_idx</span>
            <span class="s0">)</span>
            <span class="s0">move(</span>
                <span class="s0">deref(self.neigh_indices_chunks[thread_num])[idx].begin(),</span>
                <span class="s0">deref(self.neigh_indices_chunks[thread_num])[idx].end(),</span>
                <span class="s0">deref(self.neigh_indices)[idx].begin() + last_element_idx</span>
            <span class="s0">)</span>
            <span class="s0">last_element_idx += deref(self.neigh_distances_chunks[thread_num])[idx].size()</span>

    <span class="s0">cdef void _parallel_on_Y_finalize(</span>
        <span class="s0">self,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t idx</span>

        <span class="s0">with nogil, parallel(num_threads=self.effective_n_threads):</span>
            <span class="s0"># Merge vectors used in threads into the main ones.</span>
            <span class="s0"># This is done in parallel sample-wise (no need for locks).</span>
            <span class="s0">for idx in prange(self.n_samples_X, schedule='static'):</span>
                <span class="s0">self._merge_vectors(idx, self.chunks_n_threads)</span>

            <span class="s0"># The content of the vector have been std::moved.</span>
            <span class="s0"># Hence they can't be used anymore and can be deleted.</span>
            <span class="s0"># Their deletion is carried out automatically as the</span>
            <span class="s0"># implementation relies on shared pointers.</span>

            <span class="s0"># Sort in parallel in ascending order w.r.t the distances if requested.</span>
            <span class="s0">if self.sort_results:</span>
                <span class="s0">for idx in prange(self.n_samples_X, schedule='static'):</span>
                    <span class="s0">simultaneous_sort(</span>
                        <span class="s0">deref(self.neigh_distances)[idx].data(),</span>
                        <span class="s0">deref(self.neigh_indices)[idx].data(),</span>
                        <span class="s0">deref(self.neigh_indices)[idx].size()</span>
                    <span class="s0">)</span>

        <span class="s0">return</span>

    <span class="s0">cdef void compute_exact_distances(self) noexcept nogil:</span>
        <span class="s0">&quot;&quot;&quot;Convert rank-preserving distances to pairwise distances in parallel.&quot;&quot;&quot;</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t i</span>
            <span class="s0">vector[intp_t].size_type j</span>

        <span class="s0">for i in prange(self.n_samples_X, nogil=True, schedule='static',</span>
                        <span class="s0">num_threads=self.effective_n_threads):</span>
            <span class="s0">for j in range(deref(self.neigh_indices)[i].size()):</span>
                <span class="s0">deref(self.neigh_distances)[i][j] = (</span>
                        <span class="s0">self.datasets_pair.distance_metric._rdist_to_dist(</span>
                            <span class="s0"># Guard against potential -0., causing nan production.</span>
                            <span class="s0">max(deref(self.neigh_distances)[i][j], 0.)</span>
                        <span class="s0">)</span>
                <span class="s0">)</span>


<span class="s0">cdef class EuclideanRadiusNeighbors{{name_suffix}}(RadiusNeighbors{{name_suffix}}):</span>
    <span class="s0">&quot;&quot;&quot;EuclideanDistance-specialisation of RadiusNeighbors{{name_suffix}}.&quot;&quot;&quot;</span>

    <span class="s0">@classmethod</span>
    <span class="s0">def is_usable_for(cls, X, Y, metric) -&gt; bool:</span>
        <span class="s0">return (RadiusNeighbors{{name_suffix}}.is_usable_for(X, Y, metric)</span>
                <span class="s0">and not _in_unstable_openblas_configuration())</span>

    <span class="s0">def __init__(</span>
        <span class="s0">self,</span>
        <span class="s0">X,</span>
        <span class="s0">Y,</span>
        <span class="s0">float64_t radius,</span>
        <span class="s0">bint use_squared_distances=False,</span>
        <span class="s0">chunk_size=None,</span>
        <span class="s0">strategy=None,</span>
        <span class="s0">sort_results=False,</span>
        <span class="s0">metric_kwargs=None,</span>
    <span class="s0">):</span>
        <span class="s0">if (</span>
            <span class="s0">isinstance(metric_kwargs, dict) and</span>
            <span class="s0">(metric_kwargs.keys() - {&quot;X_norm_squared&quot;, &quot;Y_norm_squared&quot;})</span>
        <span class="s0">):</span>
            <span class="s0">warnings.warn(</span>
                <span class="s0">f&quot;Some metric_kwargs have been passed ({metric_kwargs}) but aren't &quot;</span>
                <span class="s0">f&quot;usable for this case (EuclideanRadiusNeighbors64) and will be ignored.&quot;,</span>
                <span class="s0">UserWarning,</span>
                <span class="s0">stacklevel=3,</span>
            <span class="s0">)</span>

        <span class="s0">super().__init__(</span>
            <span class="s0"># The datasets pair here is used for exact distances computations</span>
            <span class="s0">datasets_pair=DatasetsPair{{name_suffix}}.get_for(X, Y, metric=&quot;euclidean&quot;),</span>
            <span class="s0">radius=radius,</span>
            <span class="s0">chunk_size=chunk_size,</span>
            <span class="s0">strategy=strategy,</span>
            <span class="s0">sort_results=sort_results,</span>
        <span class="s0">)</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t dist_middle_terms_chunks_size = self.Y_n_samples_chunk * self.X_n_samples_chunk</span>

        <span class="s0">self.middle_term_computer = MiddleTermComputer{{name_suffix}}.get_for(</span>
            <span class="s0">X,</span>
            <span class="s0">Y,</span>
            <span class="s0">self.effective_n_threads,</span>
            <span class="s0">self.chunks_n_threads,</span>
            <span class="s0">dist_middle_terms_chunks_size,</span>
            <span class="s0">n_features=X.shape[1],</span>
            <span class="s0">chunk_size=self.chunk_size,</span>
        <span class="s0">)</span>

        <span class="s0">if metric_kwargs is not None and &quot;Y_norm_squared&quot; in metric_kwargs:</span>
            <span class="s0">self.Y_norm_squared = check_array(</span>
                <span class="s0">metric_kwargs.pop(&quot;Y_norm_squared&quot;),</span>
                <span class="s0">ensure_2d=False,</span>
                <span class="s0">input_name=&quot;Y_norm_squared&quot;,</span>
                <span class="s0">dtype=np.float64,</span>
            <span class="s0">)</span>
        <span class="s0">else:</span>
            <span class="s0">self.Y_norm_squared = _sqeuclidean_row_norms{{name_suffix}}(</span>
                <span class="s0">Y,</span>
                <span class="s0">self.effective_n_threads,</span>
            <span class="s0">)</span>

        <span class="s0">if metric_kwargs is not None and &quot;X_norm_squared&quot; in metric_kwargs:</span>
            <span class="s0">self.X_norm_squared = check_array(</span>
                <span class="s0">metric_kwargs.pop(&quot;X_norm_squared&quot;),</span>
                <span class="s0">ensure_2d=False,</span>
                <span class="s0">input_name=&quot;X_norm_squared&quot;,</span>
                <span class="s0">dtype=np.float64,</span>
            <span class="s0">)</span>
        <span class="s0">else:</span>
            <span class="s0"># Do not recompute norms if datasets are identical.</span>
            <span class="s0">self.X_norm_squared = (</span>
                <span class="s0">self.Y_norm_squared if X is Y else</span>
                <span class="s0">_sqeuclidean_row_norms{{name_suffix}}(</span>
                    <span class="s0">X,</span>
                    <span class="s0">self.effective_n_threads,</span>
                <span class="s0">)</span>
            <span class="s0">)</span>

        <span class="s0">self.use_squared_distances = use_squared_distances</span>

        <span class="s0">if use_squared_distances:</span>
            <span class="s0"># In this specialisation and this setup, the value passed to the radius is</span>
            <span class="s0"># already considered to be the adapted radius, so we overwrite it.</span>
            <span class="s0">self.r_radius = radius</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_X_parallel_init(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">RadiusNeighbors{{name_suffix}}._parallel_on_X_parallel_init(self, thread_num)</span>
        <span class="s0">self.middle_term_computer._parallel_on_X_parallel_init(thread_num)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_X_init_chunk(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">RadiusNeighbors{{name_suffix}}._parallel_on_X_init_chunk(self, thread_num, X_start, X_end)</span>
        <span class="s0">self.middle_term_computer._parallel_on_X_init_chunk(thread_num, X_start, X_end)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_X_pre_compute_and_reduce_distances_on_chunks(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
        <span class="s0">intp_t Y_start,</span>
        <span class="s0">intp_t Y_end,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">RadiusNeighbors{{name_suffix}}._parallel_on_X_pre_compute_and_reduce_distances_on_chunks(</span>
            <span class="s0">self,</span>
            <span class="s0">X_start, X_end,</span>
            <span class="s0">Y_start, Y_end,</span>
            <span class="s0">thread_num,</span>
        <span class="s0">)</span>
        <span class="s0">self.middle_term_computer._parallel_on_X_pre_compute_and_reduce_distances_on_chunks(</span>
            <span class="s0">X_start, X_end, Y_start, Y_end, thread_num,</span>
        <span class="s0">)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_Y_init(</span>
        <span class="s0">self,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">RadiusNeighbors{{name_suffix}}._parallel_on_Y_init(self)</span>
        <span class="s0">self.middle_term_computer._parallel_on_Y_init()</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_Y_parallel_init(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t thread_num,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">RadiusNeighbors{{name_suffix}}._parallel_on_Y_parallel_init(self, thread_num, X_start, X_end)</span>
        <span class="s0">self.middle_term_computer._parallel_on_Y_parallel_init(thread_num, X_start, X_end)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _parallel_on_Y_pre_compute_and_reduce_distances_on_chunks(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
        <span class="s0">intp_t Y_start,</span>
        <span class="s0">intp_t Y_end,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">RadiusNeighbors{{name_suffix}}._parallel_on_Y_pre_compute_and_reduce_distances_on_chunks(</span>
            <span class="s0">self,</span>
            <span class="s0">X_start, X_end,</span>
            <span class="s0">Y_start, Y_end,</span>
            <span class="s0">thread_num,</span>
        <span class="s0">)</span>
        <span class="s0">self.middle_term_computer._parallel_on_Y_pre_compute_and_reduce_distances_on_chunks(</span>
            <span class="s0">X_start, X_end, Y_start, Y_end, thread_num</span>
        <span class="s0">)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void compute_exact_distances(self) noexcept nogil:</span>
        <span class="s0">if not self.use_squared_distances:</span>
            <span class="s0">RadiusNeighbors{{name_suffix}}.compute_exact_distances(self)</span>

    <span class="s0">@final</span>
    <span class="s0">cdef void _compute_and_reduce_distances_on_chunks(</span>
        <span class="s0">self,</span>
        <span class="s0">intp_t X_start,</span>
        <span class="s0">intp_t X_end,</span>
        <span class="s0">intp_t Y_start,</span>
        <span class="s0">intp_t Y_end,</span>
        <span class="s0">intp_t thread_num,</span>
    <span class="s0">) noexcept nogil:</span>
        <span class="s0">cdef:</span>
            <span class="s0">intp_t i, j</span>
            <span class="s0">float64_t sqeuclidean_dist_i_j</span>
            <span class="s0">intp_t n_X = X_end - X_start</span>
            <span class="s0">intp_t n_Y = Y_end - Y_start</span>
            <span class="s0">float64_t *dist_middle_terms = self.middle_term_computer._compute_dist_middle_terms(</span>
                <span class="s0">X_start, X_end, Y_start, Y_end, thread_num</span>
            <span class="s0">)</span>

        <span class="s0"># Pushing the distance and their associated indices in vectors.</span>
        <span class="s0">for i in range(n_X):</span>
            <span class="s0">for j in range(n_Y):</span>
                <span class="s0">sqeuclidean_dist_i_j = (</span>
                    <span class="s0">self.X_norm_squared[i + X_start]</span>
                    <span class="s0">+ dist_middle_terms[i * n_Y + j]</span>
                    <span class="s0">+ self.Y_norm_squared[j + Y_start]</span>
                <span class="s0">)</span>

                <span class="s0"># Catastrophic cancellation might cause -0. to be present,</span>
                <span class="s0"># e.g. when computing d(x_i, y_i) when X is Y.</span>
                <span class="s0">sqeuclidean_dist_i_j = max(0., sqeuclidean_dist_i_j)</span>

                <span class="s0">if sqeuclidean_dist_i_j &lt;= self.r_radius:</span>
                    <span class="s0">deref(self.neigh_distances_chunks[thread_num])[i + X_start].push_back(sqeuclidean_dist_i_j)</span>
                    <span class="s0">deref(self.neigh_indices_chunks[thread_num])[i + X_start].push_back(j + Y_start)</span>

<span class="s0">{{endfor}}</span>
</pre>
</body>
</html>