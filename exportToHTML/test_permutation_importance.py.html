<html>
<head>
<title>test_permutation_importance.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #6aab73;}
.s4 { color: #2aacb8;}
.s5 { color: #7a7e85;}
.s6 { color: #5f826b; font-style: italic;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_permutation_importance.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">joblib </span><span class="s0">import </span><span class="s1">parallel_backend</span>
<span class="s0">from </span><span class="s1">numpy</span><span class="s2">.</span><span class="s1">testing </span><span class="s0">import </span><span class="s1">assert_allclose</span>

<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">compose </span><span class="s0">import </span><span class="s1">ColumnTransformer</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">datasets </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">load_diabetes</span><span class="s2">,</span>
    <span class="s1">load_iris</span><span class="s2">,</span>
    <span class="s1">make_classification</span><span class="s2">,</span>
    <span class="s1">make_regression</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">dummy </span><span class="s0">import </span><span class="s1">DummyClassifier</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">ensemble </span><span class="s0">import </span><span class="s1">RandomForestClassifier</span><span class="s2">, </span><span class="s1">RandomForestRegressor</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">impute </span><span class="s0">import </span><span class="s1">SimpleImputer</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">inspection </span><span class="s0">import </span><span class="s1">permutation_importance</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">linear_model </span><span class="s0">import </span><span class="s1">LinearRegression</span><span class="s2">, </span><span class="s1">LogisticRegression</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">metrics </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">get_scorer</span><span class="s2">,</span>
    <span class="s1">mean_squared_error</span><span class="s2">,</span>
    <span class="s1">r2_score</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">model_selection </span><span class="s0">import </span><span class="s1">train_test_split</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">pipeline </span><span class="s0">import </span><span class="s1">make_pipeline</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">preprocessing </span><span class="s0">import </span><span class="s1">KBinsDiscretizer</span><span class="s2">, </span><span class="s1">OneHotEncoder</span><span class="s2">, </span><span class="s1">StandardScaler</span><span class="s2">, </span><span class="s1">scale</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">_testing </span><span class="s0">import </span><span class="s1">_convert_container</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;n_jobs&quot;</span><span class="s2">, [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;max_samples&quot;</span><span class="s2">, [</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;sample_weight&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">, </span><span class="s3">&quot;ones&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_permutation_importance_correlated_feature_regression</span><span class="s2">(</span>
    <span class="s1">n_jobs</span><span class="s2">, </span><span class="s1">max_samples</span><span class="s2">, </span><span class="s1">sample_weight</span>
<span class="s2">):</span>
    <span class="s5"># Make sure that feature highly correlated to the target have a higher</span>
    <span class="s5"># importance</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">n_repeats </span><span class="s2">= </span><span class="s4">5</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">load_diabetes</span><span class="s2">(</span><span class="s1">return_X_y</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s1">y_with_little_noise </span><span class="s2">= (</span><span class="s1">y </span><span class="s2">+ </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">scale</span><span class="s2">=</span><span class="s4">0.001</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">y</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])).</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>

    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">hstack</span><span class="s2">([</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_with_little_noise</span><span class="s2">])</span>

    <span class="s1">weights </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones_like</span><span class="s2">(</span><span class="s1">y</span><span class="s2">) </span><span class="s0">if </span><span class="s1">sample_weight </span><span class="s2">== </span><span class="s3">&quot;ones&quot; </span><span class="s0">else </span><span class="s1">sample_weight</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">RandomForestRegressor</span><span class="s2">(</span><span class="s1">n_estimators</span><span class="s2">=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">result </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
        <span class="s1">clf</span><span class="s2">,</span>
        <span class="s1">X</span><span class="s2">,</span>
        <span class="s1">y</span><span class="s2">,</span>
        <span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">weights</span><span class="s2">,</span>
        <span class="s1">n_repeats</span><span class="s2">=</span><span class="s1">n_repeats</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">rng</span><span class="s2">,</span>
        <span class="s1">n_jobs</span><span class="s2">=</span><span class="s1">n_jobs</span><span class="s2">,</span>
        <span class="s1">max_samples</span><span class="s2">=</span><span class="s1">max_samples</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">result</span><span class="s2">.</span><span class="s1">importances</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">], </span><span class="s1">n_repeats</span><span class="s2">)</span>

    <span class="s5"># the correlated feature with y was added as the last column and should</span>
    <span class="s5"># have the highest importance</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">result</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">] &gt; </span><span class="s1">result</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">])</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;n_jobs&quot;</span><span class="s2">, [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;max_samples&quot;</span><span class="s2">, [</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_permutation_importance_correlated_feature_regression_pandas</span><span class="s2">(</span>
    <span class="s1">n_jobs</span><span class="s2">, </span><span class="s1">max_samples</span>
<span class="s2">):</span>
    <span class="s1">pd </span><span class="s2">= </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">importorskip</span><span class="s2">(</span><span class="s3">&quot;pandas&quot;</span><span class="s2">)</span>

    <span class="s5"># Make sure that feature highly correlated to the target have a higher</span>
    <span class="s5"># importance</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">n_repeats </span><span class="s2">= </span><span class="s4">5</span>

    <span class="s1">dataset </span><span class="s2">= </span><span class="s1">load_iris</span><span class="s2">()</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">dataset</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">dataset</span><span class="s2">.</span><span class="s1">target</span>
    <span class="s1">y_with_little_noise </span><span class="s2">= (</span><span class="s1">y </span><span class="s2">+ </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">scale</span><span class="s2">=</span><span class="s4">0.001</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">y</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">0</span><span class="s2">])).</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>

    <span class="s5"># Adds feature correlated with y as the last column</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">pd</span><span class="s2">.</span><span class="s1">DataFrame</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">columns</span><span class="s2">=</span><span class="s1">dataset</span><span class="s2">.</span><span class="s1">feature_names</span><span class="s2">)</span>
    <span class="s1">X</span><span class="s2">[</span><span class="s3">&quot;correlated_feature&quot;</span><span class="s2">] = </span><span class="s1">y_with_little_noise</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">RandomForestClassifier</span><span class="s2">(</span><span class="s1">n_estimators</span><span class="s2">=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">result </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
        <span class="s1">clf</span><span class="s2">,</span>
        <span class="s1">X</span><span class="s2">,</span>
        <span class="s1">y</span><span class="s2">,</span>
        <span class="s1">n_repeats</span><span class="s2">=</span><span class="s1">n_repeats</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">rng</span><span class="s2">,</span>
        <span class="s1">n_jobs</span><span class="s2">=</span><span class="s1">n_jobs</span><span class="s2">,</span>
        <span class="s1">max_samples</span><span class="s2">=</span><span class="s1">max_samples</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">result</span><span class="s2">.</span><span class="s1">importances</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">], </span><span class="s1">n_repeats</span><span class="s2">)</span>

    <span class="s5"># the correlated feature with y was added as the last column and should</span>
    <span class="s5"># have the highest importance</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">result</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">] &gt; </span><span class="s1">result</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">])</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;n_jobs&quot;</span><span class="s2">, [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;max_samples&quot;</span><span class="s2">, [</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_robustness_to_high_cardinality_noisy_feature</span><span class="s2">(</span><span class="s1">n_jobs</span><span class="s2">, </span><span class="s1">max_samples</span><span class="s2">, </span><span class="s1">seed</span><span class="s2">=</span><span class="s4">42</span><span class="s2">):</span>
    <span class="s5"># Permutation variable importance should not be affected by the high</span>
    <span class="s5"># cardinality bias of traditional feature importances, especially when</span>
    <span class="s5"># computed on a held-out test set:</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">seed</span><span class="s2">)</span>
    <span class="s1">n_repeats </span><span class="s2">= </span><span class="s4">5</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">1000</span>
    <span class="s1">n_classes </span><span class="s2">= </span><span class="s4">5</span>
    <span class="s1">n_informative_features </span><span class="s2">= </span><span class="s4">2</span>
    <span class="s1">n_noise_features </span><span class="s2">= </span><span class="s4">1</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s1">n_informative_features </span><span class="s2">+ </span><span class="s1">n_noise_features</span>

    <span class="s5"># Generate a multiclass classification dataset and a set of informative</span>
    <span class="s5"># binary features that can be used to predict some classes of y exactly</span>
    <span class="s5"># while leaving some classes unexplained to make the problem harder.</span>
    <span class="s1">classes </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">n_classes</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">choice</span><span class="s2">(</span><span class="s1">classes</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">hstack</span><span class="s2">([(</span><span class="s1">y </span><span class="s2">== </span><span class="s1">c</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">) </span><span class="s0">for </span><span class="s1">c </span><span class="s0">in </span><span class="s1">classes</span><span class="s2">[:</span><span class="s1">n_informative_features</span><span class="s2">]])</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">)</span>

    <span class="s5"># Not all target classes are explained by the binary class indicator</span>
    <span class="s5"># features:</span>
    <span class="s0">assert </span><span class="s1">n_informative_features </span><span class="s2">&lt; </span><span class="s1">n_classes</span>

    <span class="s5"># Add 10 other noisy features with high cardinality (numerical) values</span>
    <span class="s5"># that can be used to overfit the training data.</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">([</span><span class="s1">X</span><span class="s2">, </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_noise_features</span><span class="s2">)], </span><span class="s1">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>

    <span class="s5"># Split the dataset to be able to evaluate on a held-out test set. The</span>
    <span class="s5"># Test size should be large enough for importance measurements to be</span>
    <span class="s5"># stable:</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span>
        <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">test_size</span><span class="s2">=</span><span class="s4">0.5</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">rng</span>
    <span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">RandomForestClassifier</span><span class="s2">(</span><span class="s1">n_estimators</span><span class="s2">=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">rng</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>

    <span class="s5"># Variable importances computed by impurity decrease on the tree node</span>
    <span class="s5"># splits often use the noisy features in splits. This can give misleading</span>
    <span class="s5"># impression that high cardinality noisy variables are the most important:</span>
    <span class="s1">tree_importances </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">feature_importances_</span>
    <span class="s1">informative_tree_importances </span><span class="s2">= </span><span class="s1">tree_importances</span><span class="s2">[:</span><span class="s1">n_informative_features</span><span class="s2">]</span>
    <span class="s1">noisy_tree_importances </span><span class="s2">= </span><span class="s1">tree_importances</span><span class="s2">[</span><span class="s1">n_informative_features</span><span class="s2">:]</span>
    <span class="s0">assert </span><span class="s1">informative_tree_importances</span><span class="s2">.</span><span class="s1">max</span><span class="s2">() &lt; </span><span class="s1">noisy_tree_importances</span><span class="s2">.</span><span class="s1">min</span><span class="s2">()</span>

    <span class="s5"># Let's check that permutation-based feature importances do not have this</span>
    <span class="s5"># problem.</span>
    <span class="s1">r </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
        <span class="s1">clf</span><span class="s2">,</span>
        <span class="s1">X_test</span><span class="s2">,</span>
        <span class="s1">y_test</span><span class="s2">,</span>
        <span class="s1">n_repeats</span><span class="s2">=</span><span class="s1">n_repeats</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">rng</span><span class="s2">,</span>
        <span class="s1">n_jobs</span><span class="s2">=</span><span class="s1">n_jobs</span><span class="s2">,</span>
        <span class="s1">max_samples</span><span class="s2">=</span><span class="s1">max_samples</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">r</span><span class="s2">.</span><span class="s1">importances</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">], </span><span class="s1">n_repeats</span><span class="s2">)</span>

    <span class="s5"># Split the importances between informative and noisy features</span>
    <span class="s1">informative_importances </span><span class="s2">= </span><span class="s1">r</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[:</span><span class="s1">n_informative_features</span><span class="s2">]</span>
    <span class="s1">noisy_importances </span><span class="s2">= </span><span class="s1">r</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[</span><span class="s1">n_informative_features</span><span class="s2">:]</span>

    <span class="s5"># Because we do not have a binary variable explaining each target classes,</span>
    <span class="s5"># the RF model will have to use the random variable to make some</span>
    <span class="s5"># (overfitting) splits (as max_depth is not set). Therefore the noisy</span>
    <span class="s5"># variables will be non-zero but with small values oscillating around</span>
    <span class="s5"># zero:</span>
    <span class="s0">assert </span><span class="s1">max</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">abs</span><span class="s2">(</span><span class="s1">noisy_importances</span><span class="s2">)) &gt; </span><span class="s4">1e-7</span>
    <span class="s0">assert </span><span class="s1">noisy_importances</span><span class="s2">.</span><span class="s1">max</span><span class="s2">() &lt; </span><span class="s4">0.05</span>

    <span class="s5"># The binary features correlated with y should have a higher importance</span>
    <span class="s5"># than the high cardinality noisy features.</span>
    <span class="s5"># The maximum test accuracy is 2 / 5 == 0.4, each informative feature</span>
    <span class="s5"># contributing approximately a bit more than 0.2 of accuracy.</span>
    <span class="s0">assert </span><span class="s1">informative_importances</span><span class="s2">.</span><span class="s1">min</span><span class="s2">() &gt; </span><span class="s4">0.15</span>


<span class="s0">def </span><span class="s1">test_permutation_importance_mixed_types</span><span class="s2">():</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">n_repeats </span><span class="s2">= </span><span class="s4">4</span>

    <span class="s5"># Last column is correlated with y</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">3.0</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">nan</span><span class="s2">], [</span><span class="s4">2</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]]).</span><span class="s1">T</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">])</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">make_pipeline</span><span class="s2">(</span><span class="s1">SimpleImputer</span><span class="s2">(), </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">))</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">result </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">=</span><span class="s1">n_repeats</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">rng</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">result</span><span class="s2">.</span><span class="s1">importances</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">], </span><span class="s1">n_repeats</span><span class="s2">)</span>

    <span class="s5"># the correlated feature with y is the last column and should</span>
    <span class="s5"># have the highest importance</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">result</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">] &gt; </span><span class="s1">result</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">])</span>

    <span class="s5"># use another random state</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">result2 </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">=</span><span class="s1">n_repeats</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">rng</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">result2</span><span class="s2">.</span><span class="s1">importances</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">], </span><span class="s1">n_repeats</span><span class="s2">)</span>

    <span class="s0">assert not </span><span class="s1">np</span><span class="s2">.</span><span class="s1">allclose</span><span class="s2">(</span><span class="s1">result</span><span class="s2">.</span><span class="s1">importances</span><span class="s2">, </span><span class="s1">result2</span><span class="s2">.</span><span class="s1">importances</span><span class="s2">)</span>

    <span class="s5"># the correlated feature with y is the last column and should</span>
    <span class="s5"># have the highest importance</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">result2</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">] &gt; </span><span class="s1">result2</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">])</span>


<span class="s0">def </span><span class="s1">test_permutation_importance_mixed_types_pandas</span><span class="s2">():</span>
    <span class="s1">pd </span><span class="s2">= </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">importorskip</span><span class="s2">(</span><span class="s3">&quot;pandas&quot;</span><span class="s2">)</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">42</span><span class="s2">)</span>
    <span class="s1">n_repeats </span><span class="s2">= </span><span class="s4">5</span>

    <span class="s5"># Last column is correlated with y</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">pd</span><span class="s2">.</span><span class="s1">DataFrame</span><span class="s2">({</span><span class="s3">&quot;col1&quot;</span><span class="s2">: [</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">3.0</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">nan</span><span class="s2">], </span><span class="s3">&quot;col2&quot;</span><span class="s2">: [</span><span class="s3">&quot;a&quot;</span><span class="s2">, </span><span class="s3">&quot;b&quot;</span><span class="s2">, </span><span class="s3">&quot;a&quot;</span><span class="s2">, </span><span class="s3">&quot;b&quot;</span><span class="s2">]})</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">])</span>

    <span class="s1">num_preprocess </span><span class="s2">= </span><span class="s1">make_pipeline</span><span class="s2">(</span><span class="s1">SimpleImputer</span><span class="s2">(), </span><span class="s1">StandardScaler</span><span class="s2">())</span>
    <span class="s1">preprocess </span><span class="s2">= </span><span class="s1">ColumnTransformer</span><span class="s2">(</span>
        <span class="s2">[(</span><span class="s3">&quot;num&quot;</span><span class="s2">, </span><span class="s1">num_preprocess</span><span class="s2">, [</span><span class="s3">&quot;col1&quot;</span><span class="s2">]), (</span><span class="s3">&quot;cat&quot;</span><span class="s2">, </span><span class="s1">OneHotEncoder</span><span class="s2">(), [</span><span class="s3">&quot;col2&quot;</span><span class="s2">])]</span>
    <span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">make_pipeline</span><span class="s2">(</span><span class="s1">preprocess</span><span class="s2">, </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">))</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">result </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">=</span><span class="s1">n_repeats</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">rng</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">result</span><span class="s2">.</span><span class="s1">importances</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">], </span><span class="s1">n_repeats</span><span class="s2">)</span>
    <span class="s5"># the correlated feature with y is the last column and should</span>
    <span class="s5"># have the highest importance</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">result</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[-</span><span class="s4">1</span><span class="s2">] &gt; </span><span class="s1">result</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[:-</span><span class="s4">1</span><span class="s2">])</span>


<span class="s0">def </span><span class="s1">test_permutation_importance_linear_regresssion</span><span class="s2">():</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_regression</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">500</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>

    <span class="s1">X </span><span class="s2">= </span><span class="s1">scale</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">scale</span><span class="s2">(</span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LinearRegression</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s5"># this relationship can be computed in closed form</span>
    <span class="s1">expected_importances </span><span class="s2">= </span><span class="s4">2 </span><span class="s2">* </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">**</span><span class="s4">2</span>
    <span class="s1">results </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
        <span class="s1">lr</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">=</span><span class="s4">50</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s3">&quot;neg_mean_squared_error&quot;</span>
    <span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span>
        <span class="s1">expected_importances</span><span class="s2">, </span><span class="s1">results</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s4">1e-1</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s4">1e-6</span>
    <span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;max_samples&quot;</span><span class="s2">, [</span><span class="s4">500</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_permutation_importance_equivalence_sequential_parallel</span><span class="s2">(</span><span class="s1">max_samples</span><span class="s2">):</span>
    <span class="s5"># regression test to make sure that sequential and parallel calls will</span>
    <span class="s5"># output the same results.</span>
    <span class="s5"># Also tests that max_samples equal to number of samples is equivalent to 1.0</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_regression</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">500</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LinearRegression</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">importance_sequential </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
        <span class="s1">lr</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">n_jobs</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">max_samples</span><span class="s2">=</span><span class="s1">max_samples</span>
    <span class="s2">)</span>

    <span class="s5"># First check that the problem is structured enough and that the model is</span>
    <span class="s5"># complex enough to not yield trivial, constant importances:</span>
    <span class="s1">imp_min </span><span class="s2">= </span><span class="s1">importance_sequential</span><span class="s2">[</span><span class="s3">&quot;importances&quot;</span><span class="s2">].</span><span class="s1">min</span><span class="s2">()</span>
    <span class="s1">imp_max </span><span class="s2">= </span><span class="s1">importance_sequential</span><span class="s2">[</span><span class="s3">&quot;importances&quot;</span><span class="s2">].</span><span class="s1">max</span><span class="s2">()</span>
    <span class="s0">assert </span><span class="s1">imp_max </span><span class="s2">- </span><span class="s1">imp_min </span><span class="s2">&gt; </span><span class="s4">0.3</span>

    <span class="s5"># The actually check that parallelism does not impact the results</span>
    <span class="s5"># either with shared memory (threading) or without isolated memory</span>
    <span class="s5"># via process-based parallelism using the default backend</span>
    <span class="s5"># ('loky' or 'multiprocessing') depending on the joblib version:</span>

    <span class="s5"># process-based parallelism (by default):</span>
    <span class="s1">importance_processes </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
        <span class="s1">lr</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">n_jobs</span><span class="s2">=</span><span class="s4">2</span>
    <span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span>
        <span class="s1">importance_processes</span><span class="s2">[</span><span class="s3">&quot;importances&quot;</span><span class="s2">], </span><span class="s1">importance_sequential</span><span class="s2">[</span><span class="s3">&quot;importances&quot;</span><span class="s2">]</span>
    <span class="s2">)</span>

    <span class="s5"># thread-based parallelism:</span>
    <span class="s0">with </span><span class="s1">parallel_backend</span><span class="s2">(</span><span class="s3">&quot;threading&quot;</span><span class="s2">):</span>
        <span class="s1">importance_threading </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
            <span class="s1">lr</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">, </span><span class="s1">n_jobs</span><span class="s2">=</span><span class="s4">2</span>
        <span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span>
        <span class="s1">importance_threading</span><span class="s2">[</span><span class="s3">&quot;importances&quot;</span><span class="s2">], </span><span class="s1">importance_sequential</span><span class="s2">[</span><span class="s3">&quot;importances&quot;</span><span class="s2">]</span>
    <span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;n_jobs&quot;</span><span class="s2">, [</span><span class="s0">None</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;max_samples&quot;</span><span class="s2">, [</span><span class="s4">0.5</span><span class="s2">, </span><span class="s4">1.0</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_permutation_importance_equivalence_array_dataframe</span><span class="s2">(</span><span class="s1">n_jobs</span><span class="s2">, </span><span class="s1">max_samples</span><span class="s2">):</span>
    <span class="s5"># This test checks that the column shuffling logic has the same behavior</span>
    <span class="s5"># both a dataframe and a simple numpy array.</span>
    <span class="s1">pd </span><span class="s2">= </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">importorskip</span><span class="s2">(</span><span class="s3">&quot;pandas&quot;</span><span class="s2">)</span>

    <span class="s5"># regression test to make sure that sequential and parallel calls will</span>
    <span class="s5"># output the same results.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_regression</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">100</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">X_df </span><span class="s2">= </span><span class="s1">pd</span><span class="s2">.</span><span class="s1">DataFrame</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s5"># Add a categorical feature that is statistically linked to y:</span>
    <span class="s1">binner </span><span class="s2">= </span><span class="s1">KBinsDiscretizer</span><span class="s2">(</span><span class="s1">n_bins</span><span class="s2">=</span><span class="s4">3</span><span class="s2">, </span><span class="s1">encode</span><span class="s2">=</span><span class="s3">&quot;ordinal&quot;</span><span class="s2">)</span>
    <span class="s1">cat_column </span><span class="s2">= </span><span class="s1">binner</span><span class="s2">.</span><span class="s1">fit_transform</span><span class="s2">(</span><span class="s1">y</span><span class="s2">.</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">))</span>

    <span class="s5"># Concatenate the extra column to the numpy array: integers will be</span>
    <span class="s5"># cast to float values</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">hstack</span><span class="s2">([</span><span class="s1">X</span><span class="s2">, </span><span class="s1">cat_column</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">X</span><span class="s2">.</span><span class="s1">dtype</span><span class="s2">.</span><span class="s1">kind </span><span class="s2">== </span><span class="s3">&quot;f&quot;</span>

    <span class="s5"># Insert extra column as a non-numpy-native dtype (while keeping backward</span>
    <span class="s5"># compat for old pandas versions):</span>
    <span class="s0">if </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">pd</span><span class="s2">, </span><span class="s3">&quot;Categorical&quot;</span><span class="s2">):</span>
        <span class="s1">cat_column </span><span class="s2">= </span><span class="s1">pd</span><span class="s2">.</span><span class="s1">Categorical</span><span class="s2">(</span><span class="s1">cat_column</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">())</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">cat_column </span><span class="s2">= </span><span class="s1">cat_column</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">()</span>
    <span class="s1">new_col_idx </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">X_df</span><span class="s2">.</span><span class="s1">columns</span><span class="s2">)</span>
    <span class="s1">X_df</span><span class="s2">[</span><span class="s1">new_col_idx</span><span class="s2">] = </span><span class="s1">cat_column</span>
    <span class="s0">assert </span><span class="s1">X_df</span><span class="s2">[</span><span class="s1">new_col_idx</span><span class="s2">].</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">cat_column</span><span class="s2">.</span><span class="s1">dtype</span>

    <span class="s5"># Stich an arbitrary index to the dataframe:</span>
    <span class="s1">X_df</span><span class="s2">.</span><span class="s1">index </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">len</span><span class="s2">(</span><span class="s1">X_df</span><span class="s2">)).</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">str</span><span class="s2">)</span>

    <span class="s1">rf </span><span class="s2">= </span><span class="s1">RandomForestRegressor</span><span class="s2">(</span><span class="s1">n_estimators</span><span class="s2">=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">max_depth</span><span class="s2">=</span><span class="s4">3</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">rf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">n_repeats </span><span class="s2">= </span><span class="s4">3</span>
    <span class="s1">importance_array </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
        <span class="s1">rf</span><span class="s2">,</span>
        <span class="s1">X</span><span class="s2">,</span>
        <span class="s1">y</span><span class="s2">,</span>
        <span class="s1">n_repeats</span><span class="s2">=</span><span class="s1">n_repeats</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">,</span>
        <span class="s1">n_jobs</span><span class="s2">=</span><span class="s1">n_jobs</span><span class="s2">,</span>
        <span class="s1">max_samples</span><span class="s2">=</span><span class="s1">max_samples</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s5"># First check that the problem is structured enough and that the model is</span>
    <span class="s5"># complex enough to not yield trivial, constant importances:</span>
    <span class="s1">imp_min </span><span class="s2">= </span><span class="s1">importance_array</span><span class="s2">[</span><span class="s3">&quot;importances&quot;</span><span class="s2">].</span><span class="s1">min</span><span class="s2">()</span>
    <span class="s1">imp_max </span><span class="s2">= </span><span class="s1">importance_array</span><span class="s2">[</span><span class="s3">&quot;importances&quot;</span><span class="s2">].</span><span class="s1">max</span><span class="s2">()</span>
    <span class="s0">assert </span><span class="s1">imp_max </span><span class="s2">- </span><span class="s1">imp_min </span><span class="s2">&gt; </span><span class="s4">0.3</span>

    <span class="s5"># Now check that importances computed on dataframe matche the values</span>
    <span class="s5"># of those computed on the array with the same data.</span>
    <span class="s1">importance_dataframe </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
        <span class="s1">rf</span><span class="s2">,</span>
        <span class="s1">X_df</span><span class="s2">,</span>
        <span class="s1">y</span><span class="s2">,</span>
        <span class="s1">n_repeats</span><span class="s2">=</span><span class="s1">n_repeats</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">,</span>
        <span class="s1">n_jobs</span><span class="s2">=</span><span class="s1">n_jobs</span><span class="s2">,</span>
        <span class="s1">max_samples</span><span class="s2">=</span><span class="s1">max_samples</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span>
        <span class="s1">importance_array</span><span class="s2">[</span><span class="s3">&quot;importances&quot;</span><span class="s2">], </span><span class="s1">importance_dataframe</span><span class="s2">[</span><span class="s3">&quot;importances&quot;</span><span class="s2">]</span>
    <span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;input_type&quot;</span><span class="s2">, [</span><span class="s3">&quot;array&quot;</span><span class="s2">, </span><span class="s3">&quot;dataframe&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_permutation_importance_large_memmaped_data</span><span class="s2">(</span><span class="s1">input_type</span><span class="s2">):</span>
    <span class="s5"># Smoke, non-regression test for:</span>
    <span class="s5"># https://github.com/scikit-learn/scikit-learn/issues/15810</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s1">int</span><span class="s2">(</span><span class="s4">5e4</span><span class="s2">), </span><span class="s4">4</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span>
    <span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">X</span><span class="s2">.</span><span class="s1">nbytes </span><span class="s2">&gt; </span><span class="s4">1e6  </span><span class="s5"># trigger joblib memmaping</span>

    <span class="s1">X </span><span class="s2">= </span><span class="s1">_convert_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">input_type</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">DummyClassifier</span><span class="s2">(</span><span class="s1">strategy</span><span class="s2">=</span><span class="s3">&quot;prior&quot;</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s5"># Actual smoke test: should not raise any error:</span>
    <span class="s1">n_repeats </span><span class="s2">= </span><span class="s4">5</span>
    <span class="s1">r </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">=</span><span class="s1">n_repeats</span><span class="s2">, </span><span class="s1">n_jobs</span><span class="s2">=</span><span class="s4">2</span><span class="s2">)</span>

    <span class="s5"># Auxiliary check: DummyClassifier is feature independent:</span>
    <span class="s5"># permutating feature should not change the predictions</span>
    <span class="s1">expected_importances </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">))</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">expected_importances</span><span class="s2">, </span><span class="s1">r</span><span class="s2">.</span><span class="s1">importances</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_permutation_importance_sample_weight</span><span class="s2">():</span>
    <span class="s5"># Creating data with 2 features and 1000 samples, where the target</span>
    <span class="s5"># variable is a linear combination of the two features, such that</span>
    <span class="s5"># in half of the samples the impact of feature 1 is twice the impact of</span>
    <span class="s5"># feature 2, and vice versa on the other half of the samples.</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">1000</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s4">2</span>
    <span class="s1">n_half_samples </span><span class="s2">= </span><span class="s1">n_samples </span><span class="s2">// </span><span class="s4">2</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s4">0.0</span><span class="s2">, </span><span class="s4">0.001</span><span class="s2">, (</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">))</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">y</span><span class="s2">[:</span><span class="s1">n_half_samples</span><span class="s2">] = </span><span class="s4">2 </span><span class="s2">* </span><span class="s1">x</span><span class="s2">[:</span><span class="s1">n_half_samples</span><span class="s2">, </span><span class="s4">0</span><span class="s2">] + </span><span class="s1">x</span><span class="s2">[:</span><span class="s1">n_half_samples</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]</span>
    <span class="s1">y</span><span class="s2">[</span><span class="s1">n_half_samples</span><span class="s2">:] = </span><span class="s1">x</span><span class="s2">[</span><span class="s1">n_half_samples</span><span class="s2">:, </span><span class="s4">0</span><span class="s2">] + </span><span class="s4">2 </span><span class="s2">* </span><span class="s1">x</span><span class="s2">[</span><span class="s1">n_half_samples</span><span class="s2">:, </span><span class="s4">1</span><span class="s2">]</span>

    <span class="s5"># Fitting linear regression with perfect prediction</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LinearRegression</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s5"># When all samples are weighted with the same weights, the ratio of</span>
    <span class="s5"># the two features importance should equal to 1 on expectation (when using</span>
    <span class="s5"># mean absolutes error as the loss function).</span>
    <span class="s1">pi </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
        <span class="s1">lr</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s3">&quot;neg_mean_absolute_error&quot;</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">=</span><span class="s4">200</span>
    <span class="s2">)</span>
    <span class="s1">x1_x2_imp_ratio_w_none </span><span class="s2">= </span><span class="s1">pi</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] / </span><span class="s1">pi</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s0">assert </span><span class="s1">x1_x2_imp_ratio_w_none </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s4">1</span><span class="s2">, </span><span class="s4">0.01</span><span class="s2">)</span>

    <span class="s5"># When passing a vector of ones as the sample_weight, results should be</span>
    <span class="s5"># the same as in the case that sample_weight=None.</span>
    <span class="s1">w </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">pi </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
        <span class="s1">lr</span><span class="s2">,</span>
        <span class="s1">x</span><span class="s2">,</span>
        <span class="s1">y</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
        <span class="s1">scoring</span><span class="s2">=</span><span class="s3">&quot;neg_mean_absolute_error&quot;</span><span class="s2">,</span>
        <span class="s1">n_repeats</span><span class="s2">=</span><span class="s4">200</span><span class="s2">,</span>
        <span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">w</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">x1_x2_imp_ratio_w_ones </span><span class="s2">= </span><span class="s1">pi</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] / </span><span class="s1">pi</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s0">assert </span><span class="s1">x1_x2_imp_ratio_w_ones </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">x1_x2_imp_ratio_w_none</span><span class="s2">, </span><span class="s4">0.01</span><span class="s2">)</span>

    <span class="s5"># When the ratio between the weights of the first half of the samples and</span>
    <span class="s5"># the second half of the samples approaches to infinity, the ratio of</span>
    <span class="s5"># the two features importance should equal to 2 on expectation (when using</span>
    <span class="s5"># mean absolutes error as the loss function).</span>
    <span class="s1">w </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">hstack</span><span class="s2">([</span><span class="s1">np</span><span class="s2">.</span><span class="s1">repeat</span><span class="s2">(</span><span class="s4">10.0</span><span class="s2">**</span><span class="s4">10</span><span class="s2">, </span><span class="s1">n_half_samples</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">repeat</span><span class="s2">(</span><span class="s4">1.0</span><span class="s2">, </span><span class="s1">n_half_samples</span><span class="s2">)])</span>
    <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">w</span><span class="s2">)</span>
    <span class="s1">pi </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
        <span class="s1">lr</span><span class="s2">,</span>
        <span class="s1">x</span><span class="s2">,</span>
        <span class="s1">y</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
        <span class="s1">scoring</span><span class="s2">=</span><span class="s3">&quot;neg_mean_absolute_error&quot;</span><span class="s2">,</span>
        <span class="s1">n_repeats</span><span class="s2">=</span><span class="s4">200</span><span class="s2">,</span>
        <span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">w</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">x1_x2_imp_ratio_w </span><span class="s2">= </span><span class="s1">pi</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] / </span><span class="s1">pi</span><span class="s2">.</span><span class="s1">importances_mean</span><span class="s2">[</span><span class="s4">1</span><span class="s2">]</span>
    <span class="s0">assert </span><span class="s1">x1_x2_imp_ratio_w </span><span class="s2">/ </span><span class="s1">x1_x2_imp_ratio_w_none </span><span class="s2">== </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s4">2</span><span class="s2">, </span><span class="s4">0.01</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_permutation_importance_no_weights_scoring_function</span><span class="s2">():</span>
    <span class="s5"># Creating a scorer function that does not takes sample_weight</span>
    <span class="s0">def </span><span class="s1">my_scorer</span><span class="s2">(</span><span class="s1">estimator</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s4">1</span>

    <span class="s5"># Creating some data and estimator for the permutation test</span>
    <span class="s1">x </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">], [</span><span class="s4">3</span><span class="s2">, </span><span class="s4">4</span><span class="s2">]])</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">])</span>
    <span class="s1">w </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">])</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LinearRegression</span><span class="s2">()</span>
    <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s5"># test that permutation_importance does not return error when</span>
    <span class="s5"># sample_weight is None</span>
    <span class="s0">try</span><span class="s2">:</span>
        <span class="s1">permutation_importance</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">my_scorer</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
    <span class="s0">except </span><span class="s1">TypeError</span><span class="s2">:</span>
        <span class="s1">pytest</span><span class="s2">.</span><span class="s1">fail</span><span class="s2">(</span>
            <span class="s3">&quot;permutation_test raised an error when using a scorer &quot;</span>
            <span class="s3">&quot;function that does not accept sample_weight even though &quot;</span>
            <span class="s3">&quot;sample_weight was None&quot;</span>
        <span class="s2">)</span>

    <span class="s5"># test that permutation_importance raise exception when sample_weight is</span>
    <span class="s5"># not None</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">TypeError</span><span class="s2">):</span>
        <span class="s1">permutation_importance</span><span class="s2">(</span>
            <span class="s1">lr</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">my_scorer</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">w</span>
        <span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;list_single_scorer, multi_scorer&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">([</span><span class="s3">&quot;r2&quot;</span><span class="s2">, </span><span class="s3">&quot;neg_mean_squared_error&quot;</span><span class="s2">], [</span><span class="s3">&quot;r2&quot;</span><span class="s2">, </span><span class="s3">&quot;neg_mean_squared_error&quot;</span><span class="s2">]),</span>
        <span class="s2">(</span>
            <span class="s2">[</span><span class="s3">&quot;r2&quot;</span><span class="s2">, </span><span class="s3">&quot;neg_mean_squared_error&quot;</span><span class="s2">],</span>
            <span class="s2">{</span>
                <span class="s3">&quot;r2&quot;</span><span class="s2">: </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;r2&quot;</span><span class="s2">),</span>
                <span class="s3">&quot;neg_mean_squared_error&quot;</span><span class="s2">: </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;neg_mean_squared_error&quot;</span><span class="s2">),</span>
            <span class="s2">},</span>
        <span class="s2">),</span>
        <span class="s2">(</span>
            <span class="s2">[</span><span class="s3">&quot;r2&quot;</span><span class="s2">, </span><span class="s3">&quot;neg_mean_squared_error&quot;</span><span class="s2">],</span>
            <span class="s0">lambda </span><span class="s1">estimator</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">: {</span>
                <span class="s3">&quot;r2&quot;</span><span class="s2">: </span><span class="s1">r2_score</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">estimator</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)),</span>
                <span class="s3">&quot;neg_mean_squared_error&quot;</span><span class="s2">: -</span><span class="s1">mean_squared_error</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">estimator</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)),</span>
            <span class="s2">},</span>
        <span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_permutation_importance_multi_metric</span><span class="s2">(</span><span class="s1">list_single_scorer</span><span class="s2">, </span><span class="s1">multi_scorer</span><span class="s2">):</span>
    <span class="s5"># Test permutation importance when scoring contains multiple scorers</span>

    <span class="s5"># Creating some data and estimator for the permutation test</span>
    <span class="s1">x</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_regression</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s4">500</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s4">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LinearRegression</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">multi_importance </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
        <span class="s1">lr</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">multi_scorer</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">=</span><span class="s4">2</span>
    <span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">set</span><span class="s2">(</span><span class="s1">multi_importance</span><span class="s2">.</span><span class="s1">keys</span><span class="s2">()) == </span><span class="s1">set</span><span class="s2">(</span><span class="s1">list_single_scorer</span><span class="s2">)</span>

    <span class="s0">for </span><span class="s1">scorer </span><span class="s0">in </span><span class="s1">list_single_scorer</span><span class="s2">:</span>
        <span class="s1">multi_result </span><span class="s2">= </span><span class="s1">multi_importance</span><span class="s2">[</span><span class="s1">scorer</span><span class="s2">]</span>
        <span class="s1">single_result </span><span class="s2">= </span><span class="s1">permutation_importance</span><span class="s2">(</span>
            <span class="s1">lr</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scorer</span><span class="s2">, </span><span class="s1">n_repeats</span><span class="s2">=</span><span class="s4">2</span>
        <span class="s2">)</span>

        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">multi_result</span><span class="s2">.</span><span class="s1">importances</span><span class="s2">, </span><span class="s1">single_result</span><span class="s2">.</span><span class="s1">importances</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_permutation_importance_max_samples_error</span><span class="s2">():</span>
    <span class="s6">&quot;&quot;&quot;Check that a proper error message is raised when `max_samples` is not 
    set to a valid input value. 
    &quot;&quot;&quot;</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([(</span><span class="s4">1.0</span><span class="s2">, </span><span class="s4">2.0</span><span class="s2">, </span><span class="s4">3.0</span><span class="s2">, </span><span class="s4">4.0</span><span class="s2">)]).</span><span class="s1">T</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">])</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">()</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">err_msg </span><span class="s2">= </span><span class="s3">r&quot;max_samples must be &lt;= n_samples&quot;</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">err_msg</span><span class="s2">):</span>
        <span class="s1">permutation_importance</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">max_samples</span><span class="s2">=</span><span class="s4">5</span><span class="s2">)</span>
</pre>
</body>
</html>