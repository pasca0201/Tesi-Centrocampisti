<html>
<head>
<title>test_linear_loss.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #cf8e6d;}
.s3 { color: #bcbec4;}
.s4 { color: #7a7e85;}
.s5 { color: #2aacb8;}
.s6 { color: #6aab73;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_linear_loss.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Tests for LinearModelLoss 
 
Note that correctness of losses (which compose LinearModelLoss) is already well 
covered in the _loss module. 
&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pytest</span>
<span class="s2">from </span><span class="s1">numpy</span><span class="s3">.</span><span class="s1">testing </span><span class="s2">import </span><span class="s1">assert_allclose</span>
<span class="s2">from </span><span class="s1">scipy </span><span class="s2">import </span><span class="s1">linalg</span><span class="s3">, </span><span class="s1">optimize</span>

<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">_loss</span><span class="s3">.</span><span class="s1">loss </span><span class="s2">import </span><span class="s3">(</span>
    <span class="s1">HalfBinomialLoss</span><span class="s3">,</span>
    <span class="s1">HalfMultinomialLoss</span><span class="s3">,</span>
    <span class="s1">HalfPoissonLoss</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">datasets </span><span class="s2">import </span><span class="s1">make_low_rank_matrix</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">linear_model</span><span class="s3">.</span><span class="s1">_linear_loss </span><span class="s2">import </span><span class="s1">LinearModelLoss</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">extmath </span><span class="s2">import </span><span class="s1">squared_norm</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">fixes </span><span class="s2">import </span><span class="s1">CSR_CONTAINERS</span>

<span class="s4"># We do not need to test all losses, just what LinearModelLoss does on top of the</span>
<span class="s4"># base losses.</span>
<span class="s1">LOSSES </span><span class="s3">= [</span><span class="s1">HalfBinomialLoss</span><span class="s3">, </span><span class="s1">HalfMultinomialLoss</span><span class="s3">, </span><span class="s1">HalfPoissonLoss</span><span class="s3">]</span>


<span class="s2">def </span><span class="s1">random_X_y_coef</span><span class="s3">(</span>
    <span class="s1">linear_model_loss</span><span class="s3">, </span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">, </span><span class="s1">coef_bound</span><span class="s3">=(-</span><span class="s5">2</span><span class="s3">, </span><span class="s5">2</span><span class="s3">), </span><span class="s1">seed</span><span class="s3">=</span><span class="s5">42</span>
<span class="s3">):</span>
    <span class="s0">&quot;&quot;&quot;Random generate y, X and coef in valid range.&quot;&quot;&quot;</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s1">seed</span><span class="s3">)</span>
    <span class="s1">n_dof </span><span class="s3">= </span><span class="s1">n_features </span><span class="s3">+ </span><span class="s1">linear_model_loss</span><span class="s3">.</span><span class="s1">fit_intercept</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">make_low_rank_matrix</span><span class="s3">(</span>
        <span class="s1">n_samples</span><span class="s3">=</span><span class="s1">n_samples</span><span class="s3">,</span>
        <span class="s1">n_features</span><span class="s3">=</span><span class="s1">n_features</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s1">rng</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">coef </span><span class="s3">= </span><span class="s1">linear_model_loss</span><span class="s3">.</span><span class="s1">init_zero_coef</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>

    <span class="s2">if </span><span class="s1">linear_model_loss</span><span class="s3">.</span><span class="s1">base_loss</span><span class="s3">.</span><span class="s1">is_multiclass</span><span class="s3">:</span>
        <span class="s1">n_classes </span><span class="s3">= </span><span class="s1">linear_model_loss</span><span class="s3">.</span><span class="s1">base_loss</span><span class="s3">.</span><span class="s1">n_classes</span>
        <span class="s1">coef</span><span class="s3">.</span><span class="s1">flat</span><span class="s3">[:] = </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">uniform</span><span class="s3">(</span>
            <span class="s1">low</span><span class="s3">=</span><span class="s1">coef_bound</span><span class="s3">[</span><span class="s5">0</span><span class="s3">],</span>
            <span class="s1">high</span><span class="s3">=</span><span class="s1">coef_bound</span><span class="s3">[</span><span class="s5">1</span><span class="s3">],</span>
            <span class="s1">size</span><span class="s3">=</span><span class="s1">n_classes </span><span class="s3">* </span><span class="s1">n_dof</span><span class="s3">,</span>
        <span class="s3">)</span>
        <span class="s2">if </span><span class="s1">linear_model_loss</span><span class="s3">.</span><span class="s1">fit_intercept</span><span class="s3">:</span>
            <span class="s1">raw_prediction </span><span class="s3">= </span><span class="s1">X </span><span class="s3">@ </span><span class="s1">coef</span><span class="s3">[:, :-</span><span class="s5">1</span><span class="s3">].</span><span class="s1">T </span><span class="s3">+ </span><span class="s1">coef</span><span class="s3">[:, -</span><span class="s5">1</span><span class="s3">]</span>
        <span class="s2">else</span><span class="s3">:</span>
            <span class="s1">raw_prediction </span><span class="s3">= </span><span class="s1">X </span><span class="s3">@ </span><span class="s1">coef</span><span class="s3">.</span><span class="s1">T</span>
        <span class="s1">proba </span><span class="s3">= </span><span class="s1">linear_model_loss</span><span class="s3">.</span><span class="s1">base_loss</span><span class="s3">.</span><span class="s1">link</span><span class="s3">.</span><span class="s1">inverse</span><span class="s3">(</span><span class="s1">raw_prediction</span><span class="s3">)</span>

        <span class="s4"># y = rng.choice(np.arange(n_classes), p=proba) does not work.</span>
        <span class="s4"># See https://stackoverflow.com/a/34190035/16761084</span>
        <span class="s2">def </span><span class="s1">choice_vectorized</span><span class="s3">(</span><span class="s1">items</span><span class="s3">, </span><span class="s1">p</span><span class="s3">):</span>
            <span class="s1">s </span><span class="s3">= </span><span class="s1">p</span><span class="s3">.</span><span class="s1">cumsum</span><span class="s3">(</span><span class="s1">axis</span><span class="s3">=</span><span class="s5">1</span><span class="s3">)</span>
            <span class="s1">r </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">rand</span><span class="s3">(</span><span class="s1">p</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">])[:, </span><span class="s2">None</span><span class="s3">]</span>
            <span class="s1">k </span><span class="s3">= (</span><span class="s1">s </span><span class="s3">&lt; </span><span class="s1">r</span><span class="s3">).</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">axis</span><span class="s3">=</span><span class="s5">1</span><span class="s3">)</span>
            <span class="s2">return </span><span class="s1">items</span><span class="s3">[</span><span class="s1">k</span><span class="s3">]</span>

        <span class="s1">y </span><span class="s3">= </span><span class="s1">choice_vectorized</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">arange</span><span class="s3">(</span><span class="s1">n_classes</span><span class="s3">), </span><span class="s1">p</span><span class="s3">=</span><span class="s1">proba</span><span class="s3">).</span><span class="s1">astype</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float64</span><span class="s3">)</span>
    <span class="s2">else</span><span class="s3">:</span>
        <span class="s1">coef</span><span class="s3">.</span><span class="s1">flat</span><span class="s3">[:] = </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">uniform</span><span class="s3">(</span>
            <span class="s1">low</span><span class="s3">=</span><span class="s1">coef_bound</span><span class="s3">[</span><span class="s5">0</span><span class="s3">],</span>
            <span class="s1">high</span><span class="s3">=</span><span class="s1">coef_bound</span><span class="s3">[</span><span class="s5">1</span><span class="s3">],</span>
            <span class="s1">size</span><span class="s3">=</span><span class="s1">n_dof</span><span class="s3">,</span>
        <span class="s3">)</span>
        <span class="s2">if </span><span class="s1">linear_model_loss</span><span class="s3">.</span><span class="s1">fit_intercept</span><span class="s3">:</span>
            <span class="s1">raw_prediction </span><span class="s3">= </span><span class="s1">X </span><span class="s3">@ </span><span class="s1">coef</span><span class="s3">[:-</span><span class="s5">1</span><span class="s3">] + </span><span class="s1">coef</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">]</span>
        <span class="s2">else</span><span class="s3">:</span>
            <span class="s1">raw_prediction </span><span class="s3">= </span><span class="s1">X </span><span class="s3">@ </span><span class="s1">coef</span>
        <span class="s1">y </span><span class="s3">= </span><span class="s1">linear_model_loss</span><span class="s3">.</span><span class="s1">base_loss</span><span class="s3">.</span><span class="s1">link</span><span class="s3">.</span><span class="s1">inverse</span><span class="s3">(</span>
            <span class="s1">raw_prediction </span><span class="s3">+ </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">uniform</span><span class="s3">(</span><span class="s1">low</span><span class="s3">=-</span><span class="s5">1</span><span class="s3">, </span><span class="s1">high</span><span class="s3">=</span><span class="s5">1</span><span class="s3">, </span><span class="s1">size</span><span class="s3">=</span><span class="s1">n_samples</span><span class="s3">)</span>
        <span class="s3">)</span>

    <span class="s2">return </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">coef</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;base_loss&quot;</span><span class="s3">, </span><span class="s1">LOSSES</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;fit_intercept&quot;</span><span class="s3">, [</span><span class="s2">False</span><span class="s3">, </span><span class="s2">True</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;n_features&quot;</span><span class="s3">, [</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">10</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;dtype&quot;</span><span class="s3">, [</span><span class="s2">None</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">float64</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">int64</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_init_zero_coef</span><span class="s3">(</span><span class="s1">base_loss</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">):</span>
    <span class="s0">&quot;&quot;&quot;Test that init_zero_coef initializes coef correctly.&quot;&quot;&quot;</span>
    <span class="s1">loss </span><span class="s3">= </span><span class="s1">LinearModelLoss</span><span class="s3">(</span><span class="s1">base_loss</span><span class="s3">=</span><span class="s1">base_loss</span><span class="s3">(), </span><span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">)</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s5">42</span><span class="s3">)</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=(</span><span class="s5">5</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">))</span>
    <span class="s1">coef </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">init_zero_coef</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">dtype</span><span class="s3">)</span>
    <span class="s2">if </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">base_loss</span><span class="s3">.</span><span class="s1">is_multiclass</span><span class="s3">:</span>
        <span class="s1">n_classes </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">base_loss</span><span class="s3">.</span><span class="s1">n_classes</span>
        <span class="s2">assert </span><span class="s1">coef</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== (</span><span class="s1">n_classes</span><span class="s3">, </span><span class="s1">n_features </span><span class="s3">+ </span><span class="s1">fit_intercept</span><span class="s3">)</span>
        <span class="s2">assert </span><span class="s1">coef</span><span class="s3">.</span><span class="s1">flags</span><span class="s3">[</span><span class="s6">&quot;F_CONTIGUOUS&quot;</span><span class="s3">]</span>
    <span class="s2">else</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">coef</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== (</span><span class="s1">n_features </span><span class="s3">+ </span><span class="s1">fit_intercept</span><span class="s3">,)</span>

    <span class="s2">if </span><span class="s1">dtype </span><span class="s2">is None</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">coef</span><span class="s3">.</span><span class="s1">dtype </span><span class="s3">== </span><span class="s1">X</span><span class="s3">.</span><span class="s1">dtype</span>
    <span class="s2">else</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">coef</span><span class="s3">.</span><span class="s1">dtype </span><span class="s3">== </span><span class="s1">dtype</span>

    <span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">count_nonzero</span><span class="s3">(</span><span class="s1">coef</span><span class="s3">) == </span><span class="s5">0</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;base_loss&quot;</span><span class="s3">, </span><span class="s1">LOSSES</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;fit_intercept&quot;</span><span class="s3">, [</span><span class="s2">False</span><span class="s3">, </span><span class="s2">True</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;sample_weight&quot;</span><span class="s3">, [</span><span class="s2">None</span><span class="s3">, </span><span class="s6">&quot;range&quot;</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;l2_reg_strength&quot;</span><span class="s3">, [</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;csr_container&quot;</span><span class="s3">, </span><span class="s1">CSR_CONTAINERS</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_loss_grad_hess_are_the_same</span><span class="s3">(</span>
    <span class="s1">base_loss</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">, </span><span class="s1">csr_container</span>
<span class="s3">):</span>
    <span class="s0">&quot;&quot;&quot;Test that loss and gradient are the same across different functions.&quot;&quot;&quot;</span>
    <span class="s1">loss </span><span class="s3">= </span><span class="s1">LinearModelLoss</span><span class="s3">(</span><span class="s1">base_loss</span><span class="s3">=</span><span class="s1">base_loss</span><span class="s3">(), </span><span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">)</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">coef </span><span class="s3">= </span><span class="s1">random_X_y_coef</span><span class="s3">(</span>
        <span class="s1">linear_model_loss</span><span class="s3">=</span><span class="s1">loss</span><span class="s3">, </span><span class="s1">n_samples</span><span class="s3">=</span><span class="s5">10</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s5">5</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">=</span><span class="s5">42</span>
    <span class="s3">)</span>

    <span class="s2">if </span><span class="s1">sample_weight </span><span class="s3">== </span><span class="s6">&quot;range&quot;</span><span class="s3">:</span>
        <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linspace</span><span class="s3">(</span><span class="s5">1</span><span class="s3">, </span><span class="s1">y</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">], </span><span class="s1">num</span><span class="s3">=</span><span class="s1">y</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">])</span>

    <span class="s1">l1 </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">loss</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
    <span class="s3">)</span>
    <span class="s1">g1 </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
    <span class="s3">)</span>
    <span class="s1">l2</span><span class="s3">, </span><span class="s1">g2 </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">loss_gradient</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
    <span class="s3">)</span>
    <span class="s1">g3</span><span class="s3">, </span><span class="s1">h3 </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient_hessian_product</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
    <span class="s3">)</span>
    <span class="s2">if not </span><span class="s1">base_loss</span><span class="s3">.</span><span class="s1">is_multiclass</span><span class="s3">:</span>
        <span class="s1">g4</span><span class="s3">, </span><span class="s1">h4</span><span class="s3">, </span><span class="s1">_ </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient_hessian</span><span class="s3">(</span>
            <span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
        <span class="s3">)</span>
    <span class="s2">else</span><span class="s3">:</span>
        <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">NotImplementedError</span><span class="s3">):</span>
            <span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient_hessian</span><span class="s3">(</span>
                <span class="s1">coef</span><span class="s3">,</span>
                <span class="s1">X</span><span class="s3">,</span>
                <span class="s1">y</span><span class="s3">,</span>
                <span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">,</span>
                <span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span><span class="s3">,</span>
            <span class="s3">)</span>

    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">l1</span><span class="s3">, </span><span class="s1">l2</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g1</span><span class="s3">, </span><span class="s1">g2</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g1</span><span class="s3">, </span><span class="s1">g3</span><span class="s3">)</span>
    <span class="s2">if not </span><span class="s1">base_loss</span><span class="s3">.</span><span class="s1">is_multiclass</span><span class="s3">:</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g1</span><span class="s3">, </span><span class="s1">g4</span><span class="s3">)</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">h4 </span><span class="s3">@ </span><span class="s1">g4</span><span class="s3">, </span><span class="s1">h3</span><span class="s3">(</span><span class="s1">g3</span><span class="s3">))</span>

    <span class="s4"># same for sparse X</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">l1_sp </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">loss</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
    <span class="s3">)</span>
    <span class="s1">g1_sp </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
    <span class="s3">)</span>
    <span class="s1">l2_sp</span><span class="s3">, </span><span class="s1">g2_sp </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">loss_gradient</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
    <span class="s3">)</span>
    <span class="s1">g3_sp</span><span class="s3">, </span><span class="s1">h3_sp </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient_hessian_product</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
    <span class="s3">)</span>
    <span class="s2">if not </span><span class="s1">base_loss</span><span class="s3">.</span><span class="s1">is_multiclass</span><span class="s3">:</span>
        <span class="s1">g4_sp</span><span class="s3">, </span><span class="s1">h4_sp</span><span class="s3">, </span><span class="s1">_ </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient_hessian</span><span class="s3">(</span>
            <span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
        <span class="s3">)</span>

    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">l1</span><span class="s3">, </span><span class="s1">l1_sp</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">l1</span><span class="s3">, </span><span class="s1">l2_sp</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g1</span><span class="s3">, </span><span class="s1">g1_sp</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g1</span><span class="s3">, </span><span class="s1">g2_sp</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g1</span><span class="s3">, </span><span class="s1">g3_sp</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">h3</span><span class="s3">(</span><span class="s1">g1</span><span class="s3">), </span><span class="s1">h3_sp</span><span class="s3">(</span><span class="s1">g1_sp</span><span class="s3">))</span>
    <span class="s2">if not </span><span class="s1">base_loss</span><span class="s3">.</span><span class="s1">is_multiclass</span><span class="s3">:</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g1</span><span class="s3">, </span><span class="s1">g4_sp</span><span class="s3">)</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">h4 </span><span class="s3">@ </span><span class="s1">g4</span><span class="s3">, </span><span class="s1">h4_sp </span><span class="s3">@ </span><span class="s1">g1_sp</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;base_loss&quot;</span><span class="s3">, </span><span class="s1">LOSSES</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;sample_weight&quot;</span><span class="s3">, [</span><span class="s2">None</span><span class="s3">, </span><span class="s6">&quot;range&quot;</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;l2_reg_strength&quot;</span><span class="s3">, [</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;X_container&quot;</span><span class="s3">, </span><span class="s1">CSR_CONTAINERS </span><span class="s3">+ [</span><span class="s2">None</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_loss_gradients_hessp_intercept</span><span class="s3">(</span>
    <span class="s1">base_loss</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">, </span><span class="s1">X_container</span>
<span class="s3">):</span>
    <span class="s0">&quot;&quot;&quot;Test that loss and gradient handle intercept correctly.&quot;&quot;&quot;</span>
    <span class="s1">loss </span><span class="s3">= </span><span class="s1">LinearModelLoss</span><span class="s3">(</span><span class="s1">base_loss</span><span class="s3">=</span><span class="s1">base_loss</span><span class="s3">(), </span><span class="s1">fit_intercept</span><span class="s3">=</span><span class="s2">False</span><span class="s3">)</span>
    <span class="s1">loss_inter </span><span class="s3">= </span><span class="s1">LinearModelLoss</span><span class="s3">(</span><span class="s1">base_loss</span><span class="s3">=</span><span class="s1">base_loss</span><span class="s3">(), </span><span class="s1">fit_intercept</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features </span><span class="s3">= </span><span class="s5">10</span><span class="s3">, </span><span class="s5">5</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">coef </span><span class="s3">= </span><span class="s1">random_X_y_coef</span><span class="s3">(</span>
        <span class="s1">linear_model_loss</span><span class="s3">=</span><span class="s1">loss</span><span class="s3">, </span><span class="s1">n_samples</span><span class="s3">=</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s1">n_features</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">=</span><span class="s5">42</span>
    <span class="s3">)</span>

    <span class="s1">X</span><span class="s3">[:, -</span><span class="s5">1</span><span class="s3">] = </span><span class="s5">1  </span><span class="s4"># make last column of 1 to mimic intercept term</span>
    <span class="s1">X_inter </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span>
        <span class="s3">:, :-</span><span class="s5">1</span>
    <span class="s3">]  </span><span class="s4"># exclude intercept column as it is added automatically by loss_inter</span>

    <span class="s2">if </span><span class="s1">X_container </span><span class="s2">is not None</span><span class="s3">:</span>
        <span class="s1">X </span><span class="s3">= </span><span class="s1">X_container</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>

    <span class="s2">if </span><span class="s1">sample_weight </span><span class="s3">== </span><span class="s6">&quot;range&quot;</span><span class="s3">:</span>
        <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linspace</span><span class="s3">(</span><span class="s5">1</span><span class="s3">, </span><span class="s1">y</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">], </span><span class="s1">num</span><span class="s3">=</span><span class="s1">y</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">])</span>

    <span class="s1">l</span><span class="s3">, </span><span class="s1">g </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">loss_gradient</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
    <span class="s3">)</span>
    <span class="s1">_</span><span class="s3">, </span><span class="s1">hessp </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient_hessian_product</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
    <span class="s3">)</span>
    <span class="s1">l_inter</span><span class="s3">, </span><span class="s1">g_inter </span><span class="s3">= </span><span class="s1">loss_inter</span><span class="s3">.</span><span class="s1">loss_gradient</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">, </span><span class="s1">X_inter</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
    <span class="s3">)</span>
    <span class="s1">_</span><span class="s3">, </span><span class="s1">hessp_inter </span><span class="s3">= </span><span class="s1">loss_inter</span><span class="s3">.</span><span class="s1">gradient_hessian_product</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">, </span><span class="s1">X_inter</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
    <span class="s3">)</span>

    <span class="s4"># Note, that intercept gets no L2 penalty.</span>
    <span class="s2">assert </span><span class="s1">l </span><span class="s3">== </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">approx</span><span class="s3">(</span>
        <span class="s1">l_inter </span><span class="s3">+ </span><span class="s5">0.5 </span><span class="s3">* </span><span class="s1">l2_reg_strength </span><span class="s3">* </span><span class="s1">squared_norm</span><span class="s3">(</span><span class="s1">coef</span><span class="s3">.</span><span class="s1">T</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">])</span>
    <span class="s3">)</span>

    <span class="s1">g_inter_corrected </span><span class="s3">= </span><span class="s1">g_inter</span>
    <span class="s1">g_inter_corrected</span><span class="s3">.</span><span class="s1">T</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">] += </span><span class="s1">l2_reg_strength </span><span class="s3">* </span><span class="s1">coef</span><span class="s3">.</span><span class="s1">T</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">]</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g</span><span class="s3">, </span><span class="s1">g_inter_corrected</span><span class="s3">)</span>

    <span class="s1">s </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s5">42</span><span class="s3">).</span><span class="s1">randn</span><span class="s3">(*</span><span class="s1">coef</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">)</span>
    <span class="s1">h </span><span class="s3">= </span><span class="s1">hessp</span><span class="s3">(</span><span class="s1">s</span><span class="s3">)</span>
    <span class="s1">h_inter </span><span class="s3">= </span><span class="s1">hessp_inter</span><span class="s3">(</span><span class="s1">s</span><span class="s3">)</span>
    <span class="s1">h_inter_corrected </span><span class="s3">= </span><span class="s1">h_inter</span>
    <span class="s1">h_inter_corrected</span><span class="s3">.</span><span class="s1">T</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">] += </span><span class="s1">l2_reg_strength </span><span class="s3">* </span><span class="s1">s</span><span class="s3">.</span><span class="s1">T</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">]</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">h</span><span class="s3">, </span><span class="s1">h_inter_corrected</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;base_loss&quot;</span><span class="s3">, </span><span class="s1">LOSSES</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;fit_intercept&quot;</span><span class="s3">, [</span><span class="s2">False</span><span class="s3">, </span><span class="s2">True</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;sample_weight&quot;</span><span class="s3">, [</span><span class="s2">None</span><span class="s3">, </span><span class="s6">&quot;range&quot;</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;l2_reg_strength&quot;</span><span class="s3">, [</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_gradients_hessians_numerically</span><span class="s3">(</span>
    <span class="s1">base_loss</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span>
<span class="s3">):</span>
    <span class="s0">&quot;&quot;&quot;Test gradients and hessians with numerical derivatives. 
 
    Gradient should equal the numerical derivatives of the loss function. 
    Hessians should equal the numerical derivatives of gradients. 
    &quot;&quot;&quot;</span>
    <span class="s1">loss </span><span class="s3">= </span><span class="s1">LinearModelLoss</span><span class="s3">(</span><span class="s1">base_loss</span><span class="s3">=</span><span class="s1">base_loss</span><span class="s3">(), </span><span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">)</span>
    <span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features </span><span class="s3">= </span><span class="s5">10</span><span class="s3">, </span><span class="s5">5</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">coef </span><span class="s3">= </span><span class="s1">random_X_y_coef</span><span class="s3">(</span>
        <span class="s1">linear_model_loss</span><span class="s3">=</span><span class="s1">loss</span><span class="s3">, </span><span class="s1">n_samples</span><span class="s3">=</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s1">n_features</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">=</span><span class="s5">42</span>
    <span class="s3">)</span>
    <span class="s1">coef </span><span class="s3">= </span><span class="s1">coef</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(</span><span class="s1">order</span><span class="s3">=</span><span class="s6">&quot;F&quot;</span><span class="s3">)  </span><span class="s4"># this is important only for multinomial loss</span>

    <span class="s2">if </span><span class="s1">sample_weight </span><span class="s3">== </span><span class="s6">&quot;range&quot;</span><span class="s3">:</span>
        <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linspace</span><span class="s3">(</span><span class="s5">1</span><span class="s3">, </span><span class="s1">y</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">], </span><span class="s1">num</span><span class="s3">=</span><span class="s1">y</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">])</span>

    <span class="s4"># 1. Check gradients numerically</span>
    <span class="s1">eps </span><span class="s3">= </span><span class="s5">1e-6</span>
    <span class="s1">g</span><span class="s3">, </span><span class="s1">hessp </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient_hessian_product</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span>
    <span class="s3">)</span>
    <span class="s4"># Use a trick to get central finite difference of accuracy 4 (five-point stencil)</span>
    <span class="s4"># https://en.wikipedia.org/wiki/Numerical_differentiation</span>
    <span class="s4"># https://en.wikipedia.org/wiki/Finite_difference_coefficient</span>
    <span class="s4"># approx_g1 = (f(x + eps) - f(x - eps)) / (2*eps)</span>
    <span class="s1">approx_g1 </span><span class="s3">= </span><span class="s1">optimize</span><span class="s3">.</span><span class="s1">approx_fprime</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">,</span>
        <span class="s2">lambda </span><span class="s1">coef</span><span class="s3">: </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">loss</span><span class="s3">(</span>
            <span class="s1">coef </span><span class="s3">- </span><span class="s1">eps</span><span class="s3">,</span>
            <span class="s1">X</span><span class="s3">,</span>
            <span class="s1">y</span><span class="s3">,</span>
            <span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">,</span>
            <span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span><span class="s3">,</span>
        <span class="s3">),</span>
        <span class="s5">2 </span><span class="s3">* </span><span class="s1">eps</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s4"># approx_g2 = (f(x + 2*eps) - f(x - 2*eps)) / (4*eps)</span>
    <span class="s1">approx_g2 </span><span class="s3">= </span><span class="s1">optimize</span><span class="s3">.</span><span class="s1">approx_fprime</span><span class="s3">(</span>
        <span class="s1">coef</span><span class="s3">,</span>
        <span class="s2">lambda </span><span class="s1">coef</span><span class="s3">: </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">loss</span><span class="s3">(</span>
            <span class="s1">coef </span><span class="s3">- </span><span class="s5">2 </span><span class="s3">* </span><span class="s1">eps</span><span class="s3">,</span>
            <span class="s1">X</span><span class="s3">,</span>
            <span class="s1">y</span><span class="s3">,</span>
            <span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">,</span>
            <span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span><span class="s3">,</span>
        <span class="s3">),</span>
        <span class="s5">4 </span><span class="s3">* </span><span class="s1">eps</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s4"># Five-point stencil approximation</span>
    <span class="s4"># See: https://en.wikipedia.org/wiki/Five-point_stencil#1D_first_derivative</span>
    <span class="s1">approx_g </span><span class="s3">= (</span><span class="s5">4 </span><span class="s3">* </span><span class="s1">approx_g1 </span><span class="s3">- </span><span class="s1">approx_g2</span><span class="s3">) / </span><span class="s5">3</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g</span><span class="s3">, </span><span class="s1">approx_g</span><span class="s3">, </span><span class="s1">rtol</span><span class="s3">=</span><span class="s5">1e-2</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s5">1e-8</span><span class="s3">)</span>

    <span class="s4"># 2. Check hessp numerically along the second direction of the gradient</span>
    <span class="s1">vector </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros_like</span><span class="s3">(</span><span class="s1">g</span><span class="s3">)</span>
    <span class="s1">vector</span><span class="s3">[</span><span class="s5">1</span><span class="s3">] = </span><span class="s5">1</span>
    <span class="s1">hess_col </span><span class="s3">= </span><span class="s1">hessp</span><span class="s3">(</span><span class="s1">vector</span><span class="s3">)</span>
    <span class="s4"># Computation of the Hessian is particularly fragile to numerical errors when doing</span>
    <span class="s4"># simple finite differences. Here we compute the grad along a path in the direction</span>
    <span class="s4"># of the vector and then use a least-square regression to estimate the slope</span>
    <span class="s1">eps </span><span class="s3">= </span><span class="s5">1e-3</span>
    <span class="s1">d_x </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linspace</span><span class="s3">(-</span><span class="s1">eps</span><span class="s3">, </span><span class="s1">eps</span><span class="s3">, </span><span class="s5">30</span><span class="s3">)</span>
    <span class="s1">d_grad </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">(</span>
        <span class="s3">[</span>
            <span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient</span><span class="s3">(</span>
                <span class="s1">coef </span><span class="s3">+ </span><span class="s1">t </span><span class="s3">* </span><span class="s1">vector</span><span class="s3">,</span>
                <span class="s1">X</span><span class="s3">,</span>
                <span class="s1">y</span><span class="s3">,</span>
                <span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">,</span>
                <span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s1">l2_reg_strength</span><span class="s3">,</span>
            <span class="s3">)</span>
            <span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">d_x</span>
        <span class="s3">]</span>
    <span class="s3">)</span>
    <span class="s1">d_grad </span><span class="s3">-= </span><span class="s1">d_grad</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">axis</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">approx_hess_col </span><span class="s3">= </span><span class="s1">linalg</span><span class="s3">.</span><span class="s1">lstsq</span><span class="s3">(</span><span class="s1">d_x</span><span class="s3">[:, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">newaxis</span><span class="s3">], </span><span class="s1">d_grad</span><span class="s3">)[</span><span class="s5">0</span><span class="s3">].</span><span class="s1">ravel</span><span class="s3">()</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">approx_hess_col</span><span class="s3">, </span><span class="s1">hess_col</span><span class="s3">, </span><span class="s1">rtol</span><span class="s3">=</span><span class="s5">1e-3</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;fit_intercept&quot;</span><span class="s3">, [</span><span class="s2">False</span><span class="s3">, </span><span class="s2">True</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_multinomial_coef_shape</span><span class="s3">(</span><span class="s1">fit_intercept</span><span class="s3">):</span>
    <span class="s0">&quot;&quot;&quot;Test that multinomial LinearModelLoss respects shape of coef.&quot;&quot;&quot;</span>
    <span class="s1">loss </span><span class="s3">= </span><span class="s1">LinearModelLoss</span><span class="s3">(</span><span class="s1">base_loss</span><span class="s3">=</span><span class="s1">HalfMultinomialLoss</span><span class="s3">(), </span><span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">)</span>
    <span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features </span><span class="s3">= </span><span class="s5">10</span><span class="s3">, </span><span class="s5">5</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">coef </span><span class="s3">= </span><span class="s1">random_X_y_coef</span><span class="s3">(</span>
        <span class="s1">linear_model_loss</span><span class="s3">=</span><span class="s1">loss</span><span class="s3">, </span><span class="s1">n_samples</span><span class="s3">=</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s1">n_features</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">=</span><span class="s5">42</span>
    <span class="s3">)</span>
    <span class="s1">s </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s5">42</span><span class="s3">).</span><span class="s1">randn</span><span class="s3">(*</span><span class="s1">coef</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">)</span>

    <span class="s1">l</span><span class="s3">, </span><span class="s1">g </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">loss_gradient</span><span class="s3">(</span><span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">g1 </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient</span><span class="s3">(</span><span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">g2</span><span class="s3">, </span><span class="s1">hessp </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient_hessian_product</span><span class="s3">(</span><span class="s1">coef</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">h </span><span class="s3">= </span><span class="s1">hessp</span><span class="s3">(</span><span class="s1">s</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">g</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== </span><span class="s1">coef</span><span class="s3">.</span><span class="s1">shape</span>
    <span class="s2">assert </span><span class="s1">h</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== </span><span class="s1">coef</span><span class="s3">.</span><span class="s1">shape</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g</span><span class="s3">, </span><span class="s1">g1</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g</span><span class="s3">, </span><span class="s1">g2</span><span class="s3">)</span>

    <span class="s1">coef_r </span><span class="s3">= </span><span class="s1">coef</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(</span><span class="s1">order</span><span class="s3">=</span><span class="s6">&quot;F&quot;</span><span class="s3">)</span>
    <span class="s1">s_r </span><span class="s3">= </span><span class="s1">s</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(</span><span class="s1">order</span><span class="s3">=</span><span class="s6">&quot;F&quot;</span><span class="s3">)</span>
    <span class="s1">l_r</span><span class="s3">, </span><span class="s1">g_r </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">loss_gradient</span><span class="s3">(</span><span class="s1">coef_r</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">g1_r </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient</span><span class="s3">(</span><span class="s1">coef_r</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">g2_r</span><span class="s3">, </span><span class="s1">hessp_r </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">gradient_hessian_product</span><span class="s3">(</span><span class="s1">coef_r</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">h_r </span><span class="s3">= </span><span class="s1">hessp_r</span><span class="s3">(</span><span class="s1">s_r</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">g_r</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== </span><span class="s1">coef_r</span><span class="s3">.</span><span class="s1">shape</span>
    <span class="s2">assert </span><span class="s1">h_r</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== </span><span class="s1">coef_r</span><span class="s3">.</span><span class="s1">shape</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g_r</span><span class="s3">, </span><span class="s1">g1_r</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g_r</span><span class="s3">, </span><span class="s1">g2_r</span><span class="s3">)</span>

    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">g</span><span class="s3">, </span><span class="s1">g_r</span><span class="s3">.</span><span class="s1">reshape</span><span class="s3">(</span><span class="s1">loss</span><span class="s3">.</span><span class="s1">base_loss</span><span class="s3">.</span><span class="s1">n_classes</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">, </span><span class="s1">order</span><span class="s3">=</span><span class="s6">&quot;F&quot;</span><span class="s3">))</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">h</span><span class="s3">, </span><span class="s1">h_r</span><span class="s3">.</span><span class="s1">reshape</span><span class="s3">(</span><span class="s1">loss</span><span class="s3">.</span><span class="s1">base_loss</span><span class="s3">.</span><span class="s1">n_classes</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">, </span><span class="s1">order</span><span class="s3">=</span><span class="s6">&quot;F&quot;</span><span class="s3">))</span>
</pre>
</body>
</html>