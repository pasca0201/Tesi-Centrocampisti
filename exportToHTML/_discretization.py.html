<html>
<head>
<title>_discretization.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #7a7e85;}
.s1 { color: #bcbec4;}
.s2 { color: #cf8e6d;}
.s3 { color: #bcbec4;}
.s4 { color: #5f826b; font-style: italic;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_discretization.py</font>
</center></td></tr></table>
<pre><span class="s0"># Author: Henry Lin &lt;hlin117@gmail.com&gt;</span>
<span class="s0">#         Tom Dupr√© la Tour</span>

<span class="s0"># License: BSD</span>


<span class="s2">import </span><span class="s1">warnings</span>
<span class="s2">from </span><span class="s1">numbers </span><span class="s2">import </span><span class="s1">Integral</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">from </span><span class="s3">..</span><span class="s1">base </span><span class="s2">import </span><span class="s1">BaseEstimator</span><span class="s3">, </span><span class="s1">TransformerMixin</span><span class="s3">, </span><span class="s1">_fit_context</span>
<span class="s2">from </span><span class="s3">..</span><span class="s1">utils </span><span class="s2">import </span><span class="s1">resample</span>
<span class="s2">from </span><span class="s3">..</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">_param_validation </span><span class="s2">import </span><span class="s1">Interval</span><span class="s3">, </span><span class="s1">Options</span><span class="s3">, </span><span class="s1">StrOptions</span>
<span class="s2">from </span><span class="s3">..</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">deprecation </span><span class="s2">import </span><span class="s1">_deprecate_Xt_in_inverse_transform</span>
<span class="s2">from </span><span class="s3">..</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">stats </span><span class="s2">import </span><span class="s1">_weighted_percentile</span>
<span class="s2">from </span><span class="s3">..</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">validation </span><span class="s2">import </span><span class="s3">(</span>
    <span class="s1">_check_feature_names_in</span><span class="s3">,</span>
    <span class="s1">_check_sample_weight</span><span class="s3">,</span>
    <span class="s1">check_array</span><span class="s3">,</span>
    <span class="s1">check_is_fitted</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s2">from </span><span class="s3">.</span><span class="s1">_encoders </span><span class="s2">import </span><span class="s1">OneHotEncoder</span>


<span class="s2">class </span><span class="s1">KBinsDiscretizer</span><span class="s3">(</span><span class="s1">TransformerMixin</span><span class="s3">, </span><span class="s1">BaseEstimator</span><span class="s3">):</span>
    <span class="s4">&quot;&quot;&quot; 
    Bin continuous data into intervals. 
 
    Read more in the :ref:`User Guide &lt;preprocessing_discretization&gt;`. 
 
    .. versionadded:: 0.20 
 
    Parameters 
    ---------- 
    n_bins : int or array-like of shape (n_features,), default=5 
        The number of bins to produce. Raises ValueError if ``n_bins &lt; 2``. 
 
    encode : {'onehot', 'onehot-dense', 'ordinal'}, default='onehot' 
        Method used to encode the transformed result. 
 
        - 'onehot': Encode the transformed result with one-hot encoding 
          and return a sparse matrix. Ignored features are always 
          stacked to the right. 
        - 'onehot-dense': Encode the transformed result with one-hot encoding 
          and return a dense array. Ignored features are always 
          stacked to the right. 
        - 'ordinal': Return the bin identifier encoded as an integer value. 
 
    strategy : {'uniform', 'quantile', 'kmeans'}, default='quantile' 
        Strategy used to define the widths of the bins. 
 
        - 'uniform': All bins in each feature have identical widths. 
        - 'quantile': All bins in each feature have the same number of points. 
        - 'kmeans': Values in each bin have the same nearest center of a 1D 
          k-means cluster. 
 
        For an example of the different strategies see: 
        :ref:`sphx_glr_auto_examples_preprocessing_plot_discretization_strategies.py`. 
 
    dtype : {np.float32, np.float64}, default=None 
        The desired data-type for the output. If None, output dtype is 
        consistent with input dtype. Only np.float32 and np.float64 are 
        supported. 
 
        .. versionadded:: 0.24 
 
    subsample : int or None, default=200_000 
        Maximum number of samples, used to fit the model, for computational 
        efficiency. 
        `subsample=None` means that all the training samples are used when 
        computing the quantiles that determine the binning thresholds. 
        Since quantile computation relies on sorting each column of `X` and 
        that sorting has an `n log(n)` time complexity, 
        it is recommended to use subsampling on datasets with a 
        very large number of samples. 
 
        .. versionchanged:: 1.3 
            The default value of `subsample` changed from `None` to `200_000` when 
            `strategy=&quot;quantile&quot;`. 
 
        .. versionchanged:: 1.5 
            The default value of `subsample` changed from `None` to `200_000` when 
            `strategy=&quot;uniform&quot;` or `strategy=&quot;kmeans&quot;`. 
 
    random_state : int, RandomState instance or None, default=None 
        Determines random number generation for subsampling. 
        Pass an int for reproducible results across multiple function calls. 
        See the `subsample` parameter for more details. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
        .. versionadded:: 1.1 
 
    Attributes 
    ---------- 
    bin_edges_ : ndarray of ndarray of shape (n_features,) 
        The edges of each bin. Contain arrays of varying shapes ``(n_bins_, )`` 
        Ignored features will have empty arrays. 
 
    n_bins_ : ndarray of shape (n_features,), dtype=np.int64 
        Number of bins per feature. Bins whose width are too small 
        (i.e., &lt;= 1e-8) are removed with a warning. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    See Also 
    -------- 
    Binarizer : Class used to bin values as ``0`` or 
        ``1`` based on a parameter ``threshold``. 
 
    Notes 
    ----- 
 
    For a visualization of discretization on different datasets refer to 
    :ref:`sphx_glr_auto_examples_preprocessing_plot_discretization_classification.py`. 
    On the effect of discretization on linear models see: 
    :ref:`sphx_glr_auto_examples_preprocessing_plot_discretization.py`. 
 
    In bin edges for feature ``i``, the first and last values are used only for 
    ``inverse_transform``. During transform, bin edges are extended to:: 
 
      np.concatenate([-np.inf, bin_edges_[i][1:-1], np.inf]) 
 
    You can combine ``KBinsDiscretizer`` with 
    :class:`~sklearn.compose.ColumnTransformer` if you only want to preprocess 
    part of the features. 
 
    ``KBinsDiscretizer`` might produce constant features (e.g., when 
    ``encode = 'onehot'`` and certain bins do not contain any data). 
    These features can be removed with feature selection algorithms 
    (e.g., :class:`~sklearn.feature_selection.VarianceThreshold`). 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.preprocessing import KBinsDiscretizer 
    &gt;&gt;&gt; X = [[-2, 1, -4,   -1], 
    ...      [-1, 2, -3, -0.5], 
    ...      [ 0, 3, -2,  0.5], 
    ...      [ 1, 4, -1,    2]] 
    &gt;&gt;&gt; est = KBinsDiscretizer( 
    ...     n_bins=3, encode='ordinal', strategy='uniform' 
    ... ) 
    &gt;&gt;&gt; est.fit(X) 
    KBinsDiscretizer(...) 
    &gt;&gt;&gt; Xt = est.transform(X) 
    &gt;&gt;&gt; Xt  # doctest: +SKIP 
    array([[ 0., 0., 0., 0.], 
           [ 1., 1., 1., 0.], 
           [ 2., 2., 2., 1.], 
           [ 2., 2., 2., 2.]]) 
 
    Sometimes it may be useful to convert the data back into the original 
    feature space. The ``inverse_transform`` function converts the binned 
    data into the original feature space. Each value will be equal to the mean 
    of the two bin edges. 
 
    &gt;&gt;&gt; est.bin_edges_[0] 
    array([-2., -1.,  0.,  1.]) 
    &gt;&gt;&gt; est.inverse_transform(Xt) 
    array([[-1.5,  1.5, -3.5, -0.5], 
           [-0.5,  2.5, -2.5, -0.5], 
           [ 0.5,  3.5, -1.5,  0.5], 
           [ 0.5,  3.5, -1.5,  1.5]]) 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s3">: </span><span class="s1">dict </span><span class="s3">= {</span>
        <span class="s5">&quot;n_bins&quot;</span><span class="s3">: [</span><span class="s1">Interval</span><span class="s3">(</span><span class="s1">Integral</span><span class="s3">, </span><span class="s6">2</span><span class="s3">, </span><span class="s2">None</span><span class="s3">, </span><span class="s1">closed</span><span class="s3">=</span><span class="s5">&quot;left&quot;</span><span class="s3">), </span><span class="s5">&quot;array-like&quot;</span><span class="s3">],</span>
        <span class="s5">&quot;encode&quot;</span><span class="s3">: [</span><span class="s1">StrOptions</span><span class="s3">({</span><span class="s5">&quot;onehot&quot;</span><span class="s3">, </span><span class="s5">&quot;onehot-dense&quot;</span><span class="s3">, </span><span class="s5">&quot;ordinal&quot;</span><span class="s3">})],</span>
        <span class="s5">&quot;strategy&quot;</span><span class="s3">: [</span><span class="s1">StrOptions</span><span class="s3">({</span><span class="s5">&quot;uniform&quot;</span><span class="s3">, </span><span class="s5">&quot;quantile&quot;</span><span class="s3">, </span><span class="s5">&quot;kmeans&quot;</span><span class="s3">})],</span>
        <span class="s5">&quot;dtype&quot;</span><span class="s3">: [</span><span class="s1">Options</span><span class="s3">(</span><span class="s1">type</span><span class="s3">, {</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float64</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">}), </span><span class="s2">None</span><span class="s3">],</span>
        <span class="s5">&quot;subsample&quot;</span><span class="s3">: [</span><span class="s1">Interval</span><span class="s3">(</span><span class="s1">Integral</span><span class="s3">, </span><span class="s6">1</span><span class="s3">, </span><span class="s2">None</span><span class="s3">, </span><span class="s1">closed</span><span class="s3">=</span><span class="s5">&quot;left&quot;</span><span class="s3">), </span><span class="s2">None</span><span class="s3">],</span>
        <span class="s5">&quot;random_state&quot;</span><span class="s3">: [</span><span class="s5">&quot;random_state&quot;</span><span class="s3">],</span>
    <span class="s3">}</span>

    <span class="s2">def </span><span class="s1">__init__</span><span class="s3">(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s1">n_bins</span><span class="s3">=</span><span class="s6">5</span><span class="s3">,</span>
        <span class="s3">*,</span>
        <span class="s1">encode</span><span class="s3">=</span><span class="s5">&quot;onehot&quot;</span><span class="s3">,</span>
        <span class="s1">strategy</span><span class="s3">=</span><span class="s5">&quot;quantile&quot;</span><span class="s3">,</span>
        <span class="s1">dtype</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
        <span class="s1">subsample</span><span class="s3">=</span><span class="s6">200_000</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
    <span class="s3">):</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">n_bins </span><span class="s3">= </span><span class="s1">n_bins</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">encode </span><span class="s3">= </span><span class="s1">encode</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">strategy </span><span class="s3">= </span><span class="s1">strategy</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">dtype </span><span class="s3">= </span><span class="s1">dtype</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">subsample </span><span class="s3">= </span><span class="s1">subsample</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">random_state </span><span class="s3">= </span><span class="s1">random_state</span>

    <span class="s3">@</span><span class="s1">_fit_context</span><span class="s3">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s2">def </span><span class="s1">fit</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">=</span><span class="s2">None</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s2">None</span><span class="s3">):</span>
        <span class="s4">&quot;&quot;&quot; 
        Fit the estimator. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Data to be discretized. 
 
        y : None 
            Ignored. This parameter exists only for compatibility with 
            :class:`~sklearn.pipeline.Pipeline`. 
 
        sample_weight : ndarray of shape (n_samples,) 
            Contains weight values to be associated with each sample. 
            Cannot be used when `strategy` is set to `&quot;uniform&quot;`. 
 
            .. versionadded:: 1.3 
 
        Returns 
        ------- 
        self : object 
            Returns the instance itself. 
        &quot;&quot;&quot;</span>
        <span class="s1">X </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_validate_data</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">=</span><span class="s5">&quot;numeric&quot;</span><span class="s3">)</span>

        <span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">dtype </span><span class="s2">in </span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float64</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">):</span>
            <span class="s1">output_dtype </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">dtype</span>
        <span class="s2">else</span><span class="s3">:  </span><span class="s0"># self.dtype is None</span>
            <span class="s1">output_dtype </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">dtype</span>

        <span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span>

        <span class="s2">if </span><span class="s1">sample_weight </span><span class="s2">is not None and </span><span class="s1">self</span><span class="s3">.</span><span class="s1">strategy </span><span class="s3">== </span><span class="s5">&quot;uniform&quot;</span><span class="s3">:</span>
            <span class="s2">raise </span><span class="s1">ValueError</span><span class="s3">(</span>
                <span class="s5">&quot;`sample_weight` was provided but it cannot be &quot;</span>
                <span class="s5">&quot;used with strategy='uniform'. Got strategy=&quot;</span>
                <span class="s5">f&quot;</span><span class="s2">{</span><span class="s1">self</span><span class="s3">.</span><span class="s1">strategy</span><span class="s2">!r} </span><span class="s5">instead.&quot;</span>
            <span class="s3">)</span>

        <span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">subsample </span><span class="s2">is not None and </span><span class="s1">n_samples </span><span class="s3">&gt; </span><span class="s1">self</span><span class="s3">.</span><span class="s1">subsample</span><span class="s3">:</span>
            <span class="s0"># Take a subsample of `X`</span>
            <span class="s1">X </span><span class="s3">= </span><span class="s1">resample</span><span class="s3">(</span>
                <span class="s1">X</span><span class="s3">,</span>
                <span class="s1">replace</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
                <span class="s1">n_samples</span><span class="s3">=</span><span class="s1">self</span><span class="s3">.</span><span class="s1">subsample</span><span class="s3">,</span>
                <span class="s1">random_state</span><span class="s3">=</span><span class="s1">self</span><span class="s3">.</span><span class="s1">random_state</span><span class="s3">,</span>
            <span class="s3">)</span>

        <span class="s1">n_features </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s6">1</span><span class="s3">]</span>
        <span class="s1">n_bins </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_validate_n_bins</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">)</span>

        <span class="s2">if </span><span class="s1">sample_weight </span><span class="s2">is not None</span><span class="s3">:</span>
            <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">_check_sample_weight</span><span class="s3">(</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">X</span><span class="s3">.</span><span class="s1">dtype</span><span class="s3">)</span>

        <span class="s1">bin_edges </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">object</span><span class="s3">)</span>
        <span class="s2">for </span><span class="s1">jj </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">):</span>
            <span class="s1">column </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[:, </span><span class="s1">jj</span><span class="s3">]</span>
            <span class="s1">col_min</span><span class="s3">, </span><span class="s1">col_max </span><span class="s3">= </span><span class="s1">column</span><span class="s3">.</span><span class="s1">min</span><span class="s3">(), </span><span class="s1">column</span><span class="s3">.</span><span class="s1">max</span><span class="s3">()</span>

            <span class="s2">if </span><span class="s1">col_min </span><span class="s3">== </span><span class="s1">col_max</span><span class="s3">:</span>
                <span class="s1">warnings</span><span class="s3">.</span><span class="s1">warn</span><span class="s3">(</span>
                    <span class="s5">&quot;Feature %d is constant and will be replaced with 0.&quot; </span><span class="s3">% </span><span class="s1">jj</span>
                <span class="s3">)</span>
                <span class="s1">n_bins</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">] = </span><span class="s6">1</span>
                <span class="s1">bin_edges</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">] = </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([-</span><span class="s1">np</span><span class="s3">.</span><span class="s1">inf</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">inf</span><span class="s3">])</span>
                <span class="s2">continue</span>

            <span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">strategy </span><span class="s3">== </span><span class="s5">&quot;uniform&quot;</span><span class="s3">:</span>
                <span class="s1">bin_edges</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">] = </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linspace</span><span class="s3">(</span><span class="s1">col_min</span><span class="s3">, </span><span class="s1">col_max</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">] + </span><span class="s6">1</span><span class="s3">)</span>

            <span class="s2">elif </span><span class="s1">self</span><span class="s3">.</span><span class="s1">strategy </span><span class="s3">== </span><span class="s5">&quot;quantile&quot;</span><span class="s3">:</span>
                <span class="s1">quantiles </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linspace</span><span class="s3">(</span><span class="s6">0</span><span class="s3">, </span><span class="s6">100</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">] + </span><span class="s6">1</span><span class="s3">)</span>
                <span class="s2">if </span><span class="s1">sample_weight </span><span class="s2">is None</span><span class="s3">:</span>
                    <span class="s1">bin_edges</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">] = </span><span class="s1">np</span><span class="s3">.</span><span class="s1">asarray</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">percentile</span><span class="s3">(</span><span class="s1">column</span><span class="s3">, </span><span class="s1">quantiles</span><span class="s3">))</span>
                <span class="s2">else</span><span class="s3">:</span>
                    <span class="s1">bin_edges</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">] = </span><span class="s1">np</span><span class="s3">.</span><span class="s1">asarray</span><span class="s3">(</span>
                        <span class="s3">[</span>
                            <span class="s1">_weighted_percentile</span><span class="s3">(</span><span class="s1">column</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">q</span><span class="s3">)</span>
                            <span class="s2">for </span><span class="s1">q </span><span class="s2">in </span><span class="s1">quantiles</span>
                        <span class="s3">],</span>
                        <span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float64</span><span class="s3">,</span>
                    <span class="s3">)</span>
            <span class="s2">elif </span><span class="s1">self</span><span class="s3">.</span><span class="s1">strategy </span><span class="s3">== </span><span class="s5">&quot;kmeans&quot;</span><span class="s3">:</span>
                <span class="s2">from </span><span class="s3">..</span><span class="s1">cluster </span><span class="s2">import </span><span class="s1">KMeans  </span><span class="s0"># fixes import loops</span>

                <span class="s0"># Deterministic initialization with uniform spacing</span>
                <span class="s1">uniform_edges </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linspace</span><span class="s3">(</span><span class="s1">col_min</span><span class="s3">, </span><span class="s1">col_max</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">] + </span><span class="s6">1</span><span class="s3">)</span>
                <span class="s1">init </span><span class="s3">= (</span><span class="s1">uniform_edges</span><span class="s3">[</span><span class="s6">1</span><span class="s3">:] + </span><span class="s1">uniform_edges</span><span class="s3">[:-</span><span class="s6">1</span><span class="s3">])[:, </span><span class="s2">None</span><span class="s3">] * </span><span class="s6">0.5</span>

                <span class="s0"># 1D k-means procedure</span>
                <span class="s1">km </span><span class="s3">= </span><span class="s1">KMeans</span><span class="s3">(</span><span class="s1">n_clusters</span><span class="s3">=</span><span class="s1">n_bins</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">], </span><span class="s1">init</span><span class="s3">=</span><span class="s1">init</span><span class="s3">, </span><span class="s1">n_init</span><span class="s3">=</span><span class="s6">1</span><span class="s3">)</span>
                <span class="s1">centers </span><span class="s3">= </span><span class="s1">km</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span>
                    <span class="s1">column</span><span class="s3">[:, </span><span class="s2">None</span><span class="s3">], </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span>
                <span class="s3">).</span><span class="s1">cluster_centers_</span><span class="s3">[:, </span><span class="s6">0</span><span class="s3">]</span>
                <span class="s0"># Must sort, centers may be unsorted even with sorted init</span>
                <span class="s1">centers</span><span class="s3">.</span><span class="s1">sort</span><span class="s3">()</span>
                <span class="s1">bin_edges</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">] = (</span><span class="s1">centers</span><span class="s3">[</span><span class="s6">1</span><span class="s3">:] + </span><span class="s1">centers</span><span class="s3">[:-</span><span class="s6">1</span><span class="s3">]) * </span><span class="s6">0.5</span>
                <span class="s1">bin_edges</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">] = </span><span class="s1">np</span><span class="s3">.</span><span class="s1">r_</span><span class="s3">[</span><span class="s1">col_min</span><span class="s3">, </span><span class="s1">bin_edges</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">], </span><span class="s1">col_max</span><span class="s3">]</span>

            <span class="s0"># Remove bins whose width are too small (i.e., &lt;= 1e-8)</span>
            <span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">strategy </span><span class="s2">in </span><span class="s3">(</span><span class="s5">&quot;quantile&quot;</span><span class="s3">, </span><span class="s5">&quot;kmeans&quot;</span><span class="s3">):</span>
                <span class="s1">mask </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ediff1d</span><span class="s3">(</span><span class="s1">bin_edges</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">], </span><span class="s1">to_begin</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">inf</span><span class="s3">) &gt; </span><span class="s6">1e-8</span>
                <span class="s1">bin_edges</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">] = </span><span class="s1">bin_edges</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">][</span><span class="s1">mask</span><span class="s3">]</span>
                <span class="s2">if </span><span class="s1">len</span><span class="s3">(</span><span class="s1">bin_edges</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">]) - </span><span class="s6">1 </span><span class="s3">!= </span><span class="s1">n_bins</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">]:</span>
                    <span class="s1">warnings</span><span class="s3">.</span><span class="s1">warn</span><span class="s3">(</span>
                        <span class="s5">&quot;Bins whose width are too small (i.e., &lt;= &quot;</span>
                        <span class="s5">&quot;1e-8) in feature %d are removed. Consider &quot;</span>
                        <span class="s5">&quot;decreasing the number of bins.&quot; </span><span class="s3">% </span><span class="s1">jj</span>
                    <span class="s3">)</span>
                    <span class="s1">n_bins</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">] = </span><span class="s1">len</span><span class="s3">(</span><span class="s1">bin_edges</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">]) - </span><span class="s6">1</span>

        <span class="s1">self</span><span class="s3">.</span><span class="s1">bin_edges_ </span><span class="s3">= </span><span class="s1">bin_edges</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">n_bins_ </span><span class="s3">= </span><span class="s1">n_bins</span>

        <span class="s2">if </span><span class="s5">&quot;onehot&quot; </span><span class="s2">in </span><span class="s1">self</span><span class="s3">.</span><span class="s1">encode</span><span class="s3">:</span>
            <span class="s1">self</span><span class="s3">.</span><span class="s1">_encoder </span><span class="s3">= </span><span class="s1">OneHotEncoder</span><span class="s3">(</span>
                <span class="s1">categories</span><span class="s3">=[</span><span class="s1">np</span><span class="s3">.</span><span class="s1">arange</span><span class="s3">(</span><span class="s1">i</span><span class="s3">) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_bins_</span><span class="s3">],</span>
                <span class="s1">sparse_output</span><span class="s3">=</span><span class="s1">self</span><span class="s3">.</span><span class="s1">encode </span><span class="s3">== </span><span class="s5">&quot;onehot&quot;</span><span class="s3">,</span>
                <span class="s1">dtype</span><span class="s3">=</span><span class="s1">output_dtype</span><span class="s3">,</span>
            <span class="s3">)</span>
            <span class="s0"># Fit the OneHotEncoder with toy datasets</span>
            <span class="s0"># so that it's ready for use after the KBinsDiscretizer is fitted</span>
            <span class="s1">self</span><span class="s3">.</span><span class="s1">_encoder</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">((</span><span class="s6">1</span><span class="s3">, </span><span class="s1">len</span><span class="s3">(</span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_bins_</span><span class="s3">))))</span>

        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">_validate_n_bins</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">):</span>
        <span class="s4">&quot;&quot;&quot;Returns n_bins_, the number of bins per feature.&quot;&quot;&quot;</span>
        <span class="s1">orig_bins </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_bins</span>
        <span class="s2">if </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">orig_bins</span><span class="s3">, </span><span class="s1">Integral</span><span class="s3">):</span>
            <span class="s2">return </span><span class="s1">np</span><span class="s3">.</span><span class="s1">full</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">, </span><span class="s1">orig_bins</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">int</span><span class="s3">)</span>

        <span class="s1">n_bins </span><span class="s3">= </span><span class="s1">check_array</span><span class="s3">(</span><span class="s1">orig_bins</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">int</span><span class="s3">, </span><span class="s1">copy</span><span class="s3">=</span><span class="s2">True</span><span class="s3">, </span><span class="s1">ensure_2d</span><span class="s3">=</span><span class="s2">False</span><span class="s3">)</span>

        <span class="s2">if </span><span class="s1">n_bins</span><span class="s3">.</span><span class="s1">ndim </span><span class="s3">&gt; </span><span class="s6">1 </span><span class="s2">or </span><span class="s1">n_bins</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s6">0</span><span class="s3">] != </span><span class="s1">n_features</span><span class="s3">:</span>
            <span class="s2">raise </span><span class="s1">ValueError</span><span class="s3">(</span><span class="s5">&quot;n_bins must be a scalar or array of shape (n_features,).&quot;</span><span class="s3">)</span>

        <span class="s1">bad_nbins_value </span><span class="s3">= (</span><span class="s1">n_bins </span><span class="s3">&lt; </span><span class="s6">2</span><span class="s3">) | (</span><span class="s1">n_bins </span><span class="s3">!= </span><span class="s1">orig_bins</span><span class="s3">)</span>

        <span class="s1">violating_indices </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">where</span><span class="s3">(</span><span class="s1">bad_nbins_value</span><span class="s3">)[</span><span class="s6">0</span><span class="s3">]</span>
        <span class="s2">if </span><span class="s1">violating_indices</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s6">0</span><span class="s3">] &gt; </span><span class="s6">0</span><span class="s3">:</span>
            <span class="s1">indices </span><span class="s3">= </span><span class="s5">&quot;, &quot;</span><span class="s3">.</span><span class="s1">join</span><span class="s3">(</span><span class="s1">str</span><span class="s3">(</span><span class="s1">i</span><span class="s3">) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">violating_indices</span><span class="s3">)</span>
            <span class="s2">raise </span><span class="s1">ValueError</span><span class="s3">(</span>
                <span class="s5">&quot;{} received an invalid number &quot;</span>
                <span class="s5">&quot;of bins at indices {}. Number of bins &quot;</span>
                <span class="s5">&quot;must be at least 2, and must be an int.&quot;</span><span class="s3">.</span><span class="s1">format</span><span class="s3">(</span>
                    <span class="s1">KBinsDiscretizer</span><span class="s3">.</span><span class="s1">__name__</span><span class="s3">, </span><span class="s1">indices</span>
                <span class="s3">)</span>
            <span class="s3">)</span>
        <span class="s2">return </span><span class="s1">n_bins</span>

    <span class="s2">def </span><span class="s1">transform</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">):</span>
        <span class="s4">&quot;&quot;&quot; 
        Discretize the data. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Data to be discretized. 
 
        Returns 
        ------- 
        Xt : {ndarray, sparse matrix}, dtype={np.float32, np.float64} 
            Data in the binned space. Will be a sparse matrix if 
            `self.encode='onehot'` and ndarray otherwise. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s3">(</span><span class="s1">self</span><span class="s3">)</span>

        <span class="s0"># check input and attribute dtypes</span>
        <span class="s1">dtype </span><span class="s3">= (</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float64</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">) </span><span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">dtype </span><span class="s2">is None else </span><span class="s1">self</span><span class="s3">.</span><span class="s1">dtype</span>
        <span class="s1">Xt </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_validate_data</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">copy</span><span class="s3">=</span><span class="s2">True</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">dtype</span><span class="s3">, </span><span class="s1">reset</span><span class="s3">=</span><span class="s2">False</span><span class="s3">)</span>

        <span class="s1">bin_edges </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">bin_edges_</span>
        <span class="s2">for </span><span class="s1">jj </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">Xt</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s6">1</span><span class="s3">]):</span>
            <span class="s1">Xt</span><span class="s3">[:, </span><span class="s1">jj</span><span class="s3">] = </span><span class="s1">np</span><span class="s3">.</span><span class="s1">searchsorted</span><span class="s3">(</span><span class="s1">bin_edges</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">][</span><span class="s6">1</span><span class="s3">:-</span><span class="s6">1</span><span class="s3">], </span><span class="s1">Xt</span><span class="s3">[:, </span><span class="s1">jj</span><span class="s3">], </span><span class="s1">side</span><span class="s3">=</span><span class="s5">&quot;right&quot;</span><span class="s3">)</span>

        <span class="s2">if </span><span class="s1">self</span><span class="s3">.</span><span class="s1">encode </span><span class="s3">== </span><span class="s5">&quot;ordinal&quot;</span><span class="s3">:</span>
            <span class="s2">return </span><span class="s1">Xt</span>

        <span class="s1">dtype_init </span><span class="s3">= </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s5">&quot;onehot&quot; </span><span class="s2">in </span><span class="s1">self</span><span class="s3">.</span><span class="s1">encode</span><span class="s3">:</span>
            <span class="s1">dtype_init </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_encoder</span><span class="s3">.</span><span class="s1">dtype</span>
            <span class="s1">self</span><span class="s3">.</span><span class="s1">_encoder</span><span class="s3">.</span><span class="s1">dtype </span><span class="s3">= </span><span class="s1">Xt</span><span class="s3">.</span><span class="s1">dtype</span>
        <span class="s2">try</span><span class="s3">:</span>
            <span class="s1">Xt_enc </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_encoder</span><span class="s3">.</span><span class="s1">transform</span><span class="s3">(</span><span class="s1">Xt</span><span class="s3">)</span>
        <span class="s2">finally</span><span class="s3">:</span>
            <span class="s0"># revert the initial dtype to avoid modifying self.</span>
            <span class="s1">self</span><span class="s3">.</span><span class="s1">_encoder</span><span class="s3">.</span><span class="s1">dtype </span><span class="s3">= </span><span class="s1">dtype_init</span>
        <span class="s2">return </span><span class="s1">Xt_enc</span>

    <span class="s2">def </span><span class="s1">inverse_transform</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">=</span><span class="s2">None</span><span class="s3">, *, </span><span class="s1">Xt</span><span class="s3">=</span><span class="s2">None</span><span class="s3">):</span>
        <span class="s4">&quot;&quot;&quot; 
        Transform discretized data back to original feature space. 
 
        Note that this function does not regenerate the original data 
        due to discretization rounding. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Transformed data in the binned space. 
 
        Xt : array-like of shape (n_samples, n_features) 
            Transformed data in the binned space. 
 
            .. deprecated:: 1.5 
                `Xt` was deprecated in 1.5 and will be removed in 1.7. Use `X` instead. 
 
        Returns 
        ------- 
        Xinv : ndarray, dtype={np.float32, np.float64} 
            Data in the original feature space. 
        &quot;&quot;&quot;</span>
        <span class="s1">X </span><span class="s3">= </span><span class="s1">_deprecate_Xt_in_inverse_transform</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">Xt</span><span class="s3">)</span>

        <span class="s1">check_is_fitted</span><span class="s3">(</span><span class="s1">self</span><span class="s3">)</span>

        <span class="s2">if </span><span class="s5">&quot;onehot&quot; </span><span class="s2">in </span><span class="s1">self</span><span class="s3">.</span><span class="s1">encode</span><span class="s3">:</span>
            <span class="s1">X </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_encoder</span><span class="s3">.</span><span class="s1">inverse_transform</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>

        <span class="s1">Xinv </span><span class="s3">= </span><span class="s1">check_array</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">copy</span><span class="s3">=</span><span class="s2">True</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">=(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float64</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">))</span>
        <span class="s1">n_features </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">n_bins_</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s6">0</span><span class="s3">]</span>
        <span class="s2">if </span><span class="s1">Xinv</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s6">1</span><span class="s3">] != </span><span class="s1">n_features</span><span class="s3">:</span>
            <span class="s2">raise </span><span class="s1">ValueError</span><span class="s3">(</span>
                <span class="s5">&quot;Incorrect number of features. Expecting {}, received {}.&quot;</span><span class="s3">.</span><span class="s1">format</span><span class="s3">(</span>
                    <span class="s1">n_features</span><span class="s3">, </span><span class="s1">Xinv</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s6">1</span><span class="s3">]</span>
                <span class="s3">)</span>
            <span class="s3">)</span>

        <span class="s2">for </span><span class="s1">jj </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">):</span>
            <span class="s1">bin_edges </span><span class="s3">= </span><span class="s1">self</span><span class="s3">.</span><span class="s1">bin_edges_</span><span class="s3">[</span><span class="s1">jj</span><span class="s3">]</span>
            <span class="s1">bin_centers </span><span class="s3">= (</span><span class="s1">bin_edges</span><span class="s3">[</span><span class="s6">1</span><span class="s3">:] + </span><span class="s1">bin_edges</span><span class="s3">[:-</span><span class="s6">1</span><span class="s3">]) * </span><span class="s6">0.5</span>
            <span class="s1">Xinv</span><span class="s3">[:, </span><span class="s1">jj</span><span class="s3">] = </span><span class="s1">bin_centers</span><span class="s3">[(</span><span class="s1">Xinv</span><span class="s3">[:, </span><span class="s1">jj</span><span class="s3">]).</span><span class="s1">astype</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">int64</span><span class="s3">)]</span>

        <span class="s2">return </span><span class="s1">Xinv</span>

    <span class="s2">def </span><span class="s1">get_feature_names_out</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">input_features</span><span class="s3">=</span><span class="s2">None</span><span class="s3">):</span>
        <span class="s4">&quot;&quot;&quot;Get output feature names. 
 
        Parameters 
        ---------- 
        input_features : array-like of str or None, default=None 
            Input features. 
 
            - If `input_features` is `None`, then `feature_names_in_` is 
              used as feature names in. If `feature_names_in_` is not defined, 
              then the following input feature names are generated: 
              `[&quot;x0&quot;, &quot;x1&quot;, ..., &quot;x(n_features_in_ - 1)&quot;]`. 
            - If `input_features` is an array-like, then `input_features` must 
              match `feature_names_in_` if `feature_names_in_` is defined. 
 
        Returns 
        ------- 
        feature_names_out : ndarray of str objects 
            Transformed feature names. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s5">&quot;n_features_in_&quot;</span><span class="s3">)</span>
        <span class="s1">input_features </span><span class="s3">= </span><span class="s1">_check_feature_names_in</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">input_features</span><span class="s3">)</span>
        <span class="s2">if </span><span class="s1">hasattr</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s5">&quot;_encoder&quot;</span><span class="s3">):</span>
            <span class="s2">return </span><span class="s1">self</span><span class="s3">.</span><span class="s1">_encoder</span><span class="s3">.</span><span class="s1">get_feature_names_out</span><span class="s3">(</span><span class="s1">input_features</span><span class="s3">)</span>

        <span class="s0"># ordinal encoding</span>
        <span class="s2">return </span><span class="s1">input_features</span>
</pre>
</body>
</html>