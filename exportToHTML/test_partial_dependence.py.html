<html>
<head>
<title>test_partial_dependence.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #cf8e6d;}
.s3 { color: #bcbec4;}
.s4 { color: #7a7e85;}
.s5 { color: #2aacb8;}
.s6 { color: #6aab73;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_partial_dependence.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Testing for the partial dependence module. 
&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pytest</span>

<span class="s2">import </span><span class="s1">sklearn</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">base </span><span class="s2">import </span><span class="s1">BaseEstimator</span><span class="s3">, </span><span class="s1">ClassifierMixin</span><span class="s3">, </span><span class="s1">clone</span><span class="s3">, </span><span class="s1">is_regressor</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">cluster </span><span class="s2">import </span><span class="s1">KMeans</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">compose </span><span class="s2">import </span><span class="s1">make_column_transformer</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">datasets </span><span class="s2">import </span><span class="s1">load_iris</span><span class="s3">, </span><span class="s1">make_classification</span><span class="s3">, </span><span class="s1">make_regression</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">dummy </span><span class="s2">import </span><span class="s1">DummyClassifier</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">ensemble </span><span class="s2">import </span><span class="s3">(</span>
    <span class="s1">GradientBoostingClassifier</span><span class="s3">,</span>
    <span class="s1">GradientBoostingRegressor</span><span class="s3">,</span>
    <span class="s1">HistGradientBoostingClassifier</span><span class="s3">,</span>
    <span class="s1">HistGradientBoostingRegressor</span><span class="s3">,</span>
    <span class="s1">RandomForestRegressor</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">exceptions </span><span class="s2">import </span><span class="s1">NotFittedError</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">inspection </span><span class="s2">import </span><span class="s1">partial_dependence</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">inspection</span><span class="s3">.</span><span class="s1">_partial_dependence </span><span class="s2">import </span><span class="s3">(</span>
    <span class="s1">_grid_from_X</span><span class="s3">,</span>
    <span class="s1">_partial_dependence_brute</span><span class="s3">,</span>
    <span class="s1">_partial_dependence_recursion</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">linear_model </span><span class="s2">import </span><span class="s1">LinearRegression</span><span class="s3">, </span><span class="s1">LogisticRegression</span><span class="s3">, </span><span class="s1">MultiTaskLasso</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">metrics </span><span class="s2">import </span><span class="s1">r2_score</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">pipeline </span><span class="s2">import </span><span class="s1">make_pipeline</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">preprocessing </span><span class="s2">import </span><span class="s3">(</span>
    <span class="s1">PolynomialFeatures</span><span class="s3">,</span>
    <span class="s1">RobustScaler</span><span class="s3">,</span>
    <span class="s1">StandardScaler</span><span class="s3">,</span>
    <span class="s1">scale</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">tree </span><span class="s2">import </span><span class="s1">DecisionTreeRegressor</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">tree</span><span class="s3">.</span><span class="s1">tests</span><span class="s3">.</span><span class="s1">test_tree </span><span class="s2">import </span><span class="s1">assert_is_subtree</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">_testing </span><span class="s2">import </span><span class="s1">assert_allclose</span><span class="s3">, </span><span class="s1">assert_array_equal</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">fixes </span><span class="s2">import </span><span class="s1">_IS_32BIT</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">validation </span><span class="s2">import </span><span class="s1">check_random_state</span>

<span class="s4"># toy sample</span>
<span class="s1">X </span><span class="s3">= [[-</span><span class="s5">2</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">], [-</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">], [-</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">2</span><span class="s3">], [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">], [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], [</span><span class="s5">2</span><span class="s3">, </span><span class="s5">1</span><span class="s3">]]</span>
<span class="s1">y </span><span class="s3">= [-</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">]</span>


<span class="s4"># (X, y), n_targets  &lt;-- as expected in the output of partial_dep()</span>
<span class="s1">binary_classification_data </span><span class="s3">= (</span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s5">50</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">), </span><span class="s5">1</span><span class="s3">)</span>
<span class="s1">multiclass_classification_data </span><span class="s3">= (</span>
    <span class="s1">make_classification</span><span class="s3">(</span>
        <span class="s1">n_samples</span><span class="s3">=</span><span class="s5">50</span><span class="s3">, </span><span class="s1">n_classes</span><span class="s3">=</span><span class="s5">3</span><span class="s3">, </span><span class="s1">n_clusters_per_class</span><span class="s3">=</span><span class="s5">1</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span>
    <span class="s3">),</span>
    <span class="s5">3</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s1">regression_data </span><span class="s3">= (</span><span class="s1">make_regression</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s5">50</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">), </span><span class="s5">1</span><span class="s3">)</span>
<span class="s1">multioutput_regression_data </span><span class="s3">= (</span>
    <span class="s1">make_regression</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s5">50</span><span class="s3">, </span><span class="s1">n_targets</span><span class="s3">=</span><span class="s5">2</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">),</span>
    <span class="s5">2</span><span class="s3">,</span>
<span class="s3">)</span>

<span class="s4"># iris</span>
<span class="s1">iris </span><span class="s3">= </span><span class="s1">load_iris</span><span class="s3">()</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;Estimator, method, data&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s3">(</span><span class="s1">GradientBoostingClassifier</span><span class="s3">, </span><span class="s6">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">binary_classification_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">GradientBoostingClassifier</span><span class="s3">, </span><span class="s6">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">multiclass_classification_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">GradientBoostingClassifier</span><span class="s3">, </span><span class="s6">&quot;brute&quot;</span><span class="s3">, </span><span class="s1">binary_classification_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">GradientBoostingClassifier</span><span class="s3">, </span><span class="s6">&quot;brute&quot;</span><span class="s3">, </span><span class="s1">multiclass_classification_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">GradientBoostingRegressor</span><span class="s3">, </span><span class="s6">&quot;auto&quot;</span><span class="s3">, </span><span class="s1">regression_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">GradientBoostingRegressor</span><span class="s3">, </span><span class="s6">&quot;brute&quot;</span><span class="s3">, </span><span class="s1">regression_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">DecisionTreeRegressor</span><span class="s3">, </span><span class="s6">&quot;brute&quot;</span><span class="s3">, </span><span class="s1">regression_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">LinearRegression</span><span class="s3">, </span><span class="s6">&quot;brute&quot;</span><span class="s3">, </span><span class="s1">regression_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">LinearRegression</span><span class="s3">, </span><span class="s6">&quot;brute&quot;</span><span class="s3">, </span><span class="s1">multioutput_regression_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">LogisticRegression</span><span class="s3">, </span><span class="s6">&quot;brute&quot;</span><span class="s3">, </span><span class="s1">binary_classification_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">LogisticRegression</span><span class="s3">, </span><span class="s6">&quot;brute&quot;</span><span class="s3">, </span><span class="s1">multiclass_classification_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">MultiTaskLasso</span><span class="s3">, </span><span class="s6">&quot;brute&quot;</span><span class="s3">, </span><span class="s1">multioutput_regression_data</span><span class="s3">),</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;grid_resolution&quot;</span><span class="s3">, (</span><span class="s5">5</span><span class="s3">, </span><span class="s5">10</span><span class="s3">))</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;features&quot;</span><span class="s3">, ([</span><span class="s5">1</span><span class="s3">], [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">]))</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;kind&quot;</span><span class="s3">, (</span><span class="s6">&quot;average&quot;</span><span class="s3">, </span><span class="s6">&quot;individual&quot;</span><span class="s3">, </span><span class="s6">&quot;both&quot;</span><span class="s3">))</span>
<span class="s2">def </span><span class="s1">test_output_shape</span><span class="s3">(</span><span class="s1">Estimator</span><span class="s3">, </span><span class="s1">method</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">grid_resolution</span><span class="s3">, </span><span class="s1">features</span><span class="s3">, </span><span class="s1">kind</span><span class="s3">):</span>
    <span class="s4"># Check that partial_dependence has consistent output shape for different</span>
    <span class="s4"># kinds of estimators:</span>
    <span class="s4"># - classifiers with binary and multiclass settings</span>
    <span class="s4"># - regressors</span>
    <span class="s4"># - multi-task regressors</span>

    <span class="s1">est </span><span class="s3">= </span><span class="s1">Estimator</span><span class="s3">()</span>
    <span class="s2">if </span><span class="s1">hasattr</span><span class="s3">(</span><span class="s1">est</span><span class="s3">, </span><span class="s6">&quot;n_estimators&quot;</span><span class="s3">):</span>
        <span class="s1">est</span><span class="s3">.</span><span class="s1">set_params</span><span class="s3">(</span><span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">2</span><span class="s3">)  </span><span class="s4"># speed-up computations</span>

    <span class="s4"># n_target corresponds to the number of classes (1 for binary classif) or</span>
    <span class="s4"># the number of tasks / outputs in multi task settings. It's equal to 1 for</span>
    <span class="s4"># classical regression_data.</span>
    <span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">), </span><span class="s1">n_targets </span><span class="s3">= </span><span class="s1">data</span>
    <span class="s1">n_instances </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">]</span>

    <span class="s1">est</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">result </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span>
        <span class="s1">est</span><span class="s3">,</span>
        <span class="s1">X</span><span class="s3">=</span><span class="s1">X</span><span class="s3">,</span>
        <span class="s1">features</span><span class="s3">=</span><span class="s1">features</span><span class="s3">,</span>
        <span class="s1">method</span><span class="s3">=</span><span class="s1">method</span><span class="s3">,</span>
        <span class="s1">kind</span><span class="s3">=</span><span class="s1">kind</span><span class="s3">,</span>
        <span class="s1">grid_resolution</span><span class="s3">=</span><span class="s1">grid_resolution</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">pdp</span><span class="s3">, </span><span class="s1">axes </span><span class="s3">= </span><span class="s1">result</span><span class="s3">, </span><span class="s1">result</span><span class="s3">[</span><span class="s6">&quot;grid_values&quot;</span><span class="s3">]</span>

    <span class="s1">expected_pdp_shape </span><span class="s3">= (</span><span class="s1">n_targets</span><span class="s3">, *[</span><span class="s1">grid_resolution </span><span class="s2">for </span><span class="s1">_ </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">len</span><span class="s3">(</span><span class="s1">features</span><span class="s3">))])</span>
    <span class="s1">expected_ice_shape </span><span class="s3">= (</span>
        <span class="s1">n_targets</span><span class="s3">,</span>
        <span class="s1">n_instances</span><span class="s3">,</span>
        <span class="s3">*[</span><span class="s1">grid_resolution </span><span class="s2">for </span><span class="s1">_ </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">len</span><span class="s3">(</span><span class="s1">features</span><span class="s3">))],</span>
    <span class="s3">)</span>
    <span class="s2">if </span><span class="s1">kind </span><span class="s3">== </span><span class="s6">&quot;average&quot;</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">pdp</span><span class="s3">.</span><span class="s1">average</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== </span><span class="s1">expected_pdp_shape</span>
    <span class="s2">elif </span><span class="s1">kind </span><span class="s3">== </span><span class="s6">&quot;individual&quot;</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">pdp</span><span class="s3">.</span><span class="s1">individual</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== </span><span class="s1">expected_ice_shape</span>
    <span class="s2">else</span><span class="s3">:  </span><span class="s4"># 'both'</span>
        <span class="s2">assert </span><span class="s1">pdp</span><span class="s3">.</span><span class="s1">average</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== </span><span class="s1">expected_pdp_shape</span>
        <span class="s2">assert </span><span class="s1">pdp</span><span class="s3">.</span><span class="s1">individual</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== </span><span class="s1">expected_ice_shape</span>

    <span class="s1">expected_axes_shape </span><span class="s3">= (</span><span class="s1">len</span><span class="s3">(</span><span class="s1">features</span><span class="s3">), </span><span class="s1">grid_resolution</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">axes </span><span class="s2">is not None</span>
    <span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">asarray</span><span class="s3">(</span><span class="s1">axes</span><span class="s3">).</span><span class="s1">shape </span><span class="s3">== </span><span class="s1">expected_axes_shape</span>


<span class="s2">def </span><span class="s1">test_grid_from_X</span><span class="s3">():</span>
    <span class="s4"># tests for _grid_from_X: sanity check for output, and for shapes.</span>

    <span class="s4"># Make sure that the grid is a cartesian product of the input (it will use</span>
    <span class="s4"># the unique values instead of the percentiles)</span>
    <span class="s1">percentiles </span><span class="s3">= (</span><span class="s5">0.05</span><span class="s3">, </span><span class="s5">0.95</span><span class="s3">)</span>
    <span class="s1">grid_resolution </span><span class="s3">= </span><span class="s5">100</span>
    <span class="s1">is_categorical </span><span class="s3">= [</span><span class="s2">False</span><span class="s3">, </span><span class="s2">False</span><span class="s3">]</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">asarray</span><span class="s3">([[</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], [</span><span class="s5">3</span><span class="s3">, </span><span class="s5">4</span><span class="s3">]])</span>
    <span class="s1">grid</span><span class="s3">, </span><span class="s1">axes </span><span class="s3">= </span><span class="s1">_grid_from_X</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">percentiles</span><span class="s3">, </span><span class="s1">is_categorical</span><span class="s3">, </span><span class="s1">grid_resolution</span><span class="s3">)</span>
    <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">grid</span><span class="s3">, [[</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">4</span><span class="s3">], [</span><span class="s5">3</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], [</span><span class="s5">3</span><span class="s3">, </span><span class="s5">4</span><span class="s3">]])</span>
    <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">axes</span><span class="s3">, </span><span class="s1">X</span><span class="s3">.</span><span class="s1">T</span><span class="s3">)</span>

    <span class="s4"># test shapes of returned objects depending on the number of unique values</span>
    <span class="s4"># for a feature.</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">grid_resolution </span><span class="s3">= </span><span class="s5">15</span>

    <span class="s4"># n_unique_values &gt; grid_resolution</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=(</span><span class="s5">20</span><span class="s3">, </span><span class="s5">2</span><span class="s3">))</span>
    <span class="s1">grid</span><span class="s3">, </span><span class="s1">axes </span><span class="s3">= </span><span class="s1">_grid_from_X</span><span class="s3">(</span>
        <span class="s1">X</span><span class="s3">, </span><span class="s1">percentiles</span><span class="s3">, </span><span class="s1">is_categorical</span><span class="s3">, </span><span class="s1">grid_resolution</span><span class="s3">=</span><span class="s1">grid_resolution</span>
    <span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">grid</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== (</span><span class="s1">grid_resolution </span><span class="s3">* </span><span class="s1">grid_resolution</span><span class="s3">, </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">1</span><span class="s3">])</span>
    <span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">asarray</span><span class="s3">(</span><span class="s1">axes</span><span class="s3">).</span><span class="s1">shape </span><span class="s3">== (</span><span class="s5">2</span><span class="s3">, </span><span class="s1">grid_resolution</span><span class="s3">)</span>

    <span class="s4"># n_unique_values &lt; grid_resolution, will use actual values</span>
    <span class="s1">n_unique_values </span><span class="s3">= </span><span class="s5">12</span>
    <span class="s1">X</span><span class="s3">[</span><span class="s1">n_unique_values </span><span class="s3">- </span><span class="s5">1 </span><span class="s3">:, </span><span class="s5">0</span><span class="s3">] = </span><span class="s5">12345</span>
    <span class="s1">rng</span><span class="s3">.</span><span class="s1">shuffle</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)  </span><span class="s4"># just to make sure the order is irrelevant</span>
    <span class="s1">grid</span><span class="s3">, </span><span class="s1">axes </span><span class="s3">= </span><span class="s1">_grid_from_X</span><span class="s3">(</span>
        <span class="s1">X</span><span class="s3">, </span><span class="s1">percentiles</span><span class="s3">, </span><span class="s1">is_categorical</span><span class="s3">, </span><span class="s1">grid_resolution</span><span class="s3">=</span><span class="s1">grid_resolution</span>
    <span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">grid</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== (</span><span class="s1">n_unique_values </span><span class="s3">* </span><span class="s1">grid_resolution</span><span class="s3">, </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">1</span><span class="s3">])</span>
    <span class="s4"># axes is a list of arrays of different shapes</span>
    <span class="s2">assert </span><span class="s1">axes</span><span class="s3">[</span><span class="s5">0</span><span class="s3">].</span><span class="s1">shape </span><span class="s3">== (</span><span class="s1">n_unique_values</span><span class="s3">,)</span>
    <span class="s2">assert </span><span class="s1">axes</span><span class="s3">[</span><span class="s5">1</span><span class="s3">].</span><span class="s1">shape </span><span class="s3">== (</span><span class="s1">grid_resolution</span><span class="s3">,)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;grid_resolution&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s5">2</span><span class="s3">,  </span><span class="s4"># since n_categories &gt; 2, we should not use quantiles resampling</span>
        <span class="s5">100</span><span class="s3">,</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_grid_from_X_with_categorical</span><span class="s3">(</span><span class="s1">grid_resolution</span><span class="s3">):</span>
    <span class="s0">&quot;&quot;&quot;Check that `_grid_from_X` always sample from categories and does not 
    depend from the percentiles. 
    &quot;&quot;&quot;</span>
    <span class="s1">pd </span><span class="s3">= </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">importorskip</span><span class="s3">(</span><span class="s6">&quot;pandas&quot;</span><span class="s3">)</span>
    <span class="s1">percentiles </span><span class="s3">= (</span><span class="s5">0.05</span><span class="s3">, </span><span class="s5">0.95</span><span class="s3">)</span>
    <span class="s1">is_categorical </span><span class="s3">= [</span><span class="s2">True</span><span class="s3">]</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">pd</span><span class="s3">.</span><span class="s1">DataFrame</span><span class="s3">({</span><span class="s6">&quot;cat_feature&quot;</span><span class="s3">: [</span><span class="s6">&quot;A&quot;</span><span class="s3">, </span><span class="s6">&quot;B&quot;</span><span class="s3">, </span><span class="s6">&quot;C&quot;</span><span class="s3">, </span><span class="s6">&quot;A&quot;</span><span class="s3">, </span><span class="s6">&quot;B&quot;</span><span class="s3">, </span><span class="s6">&quot;D&quot;</span><span class="s3">, </span><span class="s6">&quot;E&quot;</span><span class="s3">]})</span>
    <span class="s1">grid</span><span class="s3">, </span><span class="s1">axes </span><span class="s3">= </span><span class="s1">_grid_from_X</span><span class="s3">(</span>
        <span class="s1">X</span><span class="s3">, </span><span class="s1">percentiles</span><span class="s3">, </span><span class="s1">is_categorical</span><span class="s3">, </span><span class="s1">grid_resolution</span><span class="s3">=</span><span class="s1">grid_resolution</span>
    <span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">grid</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== (</span><span class="s5">5</span><span class="s3">, </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">1</span><span class="s3">])</span>
    <span class="s2">assert </span><span class="s1">axes</span><span class="s3">[</span><span class="s5">0</span><span class="s3">].</span><span class="s1">shape </span><span class="s3">== (</span><span class="s5">5</span><span class="s3">,)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;grid_resolution&quot;</span><span class="s3">, [</span><span class="s5">3</span><span class="s3">, </span><span class="s5">100</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_grid_from_X_heterogeneous_type</span><span class="s3">(</span><span class="s1">grid_resolution</span><span class="s3">):</span>
    <span class="s0">&quot;&quot;&quot;Check that `_grid_from_X` always sample from categories and does not 
    depend from the percentiles. 
    &quot;&quot;&quot;</span>
    <span class="s1">pd </span><span class="s3">= </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">importorskip</span><span class="s3">(</span><span class="s6">&quot;pandas&quot;</span><span class="s3">)</span>
    <span class="s1">percentiles </span><span class="s3">= (</span><span class="s5">0.05</span><span class="s3">, </span><span class="s5">0.95</span><span class="s3">)</span>
    <span class="s1">is_categorical </span><span class="s3">= [</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">]</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">pd</span><span class="s3">.</span><span class="s1">DataFrame</span><span class="s3">(</span>
        <span class="s3">{</span>
            <span class="s6">&quot;cat&quot;</span><span class="s3">: [</span><span class="s6">&quot;A&quot;</span><span class="s3">, </span><span class="s6">&quot;B&quot;</span><span class="s3">, </span><span class="s6">&quot;C&quot;</span><span class="s3">, </span><span class="s6">&quot;A&quot;</span><span class="s3">, </span><span class="s6">&quot;B&quot;</span><span class="s3">, </span><span class="s6">&quot;D&quot;</span><span class="s3">, </span><span class="s6">&quot;E&quot;</span><span class="s3">, </span><span class="s6">&quot;A&quot;</span><span class="s3">, </span><span class="s6">&quot;B&quot;</span><span class="s3">, </span><span class="s6">&quot;D&quot;</span><span class="s3">],</span>
            <span class="s6">&quot;num&quot;</span><span class="s3">: [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">, </span><span class="s5">5</span><span class="s3">, </span><span class="s5">6</span><span class="s3">, </span><span class="s5">6</span><span class="s3">, </span><span class="s5">6</span><span class="s3">, </span><span class="s5">6</span><span class="s3">, </span><span class="s5">8</span><span class="s3">],</span>
        <span class="s3">}</span>
    <span class="s3">)</span>
    <span class="s1">nunique </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">nunique</span><span class="s3">()</span>

    <span class="s1">grid</span><span class="s3">, </span><span class="s1">axes </span><span class="s3">= </span><span class="s1">_grid_from_X</span><span class="s3">(</span>
        <span class="s1">X</span><span class="s3">, </span><span class="s1">percentiles</span><span class="s3">, </span><span class="s1">is_categorical</span><span class="s3">, </span><span class="s1">grid_resolution</span><span class="s3">=</span><span class="s1">grid_resolution</span>
    <span class="s3">)</span>
    <span class="s2">if </span><span class="s1">grid_resolution </span><span class="s3">== </span><span class="s5">3</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">grid</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== (</span><span class="s5">15</span><span class="s3">, </span><span class="s5">2</span><span class="s3">)</span>
        <span class="s2">assert </span><span class="s1">axes</span><span class="s3">[</span><span class="s5">0</span><span class="s3">].</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">] == </span><span class="s1">nunique</span><span class="s3">[</span><span class="s6">&quot;num&quot;</span><span class="s3">]</span>
        <span class="s2">assert </span><span class="s1">axes</span><span class="s3">[</span><span class="s5">1</span><span class="s3">].</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">] == </span><span class="s1">grid_resolution</span>
    <span class="s2">else</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">grid</span><span class="s3">.</span><span class="s1">shape </span><span class="s3">== (</span><span class="s5">25</span><span class="s3">, </span><span class="s5">2</span><span class="s3">)</span>
        <span class="s2">assert </span><span class="s1">axes</span><span class="s3">[</span><span class="s5">0</span><span class="s3">].</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">] == </span><span class="s1">nunique</span><span class="s3">[</span><span class="s6">&quot;cat&quot;</span><span class="s3">]</span>
        <span class="s2">assert </span><span class="s1">axes</span><span class="s3">[</span><span class="s5">1</span><span class="s3">].</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">] == </span><span class="s1">nunique</span><span class="s3">[</span><span class="s6">&quot;cat&quot;</span><span class="s3">]</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;grid_resolution, percentiles, err_msg&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s3">(</span><span class="s5">2</span><span class="s3">, (</span><span class="s5">0</span><span class="s3">, </span><span class="s5">0.0001</span><span class="s3">), </span><span class="s6">&quot;percentiles are too close&quot;</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s5">100</span><span class="s3">, (</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">, </span><span class="s5">3</span><span class="s3">, </span><span class="s5">4</span><span class="s3">), </span><span class="s6">&quot;'percentiles' must be a sequence of 2 elements&quot;</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s5">100</span><span class="s3">, </span><span class="s5">12345</span><span class="s3">, </span><span class="s6">&quot;'percentiles' must be a sequence of 2 elements&quot;</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s5">100</span><span class="s3">, (-</span><span class="s5">1</span><span class="s3">, </span><span class="s5">0.95</span><span class="s3">), </span><span class="s6">r&quot;'percentiles' values must be in \[0, 1\]&quot;</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s5">100</span><span class="s3">, (</span><span class="s5">0.05</span><span class="s3">, </span><span class="s5">2</span><span class="s3">), </span><span class="s6">r&quot;'percentiles' values must be in \[0, 1\]&quot;</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s5">100</span><span class="s3">, (</span><span class="s5">0.9</span><span class="s3">, </span><span class="s5">0.1</span><span class="s3">), </span><span class="s6">r&quot;percentiles\[0\] must be strictly less than&quot;</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s5">1</span><span class="s3">, (</span><span class="s5">0.05</span><span class="s3">, </span><span class="s5">0.95</span><span class="s3">), </span><span class="s6">&quot;'grid_resolution' must be strictly greater than 1&quot;</span><span class="s3">),</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_grid_from_X_error</span><span class="s3">(</span><span class="s1">grid_resolution</span><span class="s3">, </span><span class="s1">percentiles</span><span class="s3">, </span><span class="s1">err_msg</span><span class="s3">):</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">asarray</span><span class="s3">([[</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], [</span><span class="s5">3</span><span class="s3">, </span><span class="s5">4</span><span class="s3">]])</span>
    <span class="s1">is_categorical </span><span class="s3">= [</span><span class="s2">False</span><span class="s3">]</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">err_msg</span><span class="s3">):</span>
        <span class="s1">_grid_from_X</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">percentiles</span><span class="s3">, </span><span class="s1">is_categorical</span><span class="s3">, </span><span class="s1">grid_resolution</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;target_feature&quot;</span><span class="s3">, </span><span class="s1">range</span><span class="s3">(</span><span class="s5">5</span><span class="s3">))</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;est, method&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s3">(</span><span class="s1">LinearRegression</span><span class="s3">(), </span><span class="s6">&quot;brute&quot;</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">GradientBoostingRegressor</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">), </span><span class="s6">&quot;brute&quot;</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">GradientBoostingRegressor</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">), </span><span class="s6">&quot;recursion&quot;</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">HistGradientBoostingRegressor</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">), </span><span class="s6">&quot;brute&quot;</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">HistGradientBoostingRegressor</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">), </span><span class="s6">&quot;recursion&quot;</span><span class="s3">),</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_partial_dependence_helpers</span><span class="s3">(</span><span class="s1">est</span><span class="s3">, </span><span class="s1">method</span><span class="s3">, </span><span class="s1">target_feature</span><span class="s3">):</span>
    <span class="s4"># Check that what is returned by _partial_dependence_brute or</span>
    <span class="s4"># _partial_dependence_recursion is equivalent to manually setting a target</span>
    <span class="s4"># feature to a given value, and computing the average prediction over all</span>
    <span class="s4"># samples.</span>
    <span class="s4"># This also checks that the brute and recursion methods give the same</span>
    <span class="s4"># output.</span>
    <span class="s4"># Note that even on the trainset, the brute and the recursion methods</span>
    <span class="s4"># aren't always strictly equivalent, in particular when the slow method</span>
    <span class="s4"># generates unrealistic samples that have low mass in the joint</span>
    <span class="s4"># distribution of the input features, and when some of the features are</span>
    <span class="s4"># dependent. Hence the high tolerance on the checks.</span>

    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_regression</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s5">5</span><span class="s3">, </span><span class="s1">n_informative</span><span class="s3">=</span><span class="s5">5</span><span class="s3">)</span>
    <span class="s4"># The 'init' estimator for GBDT (here the average prediction) isn't taken</span>
    <span class="s4"># into account with the recursion method, for technical reasons. We set</span>
    <span class="s4"># the mean to 0 to that this 'bug' doesn't have any effect.</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">y </span><span class="s3">- </span><span class="s1">y</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">()</span>
    <span class="s1">est</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s4"># target feature will be set to .5 and then to 123</span>
    <span class="s1">features </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s1">target_feature</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">intp</span><span class="s3">)</span>
    <span class="s1">grid </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[</span><span class="s5">0.5</span><span class="s3">], [</span><span class="s5">123</span><span class="s3">]])</span>

    <span class="s2">if </span><span class="s1">method </span><span class="s3">== </span><span class="s6">&quot;brute&quot;</span><span class="s3">:</span>
        <span class="s1">pdp</span><span class="s3">, </span><span class="s1">predictions </span><span class="s3">= </span><span class="s1">_partial_dependence_brute</span><span class="s3">(</span>
            <span class="s1">est</span><span class="s3">, </span><span class="s1">grid</span><span class="s3">, </span><span class="s1">features</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">response_method</span><span class="s3">=</span><span class="s6">&quot;auto&quot;</span>
        <span class="s3">)</span>
    <span class="s2">else</span><span class="s3">:</span>
        <span class="s1">pdp </span><span class="s3">= </span><span class="s1">_partial_dependence_recursion</span><span class="s3">(</span><span class="s1">est</span><span class="s3">, </span><span class="s1">grid</span><span class="s3">, </span><span class="s1">features</span><span class="s3">)</span>

    <span class="s1">mean_predictions </span><span class="s3">= []</span>
    <span class="s2">for </span><span class="s1">val </span><span class="s2">in </span><span class="s3">(</span><span class="s5">0.5</span><span class="s3">, </span><span class="s5">123</span><span class="s3">):</span>
        <span class="s1">X_ </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">copy</span><span class="s3">()</span>
        <span class="s1">X_</span><span class="s3">[:, </span><span class="s1">target_feature</span><span class="s3">] = </span><span class="s1">val</span>
        <span class="s1">mean_predictions</span><span class="s3">.</span><span class="s1">append</span><span class="s3">(</span><span class="s1">est</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X_</span><span class="s3">).</span><span class="s1">mean</span><span class="s3">())</span>

    <span class="s1">pdp </span><span class="s3">= </span><span class="s1">pdp</span><span class="s3">[</span><span class="s5">0</span><span class="s3">]  </span><span class="s4"># (shape is (1, 2) so make it (2,))</span>

    <span class="s4"># allow for greater margin for error with recursion method</span>
    <span class="s1">rtol </span><span class="s3">= </span><span class="s5">1e-1 </span><span class="s2">if </span><span class="s1">method </span><span class="s3">== </span><span class="s6">&quot;recursion&quot; </span><span class="s2">else </span><span class="s5">1e-3</span>
    <span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">allclose</span><span class="s3">(</span><span class="s1">pdp</span><span class="s3">, </span><span class="s1">mean_predictions</span><span class="s3">, </span><span class="s1">rtol</span><span class="s3">=</span><span class="s1">rtol</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;seed&quot;</span><span class="s3">, </span><span class="s1">range</span><span class="s3">(</span><span class="s5">1</span><span class="s3">))</span>
<span class="s2">def </span><span class="s1">test_recursion_decision_tree_vs_forest_and_gbdt</span><span class="s3">(</span><span class="s1">seed</span><span class="s3">):</span>
    <span class="s4"># Make sure that the recursion method gives the same results on a</span>
    <span class="s4"># DecisionTreeRegressor and a GradientBoostingRegressor or a</span>
    <span class="s4"># RandomForestRegressor with 1 tree and equivalent parameters.</span>

    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s1">seed</span><span class="s3">)</span>

    <span class="s4"># Purely random dataset to avoid correlated features</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s5">1000</span>
    <span class="s1">n_features </span><span class="s3">= </span><span class="s5">5</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">)</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">) * </span><span class="s5">10</span>

    <span class="s4"># The 'init' estimator for GBDT (here the average prediction) isn't taken</span>
    <span class="s4"># into account with the recursion method, for technical reasons. We set</span>
    <span class="s4"># the mean to 0 to that this 'bug' doesn't have any effect.</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">y </span><span class="s3">- </span><span class="s1">y</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">()</span>

    <span class="s4"># set max_depth not too high to avoid splits with same gain but different</span>
    <span class="s4"># features</span>
    <span class="s1">max_depth </span><span class="s3">= </span><span class="s5">5</span>

    <span class="s1">tree_seed </span><span class="s3">= </span><span class="s5">0</span>
    <span class="s1">forest </span><span class="s3">= </span><span class="s1">RandomForestRegressor</span><span class="s3">(</span>
        <span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">1</span><span class="s3">,</span>
        <span class="s1">max_features</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
        <span class="s1">bootstrap</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
        <span class="s1">max_depth</span><span class="s3">=</span><span class="s1">max_depth</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s1">tree_seed</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s4"># The forest will use ensemble.base._set_random_states to set the</span>
    <span class="s4"># random_state of the tree sub-estimator. We simulate this here to have</span>
    <span class="s4"># equivalent estimators.</span>
    <span class="s1">equiv_random_state </span><span class="s3">= </span><span class="s1">check_random_state</span><span class="s3">(</span><span class="s1">tree_seed</span><span class="s3">).</span><span class="s1">randint</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">iinfo</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">int32</span><span class="s3">).</span><span class="s1">max</span><span class="s3">)</span>
    <span class="s1">gbdt </span><span class="s3">= </span><span class="s1">GradientBoostingRegressor</span><span class="s3">(</span>
        <span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">1</span><span class="s3">,</span>
        <span class="s1">learning_rate</span><span class="s3">=</span><span class="s5">1</span><span class="s3">,</span>
        <span class="s1">criterion</span><span class="s3">=</span><span class="s6">&quot;squared_error&quot;</span><span class="s3">,</span>
        <span class="s1">max_depth</span><span class="s3">=</span><span class="s1">max_depth</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s1">equiv_random_state</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">tree </span><span class="s3">= </span><span class="s1">DecisionTreeRegressor</span><span class="s3">(</span><span class="s1">max_depth</span><span class="s3">=</span><span class="s1">max_depth</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s1">equiv_random_state</span><span class="s3">)</span>

    <span class="s1">forest</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">gbdt</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">tree</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s4"># sanity check: if the trees aren't the same, the PD values won't be equal</span>
    <span class="s2">try</span><span class="s3">:</span>
        <span class="s1">assert_is_subtree</span><span class="s3">(</span><span class="s1">tree</span><span class="s3">.</span><span class="s1">tree_</span><span class="s3">, </span><span class="s1">gbdt</span><span class="s3">[</span><span class="s5">0</span><span class="s3">, </span><span class="s5">0</span><span class="s3">].</span><span class="s1">tree_</span><span class="s3">)</span>
        <span class="s1">assert_is_subtree</span><span class="s3">(</span><span class="s1">tree</span><span class="s3">.</span><span class="s1">tree_</span><span class="s3">, </span><span class="s1">forest</span><span class="s3">[</span><span class="s5">0</span><span class="s3">].</span><span class="s1">tree_</span><span class="s3">)</span>
    <span class="s2">except </span><span class="s1">AssertionError</span><span class="s3">:</span>
        <span class="s4"># For some reason the trees aren't exactly equal on 32bits, so the PDs</span>
        <span class="s4"># cannot be equal either. See</span>
        <span class="s4"># https://github.com/scikit-learn/scikit-learn/issues/8853</span>
        <span class="s2">assert </span><span class="s1">_IS_32BIT</span><span class="s3">, </span><span class="s6">&quot;this should only fail on 32 bit platforms&quot;</span>
        <span class="s2">return</span>

    <span class="s1">grid </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s5">50</span><span class="s3">).</span><span class="s1">reshape</span><span class="s3">(-</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">f </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">):</span>
        <span class="s1">features </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s1">f</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">intp</span><span class="s3">)</span>

        <span class="s1">pdp_forest </span><span class="s3">= </span><span class="s1">_partial_dependence_recursion</span><span class="s3">(</span><span class="s1">forest</span><span class="s3">, </span><span class="s1">grid</span><span class="s3">, </span><span class="s1">features</span><span class="s3">)</span>
        <span class="s1">pdp_gbdt </span><span class="s3">= </span><span class="s1">_partial_dependence_recursion</span><span class="s3">(</span><span class="s1">gbdt</span><span class="s3">, </span><span class="s1">grid</span><span class="s3">, </span><span class="s1">features</span><span class="s3">)</span>
        <span class="s1">pdp_tree </span><span class="s3">= </span><span class="s1">_partial_dependence_recursion</span><span class="s3">(</span><span class="s1">tree</span><span class="s3">, </span><span class="s1">grid</span><span class="s3">, </span><span class="s1">features</span><span class="s3">)</span>

        <span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">pdp_gbdt</span><span class="s3">, </span><span class="s1">pdp_tree</span><span class="s3">)</span>
        <span class="s1">np</span><span class="s3">.</span><span class="s1">testing</span><span class="s3">.</span><span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">pdp_forest</span><span class="s3">, </span><span class="s1">pdp_tree</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;est&quot;</span><span class="s3">,</span>
    <span class="s3">(</span>
        <span class="s1">GradientBoostingClassifier</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">),</span>
        <span class="s1">HistGradientBoostingClassifier</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">),</span>
    <span class="s3">),</span>
<span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;target_feature&quot;</span><span class="s3">, (</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">, </span><span class="s5">3</span><span class="s3">, </span><span class="s5">4</span><span class="s3">, </span><span class="s5">5</span><span class="s3">))</span>
<span class="s2">def </span><span class="s1">test_recursion_decision_function</span><span class="s3">(</span><span class="s1">est</span><span class="s3">, </span><span class="s1">target_feature</span><span class="s3">):</span>
    <span class="s4"># Make sure the recursion method (implicitly uses decision_function) has</span>
    <span class="s4"># the same result as using brute method with</span>
    <span class="s4"># response_method=decision_function</span>

    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">n_classes</span><span class="s3">=</span><span class="s5">2</span><span class="s3">, </span><span class="s1">n_clusters_per_class</span><span class="s3">=</span><span class="s5">1</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">1</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">y</span><span class="s3">) == </span><span class="s5">0.5  </span><span class="s4"># make sure the init estimator predicts 0 anyway</span>

    <span class="s1">est</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">preds_1 </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span>
        <span class="s1">est</span><span class="s3">,</span>
        <span class="s1">X</span><span class="s3">,</span>
        <span class="s3">[</span><span class="s1">target_feature</span><span class="s3">],</span>
        <span class="s1">response_method</span><span class="s3">=</span><span class="s6">&quot;decision_function&quot;</span><span class="s3">,</span>
        <span class="s1">method</span><span class="s3">=</span><span class="s6">&quot;recursion&quot;</span><span class="s3">,</span>
        <span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">preds_2 </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span>
        <span class="s1">est</span><span class="s3">,</span>
        <span class="s1">X</span><span class="s3">,</span>
        <span class="s3">[</span><span class="s1">target_feature</span><span class="s3">],</span>
        <span class="s1">response_method</span><span class="s3">=</span><span class="s6">&quot;decision_function&quot;</span><span class="s3">,</span>
        <span class="s1">method</span><span class="s3">=</span><span class="s6">&quot;brute&quot;</span><span class="s3">,</span>
        <span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span><span class="s3">,</span>
    <span class="s3">)</span>

    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">preds_1</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">], </span><span class="s1">preds_2</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">], </span><span class="s1">atol</span><span class="s3">=</span><span class="s5">1e-7</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;est&quot;</span><span class="s3">,</span>
    <span class="s3">(</span>
        <span class="s1">LinearRegression</span><span class="s3">(),</span>
        <span class="s1">GradientBoostingRegressor</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">),</span>
        <span class="s1">HistGradientBoostingRegressor</span><span class="s3">(</span>
            <span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">, </span><span class="s1">min_samples_leaf</span><span class="s3">=</span><span class="s5">1</span><span class="s3">, </span><span class="s1">max_leaf_nodes</span><span class="s3">=</span><span class="s2">None</span><span class="s3">, </span><span class="s1">max_iter</span><span class="s3">=</span><span class="s5">1</span>
        <span class="s3">),</span>
        <span class="s1">DecisionTreeRegressor</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">),</span>
    <span class="s3">),</span>
<span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;power&quot;</span><span class="s3">, (</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">))</span>
<span class="s2">def </span><span class="s1">test_partial_dependence_easy_target</span><span class="s3">(</span><span class="s1">est</span><span class="s3">, </span><span class="s1">power</span><span class="s3">):</span>
    <span class="s4"># If the target y only depends on one feature in an obvious way (linear or</span>
    <span class="s4"># quadratic) then the partial dependence for that feature should reflect</span>
    <span class="s4"># it.</span>
    <span class="s4"># We here fit a linear regression_data model (with polynomial features if</span>
    <span class="s4"># needed) and compute r_squared to check that the partial dependence</span>
    <span class="s4"># correctly reflects the target.</span>

    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s5">200</span>
    <span class="s1">target_variable </span><span class="s3">= </span><span class="s5">2</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=(</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s5">5</span><span class="s3">))</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[:, </span><span class="s1">target_variable</span><span class="s3">] ** </span><span class="s1">power</span>

    <span class="s1">est</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">pdp </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span>
        <span class="s1">est</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=[</span><span class="s1">target_variable</span><span class="s3">], </span><span class="s1">X</span><span class="s3">=</span><span class="s1">X</span><span class="s3">, </span><span class="s1">grid_resolution</span><span class="s3">=</span><span class="s5">1000</span><span class="s3">, </span><span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span>
    <span class="s3">)</span>

    <span class="s1">new_X </span><span class="s3">= </span><span class="s1">pdp</span><span class="s3">[</span><span class="s6">&quot;grid_values&quot;</span><span class="s3">][</span><span class="s5">0</span><span class="s3">].</span><span class="s1">reshape</span><span class="s3">(-</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">)</span>
    <span class="s1">new_y </span><span class="s3">= </span><span class="s1">pdp</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">][</span><span class="s5">0</span><span class="s3">]</span>
    <span class="s4"># add polynomial features if needed</span>
    <span class="s1">new_X </span><span class="s3">= </span><span class="s1">PolynomialFeatures</span><span class="s3">(</span><span class="s1">degree</span><span class="s3">=</span><span class="s1">power</span><span class="s3">).</span><span class="s1">fit_transform</span><span class="s3">(</span><span class="s1">new_X</span><span class="s3">)</span>

    <span class="s1">lr </span><span class="s3">= </span><span class="s1">LinearRegression</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">new_X</span><span class="s3">, </span><span class="s1">new_y</span><span class="s3">)</span>
    <span class="s1">r2 </span><span class="s3">= </span><span class="s1">r2_score</span><span class="s3">(</span><span class="s1">new_y</span><span class="s3">, </span><span class="s1">lr</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">new_X</span><span class="s3">))</span>

    <span class="s2">assert </span><span class="s1">r2 </span><span class="s3">&gt; </span><span class="s5">0.99</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;Estimator&quot;</span><span class="s3">,</span>
    <span class="s3">(</span>
        <span class="s1">sklearn</span><span class="s3">.</span><span class="s1">tree</span><span class="s3">.</span><span class="s1">DecisionTreeClassifier</span><span class="s3">,</span>
        <span class="s1">sklearn</span><span class="s3">.</span><span class="s1">tree</span><span class="s3">.</span><span class="s1">ExtraTreeClassifier</span><span class="s3">,</span>
        <span class="s1">sklearn</span><span class="s3">.</span><span class="s1">ensemble</span><span class="s3">.</span><span class="s1">ExtraTreesClassifier</span><span class="s3">,</span>
        <span class="s1">sklearn</span><span class="s3">.</span><span class="s1">neighbors</span><span class="s3">.</span><span class="s1">KNeighborsClassifier</span><span class="s3">,</span>
        <span class="s1">sklearn</span><span class="s3">.</span><span class="s1">neighbors</span><span class="s3">.</span><span class="s1">RadiusNeighborsClassifier</span><span class="s3">,</span>
        <span class="s1">sklearn</span><span class="s3">.</span><span class="s1">ensemble</span><span class="s3">.</span><span class="s1">RandomForestClassifier</span><span class="s3">,</span>
    <span class="s3">),</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_multiclass_multioutput</span><span class="s3">(</span><span class="s1">Estimator</span><span class="s3">):</span>
    <span class="s4"># Make sure error is raised for multiclass-multioutput classifiers</span>

    <span class="s4"># make multiclass-multioutput dataset</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">n_classes</span><span class="s3">=</span><span class="s5">3</span><span class="s3">, </span><span class="s1">n_clusters_per_class</span><span class="s3">=</span><span class="s5">1</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s1">y</span><span class="s3">, </span><span class="s1">y</span><span class="s3">]).</span><span class="s1">T</span>

    <span class="s1">est </span><span class="s3">= </span><span class="s1">Estimator</span><span class="s3">()</span>
    <span class="s1">est</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span>
        <span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s6">&quot;Multiclass-multioutput estimators are not supported&quot;</span>
    <span class="s3">):</span>
        <span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">est</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, [</span><span class="s5">0</span><span class="s3">])</span>


<span class="s2">class </span><span class="s1">NoPredictProbaNoDecisionFunction</span><span class="s3">(</span><span class="s1">ClassifierMixin</span><span class="s3">, </span><span class="s1">BaseEstimator</span><span class="s3">):</span>
    <span class="s2">def </span><span class="s1">fit</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">):</span>
        <span class="s4"># simulate that we have some classes</span>
        <span class="s1">self</span><span class="s3">.</span><span class="s1">classes_ </span><span class="s3">= [</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">]</span>
        <span class="s2">return </span><span class="s1">self</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s6">&quot;ignore:A Bunch will be returned&quot;</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;estimator, params, err_msg&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s3">(</span>
            <span class="s1">KMeans</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">, </span><span class="s1">n_init</span><span class="s3">=</span><span class="s6">&quot;auto&quot;</span><span class="s3">),</span>
            <span class="s3">{</span><span class="s6">&quot;features&quot;</span><span class="s3">: [</span><span class="s5">0</span><span class="s3">]},</span>
            <span class="s6">&quot;'estimator' must be a fitted regressor or classifier&quot;</span><span class="s3">,</span>
        <span class="s3">),</span>
        <span class="s3">(</span>
            <span class="s1">LinearRegression</span><span class="s3">(),</span>
            <span class="s3">{</span><span class="s6">&quot;features&quot;</span><span class="s3">: [</span><span class="s5">0</span><span class="s3">], </span><span class="s6">&quot;response_method&quot;</span><span class="s3">: </span><span class="s6">&quot;predict_proba&quot;</span><span class="s3">},</span>
            <span class="s6">&quot;The response_method parameter is ignored for regressors&quot;</span><span class="s3">,</span>
        <span class="s3">),</span>
        <span class="s3">(</span>
            <span class="s1">GradientBoostingClassifier</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">),</span>
            <span class="s3">{</span>
                <span class="s6">&quot;features&quot;</span><span class="s3">: [</span><span class="s5">0</span><span class="s3">],</span>
                <span class="s6">&quot;response_method&quot;</span><span class="s3">: </span><span class="s6">&quot;predict_proba&quot;</span><span class="s3">,</span>
                <span class="s6">&quot;method&quot;</span><span class="s3">: </span><span class="s6">&quot;recursion&quot;</span><span class="s3">,</span>
            <span class="s3">},</span>
            <span class="s6">&quot;'recursion' method, the response_method must be 'decision_function'&quot;</span><span class="s3">,</span>
        <span class="s3">),</span>
        <span class="s3">(</span>
            <span class="s1">GradientBoostingClassifier</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">),</span>
            <span class="s3">{</span><span class="s6">&quot;features&quot;</span><span class="s3">: [</span><span class="s5">0</span><span class="s3">], </span><span class="s6">&quot;response_method&quot;</span><span class="s3">: </span><span class="s6">&quot;predict_proba&quot;</span><span class="s3">, </span><span class="s6">&quot;method&quot;</span><span class="s3">: </span><span class="s6">&quot;auto&quot;</span><span class="s3">},</span>
            <span class="s6">&quot;'recursion' method, the response_method must be 'decision_function'&quot;</span><span class="s3">,</span>
        <span class="s3">),</span>
        <span class="s3">(</span>
            <span class="s1">LinearRegression</span><span class="s3">(),</span>
            <span class="s3">{</span><span class="s6">&quot;features&quot;</span><span class="s3">: [</span><span class="s5">0</span><span class="s3">], </span><span class="s6">&quot;method&quot;</span><span class="s3">: </span><span class="s6">&quot;recursion&quot;</span><span class="s3">, </span><span class="s6">&quot;kind&quot;</span><span class="s3">: </span><span class="s6">&quot;individual&quot;</span><span class="s3">},</span>
            <span class="s6">&quot;The 'recursion' method only applies when 'kind' is set to 'average'&quot;</span><span class="s3">,</span>
        <span class="s3">),</span>
        <span class="s3">(</span>
            <span class="s1">LinearRegression</span><span class="s3">(),</span>
            <span class="s3">{</span><span class="s6">&quot;features&quot;</span><span class="s3">: [</span><span class="s5">0</span><span class="s3">], </span><span class="s6">&quot;method&quot;</span><span class="s3">: </span><span class="s6">&quot;recursion&quot;</span><span class="s3">, </span><span class="s6">&quot;kind&quot;</span><span class="s3">: </span><span class="s6">&quot;both&quot;</span><span class="s3">},</span>
            <span class="s6">&quot;The 'recursion' method only applies when 'kind' is set to 'average'&quot;</span><span class="s3">,</span>
        <span class="s3">),</span>
        <span class="s3">(</span>
            <span class="s1">LinearRegression</span><span class="s3">(),</span>
            <span class="s3">{</span><span class="s6">&quot;features&quot;</span><span class="s3">: [</span><span class="s5">0</span><span class="s3">], </span><span class="s6">&quot;method&quot;</span><span class="s3">: </span><span class="s6">&quot;recursion&quot;</span><span class="s3">},</span>
            <span class="s6">&quot;Only the following estimators support the 'recursion' method:&quot;</span><span class="s3">,</span>
        <span class="s3">),</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_partial_dependence_error</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">, </span><span class="s1">params</span><span class="s3">, </span><span class="s1">err_msg</span><span class="s3">):</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">estimator</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">err_msg</span><span class="s3">):</span>
        <span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, **</span><span class="s1">params</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;estimator&quot;</span><span class="s3">, [</span><span class="s1">LinearRegression</span><span class="s3">(), </span><span class="s1">GradientBoostingClassifier</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)]</span>
<span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;features&quot;</span><span class="s3">, [-</span><span class="s5">1</span><span class="s3">, </span><span class="s5">10000</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_partial_dependence_unknown_feature_indices</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">, </span><span class="s1">features</span><span class="s3">):</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">estimator</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">err_msg </span><span class="s3">= </span><span class="s6">&quot;all features must be in&quot;</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">err_msg</span><span class="s3">):</span>
        <span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, [</span><span class="s1">features</span><span class="s3">])</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;estimator&quot;</span><span class="s3">, [</span><span class="s1">LinearRegression</span><span class="s3">(), </span><span class="s1">GradientBoostingClassifier</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)]</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_partial_dependence_unknown_feature_string</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">):</span>
    <span class="s1">pd </span><span class="s3">= </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">importorskip</span><span class="s3">(</span><span class="s6">&quot;pandas&quot;</span><span class="s3">)</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">df </span><span class="s3">= </span><span class="s1">pd</span><span class="s3">.</span><span class="s1">DataFrame</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">estimator</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">df</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">features </span><span class="s3">= [</span><span class="s6">&quot;random&quot;</span><span class="s3">]</span>
    <span class="s1">err_msg </span><span class="s3">= </span><span class="s6">&quot;A given column is not a column of the dataframe&quot;</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">err_msg</span><span class="s3">):</span>
        <span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">, </span><span class="s1">df</span><span class="s3">, </span><span class="s1">features</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;estimator&quot;</span><span class="s3">, [</span><span class="s1">LinearRegression</span><span class="s3">(), </span><span class="s1">GradientBoostingClassifier</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)]</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_partial_dependence_X_list</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">):</span>
    <span class="s4"># check that array-like objects are accepted</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">estimator</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">, </span><span class="s1">list</span><span class="s3">(</span><span class="s1">X</span><span class="s3">), [</span><span class="s5">0</span><span class="s3">], </span><span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_warning_recursion_non_constant_init</span><span class="s3">():</span>
    <span class="s4"># make sure that passing a non-constant init parameter to a GBDT and using</span>
    <span class="s4"># recursion method yields a warning.</span>

    <span class="s1">gbc </span><span class="s3">= </span><span class="s1">GradientBoostingClassifier</span><span class="s3">(</span><span class="s1">init</span><span class="s3">=</span><span class="s1">DummyClassifier</span><span class="s3">(), </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">gbc</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">warns</span><span class="s3">(</span>
        <span class="s1">UserWarning</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s6">&quot;Using recursion method with a non-constant init predictor&quot;</span>
    <span class="s3">):</span>
        <span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">gbc</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, [</span><span class="s5">0</span><span class="s3">], </span><span class="s1">method</span><span class="s3">=</span><span class="s6">&quot;recursion&quot;</span><span class="s3">, </span><span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span><span class="s3">)</span>

    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">warns</span><span class="s3">(</span>
        <span class="s1">UserWarning</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s6">&quot;Using recursion method with a non-constant init predictor&quot;</span>
    <span class="s3">):</span>
        <span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">gbc</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, [</span><span class="s5">0</span><span class="s3">], </span><span class="s1">method</span><span class="s3">=</span><span class="s6">&quot;recursion&quot;</span><span class="s3">, </span><span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_partial_dependence_sample_weight_of_fitted_estimator</span><span class="s3">():</span>
    <span class="s4"># Test near perfect correlation between partial dependence and diagonal</span>
    <span class="s4"># when sample weights emphasize y = x predictions</span>
    <span class="s4"># non-regression test for #13193</span>
    <span class="s4"># TODO: extend to HistGradientBoosting once sample_weight is supported</span>
    <span class="s1">N </span><span class="s3">= </span><span class="s5">1000</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s5">123456</span><span class="s3">)</span>
    <span class="s1">mask </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randint</span><span class="s3">(</span><span class="s5">2</span><span class="s3">, </span><span class="s1">size</span><span class="s3">=</span><span class="s1">N</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">bool</span><span class="s3">)</span>

    <span class="s1">x </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">rand</span><span class="s3">(</span><span class="s1">N</span><span class="s3">)</span>
    <span class="s4"># set y = x on mask and y = -x outside</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">x</span><span class="s3">.</span><span class="s1">copy</span><span class="s3">()</span>
    <span class="s1">y</span><span class="s3">[~</span><span class="s1">mask</span><span class="s3">] = -</span><span class="s1">y</span><span class="s3">[~</span><span class="s1">mask</span><span class="s3">]</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">c_</span><span class="s3">[</span><span class="s1">mask</span><span class="s3">, </span><span class="s1">x</span><span class="s3">]</span>
    <span class="s4"># sample weights to emphasize data points where y = x</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">(</span><span class="s1">N</span><span class="s3">)</span>
    <span class="s1">sample_weight</span><span class="s3">[</span><span class="s1">mask</span><span class="s3">] = </span><span class="s5">1000.0</span>

    <span class="s1">clf </span><span class="s3">= </span><span class="s1">GradientBoostingRegressor</span><span class="s3">(</span><span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">10</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">1</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>

    <span class="s1">pdp </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=[</span><span class="s5">1</span><span class="s3">], </span><span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span><span class="s3">)</span>

    <span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">corrcoef</span><span class="s3">(</span><span class="s1">pdp</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">], </span><span class="s1">pdp</span><span class="s3">[</span><span class="s6">&quot;grid_values&quot;</span><span class="s3">])[</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">] &gt; </span><span class="s5">0.99</span>


<span class="s2">def </span><span class="s1">test_hist_gbdt_sw_not_supported</span><span class="s3">():</span>
    <span class="s4"># TODO: remove/fix when PDP supports HGBT with sample weights</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">HistGradientBoostingRegressor</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">1</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">(</span><span class="s1">len</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)))</span>

    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span>
        <span class="s1">NotImplementedError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s6">&quot;does not support partial dependence&quot;</span>
    <span class="s3">):</span>
        <span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=[</span><span class="s5">1</span><span class="s3">])</span>


<span class="s2">def </span><span class="s1">test_partial_dependence_pipeline</span><span class="s3">():</span>
    <span class="s4"># check that the partial dependence support pipeline</span>
    <span class="s1">iris </span><span class="s3">= </span><span class="s1">load_iris</span><span class="s3">()</span>

    <span class="s1">scaler </span><span class="s3">= </span><span class="s1">StandardScaler</span><span class="s3">()</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">DummyClassifier</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">42</span><span class="s3">)</span>
    <span class="s1">pipe </span><span class="s3">= </span><span class="s1">make_pipeline</span><span class="s3">(</span><span class="s1">scaler</span><span class="s3">, </span><span class="s1">clf</span><span class="s3">)</span>

    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">scaler</span><span class="s3">.</span><span class="s1">fit_transform</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">), </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
    <span class="s1">pipe</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>

    <span class="s1">features </span><span class="s3">= </span><span class="s5">0</span>
    <span class="s1">pdp_pipe </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span>
        <span class="s1">pipe</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=[</span><span class="s1">features</span><span class="s3">], </span><span class="s1">grid_resolution</span><span class="s3">=</span><span class="s5">10</span><span class="s3">, </span><span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span>
    <span class="s3">)</span>
    <span class="s1">pdp_clf </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span>
        <span class="s1">clf</span><span class="s3">,</span>
        <span class="s1">scaler</span><span class="s3">.</span><span class="s1">transform</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">),</span>
        <span class="s1">features</span><span class="s3">=[</span><span class="s1">features</span><span class="s3">],</span>
        <span class="s1">grid_resolution</span><span class="s3">=</span><span class="s5">10</span><span class="s3">,</span>
        <span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">pdp_pipe</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">], </span><span class="s1">pdp_clf</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">])</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span>
        <span class="s1">pdp_pipe</span><span class="s3">[</span><span class="s6">&quot;grid_values&quot;</span><span class="s3">][</span><span class="s5">0</span><span class="s3">],</span>
        <span class="s1">pdp_clf</span><span class="s3">[</span><span class="s6">&quot;grid_values&quot;</span><span class="s3">][</span><span class="s5">0</span><span class="s3">] * </span><span class="s1">scaler</span><span class="s3">.</span><span class="s1">scale_</span><span class="s3">[</span><span class="s1">features</span><span class="s3">] + </span><span class="s1">scaler</span><span class="s3">.</span><span class="s1">mean_</span><span class="s3">[</span><span class="s1">features</span><span class="s3">],</span>
    <span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;estimator&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s1">LogisticRegression</span><span class="s3">(</span><span class="s1">max_iter</span><span class="s3">=</span><span class="s5">1000</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">),</span>
        <span class="s1">GradientBoostingClassifier</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">, </span><span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">5</span><span class="s3">),</span>
    <span class="s3">],</span>
    <span class="s1">ids</span><span class="s3">=[</span><span class="s6">&quot;estimator-brute&quot;</span><span class="s3">, </span><span class="s6">&quot;estimator-recursion&quot;</span><span class="s3">],</span>
<span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;preprocessor&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s2">None</span><span class="s3">,</span>
        <span class="s1">make_column_transformer</span><span class="s3">(</span>
            <span class="s3">(</span><span class="s1">StandardScaler</span><span class="s3">(), [</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">feature_names</span><span class="s3">[</span><span class="s1">i</span><span class="s3">] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s3">(</span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s3">)]),</span>
            <span class="s3">(</span><span class="s1">RobustScaler</span><span class="s3">(), [</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">feature_names</span><span class="s3">[</span><span class="s1">i</span><span class="s3">] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s3">(</span><span class="s5">1</span><span class="s3">, </span><span class="s5">3</span><span class="s3">)]),</span>
        <span class="s3">),</span>
        <span class="s1">make_column_transformer</span><span class="s3">(</span>
            <span class="s3">(</span><span class="s1">StandardScaler</span><span class="s3">(), [</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">feature_names</span><span class="s3">[</span><span class="s1">i</span><span class="s3">] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s3">(</span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s3">)]),</span>
            <span class="s1">remainder</span><span class="s3">=</span><span class="s6">&quot;passthrough&quot;</span><span class="s3">,</span>
        <span class="s3">),</span>
    <span class="s3">],</span>
    <span class="s1">ids</span><span class="s3">=[</span><span class="s6">&quot;None&quot;</span><span class="s3">, </span><span class="s6">&quot;column-transformer&quot;</span><span class="s3">, </span><span class="s6">&quot;column-transformer-passthrough&quot;</span><span class="s3">],</span>
<span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;features&quot;</span><span class="s3">,</span>
    <span class="s3">[[</span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], [</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">feature_names</span><span class="s3">[</span><span class="s1">i</span><span class="s3">] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s3">(</span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s3">)]],</span>
    <span class="s1">ids</span><span class="s3">=[</span><span class="s6">&quot;features-integer&quot;</span><span class="s3">, </span><span class="s6">&quot;features-string&quot;</span><span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_partial_dependence_dataframe</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">, </span><span class="s1">preprocessor</span><span class="s3">, </span><span class="s1">features</span><span class="s3">):</span>
    <span class="s4"># check that the partial dependence support dataframe and pipeline</span>
    <span class="s4"># including a column transformer</span>
    <span class="s1">pd </span><span class="s3">= </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">importorskip</span><span class="s3">(</span><span class="s6">&quot;pandas&quot;</span><span class="s3">)</span>
    <span class="s1">df </span><span class="s3">= </span><span class="s1">pd</span><span class="s3">.</span><span class="s1">DataFrame</span><span class="s3">(</span><span class="s1">scale</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">), </span><span class="s1">columns</span><span class="s3">=</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">feature_names</span><span class="s3">)</span>

    <span class="s1">pipe </span><span class="s3">= </span><span class="s1">make_pipeline</span><span class="s3">(</span><span class="s1">preprocessor</span><span class="s3">, </span><span class="s1">estimator</span><span class="s3">)</span>
    <span class="s1">pipe</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">df</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
    <span class="s1">pdp_pipe </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span>
        <span class="s1">pipe</span><span class="s3">, </span><span class="s1">df</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=</span><span class="s1">features</span><span class="s3">, </span><span class="s1">grid_resolution</span><span class="s3">=</span><span class="s5">10</span><span class="s3">, </span><span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span>
    <span class="s3">)</span>

    <span class="s4"># the column transformer will reorder the column when transforming</span>
    <span class="s4"># we mixed the index to be sure that we are computing the partial</span>
    <span class="s4"># dependence of the right columns</span>
    <span class="s2">if </span><span class="s1">preprocessor </span><span class="s2">is not None</span><span class="s3">:</span>
        <span class="s1">X_proc </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">preprocessor</span><span class="s3">).</span><span class="s1">fit_transform</span><span class="s3">(</span><span class="s1">df</span><span class="s3">)</span>
        <span class="s1">features_clf </span><span class="s3">= [</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">]</span>
    <span class="s2">else</span><span class="s3">:</span>
        <span class="s1">X_proc </span><span class="s3">= </span><span class="s1">df</span>
        <span class="s1">features_clf </span><span class="s3">= [</span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s3">]</span>

    <span class="s1">clf </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_proc</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
    <span class="s1">pdp_clf </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span>
        <span class="s1">clf</span><span class="s3">,</span>
        <span class="s1">X_proc</span><span class="s3">,</span>
        <span class="s1">features</span><span class="s3">=</span><span class="s1">features_clf</span><span class="s3">,</span>
        <span class="s1">method</span><span class="s3">=</span><span class="s6">&quot;brute&quot;</span><span class="s3">,</span>
        <span class="s1">grid_resolution</span><span class="s3">=</span><span class="s5">10</span><span class="s3">,</span>
        <span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span><span class="s3">,</span>
    <span class="s3">)</span>

    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">pdp_pipe</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">], </span><span class="s1">pdp_clf</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">])</span>
    <span class="s2">if </span><span class="s1">preprocessor </span><span class="s2">is not None</span><span class="s3">:</span>
        <span class="s1">scaler </span><span class="s3">= </span><span class="s1">preprocessor</span><span class="s3">.</span><span class="s1">named_transformers_</span><span class="s3">[</span><span class="s6">&quot;standardscaler&quot;</span><span class="s3">]</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span>
            <span class="s1">pdp_pipe</span><span class="s3">[</span><span class="s6">&quot;grid_values&quot;</span><span class="s3">][</span><span class="s5">1</span><span class="s3">],</span>
            <span class="s1">pdp_clf</span><span class="s3">[</span><span class="s6">&quot;grid_values&quot;</span><span class="s3">][</span><span class="s5">1</span><span class="s3">] * </span><span class="s1">scaler</span><span class="s3">.</span><span class="s1">scale_</span><span class="s3">[</span><span class="s5">1</span><span class="s3">] + </span><span class="s1">scaler</span><span class="s3">.</span><span class="s1">mean_</span><span class="s3">[</span><span class="s5">1</span><span class="s3">],</span>
        <span class="s3">)</span>
    <span class="s2">else</span><span class="s3">:</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">pdp_pipe</span><span class="s3">[</span><span class="s6">&quot;grid_values&quot;</span><span class="s3">][</span><span class="s5">1</span><span class="s3">], </span><span class="s1">pdp_clf</span><span class="s3">[</span><span class="s6">&quot;grid_values&quot;</span><span class="s3">][</span><span class="s5">1</span><span class="s3">])</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;features, expected_pd_shape&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s3">(</span><span class="s5">0</span><span class="s3">, (</span><span class="s5">3</span><span class="s3">, </span><span class="s5">10</span><span class="s3">)),</span>
        <span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">feature_names</span><span class="s3">[</span><span class="s5">0</span><span class="s3">], (</span><span class="s5">3</span><span class="s3">, </span><span class="s5">10</span><span class="s3">)),</span>
        <span class="s3">([</span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], (</span><span class="s5">3</span><span class="s3">, </span><span class="s5">10</span><span class="s3">, </span><span class="s5">10</span><span class="s3">)),</span>
        <span class="s3">([</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">feature_names</span><span class="s3">[</span><span class="s1">i</span><span class="s3">] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s3">(</span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s3">)], (</span><span class="s5">3</span><span class="s3">, </span><span class="s5">10</span><span class="s3">, </span><span class="s5">10</span><span class="s3">)),</span>
        <span class="s3">([</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">, </span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">], (</span><span class="s5">3</span><span class="s3">, </span><span class="s5">10</span><span class="s3">, </span><span class="s5">10</span><span class="s3">)),</span>
    <span class="s3">],</span>
    <span class="s1">ids</span><span class="s3">=[</span><span class="s6">&quot;scalar-int&quot;</span><span class="s3">, </span><span class="s6">&quot;scalar-str&quot;</span><span class="s3">, </span><span class="s6">&quot;list-int&quot;</span><span class="s3">, </span><span class="s6">&quot;list-str&quot;</span><span class="s3">, </span><span class="s6">&quot;mask&quot;</span><span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_partial_dependence_feature_type</span><span class="s3">(</span><span class="s1">features</span><span class="s3">, </span><span class="s1">expected_pd_shape</span><span class="s3">):</span>
    <span class="s4"># check all possible features type supported in PDP</span>
    <span class="s1">pd </span><span class="s3">= </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">importorskip</span><span class="s3">(</span><span class="s6">&quot;pandas&quot;</span><span class="s3">)</span>
    <span class="s1">df </span><span class="s3">= </span><span class="s1">pd</span><span class="s3">.</span><span class="s1">DataFrame</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">columns</span><span class="s3">=</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">feature_names</span><span class="s3">)</span>

    <span class="s1">preprocessor </span><span class="s3">= </span><span class="s1">make_column_transformer</span><span class="s3">(</span>
        <span class="s3">(</span><span class="s1">StandardScaler</span><span class="s3">(), [</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">feature_names</span><span class="s3">[</span><span class="s1">i</span><span class="s3">] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s3">(</span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s3">)]),</span>
        <span class="s3">(</span><span class="s1">RobustScaler</span><span class="s3">(), [</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">feature_names</span><span class="s3">[</span><span class="s1">i</span><span class="s3">] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s3">(</span><span class="s5">1</span><span class="s3">, </span><span class="s5">3</span><span class="s3">)]),</span>
    <span class="s3">)</span>
    <span class="s1">pipe </span><span class="s3">= </span><span class="s1">make_pipeline</span><span class="s3">(</span>
        <span class="s1">preprocessor</span><span class="s3">, </span><span class="s1">LogisticRegression</span><span class="s3">(</span><span class="s1">max_iter</span><span class="s3">=</span><span class="s5">1000</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s3">)</span>
    <span class="s1">pipe</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">df</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
    <span class="s1">pdp_pipe </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span>
        <span class="s1">pipe</span><span class="s3">, </span><span class="s1">df</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=</span><span class="s1">features</span><span class="s3">, </span><span class="s1">grid_resolution</span><span class="s3">=</span><span class="s5">10</span><span class="s3">, </span><span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span>
    <span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">pdp_pipe</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">].</span><span class="s1">shape </span><span class="s3">== </span><span class="s1">expected_pd_shape</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">pdp_pipe</span><span class="s3">[</span><span class="s6">&quot;grid_values&quot;</span><span class="s3">]) == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">pdp_pipe</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">].</span><span class="s1">shape</span><span class="s3">) - </span><span class="s5">1</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;estimator&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s1">LinearRegression</span><span class="s3">(),</span>
        <span class="s1">LogisticRegression</span><span class="s3">(),</span>
        <span class="s1">GradientBoostingRegressor</span><span class="s3">(),</span>
        <span class="s1">GradientBoostingClassifier</span><span class="s3">(),</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_partial_dependence_unfitted</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">):</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span>
    <span class="s1">preprocessor </span><span class="s3">= </span><span class="s1">make_column_transformer</span><span class="s3">(</span>
        <span class="s3">(</span><span class="s1">StandardScaler</span><span class="s3">(), [</span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s3">]), (</span><span class="s1">RobustScaler</span><span class="s3">(), [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">3</span><span class="s3">])</span>
    <span class="s3">)</span>
    <span class="s1">pipe </span><span class="s3">= </span><span class="s1">make_pipeline</span><span class="s3">(</span><span class="s1">preprocessor</span><span class="s3">, </span><span class="s1">estimator</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">NotFittedError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s6">&quot;is not fitted yet&quot;</span><span class="s3">):</span>
        <span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">pipe</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=[</span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], </span><span class="s1">grid_resolution</span><span class="s3">=</span><span class="s5">10</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">NotFittedError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s6">&quot;is not fitted yet&quot;</span><span class="s3">):</span>
        <span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=[</span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], </span><span class="s1">grid_resolution</span><span class="s3">=</span><span class="s5">10</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;Estimator, data&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s3">(</span><span class="s1">LinearRegression</span><span class="s3">, </span><span class="s1">multioutput_regression_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">LogisticRegression</span><span class="s3">, </span><span class="s1">binary_classification_data</span><span class="s3">),</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_kind_average_and_average_of_individual</span><span class="s3">(</span><span class="s1">Estimator</span><span class="s3">, </span><span class="s1">data</span><span class="s3">):</span>
    <span class="s1">est </span><span class="s3">= </span><span class="s1">Estimator</span><span class="s3">()</span>
    <span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">), </span><span class="s1">n_targets </span><span class="s3">= </span><span class="s1">data</span>
    <span class="s1">est</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">pdp_avg </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">est</span><span class="s3">, </span><span class="s1">X</span><span class="s3">=</span><span class="s1">X</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=[</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], </span><span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span><span class="s3">)</span>
    <span class="s1">pdp_ind </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">est</span><span class="s3">, </span><span class="s1">X</span><span class="s3">=</span><span class="s1">X</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=[</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], </span><span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;individual&quot;</span><span class="s3">)</span>
    <span class="s1">avg_ind </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">pdp_ind</span><span class="s3">[</span><span class="s6">&quot;individual&quot;</span><span class="s3">], </span><span class="s1">axis</span><span class="s3">=</span><span class="s5">1</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">avg_ind</span><span class="s3">, </span><span class="s1">pdp_avg</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">])</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;Estimator, data&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s3">(</span><span class="s1">LinearRegression</span><span class="s3">, </span><span class="s1">multioutput_regression_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">LogisticRegression</span><span class="s3">, </span><span class="s1">binary_classification_data</span><span class="s3">),</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_partial_dependence_kind_individual_ignores_sample_weight</span><span class="s3">(</span><span class="s1">Estimator</span><span class="s3">, </span><span class="s1">data</span><span class="s3">):</span>
    <span class="s0">&quot;&quot;&quot;Check that `sample_weight` does not have any effect on reported ICE.&quot;&quot;&quot;</span>
    <span class="s1">est </span><span class="s3">= </span><span class="s1">Estimator</span><span class="s3">()</span>
    <span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">), </span><span class="s1">n_targets </span><span class="s3">= </span><span class="s1">data</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">arange</span><span class="s3">(</span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">])</span>
    <span class="s1">est</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">pdp_nsw </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">est</span><span class="s3">, </span><span class="s1">X</span><span class="s3">=</span><span class="s1">X</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=[</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], </span><span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;individual&quot;</span><span class="s3">)</span>
    <span class="s1">pdp_sw </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span>
        <span class="s1">est</span><span class="s3">, </span><span class="s1">X</span><span class="s3">=</span><span class="s1">X</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=[</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], </span><span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;individual&quot;</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span>
    <span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">pdp_nsw</span><span class="s3">[</span><span class="s6">&quot;individual&quot;</span><span class="s3">], </span><span class="s1">pdp_sw</span><span class="s3">[</span><span class="s6">&quot;individual&quot;</span><span class="s3">])</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">pdp_nsw</span><span class="s3">[</span><span class="s6">&quot;grid_values&quot;</span><span class="s3">], </span><span class="s1">pdp_sw</span><span class="s3">[</span><span class="s6">&quot;grid_values&quot;</span><span class="s3">])</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;estimator&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s1">LinearRegression</span><span class="s3">(),</span>
        <span class="s1">LogisticRegression</span><span class="s3">(),</span>
        <span class="s1">RandomForestRegressor</span><span class="s3">(),</span>
        <span class="s1">GradientBoostingClassifier</span><span class="s3">(),</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;non_null_weight_idx&quot;</span><span class="s3">, [</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_partial_dependence_non_null_weight_idx</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">, </span><span class="s1">non_null_weight_idx</span><span class="s3">):</span>
    <span class="s0">&quot;&quot;&quot;Check that if we pass a `sample_weight` of zeros with only one index with 
    sample weight equals one, then the average `partial_dependence` with this 
    `sample_weight` is equal to the individual `partial_dependence` of the 
    corresponding index. 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span>
    <span class="s1">preprocessor </span><span class="s3">= </span><span class="s1">make_column_transformer</span><span class="s3">(</span>
        <span class="s3">(</span><span class="s1">StandardScaler</span><span class="s3">(), [</span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s3">]), (</span><span class="s1">RobustScaler</span><span class="s3">(), [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">3</span><span class="s3">])</span>
    <span class="s3">)</span>
    <span class="s1">pipe </span><span class="s3">= </span><span class="s1">make_pipeline</span><span class="s3">(</span><span class="s1">preprocessor</span><span class="s3">, </span><span class="s1">estimator</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros_like</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">sample_weight</span><span class="s3">[</span><span class="s1">non_null_weight_idx</span><span class="s3">] = </span><span class="s5">1</span>
    <span class="s1">pdp_sw </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span>
        <span class="s1">pipe</span><span class="s3">,</span>
        <span class="s1">X</span><span class="s3">,</span>
        <span class="s3">[</span><span class="s5">2</span><span class="s3">, </span><span class="s5">3</span><span class="s3">],</span>
        <span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;average&quot;</span><span class="s3">,</span>
        <span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">,</span>
        <span class="s1">grid_resolution</span><span class="s3">=</span><span class="s5">10</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">pdp_ind </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">pipe</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, [</span><span class="s5">2</span><span class="s3">, </span><span class="s5">3</span><span class="s3">], </span><span class="s1">kind</span><span class="s3">=</span><span class="s6">&quot;individual&quot;</span><span class="s3">, </span><span class="s1">grid_resolution</span><span class="s3">=</span><span class="s5">10</span><span class="s3">)</span>
    <span class="s1">output_dim </span><span class="s3">= </span><span class="s5">1 </span><span class="s2">if </span><span class="s1">is_regressor</span><span class="s3">(</span><span class="s1">pipe</span><span class="s3">) </span><span class="s2">else </span><span class="s1">len</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">unique</span><span class="s3">(</span><span class="s1">y</span><span class="s3">))</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">output_dim</span><span class="s3">):</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span>
            <span class="s1">pdp_ind</span><span class="s3">[</span><span class="s6">&quot;individual&quot;</span><span class="s3">][</span><span class="s1">i</span><span class="s3">][</span><span class="s1">non_null_weight_idx</span><span class="s3">],</span>
            <span class="s1">pdp_sw</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">][</span><span class="s1">i</span><span class="s3">],</span>
        <span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;Estimator, data&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s3">(</span><span class="s1">LinearRegression</span><span class="s3">, </span><span class="s1">multioutput_regression_data</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">LogisticRegression</span><span class="s3">, </span><span class="s1">binary_classification_data</span><span class="s3">),</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_partial_dependence_equivalence_equal_sample_weight</span><span class="s3">(</span><span class="s1">Estimator</span><span class="s3">, </span><span class="s1">data</span><span class="s3">):</span>
    <span class="s0">&quot;&quot;&quot;Check that `sample_weight=None` is equivalent to having equal weights.&quot;&quot;&quot;</span>

    <span class="s1">est </span><span class="s3">= </span><span class="s1">Estimator</span><span class="s3">()</span>
    <span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">), </span><span class="s1">n_targets </span><span class="s3">= </span><span class="s1">data</span>
    <span class="s1">est</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">params </span><span class="s3">= </span><span class="s2">None</span><span class="s3">, {</span><span class="s6">&quot;X&quot;</span><span class="s3">: </span><span class="s1">X</span><span class="s3">, </span><span class="s6">&quot;features&quot;</span><span class="s3">: [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], </span><span class="s6">&quot;kind&quot;</span><span class="s3">: </span><span class="s6">&quot;average&quot;</span><span class="s3">}</span>
    <span class="s1">pdp_sw_none </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">est</span><span class="s3">, **</span><span class="s1">params</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">(</span><span class="s1">len</span><span class="s3">(</span><span class="s1">y</span><span class="s3">))</span>
    <span class="s1">pdp_sw_unit </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">est</span><span class="s3">, **</span><span class="s1">params</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">pdp_sw_none</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">], </span><span class="s1">pdp_sw_unit</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">])</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s5">2 </span><span class="s3">* </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">(</span><span class="s1">len</span><span class="s3">(</span><span class="s1">y</span><span class="s3">))</span>
    <span class="s1">pdp_sw_doubling </span><span class="s3">= </span><span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">est</span><span class="s3">, **</span><span class="s1">params</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">pdp_sw_none</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">], </span><span class="s1">pdp_sw_doubling</span><span class="s3">[</span><span class="s6">&quot;average&quot;</span><span class="s3">])</span>


<span class="s2">def </span><span class="s1">test_partial_dependence_sample_weight_size_error</span><span class="s3">():</span>
    <span class="s0">&quot;&quot;&quot;Check that we raise an error when the size of `sample_weight` is not 
    consistent with `X` and `y`. 
    &quot;&quot;&quot;</span>
    <span class="s1">est </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">()</span>
    <span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">), </span><span class="s1">n_targets </span><span class="s3">= </span><span class="s1">binary_classification_data</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones_like</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">est</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s6">&quot;sample_weight.shape ==&quot;</span><span class="s3">):</span>
        <span class="s1">partial_dependence</span><span class="s3">(</span>
            <span class="s1">est</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=[</span><span class="s5">0</span><span class="s3">], </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">[</span><span class="s5">1</span><span class="s3">:], </span><span class="s1">grid_resolution</span><span class="s3">=</span><span class="s5">10</span>
        <span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_partial_dependence_sample_weight_with_recursion</span><span class="s3">():</span>
    <span class="s0">&quot;&quot;&quot;Check that we raise an error when `sample_weight` is provided with 
    `&quot;recursion&quot;` method. 
    &quot;&quot;&quot;</span>
    <span class="s1">est </span><span class="s3">= </span><span class="s1">RandomForestRegressor</span><span class="s3">()</span>
    <span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">), </span><span class="s1">n_targets </span><span class="s3">= </span><span class="s1">regression_data</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones_like</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">est</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>

    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s6">&quot;'recursion' method can only be applied when&quot;</span><span class="s3">):</span>
        <span class="s1">partial_dependence</span><span class="s3">(</span>
            <span class="s1">est</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=[</span><span class="s5">0</span><span class="s3">], </span><span class="s1">method</span><span class="s3">=</span><span class="s6">&quot;recursion&quot;</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span>
        <span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_mixed_type_categorical</span><span class="s3">():</span>
    <span class="s0">&quot;&quot;&quot;Check that we raise a proper error when a column has mixed types and 
    the sorting of `np.unique` will fail.&quot;&quot;&quot;</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s6">&quot;A&quot;</span><span class="s3">, </span><span class="s6">&quot;B&quot;</span><span class="s3">, </span><span class="s6">&quot;C&quot;</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">nan</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">object</span><span class="s3">).</span><span class="s1">reshape</span><span class="s3">(-</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">)</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">])</span>

    <span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">preprocessing </span><span class="s2">import </span><span class="s1">OrdinalEncoder</span>

    <span class="s1">clf </span><span class="s3">= </span><span class="s1">make_pipeline</span><span class="s3">(</span>
        <span class="s1">OrdinalEncoder</span><span class="s3">(</span><span class="s1">encoded_missing_value</span><span class="s3">=-</span><span class="s5">1</span><span class="s3">),</span>
        <span class="s1">LogisticRegression</span><span class="s3">(),</span>
    <span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s6">&quot;The column #0 contains mixed data types&quot;</span><span class="s3">):</span>
        <span class="s1">partial_dependence</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">features</span><span class="s3">=[</span><span class="s5">0</span><span class="s3">])</span>
</pre>
</body>
</html>