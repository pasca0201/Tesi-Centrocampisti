<html>
<head>
<title>_perceptron.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #7a7e85;}
.s1 { color: #bcbec4;}
.s2 { color: #cf8e6d;}
.s3 { color: #bcbec4;}
.s4 { color: #5f826b; font-style: italic;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_perceptron.py</font>
</center></td></tr></table>
<pre><span class="s0"># Author: Mathieu Blondel</span>
<span class="s0"># License: BSD 3 clause</span>
<span class="s2">from </span><span class="s1">numbers </span><span class="s2">import </span><span class="s1">Real</span>

<span class="s2">from </span><span class="s3">..</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">_param_validation </span><span class="s2">import </span><span class="s1">Interval</span><span class="s3">, </span><span class="s1">StrOptions</span>
<span class="s2">from </span><span class="s3">.</span><span class="s1">_stochastic_gradient </span><span class="s2">import </span><span class="s1">BaseSGDClassifier</span>


<span class="s2">class </span><span class="s1">Perceptron</span><span class="s3">(</span><span class="s1">BaseSGDClassifier</span><span class="s3">):</span>
    <span class="s4">&quot;&quot;&quot;Linear perceptron classifier. 
 
    The implementation is a wrapper around :class:`~sklearn.linear_model.SGDClassifier` 
    by fixing the `loss` and `learning_rate` parameters as:: 
 
        SGDClassifier(loss=&quot;perceptron&quot;, learning_rate=&quot;constant&quot;) 
 
    Other available parameters are described below and are forwarded to 
    :class:`~sklearn.linear_model.SGDClassifier`. 
 
    Read more in the :ref:`User Guide &lt;perceptron&gt;`. 
 
    Parameters 
    ---------- 
 
    penalty : {'l2','l1','elasticnet'}, default=None 
        The penalty (aka regularization term) to be used. 
 
    alpha : float, default=0.0001 
        Constant that multiplies the regularization term if regularization is 
        used. 
 
    l1_ratio : float, default=0.15 
        The Elastic Net mixing parameter, with `0 &lt;= l1_ratio &lt;= 1`. 
        `l1_ratio=0` corresponds to L2 penalty, `l1_ratio=1` to L1. 
        Only used if `penalty='elasticnet'`. 
 
        .. versionadded:: 0.24 
 
    fit_intercept : bool, default=True 
        Whether the intercept should be estimated or not. If False, the 
        data is assumed to be already centered. 
 
    max_iter : int, default=1000 
        The maximum number of passes over the training data (aka epochs). 
        It only impacts the behavior in the ``fit`` method, and not the 
        :meth:`partial_fit` method. 
 
        .. versionadded:: 0.19 
 
    tol : float or None, default=1e-3 
        The stopping criterion. If it is not None, the iterations will stop 
        when (loss &gt; previous_loss - tol). 
 
        .. versionadded:: 0.19 
 
    shuffle : bool, default=True 
        Whether or not the training data should be shuffled after each epoch. 
 
    verbose : int, default=0 
        The verbosity level. 
 
    eta0 : float, default=1 
        Constant by which the updates are multiplied. 
 
    n_jobs : int, default=None 
        The number of CPUs to use to do the OVA (One Versus All, for 
        multi-class problems) computation. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    random_state : int, RandomState instance or None, default=0 
        Used to shuffle the training data, when ``shuffle`` is set to 
        ``True``. Pass an int for reproducible output across multiple 
        function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    early_stopping : bool, default=False 
        Whether to use early stopping to terminate training when validation 
        score is not improving. If set to True, it will automatically set aside 
        a stratified fraction of training data as validation and terminate 
        training when validation score is not improving by at least `tol` for 
        `n_iter_no_change` consecutive epochs. 
 
        .. versionadded:: 0.20 
 
    validation_fraction : float, default=0.1 
        The proportion of training data to set aside as validation set for 
        early stopping. Must be between 0 and 1. 
        Only used if early_stopping is True. 
 
        .. versionadded:: 0.20 
 
    n_iter_no_change : int, default=5 
        Number of iterations with no improvement to wait before early stopping. 
 
        .. versionadded:: 0.20 
 
    class_weight : dict, {class_label: weight} or &quot;balanced&quot;, default=None 
        Preset for the class_weight fit parameter. 
 
        Weights associated with classes. If not given, all classes 
        are supposed to have weight one. 
 
        The &quot;balanced&quot; mode uses the values of y to automatically adjust 
        weights inversely proportional to class frequencies in the input data 
        as ``n_samples / (n_classes * np.bincount(y))``. 
 
    warm_start : bool, default=False 
        When set to True, reuse the solution of the previous call to fit as 
        initialization, otherwise, just erase the previous solution. See 
        :term:`the Glossary &lt;warm_start&gt;`. 
 
    Attributes 
    ---------- 
    classes_ : ndarray of shape (n_classes,) 
        The unique classes labels. 
 
    coef_ : ndarray of shape (1, n_features) if n_classes == 2 else \ 
            (n_classes, n_features) 
        Weights assigned to the features. 
 
    intercept_ : ndarray of shape (1,) if n_classes == 2 else (n_classes,) 
        Constants in decision function. 
 
    loss_function_ : concreteÂ LossFunction 
        The function that determines the loss, or difference between the 
        output of the algorithm and the target values. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    n_iter_ : int 
        The actual number of iterations to reach the stopping criterion. 
        For multiclass fits, it is the maximum over every binary fit. 
 
    t_ : int 
        Number of weight updates performed during training. 
        Same as ``(n_iter_ * n_samples + 1)``. 
 
    See Also 
    -------- 
    sklearn.linear_model.SGDClassifier : Linear classifiers 
        (SVM, logistic regression, etc.) with SGD training. 
 
    Notes 
    ----- 
    ``Perceptron`` is a classification algorithm which shares the same 
    underlying implementation with ``SGDClassifier``. In fact, 
    ``Perceptron()`` is equivalent to `SGDClassifier(loss=&quot;perceptron&quot;, 
    eta0=1, learning_rate=&quot;constant&quot;, penalty=None)`. 
 
    References 
    ---------- 
    https://en.wikipedia.org/wiki/Perceptron and references therein. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.datasets import load_digits 
    &gt;&gt;&gt; from sklearn.linear_model import Perceptron 
    &gt;&gt;&gt; X, y = load_digits(return_X_y=True) 
    &gt;&gt;&gt; clf = Perceptron(tol=1e-3, random_state=0) 
    &gt;&gt;&gt; clf.fit(X, y) 
    Perceptron() 
    &gt;&gt;&gt; clf.score(X, y) 
    0.939... 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s3">: </span><span class="s1">dict </span><span class="s3">= {**</span><span class="s1">BaseSGDClassifier</span><span class="s3">.</span><span class="s1">_parameter_constraints</span><span class="s3">}</span>
    <span class="s1">_parameter_constraints</span><span class="s3">.</span><span class="s1">pop</span><span class="s3">(</span><span class="s5">&quot;loss&quot;</span><span class="s3">)</span>
    <span class="s1">_parameter_constraints</span><span class="s3">.</span><span class="s1">pop</span><span class="s3">(</span><span class="s5">&quot;average&quot;</span><span class="s3">)</span>
    <span class="s1">_parameter_constraints</span><span class="s3">.</span><span class="s1">update</span><span class="s3">(</span>
        <span class="s3">{</span>
            <span class="s5">&quot;penalty&quot;</span><span class="s3">: [</span><span class="s1">StrOptions</span><span class="s3">({</span><span class="s5">&quot;l2&quot;</span><span class="s3">, </span><span class="s5">&quot;l1&quot;</span><span class="s3">, </span><span class="s5">&quot;elasticnet&quot;</span><span class="s3">}), </span><span class="s2">None</span><span class="s3">],</span>
            <span class="s5">&quot;alpha&quot;</span><span class="s3">: [</span><span class="s1">Interval</span><span class="s3">(</span><span class="s1">Real</span><span class="s3">, </span><span class="s6">0</span><span class="s3">, </span><span class="s2">None</span><span class="s3">, </span><span class="s1">closed</span><span class="s3">=</span><span class="s5">&quot;left&quot;</span><span class="s3">)],</span>
            <span class="s5">&quot;l1_ratio&quot;</span><span class="s3">: [</span><span class="s1">Interval</span><span class="s3">(</span><span class="s1">Real</span><span class="s3">, </span><span class="s6">0</span><span class="s3">, </span><span class="s6">1</span><span class="s3">, </span><span class="s1">closed</span><span class="s3">=</span><span class="s5">&quot;both&quot;</span><span class="s3">)],</span>
            <span class="s5">&quot;eta0&quot;</span><span class="s3">: [</span><span class="s1">Interval</span><span class="s3">(</span><span class="s1">Real</span><span class="s3">, </span><span class="s6">0</span><span class="s3">, </span><span class="s2">None</span><span class="s3">, </span><span class="s1">closed</span><span class="s3">=</span><span class="s5">&quot;left&quot;</span><span class="s3">)],</span>
        <span class="s3">}</span>
    <span class="s3">)</span>

    <span class="s2">def </span><span class="s1">__init__</span><span class="s3">(</span>
        <span class="s1">self</span><span class="s3">,</span>
        <span class="s3">*,</span>
        <span class="s1">penalty</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">=</span><span class="s6">0.0001</span><span class="s3">,</span>
        <span class="s1">l1_ratio</span><span class="s3">=</span><span class="s6">0.15</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
        <span class="s1">max_iter</span><span class="s3">=</span><span class="s6">1000</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s6">1e-3</span><span class="s3">,</span>
        <span class="s1">shuffle</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
        <span class="s1">verbose</span><span class="s3">=</span><span class="s6">0</span><span class="s3">,</span>
        <span class="s1">eta0</span><span class="s3">=</span><span class="s6">1.0</span><span class="s3">,</span>
        <span class="s1">n_jobs</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s6">0</span><span class="s3">,</span>
        <span class="s1">early_stopping</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
        <span class="s1">validation_fraction</span><span class="s3">=</span><span class="s6">0.1</span><span class="s3">,</span>
        <span class="s1">n_iter_no_change</span><span class="s3">=</span><span class="s6">5</span><span class="s3">,</span>
        <span class="s1">class_weight</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
        <span class="s1">warm_start</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
    <span class="s3">):</span>
        <span class="s1">super</span><span class="s3">().</span><span class="s1">__init__</span><span class="s3">(</span>
            <span class="s1">loss</span><span class="s3">=</span><span class="s5">&quot;perceptron&quot;</span><span class="s3">,</span>
            <span class="s1">penalty</span><span class="s3">=</span><span class="s1">penalty</span><span class="s3">,</span>
            <span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha</span><span class="s3">,</span>
            <span class="s1">l1_ratio</span><span class="s3">=</span><span class="s1">l1_ratio</span><span class="s3">,</span>
            <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
            <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">,</span>
            <span class="s1">tol</span><span class="s3">=</span><span class="s1">tol</span><span class="s3">,</span>
            <span class="s1">shuffle</span><span class="s3">=</span><span class="s1">shuffle</span><span class="s3">,</span>
            <span class="s1">verbose</span><span class="s3">=</span><span class="s1">verbose</span><span class="s3">,</span>
            <span class="s1">random_state</span><span class="s3">=</span><span class="s1">random_state</span><span class="s3">,</span>
            <span class="s1">learning_rate</span><span class="s3">=</span><span class="s5">&quot;constant&quot;</span><span class="s3">,</span>
            <span class="s1">eta0</span><span class="s3">=</span><span class="s1">eta0</span><span class="s3">,</span>
            <span class="s1">early_stopping</span><span class="s3">=</span><span class="s1">early_stopping</span><span class="s3">,</span>
            <span class="s1">validation_fraction</span><span class="s3">=</span><span class="s1">validation_fraction</span><span class="s3">,</span>
            <span class="s1">n_iter_no_change</span><span class="s3">=</span><span class="s1">n_iter_no_change</span><span class="s3">,</span>
            <span class="s1">power_t</span><span class="s3">=</span><span class="s6">0.5</span><span class="s3">,</span>
            <span class="s1">warm_start</span><span class="s3">=</span><span class="s1">warm_start</span><span class="s3">,</span>
            <span class="s1">class_weight</span><span class="s3">=</span><span class="s1">class_weight</span><span class="s3">,</span>
            <span class="s1">n_jobs</span><span class="s3">=</span><span class="s1">n_jobs</span><span class="s3">,</span>
        <span class="s3">)</span>
</pre>
</body>
</html>