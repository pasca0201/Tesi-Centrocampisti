<html>
<head>
<title>test_gpc.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #2aacb8;}
.s6 { color: #6aab73;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_gpc.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Testing for Gaussian process classification&quot;&quot;&quot;</span>

<span class="s2"># Author: Jan Hendrik Metzen &lt;jhm@informatik.uni-bremen.de&gt;</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">warnings</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">import </span><span class="s1">pytest</span>
<span class="s3">from </span><span class="s1">scipy</span><span class="s4">.</span><span class="s1">optimize </span><span class="s3">import </span><span class="s1">approx_fprime</span>

<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">exceptions </span><span class="s3">import </span><span class="s1">ConvergenceWarning</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">gaussian_process </span><span class="s3">import </span><span class="s1">GaussianProcessClassifier</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">gaussian_process</span><span class="s4">.</span><span class="s1">kernels </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">RBF</span><span class="s4">,</span>
    <span class="s1">CompoundKernel</span><span class="s4">,</span>
    <span class="s1">WhiteKernel</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">gaussian_process</span><span class="s4">.</span><span class="s1">kernels </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">ConstantKernel </span><span class="s3">as </span><span class="s1">C</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">gaussian_process</span><span class="s4">.</span><span class="s1">tests</span><span class="s4">.</span><span class="s1">_mini_sequence_kernel </span><span class="s3">import </span><span class="s1">MiniSeqKernel</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_testing </span><span class="s3">import </span><span class="s1">assert_almost_equal</span><span class="s4">, </span><span class="s1">assert_array_equal</span>


<span class="s3">def </span><span class="s1">f</span><span class="s4">(</span><span class="s1">x</span><span class="s4">):</span>
    <span class="s3">return </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sin</span><span class="s4">(</span><span class="s1">x</span><span class="s4">)</span>


<span class="s1">X </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">atleast_2d</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">linspace</span><span class="s4">(</span><span class="s5">0</span><span class="s4">, </span><span class="s5">10</span><span class="s4">, </span><span class="s5">30</span><span class="s4">)).</span><span class="s1">T</span>
<span class="s1">X2 </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">atleast_2d</span><span class="s4">([</span><span class="s5">2.0</span><span class="s4">, </span><span class="s5">4.0</span><span class="s4">, </span><span class="s5">5.5</span><span class="s4">, </span><span class="s5">6.5</span><span class="s4">, </span><span class="s5">7.5</span><span class="s4">]).</span><span class="s1">T</span>
<span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span><span class="s1">f</span><span class="s4">(</span><span class="s1">X</span><span class="s4">).</span><span class="s1">ravel</span><span class="s4">() &gt; </span><span class="s5">0</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">int</span><span class="s4">)</span>
<span class="s1">fX </span><span class="s4">= </span><span class="s1">f</span><span class="s4">(</span><span class="s1">X</span><span class="s4">).</span><span class="s1">ravel</span><span class="s4">()</span>
<span class="s1">y_mc </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">empty</span><span class="s4">(</span><span class="s1">y</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">int</span><span class="s4">)  </span><span class="s2"># multi-class</span>
<span class="s1">y_mc</span><span class="s4">[</span><span class="s1">fX </span><span class="s4">&lt; -</span><span class="s5">0.35</span><span class="s4">] = </span><span class="s5">0</span>
<span class="s1">y_mc</span><span class="s4">[(</span><span class="s1">fX </span><span class="s4">&gt;= -</span><span class="s5">0.35</span><span class="s4">) &amp; (</span><span class="s1">fX </span><span class="s4">&lt; </span><span class="s5">0.35</span><span class="s4">)] = </span><span class="s5">1</span>
<span class="s1">y_mc</span><span class="s4">[</span><span class="s1">fX </span><span class="s4">&gt; </span><span class="s5">0.35</span><span class="s4">] = </span><span class="s5">2</span>


<span class="s1">fixed_kernel </span><span class="s4">= </span><span class="s1">RBF</span><span class="s4">(</span><span class="s1">length_scale</span><span class="s4">=</span><span class="s5">1.0</span><span class="s4">, </span><span class="s1">length_scale_bounds</span><span class="s4">=</span><span class="s6">&quot;fixed&quot;</span><span class="s4">)</span>
<span class="s1">kernels </span><span class="s4">= [</span>
    <span class="s1">RBF</span><span class="s4">(</span><span class="s1">length_scale</span><span class="s4">=</span><span class="s5">0.1</span><span class="s4">),</span>
    <span class="s1">fixed_kernel</span><span class="s4">,</span>
    <span class="s1">RBF</span><span class="s4">(</span><span class="s1">length_scale</span><span class="s4">=</span><span class="s5">1.0</span><span class="s4">, </span><span class="s1">length_scale_bounds</span><span class="s4">=(</span><span class="s5">1e-3</span><span class="s4">, </span><span class="s5">1e3</span><span class="s4">)),</span>
    <span class="s1">C</span><span class="s4">(</span><span class="s5">1.0</span><span class="s4">, (</span><span class="s5">1e-2</span><span class="s4">, </span><span class="s5">1e2</span><span class="s4">)) * </span><span class="s1">RBF</span><span class="s4">(</span><span class="s1">length_scale</span><span class="s4">=</span><span class="s5">1.0</span><span class="s4">, </span><span class="s1">length_scale_bounds</span><span class="s4">=(</span><span class="s5">1e-3</span><span class="s4">, </span><span class="s5">1e3</span><span class="s4">)),</span>
<span class="s4">]</span>
<span class="s1">non_fixed_kernels </span><span class="s4">= [</span><span class="s1">kernel </span><span class="s3">for </span><span class="s1">kernel </span><span class="s3">in </span><span class="s1">kernels </span><span class="s3">if </span><span class="s1">kernel </span><span class="s4">!= </span><span class="s1">fixed_kernel</span><span class="s4">]</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s6">&quot;kernel&quot;</span><span class="s4">, </span><span class="s1">kernels</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_predict_consistent</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">):</span>
    <span class="s2"># Check binary predict decision has also predicted probability above 0.5.</span>
    <span class="s1">gpc </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">assert_array_equal</span><span class="s4">(</span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">), </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)[:, </span><span class="s5">1</span><span class="s4">] &gt;= </span><span class="s5">0.5</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_predict_consistent_structured</span><span class="s4">():</span>
    <span class="s2"># Check binary predict decision has also predicted probability above 0.5.</span>
    <span class="s1">X </span><span class="s4">= [</span><span class="s6">&quot;A&quot;</span><span class="s4">, </span><span class="s6">&quot;AB&quot;</span><span class="s4">, </span><span class="s6">&quot;B&quot;</span><span class="s4">]</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s3">True</span><span class="s4">, </span><span class="s3">False</span><span class="s4">, </span><span class="s3">True</span><span class="s4">])</span>
    <span class="s1">kernel </span><span class="s4">= </span><span class="s1">MiniSeqKernel</span><span class="s4">(</span><span class="s1">baseline_similarity_bounds</span><span class="s4">=</span><span class="s6">&quot;fixed&quot;</span><span class="s4">)</span>
    <span class="s1">gpc </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">assert_array_equal</span><span class="s4">(</span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">), </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)[:, </span><span class="s5">1</span><span class="s4">] &gt;= </span><span class="s5">0.5</span><span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s6">&quot;kernel&quot;</span><span class="s4">, </span><span class="s1">non_fixed_kernels</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_lml_improving</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">):</span>
    <span class="s2"># Test that hyperparameter-tuning improves log-marginal likelihood.</span>
    <span class="s1">gpc </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">log_marginal_likelihood</span><span class="s4">(</span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">kernel_</span><span class="s4">.</span><span class="s1">theta</span><span class="s4">) &gt; </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">log_marginal_likelihood</span><span class="s4">(</span>
        <span class="s1">kernel</span><span class="s4">.</span><span class="s1">theta</span>
    <span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s6">&quot;kernel&quot;</span><span class="s4">, </span><span class="s1">kernels</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_lml_precomputed</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">):</span>
    <span class="s2"># Test that lml of optimized kernel is stored correctly.</span>
    <span class="s1">gpc </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">assert_almost_equal</span><span class="s4">(</span>
        <span class="s1">gpc</span><span class="s4">.</span><span class="s1">log_marginal_likelihood</span><span class="s4">(</span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">kernel_</span><span class="s4">.</span><span class="s1">theta</span><span class="s4">), </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">log_marginal_likelihood</span><span class="s4">(), </span><span class="s5">7</span>
    <span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s6">&quot;kernel&quot;</span><span class="s4">, </span><span class="s1">kernels</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_lml_without_cloning_kernel</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">):</span>
    <span class="s2"># Test that clone_kernel=False has side-effects of kernel.theta.</span>
    <span class="s1">gpc </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">input_theta </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ones</span><span class="s4">(</span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">kernel_</span><span class="s4">.</span><span class="s1">theta</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">)</span>

    <span class="s1">gpc</span><span class="s4">.</span><span class="s1">log_marginal_likelihood</span><span class="s4">(</span><span class="s1">input_theta</span><span class="s4">, </span><span class="s1">clone_kernel</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>
    <span class="s1">assert_almost_equal</span><span class="s4">(</span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">kernel_</span><span class="s4">.</span><span class="s1">theta</span><span class="s4">, </span><span class="s1">input_theta</span><span class="s4">, </span><span class="s5">7</span><span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s6">&quot;kernel&quot;</span><span class="s4">, </span><span class="s1">non_fixed_kernels</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_converged_to_local_maximum</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">):</span>
    <span class="s2"># Test that we are in local maximum after hyperparameter-optimization.</span>
    <span class="s1">gpc </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

    <span class="s1">lml</span><span class="s4">, </span><span class="s1">lml_gradient </span><span class="s4">= </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">log_marginal_likelihood</span><span class="s4">(</span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">kernel_</span><span class="s4">.</span><span class="s1">theta</span><span class="s4">, </span><span class="s3">True</span><span class="s4">)</span>

    <span class="s3">assert </span><span class="s1">np</span><span class="s4">.</span><span class="s1">all</span><span class="s4">(</span>
        <span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">abs</span><span class="s4">(</span><span class="s1">lml_gradient</span><span class="s4">) &lt; </span><span class="s5">1e-4</span><span class="s4">)</span>
        <span class="s4">| (</span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">kernel_</span><span class="s4">.</span><span class="s1">theta </span><span class="s4">== </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">kernel_</span><span class="s4">.</span><span class="s1">bounds</span><span class="s4">[:, </span><span class="s5">0</span><span class="s4">])</span>
        <span class="s4">| (</span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">kernel_</span><span class="s4">.</span><span class="s1">theta </span><span class="s4">== </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">kernel_</span><span class="s4">.</span><span class="s1">bounds</span><span class="s4">[:, </span><span class="s5">1</span><span class="s4">])</span>
    <span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s6">&quot;kernel&quot;</span><span class="s4">, </span><span class="s1">kernels</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_lml_gradient</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">):</span>
    <span class="s2"># Compare analytic and numeric gradient of log marginal likelihood.</span>
    <span class="s1">gpc </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

    <span class="s1">lml</span><span class="s4">, </span><span class="s1">lml_gradient </span><span class="s4">= </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">log_marginal_likelihood</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">.</span><span class="s1">theta</span><span class="s4">, </span><span class="s3">True</span><span class="s4">)</span>
    <span class="s1">lml_gradient_approx </span><span class="s4">= </span><span class="s1">approx_fprime</span><span class="s4">(</span>
        <span class="s1">kernel</span><span class="s4">.</span><span class="s1">theta</span><span class="s4">, </span><span class="s3">lambda </span><span class="s1">theta</span><span class="s4">: </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">log_marginal_likelihood</span><span class="s4">(</span><span class="s1">theta</span><span class="s4">, </span><span class="s3">False</span><span class="s4">), </span><span class="s5">1e-10</span>
    <span class="s4">)</span>

    <span class="s1">assert_almost_equal</span><span class="s4">(</span><span class="s1">lml_gradient</span><span class="s4">, </span><span class="s1">lml_gradient_approx</span><span class="s4">, </span><span class="s5">3</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_random_starts</span><span class="s4">(</span><span class="s1">global_random_seed</span><span class="s4">):</span>
    <span class="s2"># Test that an increasing number of random-starts of GP fitting only</span>
    <span class="s2"># increases the log marginal likelihood of the chosen theta.</span>
    <span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_features </span><span class="s4">= </span><span class="s5">25</span><span class="s4">, </span><span class="s5">2</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">random</span><span class="s4">.</span><span class="s1">RandomState</span><span class="s4">(</span><span class="s1">global_random_seed</span><span class="s4">)</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">randn</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">) * </span><span class="s5">2 </span><span class="s4">- </span><span class="s5">1</span>
    <span class="s1">y </span><span class="s4">= (</span><span class="s1">np</span><span class="s4">.</span><span class="s1">sin</span><span class="s4">(</span><span class="s1">X</span><span class="s4">).</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s5">1</span><span class="s4">) + </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sin</span><span class="s4">(</span><span class="s5">3 </span><span class="s4">* </span><span class="s1">X</span><span class="s4">).</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)) &gt; </span><span class="s5">0</span>

    <span class="s1">kernel </span><span class="s4">= </span><span class="s1">C</span><span class="s4">(</span><span class="s5">1.0</span><span class="s4">, (</span><span class="s5">1e-2</span><span class="s4">, </span><span class="s5">1e2</span><span class="s4">)) * </span><span class="s1">RBF</span><span class="s4">(</span>
        <span class="s1">length_scale</span><span class="s4">=[</span><span class="s5">1e-3</span><span class="s4">] * </span><span class="s1">n_features</span><span class="s4">, </span><span class="s1">length_scale_bounds</span><span class="s4">=[(</span><span class="s5">1e-4</span><span class="s4">, </span><span class="s5">1e2</span><span class="s4">)] * </span><span class="s1">n_features</span>
    <span class="s4">)</span>
    <span class="s1">last_lml </span><span class="s4">= -</span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span>
    <span class="s3">for </span><span class="s1">n_restarts_optimizer </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s5">5</span><span class="s4">):</span>
        <span class="s1">gp </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span>
            <span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel</span><span class="s4">,</span>
            <span class="s1">n_restarts_optimizer</span><span class="s4">=</span><span class="s1">n_restarts_optimizer</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s1">global_random_seed</span><span class="s4">,</span>
        <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
        <span class="s1">lml </span><span class="s4">= </span><span class="s1">gp</span><span class="s4">.</span><span class="s1">log_marginal_likelihood</span><span class="s4">(</span><span class="s1">gp</span><span class="s4">.</span><span class="s1">kernel_</span><span class="s4">.</span><span class="s1">theta</span><span class="s4">)</span>
        <span class="s3">assert </span><span class="s1">lml </span><span class="s4">&gt; </span><span class="s1">last_lml </span><span class="s4">- </span><span class="s1">np</span><span class="s4">.</span><span class="s1">finfo</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">).</span><span class="s1">eps</span>
        <span class="s1">last_lml </span><span class="s4">= </span><span class="s1">lml</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s6">&quot;kernel&quot;</span><span class="s4">, </span><span class="s1">non_fixed_kernels</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_custom_optimizer</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">, </span><span class="s1">global_random_seed</span><span class="s4">):</span>
    <span class="s2"># Test that GPC can use externally defined optimizers.</span>
    <span class="s2"># Define a dummy optimizer that simply tests 10 random hyperparameters</span>
    <span class="s3">def </span><span class="s1">optimizer</span><span class="s4">(</span><span class="s1">obj_func</span><span class="s4">, </span><span class="s1">initial_theta</span><span class="s4">, </span><span class="s1">bounds</span><span class="s4">):</span>
        <span class="s1">rng </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">random</span><span class="s4">.</span><span class="s1">RandomState</span><span class="s4">(</span><span class="s1">global_random_seed</span><span class="s4">)</span>
        <span class="s1">theta_opt</span><span class="s4">, </span><span class="s1">func_min </span><span class="s4">= </span><span class="s1">initial_theta</span><span class="s4">, </span><span class="s1">obj_func</span><span class="s4">(</span>
            <span class="s1">initial_theta</span><span class="s4">, </span><span class="s1">eval_gradient</span><span class="s4">=</span><span class="s3">False</span>
        <span class="s4">)</span>
        <span class="s3">for </span><span class="s1">_ </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s5">10</span><span class="s4">):</span>
            <span class="s1">theta </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">atleast_1d</span><span class="s4">(</span>
                <span class="s1">rng</span><span class="s4">.</span><span class="s1">uniform</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">maximum</span><span class="s4">(-</span><span class="s5">2</span><span class="s4">, </span><span class="s1">bounds</span><span class="s4">[:, </span><span class="s5">0</span><span class="s4">]), </span><span class="s1">np</span><span class="s4">.</span><span class="s1">minimum</span><span class="s4">(</span><span class="s5">1</span><span class="s4">, </span><span class="s1">bounds</span><span class="s4">[:, </span><span class="s5">1</span><span class="s4">]))</span>
            <span class="s4">)</span>
            <span class="s1">f </span><span class="s4">= </span><span class="s1">obj_func</span><span class="s4">(</span><span class="s1">theta</span><span class="s4">, </span><span class="s1">eval_gradient</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>
            <span class="s3">if </span><span class="s1">f </span><span class="s4">&lt; </span><span class="s1">func_min</span><span class="s4">:</span>
                <span class="s1">theta_opt</span><span class="s4">, </span><span class="s1">func_min </span><span class="s4">= </span><span class="s1">theta</span><span class="s4">, </span><span class="s1">f</span>
        <span class="s3">return </span><span class="s1">theta_opt</span><span class="s4">, </span><span class="s1">func_min</span>

    <span class="s1">gpc </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel</span><span class="s4">, </span><span class="s1">optimizer</span><span class="s4">=</span><span class="s1">optimizer</span><span class="s4">)</span>
    <span class="s1">gpc</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y_mc</span><span class="s4">)</span>
    <span class="s2"># Checks that optimizer improved marginal likelihood</span>
    <span class="s3">assert </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">log_marginal_likelihood</span><span class="s4">(</span>
        <span class="s1">gpc</span><span class="s4">.</span><span class="s1">kernel_</span><span class="s4">.</span><span class="s1">theta</span>
    <span class="s4">) &gt;= </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">log_marginal_likelihood</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">.</span><span class="s1">theta</span><span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s6">&quot;kernel&quot;</span><span class="s4">, </span><span class="s1">kernels</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_multi_class</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">):</span>
    <span class="s2"># Test GPC for multi-class classification problems.</span>
    <span class="s1">gpc </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel</span><span class="s4">)</span>
    <span class="s1">gpc</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y_mc</span><span class="s4">)</span>

    <span class="s1">y_prob </span><span class="s4">= </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X2</span><span class="s4">)</span>
    <span class="s1">assert_almost_equal</span><span class="s4">(</span><span class="s1">y_prob</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s5">1</span><span class="s4">), </span><span class="s5">1</span><span class="s4">)</span>

    <span class="s1">y_pred </span><span class="s4">= </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X2</span><span class="s4">)</span>
    <span class="s1">assert_array_equal</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">argmax</span><span class="s4">(</span><span class="s1">y_prob</span><span class="s4">, </span><span class="s5">1</span><span class="s4">), </span><span class="s1">y_pred</span><span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s6">&quot;kernel&quot;</span><span class="s4">, </span><span class="s1">kernels</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_multi_class_n_jobs</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">):</span>
    <span class="s2"># Test that multi-class GPC produces identical results with n_jobs&gt;1.</span>
    <span class="s1">gpc </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel</span><span class="s4">)</span>
    <span class="s1">gpc</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y_mc</span><span class="s4">)</span>

    <span class="s1">gpc_2 </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel</span><span class="s4">, </span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s5">2</span><span class="s4">)</span>
    <span class="s1">gpc_2</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y_mc</span><span class="s4">)</span>

    <span class="s1">y_prob </span><span class="s4">= </span><span class="s1">gpc</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X2</span><span class="s4">)</span>
    <span class="s1">y_prob_2 </span><span class="s4">= </span><span class="s1">gpc_2</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X2</span><span class="s4">)</span>
    <span class="s1">assert_almost_equal</span><span class="s4">(</span><span class="s1">y_prob</span><span class="s4">, </span><span class="s1">y_prob_2</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_warning_bounds</span><span class="s4">():</span>
    <span class="s1">kernel </span><span class="s4">= </span><span class="s1">RBF</span><span class="s4">(</span><span class="s1">length_scale_bounds</span><span class="s4">=[</span><span class="s5">1e-5</span><span class="s4">, </span><span class="s5">1e-3</span><span class="s4">])</span>
    <span class="s1">gpc </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel</span><span class="s4">)</span>
    <span class="s1">warning_message </span><span class="s4">= (</span>
        <span class="s6">&quot;The optimal value found for dimension 0 of parameter &quot;</span>
        <span class="s6">&quot;length_scale is close to the specified upper bound &quot;</span>
        <span class="s6">&quot;0.001. Increasing the bound and calling fit again may &quot;</span>
        <span class="s6">&quot;find a better value.&quot;</span>
    <span class="s4">)</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">warns</span><span class="s4">(</span><span class="s1">ConvergenceWarning</span><span class="s4">, </span><span class="s1">match</span><span class="s4">=</span><span class="s1">warning_message</span><span class="s4">):</span>
        <span class="s1">gpc</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

    <span class="s1">kernel_sum </span><span class="s4">= </span><span class="s1">WhiteKernel</span><span class="s4">(</span><span class="s1">noise_level_bounds</span><span class="s4">=[</span><span class="s5">1e-5</span><span class="s4">, </span><span class="s5">1e-3</span><span class="s4">]) + </span><span class="s1">RBF</span><span class="s4">(</span>
        <span class="s1">length_scale_bounds</span><span class="s4">=[</span><span class="s5">1e3</span><span class="s4">, </span><span class="s5">1e5</span><span class="s4">]</span>
    <span class="s4">)</span>
    <span class="s1">gpc_sum </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel_sum</span><span class="s4">)</span>
    <span class="s3">with </span><span class="s1">warnings</span><span class="s4">.</span><span class="s1">catch_warnings</span><span class="s4">(</span><span class="s1">record</span><span class="s4">=</span><span class="s3">True</span><span class="s4">) </span><span class="s3">as </span><span class="s1">record</span><span class="s4">:</span>
        <span class="s1">warnings</span><span class="s4">.</span><span class="s1">simplefilter</span><span class="s4">(</span><span class="s6">&quot;always&quot;</span><span class="s4">)</span>
        <span class="s1">gpc_sum</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

        <span class="s3">assert </span><span class="s1">len</span><span class="s4">(</span><span class="s1">record</span><span class="s4">) == </span><span class="s5">2</span>

        <span class="s3">assert </span><span class="s1">issubclass</span><span class="s4">(</span><span class="s1">record</span><span class="s4">[</span><span class="s5">0</span><span class="s4">].</span><span class="s1">category</span><span class="s4">, </span><span class="s1">ConvergenceWarning</span><span class="s4">)</span>
        <span class="s3">assert </span><span class="s4">(</span>
            <span class="s1">record</span><span class="s4">[</span><span class="s5">0</span><span class="s4">].</span><span class="s1">message</span><span class="s4">.</span><span class="s1">args</span><span class="s4">[</span><span class="s5">0</span><span class="s4">] == </span><span class="s6">&quot;The optimal value found for &quot;</span>
            <span class="s6">&quot;dimension 0 of parameter &quot;</span>
            <span class="s6">&quot;k1__noise_level is close to the &quot;</span>
            <span class="s6">&quot;specified upper bound 0.001. &quot;</span>
            <span class="s6">&quot;Increasing the bound and calling &quot;</span>
            <span class="s6">&quot;fit again may find a better value.&quot;</span>
        <span class="s4">)</span>

        <span class="s3">assert </span><span class="s1">issubclass</span><span class="s4">(</span><span class="s1">record</span><span class="s4">[</span><span class="s5">1</span><span class="s4">].</span><span class="s1">category</span><span class="s4">, </span><span class="s1">ConvergenceWarning</span><span class="s4">)</span>
        <span class="s3">assert </span><span class="s4">(</span>
            <span class="s1">record</span><span class="s4">[</span><span class="s5">1</span><span class="s4">].</span><span class="s1">message</span><span class="s4">.</span><span class="s1">args</span><span class="s4">[</span><span class="s5">0</span><span class="s4">] == </span><span class="s6">&quot;The optimal value found for &quot;</span>
            <span class="s6">&quot;dimension 0 of parameter &quot;</span>
            <span class="s6">&quot;k2__length_scale is close to the &quot;</span>
            <span class="s6">&quot;specified lower bound 1000.0. &quot;</span>
            <span class="s6">&quot;Decreasing the bound and calling &quot;</span>
            <span class="s6">&quot;fit again may find a better value.&quot;</span>
        <span class="s4">)</span>

    <span class="s1">X_tile </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">tile</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s5">2</span><span class="s4">)</span>
    <span class="s1">kernel_dims </span><span class="s4">= </span><span class="s1">RBF</span><span class="s4">(</span><span class="s1">length_scale</span><span class="s4">=[</span><span class="s5">1.0</span><span class="s4">, </span><span class="s5">2.0</span><span class="s4">], </span><span class="s1">length_scale_bounds</span><span class="s4">=[</span><span class="s5">1e1</span><span class="s4">, </span><span class="s5">1e2</span><span class="s4">])</span>
    <span class="s1">gpc_dims </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(</span><span class="s1">kernel</span><span class="s4">=</span><span class="s1">kernel_dims</span><span class="s4">)</span>

    <span class="s3">with </span><span class="s1">warnings</span><span class="s4">.</span><span class="s1">catch_warnings</span><span class="s4">(</span><span class="s1">record</span><span class="s4">=</span><span class="s3">True</span><span class="s4">) </span><span class="s3">as </span><span class="s1">record</span><span class="s4">:</span>
        <span class="s1">warnings</span><span class="s4">.</span><span class="s1">simplefilter</span><span class="s4">(</span><span class="s6">&quot;always&quot;</span><span class="s4">)</span>
        <span class="s1">gpc_dims</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_tile</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

        <span class="s3">assert </span><span class="s1">len</span><span class="s4">(</span><span class="s1">record</span><span class="s4">) == </span><span class="s5">2</span>

        <span class="s3">assert </span><span class="s1">issubclass</span><span class="s4">(</span><span class="s1">record</span><span class="s4">[</span><span class="s5">0</span><span class="s4">].</span><span class="s1">category</span><span class="s4">, </span><span class="s1">ConvergenceWarning</span><span class="s4">)</span>
        <span class="s3">assert </span><span class="s4">(</span>
            <span class="s1">record</span><span class="s4">[</span><span class="s5">0</span><span class="s4">].</span><span class="s1">message</span><span class="s4">.</span><span class="s1">args</span><span class="s4">[</span><span class="s5">0</span><span class="s4">] == </span><span class="s6">&quot;The optimal value found for &quot;</span>
            <span class="s6">&quot;dimension 0 of parameter &quot;</span>
            <span class="s6">&quot;length_scale is close to the &quot;</span>
            <span class="s6">&quot;specified upper bound 100.0. &quot;</span>
            <span class="s6">&quot;Increasing the bound and calling &quot;</span>
            <span class="s6">&quot;fit again may find a better value.&quot;</span>
        <span class="s4">)</span>

        <span class="s3">assert </span><span class="s1">issubclass</span><span class="s4">(</span><span class="s1">record</span><span class="s4">[</span><span class="s5">1</span><span class="s4">].</span><span class="s1">category</span><span class="s4">, </span><span class="s1">ConvergenceWarning</span><span class="s4">)</span>
        <span class="s3">assert </span><span class="s4">(</span>
            <span class="s1">record</span><span class="s4">[</span><span class="s5">1</span><span class="s4">].</span><span class="s1">message</span><span class="s4">.</span><span class="s1">args</span><span class="s4">[</span><span class="s5">0</span><span class="s4">] == </span><span class="s6">&quot;The optimal value found for &quot;</span>
            <span class="s6">&quot;dimension 1 of parameter &quot;</span>
            <span class="s6">&quot;length_scale is close to the &quot;</span>
            <span class="s6">&quot;specified upper bound 100.0. &quot;</span>
            <span class="s6">&quot;Increasing the bound and calling &quot;</span>
            <span class="s6">&quot;fit again may find a better value.&quot;</span>
        <span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span>
    <span class="s6">&quot;params, error_type, err_msg&quot;</span><span class="s4">,</span>
    <span class="s4">[</span>
        <span class="s4">(</span>
            <span class="s4">{</span><span class="s6">&quot;kernel&quot;</span><span class="s4">: </span><span class="s1">CompoundKernel</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)},</span>
            <span class="s1">ValueError</span><span class="s4">,</span>
            <span class="s6">&quot;kernel cannot be a CompoundKernel&quot;</span><span class="s4">,</span>
        <span class="s4">)</span>
    <span class="s4">],</span>
<span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_gpc_fit_error</span><span class="s4">(</span><span class="s1">params</span><span class="s4">, </span><span class="s1">error_type</span><span class="s4">, </span><span class="s1">err_msg</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Check that expected error are raised during fit.&quot;&quot;&quot;</span>
    <span class="s1">gpc </span><span class="s4">= </span><span class="s1">GaussianProcessClassifier</span><span class="s4">(**</span><span class="s1">params</span><span class="s4">)</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">error_type</span><span class="s4">, </span><span class="s1">match</span><span class="s4">=</span><span class="s1">err_msg</span><span class="s4">):</span>
        <span class="s1">gpc</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
</pre>
</body>
</html>