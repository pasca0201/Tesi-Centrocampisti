<html>
<head>
<title>test_calibration.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #7a7e85;}
.s1 { color: #bcbec4;}
.s2 { color: #cf8e6d;}
.s3 { color: #bcbec4;}
.s4 { color: #2aacb8;}
.s5 { color: #6aab73;}
.s6 { color: #5f826b; font-style: italic;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_calibration.py</font>
</center></td></tr></table>
<pre><span class="s0"># Authors: Alexandre Gramfort &lt;alexandre.gramfort@telecom-paristech.fr&gt;</span>
<span class="s0"># License: BSD 3 clause</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pytest</span>
<span class="s2">from </span><span class="s1">numpy</span><span class="s3">.</span><span class="s1">testing </span><span class="s2">import </span><span class="s1">assert_allclose</span>

<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">base </span><span class="s2">import </span><span class="s1">BaseEstimator</span><span class="s3">, </span><span class="s1">clone</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">calibration </span><span class="s2">import </span><span class="s3">(</span>
    <span class="s1">CalibratedClassifierCV</span><span class="s3">,</span>
    <span class="s1">CalibrationDisplay</span><span class="s3">,</span>
    <span class="s1">_CalibratedClassifier</span><span class="s3">,</span>
    <span class="s1">_sigmoid_calibration</span><span class="s3">,</span>
    <span class="s1">_SigmoidCalibration</span><span class="s3">,</span>
    <span class="s1">calibration_curve</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">datasets </span><span class="s2">import </span><span class="s1">load_iris</span><span class="s3">, </span><span class="s1">make_blobs</span><span class="s3">, </span><span class="s1">make_classification</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">dummy </span><span class="s2">import </span><span class="s1">DummyClassifier</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">ensemble </span><span class="s2">import </span><span class="s3">(</span>
    <span class="s1">RandomForestClassifier</span><span class="s3">,</span>
    <span class="s1">VotingClassifier</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">exceptions </span><span class="s2">import </span><span class="s1">NotFittedError</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">feature_extraction </span><span class="s2">import </span><span class="s1">DictVectorizer</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">impute </span><span class="s2">import </span><span class="s1">SimpleImputer</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">isotonic </span><span class="s2">import </span><span class="s1">IsotonicRegression</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">linear_model </span><span class="s2">import </span><span class="s1">LogisticRegression</span><span class="s3">, </span><span class="s1">SGDClassifier</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">metrics </span><span class="s2">import </span><span class="s1">brier_score_loss</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">model_selection </span><span class="s2">import </span><span class="s3">(</span>
    <span class="s1">KFold</span><span class="s3">,</span>
    <span class="s1">LeaveOneOut</span><span class="s3">,</span>
    <span class="s1">check_cv</span><span class="s3">,</span>
    <span class="s1">cross_val_predict</span><span class="s3">,</span>
    <span class="s1">cross_val_score</span><span class="s3">,</span>
    <span class="s1">train_test_split</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">naive_bayes </span><span class="s2">import </span><span class="s1">MultinomialNB</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">pipeline </span><span class="s2">import </span><span class="s1">Pipeline</span><span class="s3">, </span><span class="s1">make_pipeline</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">preprocessing </span><span class="s2">import </span><span class="s1">LabelEncoder</span><span class="s3">, </span><span class="s1">StandardScaler</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">svm </span><span class="s2">import </span><span class="s1">LinearSVC</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">tree </span><span class="s2">import </span><span class="s1">DecisionTreeClassifier</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">_mocking </span><span class="s2">import </span><span class="s1">CheckingClassifier</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">_testing </span><span class="s2">import </span><span class="s3">(</span>
    <span class="s1">_convert_container</span><span class="s3">,</span>
    <span class="s1">assert_almost_equal</span><span class="s3">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">,</span>
    <span class="s1">assert_array_equal</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">extmath </span><span class="s2">import </span><span class="s1">softmax</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">fixes </span><span class="s2">import </span><span class="s1">CSR_CONTAINERS</span>

<span class="s1">N_SAMPLES </span><span class="s3">= </span><span class="s4">200</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">fixture</span><span class="s3">(</span><span class="s1">scope</span><span class="s3">=</span><span class="s5">&quot;module&quot;</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">data</span><span class="s3">():</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s1">N_SAMPLES</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">6</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">42</span><span class="s3">)</span>
    <span class="s2">return </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;csr_container&quot;</span><span class="s3">, </span><span class="s1">CSR_CONTAINERS</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;method&quot;</span><span class="s3">, [</span><span class="s5">&quot;sigmoid&quot;</span><span class="s3">, </span><span class="s5">&quot;isotonic&quot;</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;ensemble&quot;</span><span class="s3">, [</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_calibration</span><span class="s3">(</span><span class="s1">data</span><span class="s3">, </span><span class="s1">method</span><span class="s3">, </span><span class="s1">csr_container</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">):</span>
    <span class="s0"># Test calibration objects with isotonic and sigmoid</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s1">N_SAMPLES </span><span class="s3">// </span><span class="s4">2</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">data</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s1">seed</span><span class="s3">=</span><span class="s4">42</span><span class="s3">).</span><span class="s1">uniform</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=</span><span class="s1">y</span><span class="s3">.</span><span class="s1">size</span><span class="s3">)</span>

    <span class="s1">X </span><span class="s3">-= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">min</span><span class="s3">()  </span><span class="s0"># MultinomialNB only allows positive X</span>

    <span class="s0"># split train and test</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">sw_train </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[:</span><span class="s1">n_samples</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[:</span><span class="s1">n_samples</span><span class="s3">], </span><span class="s1">sample_weight</span><span class="s3">[:</span><span class="s1">n_samples</span><span class="s3">]</span>
    <span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_test </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s1">n_samples</span><span class="s3">:], </span><span class="s1">y</span><span class="s3">[</span><span class="s1">n_samples</span><span class="s3">:]</span>

    <span class="s0"># Naive-Bayes</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">MultinomialNB</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sw_train</span><span class="s3">)</span>
    <span class="s1">prob_pos_clf </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)[:, </span><span class="s4">1</span><span class="s3">]</span>

    <span class="s1">cal_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s1">y</span><span class="s3">.</span><span class="s1">size </span><span class="s3">+ </span><span class="s4">1</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s1">ensemble</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">):</span>
        <span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s0"># Naive Bayes with calibration</span>
    <span class="s2">for </span><span class="s1">this_X_train</span><span class="s3">, </span><span class="s1">this_X_test </span><span class="s2">in </span><span class="s3">[</span>
        <span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">), </span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)),</span>
    <span class="s3">]:</span>
        <span class="s1">cal_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">method</span><span class="s3">=</span><span class="s1">method</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s1">ensemble</span><span class="s3">)</span>
        <span class="s0"># Note that this fit overwrites the fit on the entire training</span>
        <span class="s0"># set</span>
        <span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">this_X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sw_train</span><span class="s3">)</span>
        <span class="s1">prob_pos_cal_clf </span><span class="s3">= </span><span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">this_X_test</span><span class="s3">)[:, </span><span class="s4">1</span><span class="s3">]</span>

        <span class="s0"># Check that brier score has improved after calibration</span>
        <span class="s2">assert </span><span class="s1">brier_score_loss</span><span class="s3">(</span><span class="s1">y_test</span><span class="s3">, </span><span class="s1">prob_pos_clf</span><span class="s3">) &gt; </span><span class="s1">brier_score_loss</span><span class="s3">(</span>
            <span class="s1">y_test</span><span class="s3">, </span><span class="s1">prob_pos_cal_clf</span>
        <span class="s3">)</span>

        <span class="s0"># Check invariance against relabeling [0, 1] -&gt; [1, 2]</span>
        <span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">this_X_train</span><span class="s3">, </span><span class="s1">y_train </span><span class="s3">+ </span><span class="s4">1</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sw_train</span><span class="s3">)</span>
        <span class="s1">prob_pos_cal_clf_relabeled </span><span class="s3">= </span><span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">this_X_test</span><span class="s3">)[:, </span><span class="s4">1</span><span class="s3">]</span>
        <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">prob_pos_cal_clf</span><span class="s3">, </span><span class="s1">prob_pos_cal_clf_relabeled</span><span class="s3">)</span>

        <span class="s0"># Check invariance against relabeling [0, 1] -&gt; [-1, 1]</span>
        <span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">this_X_train</span><span class="s3">, </span><span class="s4">2 </span><span class="s3">* </span><span class="s1">y_train </span><span class="s3">- </span><span class="s4">1</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sw_train</span><span class="s3">)</span>
        <span class="s1">prob_pos_cal_clf_relabeled </span><span class="s3">= </span><span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">this_X_test</span><span class="s3">)[:, </span><span class="s4">1</span><span class="s3">]</span>
        <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">prob_pos_cal_clf</span><span class="s3">, </span><span class="s1">prob_pos_cal_clf_relabeled</span><span class="s3">)</span>

        <span class="s0"># Check invariance against relabeling [0, 1] -&gt; [1, 0]</span>
        <span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">this_X_train</span><span class="s3">, (</span><span class="s1">y_train </span><span class="s3">+ </span><span class="s4">1</span><span class="s3">) % </span><span class="s4">2</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sw_train</span><span class="s3">)</span>
        <span class="s1">prob_pos_cal_clf_relabeled </span><span class="s3">= </span><span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">this_X_test</span><span class="s3">)[:, </span><span class="s4">1</span><span class="s3">]</span>
        <span class="s2">if </span><span class="s1">method </span><span class="s3">== </span><span class="s5">&quot;sigmoid&quot;</span><span class="s3">:</span>
            <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">prob_pos_cal_clf</span><span class="s3">, </span><span class="s4">1 </span><span class="s3">- </span><span class="s1">prob_pos_cal_clf_relabeled</span><span class="s3">)</span>
        <span class="s2">else</span><span class="s3">:</span>
            <span class="s0"># Isotonic calibration is not invariant against relabeling</span>
            <span class="s0"># but should improve in both cases</span>
            <span class="s2">assert </span><span class="s1">brier_score_loss</span><span class="s3">(</span><span class="s1">y_test</span><span class="s3">, </span><span class="s1">prob_pos_clf</span><span class="s3">) &gt; </span><span class="s1">brier_score_loss</span><span class="s3">(</span>
                <span class="s3">(</span><span class="s1">y_test </span><span class="s3">+ </span><span class="s4">1</span><span class="s3">) % </span><span class="s4">2</span><span class="s3">, </span><span class="s1">prob_pos_cal_clf_relabeled</span>
            <span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_calibration_default_estimator</span><span class="s3">(</span><span class="s1">data</span><span class="s3">):</span>
    <span class="s0"># Check estimator default is LinearSVC</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">data</span>
    <span class="s1">calib_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">cv</span><span class="s3">=</span><span class="s4">2</span><span class="s3">)</span>
    <span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">base_est </span><span class="s3">= </span><span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">calibrated_classifiers_</span><span class="s3">[</span><span class="s4">0</span><span class="s3">].</span><span class="s1">estimator</span>
    <span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">base_est</span><span class="s3">, </span><span class="s1">LinearSVC</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;ensemble&quot;</span><span class="s3">, [</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_calibration_cv_splitter</span><span class="s3">(</span><span class="s1">data</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">):</span>
    <span class="s0"># Check when `cv` is a CV splitter</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">data</span>

    <span class="s1">splits </span><span class="s3">= </span><span class="s4">5</span>
    <span class="s1">kfold </span><span class="s3">= </span><span class="s1">KFold</span><span class="s3">(</span><span class="s1">n_splits</span><span class="s3">=</span><span class="s1">splits</span><span class="s3">)</span>
    <span class="s1">calib_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">cv</span><span class="s3">=</span><span class="s1">kfold</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s1">ensemble</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">cv</span><span class="s3">, </span><span class="s1">KFold</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">cv</span><span class="s3">.</span><span class="s1">n_splits </span><span class="s3">== </span><span class="s1">splits</span>

    <span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">expected_n_clf </span><span class="s3">= </span><span class="s1">splits </span><span class="s2">if </span><span class="s1">ensemble </span><span class="s2">else </span><span class="s4">1</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">calibrated_classifiers_</span><span class="s3">) == </span><span class="s1">expected_n_clf</span>


<span class="s2">def </span><span class="s1">test_calibration_cv_nfold</span><span class="s3">(</span><span class="s1">data</span><span class="s3">):</span>
    <span class="s0"># Check error raised when number of examples per class less than nfold</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">data</span>

    <span class="s1">kfold </span><span class="s3">= </span><span class="s1">KFold</span><span class="s3">(</span><span class="s1">n_splits</span><span class="s3">=</span><span class="s4">101</span><span class="s3">)</span>
    <span class="s1">calib_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">cv</span><span class="s3">=</span><span class="s1">kfold</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s5">&quot;Requesting 101-fold cross-validation&quot;</span><span class="s3">):</span>
        <span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">calib_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">cv</span><span class="s3">=</span><span class="s1">LeaveOneOut</span><span class="s3">(), </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s5">&quot;LeaveOneOut cross-validation does&quot;</span><span class="s3">):</span>
        <span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;method&quot;</span><span class="s3">, [</span><span class="s5">&quot;sigmoid&quot;</span><span class="s3">, </span><span class="s5">&quot;isotonic&quot;</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;ensemble&quot;</span><span class="s3">, [</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_sample_weight</span><span class="s3">(</span><span class="s1">data</span><span class="s3">, </span><span class="s1">method</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">):</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s1">N_SAMPLES </span><span class="s3">// </span><span class="s4">2</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">data</span>

    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s1">seed</span><span class="s3">=</span><span class="s4">42</span><span class="s3">).</span><span class="s1">uniform</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=</span><span class="s1">len</span><span class="s3">(</span><span class="s1">y</span><span class="s3">))</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">sw_train </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[:</span><span class="s1">n_samples</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[:</span><span class="s1">n_samples</span><span class="s3">], </span><span class="s1">sample_weight</span><span class="s3">[:</span><span class="s1">n_samples</span><span class="s3">]</span>
    <span class="s1">X_test </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s1">n_samples</span><span class="s3">:]</span>

    <span class="s1">estimator </span><span class="s3">= </span><span class="s1">LinearSVC</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">42</span><span class="s3">)</span>
    <span class="s1">calibrated_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">, </span><span class="s1">method</span><span class="s3">=</span><span class="s1">method</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s1">ensemble</span><span class="s3">)</span>
    <span class="s1">calibrated_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sw_train</span><span class="s3">)</span>
    <span class="s1">probs_with_sw </span><span class="s3">= </span><span class="s1">calibrated_clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>

    <span class="s0"># As the weights are used for the calibration, they should still yield</span>
    <span class="s0"># different predictions</span>
    <span class="s1">calibrated_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">)</span>
    <span class="s1">probs_without_sw </span><span class="s3">= </span><span class="s1">calibrated_clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>

    <span class="s1">diff </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linalg</span><span class="s3">.</span><span class="s1">norm</span><span class="s3">(</span><span class="s1">probs_with_sw </span><span class="s3">- </span><span class="s1">probs_without_sw</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">diff </span><span class="s3">&gt; </span><span class="s4">0.1</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;method&quot;</span><span class="s3">, [</span><span class="s5">&quot;sigmoid&quot;</span><span class="s3">, </span><span class="s5">&quot;isotonic&quot;</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;ensemble&quot;</span><span class="s3">, [</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_parallel_execution</span><span class="s3">(</span><span class="s1">data</span><span class="s3">, </span><span class="s1">method</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Test parallel calibration&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">data</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">y_test </span><span class="s3">= </span><span class="s1">train_test_split</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">42</span><span class="s3">)</span>

    <span class="s1">estimator </span><span class="s3">= </span><span class="s1">make_pipeline</span><span class="s3">(</span><span class="s1">StandardScaler</span><span class="s3">(), </span><span class="s1">LinearSVC</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">42</span><span class="s3">))</span>

    <span class="s1">cal_clf_parallel </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span>
        <span class="s1">estimator</span><span class="s3">, </span><span class="s1">method</span><span class="s3">=</span><span class="s1">method</span><span class="s3">, </span><span class="s1">n_jobs</span><span class="s3">=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s1">ensemble</span>
    <span class="s3">)</span>
    <span class="s1">cal_clf_parallel</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">)</span>
    <span class="s1">probs_parallel </span><span class="s3">= </span><span class="s1">cal_clf_parallel</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>

    <span class="s1">cal_clf_sequential </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span>
        <span class="s1">estimator</span><span class="s3">, </span><span class="s1">method</span><span class="s3">=</span><span class="s1">method</span><span class="s3">, </span><span class="s1">n_jobs</span><span class="s3">=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s1">ensemble</span>
    <span class="s3">)</span>
    <span class="s1">cal_clf_sequential</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">)</span>
    <span class="s1">probs_sequential </span><span class="s3">= </span><span class="s1">cal_clf_sequential</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>

    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">probs_parallel</span><span class="s3">, </span><span class="s1">probs_sequential</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;method&quot;</span><span class="s3">, [</span><span class="s5">&quot;sigmoid&quot;</span><span class="s3">, </span><span class="s5">&quot;isotonic&quot;</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;ensemble&quot;</span><span class="s3">, [</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">])</span>
<span class="s0"># increase the number of RNG seeds to assess the statistical stability of this</span>
<span class="s0"># test:</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;seed&quot;</span><span class="s3">, </span><span class="s1">range</span><span class="s3">(</span><span class="s4">2</span><span class="s3">))</span>
<span class="s2">def </span><span class="s1">test_calibration_multiclass</span><span class="s3">(</span><span class="s1">method</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">, </span><span class="s1">seed</span><span class="s3">):</span>
    <span class="s2">def </span><span class="s1">multiclass_brier</span><span class="s3">(</span><span class="s1">y_true</span><span class="s3">, </span><span class="s1">proba_pred</span><span class="s3">, </span><span class="s1">n_classes</span><span class="s3">):</span>
        <span class="s1">Y_onehot </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">eye</span><span class="s3">(</span><span class="s1">n_classes</span><span class="s3">)[</span><span class="s1">y_true</span><span class="s3">]</span>
        <span class="s2">return </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">((</span><span class="s1">Y_onehot </span><span class="s3">- </span><span class="s1">proba_pred</span><span class="s3">) ** </span><span class="s4">2</span><span class="s3">) / </span><span class="s1">Y_onehot</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">0</span><span class="s3">]</span>

    <span class="s0"># Test calibration for multiclass with classifier that implements</span>
    <span class="s0"># only decision function.</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">LinearSVC</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">7</span><span class="s3">)</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_blobs</span><span class="s3">(</span>
        <span class="s1">n_samples</span><span class="s3">=</span><span class="s4">500</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">100</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s1">seed</span><span class="s3">, </span><span class="s1">centers</span><span class="s3">=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">cluster_std</span><span class="s3">=</span><span class="s4">15.0</span>
    <span class="s3">)</span>

    <span class="s0"># Use an unbalanced dataset by collapsing 8 clusters into one class</span>
    <span class="s0"># to make the naive calibration based on a softmax more unlikely</span>
    <span class="s0"># to work.</span>
    <span class="s1">y</span><span class="s3">[</span><span class="s1">y </span><span class="s3">&gt; </span><span class="s4">2</span><span class="s3">] = </span><span class="s4">2</span>
    <span class="s1">n_classes </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">unique</span><span class="s3">(</span><span class="s1">y</span><span class="s3">).</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">0</span><span class="s3">]</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[::</span><span class="s4">2</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[::</span><span class="s4">2</span><span class="s3">]</span>
    <span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_test </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s4">1</span><span class="s3">::</span><span class="s4">2</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[</span><span class="s4">1</span><span class="s3">::</span><span class="s4">2</span><span class="s3">]</span>

    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">)</span>

    <span class="s1">cal_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">method</span><span class="s3">=</span><span class="s1">method</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s1">ensemble</span><span class="s3">)</span>
    <span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">)</span>
    <span class="s1">probas </span><span class="s3">= </span><span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
    <span class="s0"># Check probabilities sum to 1</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">probas</span><span class="s3">, </span><span class="s1">axis</span><span class="s3">=</span><span class="s4">1</span><span class="s3">), </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">(</span><span class="s1">len</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)))</span>

    <span class="s0"># Check that the dataset is not too trivial, otherwise it's hard</span>
    <span class="s0"># to get interesting calibration data during the internal</span>
    <span class="s0"># cross-validation loop.</span>
    <span class="s2">assert </span><span class="s4">0.65 </span><span class="s3">&lt; </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_test</span><span class="s3">) &lt; </span><span class="s4">0.95</span>

    <span class="s0"># Check that the accuracy of the calibrated model is never degraded</span>
    <span class="s0"># too much compared to the original classifier.</span>
    <span class="s2">assert </span><span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_test</span><span class="s3">) &gt; </span><span class="s4">0.95 </span><span class="s3">* </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_test</span><span class="s3">)</span>

    <span class="s0"># Check that Brier loss of calibrated classifier is smaller than</span>
    <span class="s0"># loss obtained by naively turning OvR decision function to</span>
    <span class="s0"># probabilities via a softmax</span>
    <span class="s1">uncalibrated_brier </span><span class="s3">= </span><span class="s1">multiclass_brier</span><span class="s3">(</span>
        <span class="s1">y_test</span><span class="s3">, </span><span class="s1">softmax</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">.</span><span class="s1">decision_function</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)), </span><span class="s1">n_classes</span><span class="s3">=</span><span class="s1">n_classes</span>
    <span class="s3">)</span>
    <span class="s1">calibrated_brier </span><span class="s3">= </span><span class="s1">multiclass_brier</span><span class="s3">(</span><span class="s1">y_test</span><span class="s3">, </span><span class="s1">probas</span><span class="s3">, </span><span class="s1">n_classes</span><span class="s3">=</span><span class="s1">n_classes</span><span class="s3">)</span>

    <span class="s2">assert </span><span class="s1">calibrated_brier </span><span class="s3">&lt; </span><span class="s4">1.1 </span><span class="s3">* </span><span class="s1">uncalibrated_brier</span>

    <span class="s0"># Test that calibration of a multiclass classifier decreases log-loss</span>
    <span class="s0"># for RandomForestClassifier</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">RandomForestClassifier</span><span class="s3">(</span><span class="s1">n_estimators</span><span class="s3">=</span><span class="s4">30</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">42</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">)</span>
    <span class="s1">clf_probs </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
    <span class="s1">uncalibrated_brier </span><span class="s3">= </span><span class="s1">multiclass_brier</span><span class="s3">(</span><span class="s1">y_test</span><span class="s3">, </span><span class="s1">clf_probs</span><span class="s3">, </span><span class="s1">n_classes</span><span class="s3">=</span><span class="s1">n_classes</span><span class="s3">)</span>

    <span class="s1">cal_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">method</span><span class="s3">=</span><span class="s1">method</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s1">ensemble</span><span class="s3">)</span>
    <span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">)</span>
    <span class="s1">cal_clf_probs </span><span class="s3">= </span><span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
    <span class="s1">calibrated_brier </span><span class="s3">= </span><span class="s1">multiclass_brier</span><span class="s3">(</span><span class="s1">y_test</span><span class="s3">, </span><span class="s1">cal_clf_probs</span><span class="s3">, </span><span class="s1">n_classes</span><span class="s3">=</span><span class="s1">n_classes</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">calibrated_brier </span><span class="s3">&lt; </span><span class="s4">1.1 </span><span class="s3">* </span><span class="s1">uncalibrated_brier</span>


<span class="s2">def </span><span class="s1">test_calibration_zero_probability</span><span class="s3">():</span>
    <span class="s0"># Test an edge case where _CalibratedClassifier avoids numerical errors</span>
    <span class="s0"># in the multiclass normalization step if all the calibrators output</span>
    <span class="s0"># are zero all at once for a given sample and instead fallback to uniform</span>
    <span class="s0"># probabilities.</span>
    <span class="s2">class </span><span class="s1">ZeroCalibrator</span><span class="s3">:</span>
        <span class="s0"># This function is called from _CalibratedClassifier.predict_proba.</span>
        <span class="s2">def </span><span class="s1">predict</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">):</span>
            <span class="s2">return </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">0</span><span class="s3">])</span>

    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_blobs</span><span class="s3">(</span>
        <span class="s1">n_samples</span><span class="s3">=</span><span class="s4">50</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">7</span><span class="s3">, </span><span class="s1">centers</span><span class="s3">=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">cluster_std</span><span class="s3">=</span><span class="s4">15.0</span>
    <span class="s3">)</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">DummyClassifier</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">calibrator </span><span class="s3">= </span><span class="s1">ZeroCalibrator</span><span class="s3">()</span>
    <span class="s1">cal_clf </span><span class="s3">= </span><span class="s1">_CalibratedClassifier</span><span class="s3">(</span>
        <span class="s1">estimator</span><span class="s3">=</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">calibrators</span><span class="s3">=[</span><span class="s1">calibrator</span><span class="s3">], </span><span class="s1">classes</span><span class="s3">=</span><span class="s1">clf</span><span class="s3">.</span><span class="s1">classes_</span>
    <span class="s3">)</span>

    <span class="s1">probas </span><span class="s3">= </span><span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>

    <span class="s0"># Check that all probabilities are uniformly 1. / clf.n_classes_</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">probas</span><span class="s3">, </span><span class="s4">1.0 </span><span class="s3">/ </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">n_classes_</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;csr_container&quot;</span><span class="s3">, </span><span class="s1">CSR_CONTAINERS</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_calibration_prefit</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Test calibration for prefitted classifiers&quot;&quot;&quot;</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s4">50</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s4">3 </span><span class="s3">* </span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">6</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">42</span><span class="s3">)</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s1">seed</span><span class="s3">=</span><span class="s4">42</span><span class="s3">).</span><span class="s1">uniform</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=</span><span class="s1">y</span><span class="s3">.</span><span class="s1">size</span><span class="s3">)</span>

    <span class="s1">X </span><span class="s3">-= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">min</span><span class="s3">()  </span><span class="s0"># MultinomialNB only allows positive X</span>

    <span class="s0"># split train and test</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">sw_train </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[:</span><span class="s1">n_samples</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[:</span><span class="s1">n_samples</span><span class="s3">], </span><span class="s1">sample_weight</span><span class="s3">[:</span><span class="s1">n_samples</span><span class="s3">]</span>
    <span class="s1">X_calib</span><span class="s3">, </span><span class="s1">y_calib</span><span class="s3">, </span><span class="s1">sw_calib </span><span class="s3">= (</span>
        <span class="s1">X</span><span class="s3">[</span><span class="s1">n_samples </span><span class="s3">: </span><span class="s4">2 </span><span class="s3">* </span><span class="s1">n_samples</span><span class="s3">],</span>
        <span class="s1">y</span><span class="s3">[</span><span class="s1">n_samples </span><span class="s3">: </span><span class="s4">2 </span><span class="s3">* </span><span class="s1">n_samples</span><span class="s3">],</span>
        <span class="s1">sample_weight</span><span class="s3">[</span><span class="s1">n_samples </span><span class="s3">: </span><span class="s4">2 </span><span class="s3">* </span><span class="s1">n_samples</span><span class="s3">],</span>
    <span class="s3">)</span>
    <span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_test </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s4">2 </span><span class="s3">* </span><span class="s1">n_samples </span><span class="s3">:], </span><span class="s1">y</span><span class="s3">[</span><span class="s4">2 </span><span class="s3">* </span><span class="s1">n_samples </span><span class="s3">:]</span>

    <span class="s0"># Naive-Bayes</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">MultinomialNB</span><span class="s3">()</span>
    <span class="s0"># Check error if clf not prefit</span>
    <span class="s1">unfit_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s5">&quot;prefit&quot;</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">NotFittedError</span><span class="s3">):</span>
        <span class="s1">unfit_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_calib</span><span class="s3">, </span><span class="s1">y_calib</span><span class="s3">)</span>

    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">sw_train</span><span class="s3">)</span>
    <span class="s1">prob_pos_clf </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)[:, </span><span class="s4">1</span><span class="s3">]</span>

    <span class="s0"># Naive Bayes with calibration</span>
    <span class="s2">for </span><span class="s1">this_X_calib</span><span class="s3">, </span><span class="s1">this_X_test </span><span class="s2">in </span><span class="s3">[</span>
        <span class="s3">(</span><span class="s1">X_calib</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X_calib</span><span class="s3">), </span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)),</span>
    <span class="s3">]:</span>
        <span class="s2">for </span><span class="s1">method </span><span class="s2">in </span><span class="s3">[</span><span class="s5">&quot;isotonic&quot;</span><span class="s3">, </span><span class="s5">&quot;sigmoid&quot;</span><span class="s3">]:</span>
            <span class="s1">cal_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">method</span><span class="s3">=</span><span class="s1">method</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s5">&quot;prefit&quot;</span><span class="s3">)</span>

            <span class="s2">for </span><span class="s1">sw </span><span class="s2">in </span><span class="s3">[</span><span class="s1">sw_calib</span><span class="s3">, </span><span class="s2">None</span><span class="s3">]:</span>
                <span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">this_X_calib</span><span class="s3">, </span><span class="s1">y_calib</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sw</span><span class="s3">)</span>
                <span class="s1">y_prob </span><span class="s3">= </span><span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">this_X_test</span><span class="s3">)</span>
                <span class="s1">y_pred </span><span class="s3">= </span><span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">this_X_test</span><span class="s3">)</span>
                <span class="s1">prob_pos_cal_clf </span><span class="s3">= </span><span class="s1">y_prob</span><span class="s3">[:, </span><span class="s4">1</span><span class="s3">]</span>
                <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">y_pred</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">])[</span><span class="s1">np</span><span class="s3">.</span><span class="s1">argmax</span><span class="s3">(</span><span class="s1">y_prob</span><span class="s3">, </span><span class="s1">axis</span><span class="s3">=</span><span class="s4">1</span><span class="s3">)])</span>

                <span class="s2">assert </span><span class="s1">brier_score_loss</span><span class="s3">(</span><span class="s1">y_test</span><span class="s3">, </span><span class="s1">prob_pos_clf</span><span class="s3">) &gt; </span><span class="s1">brier_score_loss</span><span class="s3">(</span>
                    <span class="s1">y_test</span><span class="s3">, </span><span class="s1">prob_pos_cal_clf</span>
                <span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;method&quot;</span><span class="s3">, [</span><span class="s5">&quot;sigmoid&quot;</span><span class="s3">, </span><span class="s5">&quot;isotonic&quot;</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_calibration_ensemble_false</span><span class="s3">(</span><span class="s1">data</span><span class="s3">, </span><span class="s1">method</span><span class="s3">):</span>
    <span class="s0"># Test that `ensemble=False` is the same as using predictions from</span>
    <span class="s0"># `cross_val_predict` to train calibrator.</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">data</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">LinearSVC</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">7</span><span class="s3">)</span>

    <span class="s1">cal_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">method</span><span class="s3">=</span><span class="s1">method</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s4">3</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s2">False</span><span class="s3">)</span>
    <span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">cal_probas </span><span class="s3">= </span><span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>

    <span class="s0"># Get probas manually</span>
    <span class="s1">unbiased_preds </span><span class="s3">= </span><span class="s1">cross_val_predict</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s4">3</span><span class="s3">, </span><span class="s1">method</span><span class="s3">=</span><span class="s5">&quot;decision_function&quot;</span><span class="s3">)</span>
    <span class="s2">if </span><span class="s1">method </span><span class="s3">== </span><span class="s5">&quot;isotonic&quot;</span><span class="s3">:</span>
        <span class="s1">calibrator </span><span class="s3">= </span><span class="s1">IsotonicRegression</span><span class="s3">(</span><span class="s1">out_of_bounds</span><span class="s3">=</span><span class="s5">&quot;clip&quot;</span><span class="s3">)</span>
    <span class="s2">else</span><span class="s3">:</span>
        <span class="s1">calibrator </span><span class="s3">= </span><span class="s1">_SigmoidCalibration</span><span class="s3">()</span>
    <span class="s1">calibrator</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">unbiased_preds</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s0"># Use `clf` fit on all data</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf_df </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">decision_function</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">manual_probas </span><span class="s3">= </span><span class="s1">calibrator</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">clf_df</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">cal_probas</span><span class="s3">[:, </span><span class="s4">1</span><span class="s3">], </span><span class="s1">manual_probas</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_sigmoid_calibration</span><span class="s3">():</span>
    <span class="s6">&quot;&quot;&quot;Test calibration values with Platt sigmoid model&quot;&quot;&quot;</span>
    <span class="s1">exF </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">5</span><span class="s3">, -</span><span class="s4">4</span><span class="s3">, </span><span class="s4">1.0</span><span class="s3">])</span>
    <span class="s1">exY </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">1</span><span class="s3">, -</span><span class="s4">1</span><span class="s3">, -</span><span class="s4">1</span><span class="s3">])</span>
    <span class="s0"># computed from my python port of the C++ code in LibSVM</span>
    <span class="s1">AB_lin_libsvm </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([-</span><span class="s4">0.20261354391187855</span><span class="s3">, </span><span class="s4">0.65236314980010512</span><span class="s3">])</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">AB_lin_libsvm</span><span class="s3">, </span><span class="s1">_sigmoid_calibration</span><span class="s3">(</span><span class="s1">exF</span><span class="s3">, </span><span class="s1">exY</span><span class="s3">), </span><span class="s4">3</span><span class="s3">)</span>
    <span class="s1">lin_prob </span><span class="s3">= </span><span class="s4">1.0 </span><span class="s3">/ (</span><span class="s4">1.0 </span><span class="s3">+ </span><span class="s1">np</span><span class="s3">.</span><span class="s1">exp</span><span class="s3">(</span><span class="s1">AB_lin_libsvm</span><span class="s3">[</span><span class="s4">0</span><span class="s3">] * </span><span class="s1">exF </span><span class="s3">+ </span><span class="s1">AB_lin_libsvm</span><span class="s3">[</span><span class="s4">1</span><span class="s3">]))</span>
    <span class="s1">sk_prob </span><span class="s3">= </span><span class="s1">_SigmoidCalibration</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">exF</span><span class="s3">, </span><span class="s1">exY</span><span class="s3">).</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">exF</span><span class="s3">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">lin_prob</span><span class="s3">, </span><span class="s1">sk_prob</span><span class="s3">, </span><span class="s4">6</span><span class="s3">)</span>

    <span class="s0"># check that _SigmoidCalibration().fit only accepts 1d array or 2d column</span>
    <span class="s0"># arrays</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">):</span>
        <span class="s1">_SigmoidCalibration</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">vstack</span><span class="s3">((</span><span class="s1">exF</span><span class="s3">, </span><span class="s1">exF</span><span class="s3">)), </span><span class="s1">exY</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_calibration_curve</span><span class="s3">():</span>
    <span class="s6">&quot;&quot;&quot;Check calibration_curve function&quot;&quot;&quot;</span>
    <span class="s1">y_true </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">])</span>
    <span class="s1">y_pred </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0.0</span><span class="s3">, </span><span class="s4">0.1</span><span class="s3">, </span><span class="s4">0.2</span><span class="s3">, </span><span class="s4">0.8</span><span class="s3">, </span><span class="s4">0.9</span><span class="s3">, </span><span class="s4">1.0</span><span class="s3">])</span>
    <span class="s1">prob_true</span><span class="s3">, </span><span class="s1">prob_pred </span><span class="s3">= </span><span class="s1">calibration_curve</span><span class="s3">(</span><span class="s1">y_true</span><span class="s3">, </span><span class="s1">y_pred</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">=</span><span class="s4">2</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">prob_true</span><span class="s3">) == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">prob_pred</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">prob_true</span><span class="s3">) == </span><span class="s4">2</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">prob_true</span><span class="s3">, [</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">])</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">prob_pred</span><span class="s3">, [</span><span class="s4">0.1</span><span class="s3">, </span><span class="s4">0.9</span><span class="s3">])</span>

    <span class="s0"># Probabilities outside [0, 1] should not be accepted at all.</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">):</span>
        <span class="s1">calibration_curve</span><span class="s3">([</span><span class="s4">1</span><span class="s3">], [-</span><span class="s4">0.1</span><span class="s3">])</span>

    <span class="s0"># test that quantiles work as expected</span>
    <span class="s1">y_true2 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">])</span>
    <span class="s1">y_pred2 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0.0</span><span class="s3">, </span><span class="s4">0.1</span><span class="s3">, </span><span class="s4">0.2</span><span class="s3">, </span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">0.9</span><span class="s3">, </span><span class="s4">1.0</span><span class="s3">])</span>
    <span class="s1">prob_true_quantile</span><span class="s3">, </span><span class="s1">prob_pred_quantile </span><span class="s3">= </span><span class="s1">calibration_curve</span><span class="s3">(</span>
        <span class="s1">y_true2</span><span class="s3">, </span><span class="s1">y_pred2</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">strategy</span><span class="s3">=</span><span class="s5">&quot;quantile&quot;</span>
    <span class="s3">)</span>

    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">prob_true_quantile</span><span class="s3">) == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">prob_pred_quantile</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">prob_true_quantile</span><span class="s3">) == </span><span class="s4">2</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">prob_true_quantile</span><span class="s3">, [</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2 </span><span class="s3">/ </span><span class="s4">3</span><span class="s3">])</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">prob_pred_quantile</span><span class="s3">, [</span><span class="s4">0.1</span><span class="s3">, </span><span class="s4">0.8</span><span class="s3">])</span>

    <span class="s0"># Check that error is raised when invalid strategy is selected</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">):</span>
        <span class="s1">calibration_curve</span><span class="s3">(</span><span class="s1">y_true2</span><span class="s3">, </span><span class="s1">y_pred2</span><span class="s3">, </span><span class="s1">strategy</span><span class="s3">=</span><span class="s5">&quot;percentile&quot;</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;ensemble&quot;</span><span class="s3">, [</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_calibration_nan_imputer</span><span class="s3">(</span><span class="s1">ensemble</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Test that calibration can accept nan&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span>
        <span class="s1">n_samples</span><span class="s3">=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">n_informative</span><span class="s3">=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">n_redundant</span><span class="s3">=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">42</span>
    <span class="s3">)</span>
    <span class="s1">X</span><span class="s3">[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">] = </span><span class="s1">np</span><span class="s3">.</span><span class="s1">nan</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">Pipeline</span><span class="s3">(</span>
        <span class="s3">[(</span><span class="s5">&quot;imputer&quot;</span><span class="s3">, </span><span class="s1">SimpleImputer</span><span class="s3">()), (</span><span class="s5">&quot;rf&quot;</span><span class="s3">, </span><span class="s1">RandomForestClassifier</span><span class="s3">(</span><span class="s1">n_estimators</span><span class="s3">=</span><span class="s4">1</span><span class="s3">))]</span>
    <span class="s3">)</span>
    <span class="s1">clf_c </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">method</span><span class="s3">=</span><span class="s5">&quot;isotonic&quot;</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s1">ensemble</span><span class="s3">)</span>
    <span class="s1">clf_c</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf_c</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;ensemble&quot;</span><span class="s3">, [</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_calibration_prob_sum</span><span class="s3">(</span><span class="s1">ensemble</span><span class="s3">):</span>
    <span class="s0"># Test that sum of probabilities is (max) 1. A non-regression test for</span>
    <span class="s0"># issue #7796 - when test has fewer classes than train</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">_ </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">n_classes</span><span class="s3">=</span><span class="s4">2</span><span class="s3">)</span>
    <span class="s1">y </span><span class="s3">= [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">]</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">LinearSVC</span><span class="s3">(</span><span class="s1">C</span><span class="s3">=</span><span class="s4">1.0</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">7</span><span class="s3">)</span>
    <span class="s0"># In the first and last fold, test will have 1 class while train will have 2</span>
    <span class="s1">clf_prob </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span>
        <span class="s1">clf</span><span class="s3">, </span><span class="s1">method</span><span class="s3">=</span><span class="s5">&quot;sigmoid&quot;</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s1">KFold</span><span class="s3">(</span><span class="s1">n_splits</span><span class="s3">=</span><span class="s4">3</span><span class="s3">), </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s1">ensemble</span>
    <span class="s3">)</span>
    <span class="s1">clf_prob</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">clf_prob</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">).</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">axis</span><span class="s3">=</span><span class="s4">1</span><span class="s3">), </span><span class="s4">1.0</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;ensemble&quot;</span><span class="s3">, [</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_calibration_less_classes</span><span class="s3">(</span><span class="s1">ensemble</span><span class="s3">):</span>
    <span class="s0"># Test to check calibration works fine when train set in a test-train</span>
    <span class="s0"># split does not contain all classes</span>
    <span class="s0"># In 1st split, train is missing class 0</span>
    <span class="s0"># In 3rd split, train is missing class 3</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s4">12</span><span class="s3">, </span><span class="s4">5</span><span class="s3">)</span>
    <span class="s1">y </span><span class="s3">= [</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">] + [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">2</span><span class="s3">] + [</span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">3</span><span class="s3">]</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">DecisionTreeClassifier</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">7</span><span class="s3">)</span>
    <span class="s1">cal_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span>
        <span class="s1">clf</span><span class="s3">, </span><span class="s1">method</span><span class="s3">=</span><span class="s5">&quot;sigmoid&quot;</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s1">KFold</span><span class="s3">(</span><span class="s4">3</span><span class="s3">), </span><span class="s1">ensemble</span><span class="s3">=</span><span class="s1">ensemble</span>
    <span class="s3">)</span>
    <span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s2">if </span><span class="s1">ensemble</span><span class="s3">:</span>
        <span class="s1">classes </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">arange</span><span class="s3">(</span><span class="s4">4</span><span class="s3">)</span>
        <span class="s2">for </span><span class="s1">calib_i</span><span class="s3">, </span><span class="s1">class_i </span><span class="s2">in </span><span class="s1">zip</span><span class="s3">([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2</span><span class="s3">], [</span><span class="s4">0</span><span class="s3">, </span><span class="s4">3</span><span class="s3">]):</span>
            <span class="s1">proba </span><span class="s3">= </span><span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">calibrated_classifiers_</span><span class="s3">[</span><span class="s1">calib_i</span><span class="s3">].</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
            <span class="s0"># Check that the unobserved class has proba=0</span>
            <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">proba</span><span class="s3">[:, </span><span class="s1">class_i</span><span class="s3">], </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">len</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)))</span>
            <span class="s0"># Check for all other classes proba&gt;0</span>
            <span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">all</span><span class="s3">(</span><span class="s1">proba</span><span class="s3">[:, </span><span class="s1">classes </span><span class="s3">!= </span><span class="s1">class_i</span><span class="s3">] &gt; </span><span class="s4">0</span><span class="s3">)</span>

    <span class="s0"># When `ensemble=False`, `cross_val_predict` is used to compute predictions</span>
    <span class="s0"># to fit only one `calibrated_classifiers_`</span>
    <span class="s2">else</span><span class="s3">:</span>
        <span class="s1">proba </span><span class="s3">= </span><span class="s1">cal_clf</span><span class="s3">.</span><span class="s1">calibrated_classifiers_</span><span class="s3">[</span><span class="s4">0</span><span class="s3">].</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
        <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">proba</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">axis</span><span class="s3">=</span><span class="s4">1</span><span class="s3">), </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">(</span><span class="s1">proba</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">0</span><span class="s3">]))</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s5">&quot;X&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s4">42</span><span class="s3">).</span><span class="s1">randn</span><span class="s3">(</span><span class="s4">15</span><span class="s3">, </span><span class="s4">5</span><span class="s3">, </span><span class="s4">2</span><span class="s3">),</span>
        <span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s4">42</span><span class="s3">).</span><span class="s1">randn</span><span class="s3">(</span><span class="s4">15</span><span class="s3">, </span><span class="s4">5</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">6</span><span class="s3">),</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_calibration_accepts_ndarray</span><span class="s3">(</span><span class="s1">X</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Test that calibration accepts n-dimensional arrays as input&quot;&quot;&quot;</span>
    <span class="s1">y </span><span class="s3">= [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">]</span>

    <span class="s2">class </span><span class="s1">MockTensorClassifier</span><span class="s3">(</span><span class="s1">BaseEstimator</span><span class="s3">):</span>
        <span class="s6">&quot;&quot;&quot;A toy estimator that accepts tensor inputs&quot;&quot;&quot;</span>

        <span class="s1">_estimator_type </span><span class="s3">= </span><span class="s5">&quot;classifier&quot;</span>

        <span class="s2">def </span><span class="s1">fit</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">):</span>
            <span class="s1">self</span><span class="s3">.</span><span class="s1">classes_ </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">unique</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>
            <span class="s2">return </span><span class="s1">self</span>

        <span class="s2">def </span><span class="s1">decision_function</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">):</span>
            <span class="s0"># toy decision function that just needs to have the right shape:</span>
            <span class="s2">return </span><span class="s1">X</span><span class="s3">.</span><span class="s1">reshape</span><span class="s3">(</span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">0</span><span class="s3">], -</span><span class="s4">1</span><span class="s3">).</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">axis</span><span class="s3">=</span><span class="s4">1</span><span class="s3">)</span>

    <span class="s1">calibrated_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">MockTensorClassifier</span><span class="s3">())</span>
    <span class="s0"># we should be able to fit this classifier with no error</span>
    <span class="s1">calibrated_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">fixture</span>
<span class="s2">def </span><span class="s1">dict_data</span><span class="s3">():</span>
    <span class="s1">dict_data </span><span class="s3">= [</span>
        <span class="s3">{</span><span class="s5">&quot;state&quot;</span><span class="s3">: </span><span class="s5">&quot;NY&quot;</span><span class="s3">, </span><span class="s5">&quot;age&quot;</span><span class="s3">: </span><span class="s5">&quot;adult&quot;</span><span class="s3">},</span>
        <span class="s3">{</span><span class="s5">&quot;state&quot;</span><span class="s3">: </span><span class="s5">&quot;TX&quot;</span><span class="s3">, </span><span class="s5">&quot;age&quot;</span><span class="s3">: </span><span class="s5">&quot;adult&quot;</span><span class="s3">},</span>
        <span class="s3">{</span><span class="s5">&quot;state&quot;</span><span class="s3">: </span><span class="s5">&quot;VT&quot;</span><span class="s3">, </span><span class="s5">&quot;age&quot;</span><span class="s3">: </span><span class="s5">&quot;child&quot;</span><span class="s3">},</span>
    <span class="s3">]</span>
    <span class="s1">text_labels </span><span class="s3">= [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">]</span>
    <span class="s2">return </span><span class="s1">dict_data</span><span class="s3">, </span><span class="s1">text_labels</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">fixture</span>
<span class="s2">def </span><span class="s1">dict_data_pipeline</span><span class="s3">(</span><span class="s1">dict_data</span><span class="s3">):</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">dict_data</span>
    <span class="s1">pipeline_prefit </span><span class="s3">= </span><span class="s1">Pipeline</span><span class="s3">(</span>
        <span class="s3">[(</span><span class="s5">&quot;vectorizer&quot;</span><span class="s3">, </span><span class="s1">DictVectorizer</span><span class="s3">()), (</span><span class="s5">&quot;clf&quot;</span><span class="s3">, </span><span class="s1">RandomForestClassifier</span><span class="s3">())]</span>
    <span class="s3">)</span>
    <span class="s2">return </span><span class="s1">pipeline_prefit</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_calibration_dict_pipeline</span><span class="s3">(</span><span class="s1">dict_data</span><span class="s3">, </span><span class="s1">dict_data_pipeline</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Test that calibration works in prefit pipeline with transformer 
 
    `X` is not array-like, sparse matrix or dataframe at the start. 
    See https://github.com/scikit-learn/scikit-learn/issues/8710 
 
    Also test it can predict without running into validation errors. 
    See https://github.com/scikit-learn/scikit-learn/issues/19637 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">dict_data</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">dict_data_pipeline</span>
    <span class="s1">calib_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s5">&quot;prefit&quot;</span><span class="s3">)</span>
    <span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s0"># Check attributes are obtained from fitted estimator</span>
    <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">classes_</span><span class="s3">, </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">classes_</span><span class="s3">)</span>

    <span class="s0"># Neither the pipeline nor the calibration meta-estimator</span>
    <span class="s0"># expose the n_features_in_ check on this kind of data.</span>
    <span class="s2">assert not </span><span class="s1">hasattr</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s5">&quot;n_features_in_&quot;</span><span class="s3">)</span>
    <span class="s2">assert not </span><span class="s1">hasattr</span><span class="s3">(</span><span class="s1">calib_clf</span><span class="s3">, </span><span class="s5">&quot;n_features_in_&quot;</span><span class="s3">)</span>

    <span class="s0"># Ensure that no error is thrown with predict and predict_proba</span>
    <span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s5">&quot;clf, cv&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s1">pytest</span><span class="s3">.</span><span class="s1">param</span><span class="s3">(</span><span class="s1">LinearSVC</span><span class="s3">(</span><span class="s1">C</span><span class="s3">=</span><span class="s4">1</span><span class="s3">), </span><span class="s4">2</span><span class="s3">),</span>
        <span class="s1">pytest</span><span class="s3">.</span><span class="s1">param</span><span class="s3">(</span><span class="s1">LinearSVC</span><span class="s3">(</span><span class="s1">C</span><span class="s3">=</span><span class="s4">1</span><span class="s3">), </span><span class="s5">&quot;prefit&quot;</span><span class="s3">),</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_calibration_attributes</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">):</span>
    <span class="s0"># Check that `n_features_in_` and `classes_` attributes created properly</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">n_classes</span><span class="s3">=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">7</span><span class="s3">)</span>
    <span class="s2">if </span><span class="s1">cv </span><span class="s3">== </span><span class="s5">&quot;prefit&quot;</span><span class="s3">:</span>
        <span class="s1">clf </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">calib_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s1">cv</span><span class="s3">)</span>
    <span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s2">if </span><span class="s1">cv </span><span class="s3">== </span><span class="s5">&quot;prefit&quot;</span><span class="s3">:</span>
        <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">classes_</span><span class="s3">, </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">classes_</span><span class="s3">)</span>
        <span class="s2">assert </span><span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">n_features_in_ </span><span class="s3">== </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">n_features_in_</span>
    <span class="s2">else</span><span class="s3">:</span>
        <span class="s1">classes </span><span class="s3">= </span><span class="s1">LabelEncoder</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">y</span><span class="s3">).</span><span class="s1">classes_</span>
        <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">classes_</span><span class="s3">, </span><span class="s1">classes</span><span class="s3">)</span>
        <span class="s2">assert </span><span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">n_features_in_ </span><span class="s3">== </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">1</span><span class="s3">]</span>


<span class="s2">def </span><span class="s1">test_calibration_inconsistent_prefit_n_features_in</span><span class="s3">():</span>
    <span class="s0"># Check that `n_features_in_` from prefit base estimator</span>
    <span class="s0"># is consistent with training set</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">n_classes</span><span class="s3">=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">7</span><span class="s3">)</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">LinearSVC</span><span class="s3">(</span><span class="s1">C</span><span class="s3">=</span><span class="s4">1</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">calib_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s5">&quot;prefit&quot;</span><span class="s3">)</span>

    <span class="s1">msg </span><span class="s3">= </span><span class="s5">&quot;X has 3 features, but LinearSVC is expecting 5 features as input.&quot;</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">msg</span><span class="s3">):</span>
        <span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">[:, :</span><span class="s4">3</span><span class="s3">], </span><span class="s1">y</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_calibration_votingclassifier</span><span class="s3">():</span>
    <span class="s0"># Check that `CalibratedClassifier` works with `VotingClassifier`.</span>
    <span class="s0"># The method `predict_proba` from `VotingClassifier` is dynamically</span>
    <span class="s0"># defined via a property that only works when voting=&quot;soft&quot;.</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">n_classes</span><span class="s3">=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">7</span><span class="s3">)</span>
    <span class="s1">vote </span><span class="s3">= </span><span class="s1">VotingClassifier</span><span class="s3">(</span>
        <span class="s1">estimators</span><span class="s3">=[(</span><span class="s5">&quot;lr&quot; </span><span class="s3">+ </span><span class="s1">str</span><span class="s3">(</span><span class="s1">i</span><span class="s3">), </span><span class="s1">LogisticRegression</span><span class="s3">()) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s4">3</span><span class="s3">)],</span>
        <span class="s1">voting</span><span class="s3">=</span><span class="s5">&quot;soft&quot;</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">vote</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">calib_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">=</span><span class="s1">vote</span><span class="s3">, </span><span class="s1">cv</span><span class="s3">=</span><span class="s5">&quot;prefit&quot;</span><span class="s3">)</span>
    <span class="s0"># smoke test: should not raise an error</span>
    <span class="s1">calib_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">fixture</span><span class="s3">(</span><span class="s1">scope</span><span class="s3">=</span><span class="s5">&quot;module&quot;</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">iris_data</span><span class="s3">():</span>
    <span class="s2">return </span><span class="s1">load_iris</span><span class="s3">(</span><span class="s1">return_X_y</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">fixture</span><span class="s3">(</span><span class="s1">scope</span><span class="s3">=</span><span class="s5">&quot;module&quot;</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">iris_data_binary</span><span class="s3">(</span><span class="s1">iris_data</span><span class="s3">):</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">iris_data</span>
    <span class="s2">return </span><span class="s1">X</span><span class="s3">[</span><span class="s1">y </span><span class="s3">&lt; </span><span class="s4">2</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[</span><span class="s1">y </span><span class="s3">&lt; </span><span class="s4">2</span><span class="s3">]</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;n_bins&quot;</span><span class="s3">, [</span><span class="s4">5</span><span class="s3">, </span><span class="s4">10</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;strategy&quot;</span><span class="s3">, [</span><span class="s5">&quot;uniform&quot;</span><span class="s3">, </span><span class="s5">&quot;quantile&quot;</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_calibration_display_compute</span><span class="s3">(</span><span class="s1">pyplot</span><span class="s3">, </span><span class="s1">iris_data_binary</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">, </span><span class="s1">strategy</span><span class="s3">):</span>
    <span class="s0"># Ensure `CalibrationDisplay.from_predictions` and `calibration_curve`</span>
    <span class="s0"># compute the same results. Also checks attributes of the</span>
    <span class="s0"># CalibrationDisplay object.</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">iris_data_binary</span>

    <span class="s1">lr </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">viz </span><span class="s3">= </span><span class="s1">CalibrationDisplay</span><span class="s3">.</span><span class="s1">from_estimator</span><span class="s3">(</span>
        <span class="s1">lr</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">=</span><span class="s1">n_bins</span><span class="s3">, </span><span class="s1">strategy</span><span class="s3">=</span><span class="s1">strategy</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">=</span><span class="s4">0.8</span>
    <span class="s3">)</span>

    <span class="s1">y_prob </span><span class="s3">= </span><span class="s1">lr</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)[:, </span><span class="s4">1</span><span class="s3">]</span>
    <span class="s1">prob_true</span><span class="s3">, </span><span class="s1">prob_pred </span><span class="s3">= </span><span class="s1">calibration_curve</span><span class="s3">(</span>
        <span class="s1">y</span><span class="s3">, </span><span class="s1">y_prob</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">=</span><span class="s1">n_bins</span><span class="s3">, </span><span class="s1">strategy</span><span class="s3">=</span><span class="s1">strategy</span>
    <span class="s3">)</span>

    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">viz</span><span class="s3">.</span><span class="s1">prob_true</span><span class="s3">, </span><span class="s1">prob_true</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">viz</span><span class="s3">.</span><span class="s1">prob_pred</span><span class="s3">, </span><span class="s1">prob_pred</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">viz</span><span class="s3">.</span><span class="s1">y_prob</span><span class="s3">, </span><span class="s1">y_prob</span><span class="s3">)</span>

    <span class="s2">assert </span><span class="s1">viz</span><span class="s3">.</span><span class="s1">estimator_name </span><span class="s3">== </span><span class="s5">&quot;LogisticRegression&quot;</span>

    <span class="s0"># cannot fail thanks to pyplot fixture</span>
    <span class="s2">import </span><span class="s1">matplotlib </span><span class="s2">as </span><span class="s1">mpl  </span><span class="s0"># noqa</span>

    <span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">viz</span><span class="s3">.</span><span class="s1">line_</span><span class="s3">, </span><span class="s1">mpl</span><span class="s3">.</span><span class="s1">lines</span><span class="s3">.</span><span class="s1">Line2D</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">viz</span><span class="s3">.</span><span class="s1">line_</span><span class="s3">.</span><span class="s1">get_alpha</span><span class="s3">() == </span><span class="s4">0.8</span>
    <span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">viz</span><span class="s3">.</span><span class="s1">ax_</span><span class="s3">, </span><span class="s1">mpl</span><span class="s3">.</span><span class="s1">axes</span><span class="s3">.</span><span class="s1">Axes</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">isinstance</span><span class="s3">(</span><span class="s1">viz</span><span class="s3">.</span><span class="s1">figure_</span><span class="s3">, </span><span class="s1">mpl</span><span class="s3">.</span><span class="s1">figure</span><span class="s3">.</span><span class="s1">Figure</span><span class="s3">)</span>

    <span class="s2">assert </span><span class="s1">viz</span><span class="s3">.</span><span class="s1">ax_</span><span class="s3">.</span><span class="s1">get_xlabel</span><span class="s3">() == </span><span class="s5">&quot;Mean predicted probability (Positive class: 1)&quot;</span>
    <span class="s2">assert </span><span class="s1">viz</span><span class="s3">.</span><span class="s1">ax_</span><span class="s3">.</span><span class="s1">get_ylabel</span><span class="s3">() == </span><span class="s5">&quot;Fraction of positives (Positive class: 1)&quot;</span>

    <span class="s1">expected_legend_labels </span><span class="s3">= [</span><span class="s5">&quot;LogisticRegression&quot;</span><span class="s3">, </span><span class="s5">&quot;Perfectly calibrated&quot;</span><span class="s3">]</span>
    <span class="s1">legend_labels </span><span class="s3">= </span><span class="s1">viz</span><span class="s3">.</span><span class="s1">ax_</span><span class="s3">.</span><span class="s1">get_legend</span><span class="s3">().</span><span class="s1">get_texts</span><span class="s3">()</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">legend_labels</span><span class="s3">) == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">expected_legend_labels</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">labels </span><span class="s2">in </span><span class="s1">legend_labels</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">labels</span><span class="s3">.</span><span class="s1">get_text</span><span class="s3">() </span><span class="s2">in </span><span class="s1">expected_legend_labels</span>


<span class="s2">def </span><span class="s1">test_plot_calibration_curve_pipeline</span><span class="s3">(</span><span class="s1">pyplot</span><span class="s3">, </span><span class="s1">iris_data_binary</span><span class="s3">):</span>
    <span class="s0"># Ensure pipelines are supported by CalibrationDisplay.from_estimator</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">iris_data_binary</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">make_pipeline</span><span class="s3">(</span><span class="s1">StandardScaler</span><span class="s3">(), </span><span class="s1">LogisticRegression</span><span class="s3">())</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">viz </span><span class="s3">= </span><span class="s1">CalibrationDisplay</span><span class="s3">.</span><span class="s1">from_estimator</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">expected_legend_labels </span><span class="s3">= [</span><span class="s1">viz</span><span class="s3">.</span><span class="s1">estimator_name</span><span class="s3">, </span><span class="s5">&quot;Perfectly calibrated&quot;</span><span class="s3">]</span>
    <span class="s1">legend_labels </span><span class="s3">= </span><span class="s1">viz</span><span class="s3">.</span><span class="s1">ax_</span><span class="s3">.</span><span class="s1">get_legend</span><span class="s3">().</span><span class="s1">get_texts</span><span class="s3">()</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">legend_labels</span><span class="s3">) == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">expected_legend_labels</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">labels </span><span class="s2">in </span><span class="s1">legend_labels</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">labels</span><span class="s3">.</span><span class="s1">get_text</span><span class="s3">() </span><span class="s2">in </span><span class="s1">expected_legend_labels</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s5">&quot;name, expected_label&quot;</span><span class="s3">, [(</span><span class="s2">None</span><span class="s3">, </span><span class="s5">&quot;_line1&quot;</span><span class="s3">), (</span><span class="s5">&quot;my_est&quot;</span><span class="s3">, </span><span class="s5">&quot;my_est&quot;</span><span class="s3">)]</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_calibration_display_default_labels</span><span class="s3">(</span><span class="s1">pyplot</span><span class="s3">, </span><span class="s1">name</span><span class="s3">, </span><span class="s1">expected_label</span><span class="s3">):</span>
    <span class="s1">prob_true </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">])</span>
    <span class="s1">prob_pred </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0.2</span><span class="s3">, </span><span class="s4">0.8</span><span class="s3">, </span><span class="s4">0.8</span><span class="s3">, </span><span class="s4">0.4</span><span class="s3">])</span>
    <span class="s1">y_prob </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([])</span>

    <span class="s1">viz </span><span class="s3">= </span><span class="s1">CalibrationDisplay</span><span class="s3">(</span><span class="s1">prob_true</span><span class="s3">, </span><span class="s1">prob_pred</span><span class="s3">, </span><span class="s1">y_prob</span><span class="s3">, </span><span class="s1">estimator_name</span><span class="s3">=</span><span class="s1">name</span><span class="s3">)</span>
    <span class="s1">viz</span><span class="s3">.</span><span class="s1">plot</span><span class="s3">()</span>

    <span class="s1">expected_legend_labels </span><span class="s3">= [] </span><span class="s2">if </span><span class="s1">name </span><span class="s2">is None else </span><span class="s3">[</span><span class="s1">name</span><span class="s3">]</span>
    <span class="s1">expected_legend_labels</span><span class="s3">.</span><span class="s1">append</span><span class="s3">(</span><span class="s5">&quot;Perfectly calibrated&quot;</span><span class="s3">)</span>
    <span class="s1">legend_labels </span><span class="s3">= </span><span class="s1">viz</span><span class="s3">.</span><span class="s1">ax_</span><span class="s3">.</span><span class="s1">get_legend</span><span class="s3">().</span><span class="s1">get_texts</span><span class="s3">()</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">legend_labels</span><span class="s3">) == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">expected_legend_labels</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">labels </span><span class="s2">in </span><span class="s1">legend_labels</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">labels</span><span class="s3">.</span><span class="s1">get_text</span><span class="s3">() </span><span class="s2">in </span><span class="s1">expected_legend_labels</span>


<span class="s2">def </span><span class="s1">test_calibration_display_label_class_plot</span><span class="s3">(</span><span class="s1">pyplot</span><span class="s3">):</span>
    <span class="s0"># Checks that when instantiating `CalibrationDisplay` class then calling</span>
    <span class="s0"># `plot`, `self.estimator_name` is the one given in `plot`</span>
    <span class="s1">prob_true </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">])</span>
    <span class="s1">prob_pred </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0.2</span><span class="s3">, </span><span class="s4">0.8</span><span class="s3">, </span><span class="s4">0.8</span><span class="s3">, </span><span class="s4">0.4</span><span class="s3">])</span>
    <span class="s1">y_prob </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([])</span>

    <span class="s1">name </span><span class="s3">= </span><span class="s5">&quot;name one&quot;</span>
    <span class="s1">viz </span><span class="s3">= </span><span class="s1">CalibrationDisplay</span><span class="s3">(</span><span class="s1">prob_true</span><span class="s3">, </span><span class="s1">prob_pred</span><span class="s3">, </span><span class="s1">y_prob</span><span class="s3">, </span><span class="s1">estimator_name</span><span class="s3">=</span><span class="s1">name</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">viz</span><span class="s3">.</span><span class="s1">estimator_name </span><span class="s3">== </span><span class="s1">name</span>
    <span class="s1">name </span><span class="s3">= </span><span class="s5">&quot;name two&quot;</span>
    <span class="s1">viz</span><span class="s3">.</span><span class="s1">plot</span><span class="s3">(</span><span class="s1">name</span><span class="s3">=</span><span class="s1">name</span><span class="s3">)</span>

    <span class="s1">expected_legend_labels </span><span class="s3">= [</span><span class="s1">name</span><span class="s3">, </span><span class="s5">&quot;Perfectly calibrated&quot;</span><span class="s3">]</span>
    <span class="s1">legend_labels </span><span class="s3">= </span><span class="s1">viz</span><span class="s3">.</span><span class="s1">ax_</span><span class="s3">.</span><span class="s1">get_legend</span><span class="s3">().</span><span class="s1">get_texts</span><span class="s3">()</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">legend_labels</span><span class="s3">) == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">expected_legend_labels</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">labels </span><span class="s2">in </span><span class="s1">legend_labels</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">labels</span><span class="s3">.</span><span class="s1">get_text</span><span class="s3">() </span><span class="s2">in </span><span class="s1">expected_legend_labels</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;constructor_name&quot;</span><span class="s3">, [</span><span class="s5">&quot;from_estimator&quot;</span><span class="s3">, </span><span class="s5">&quot;from_predictions&quot;</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_calibration_display_name_multiple_calls</span><span class="s3">(</span>
    <span class="s1">constructor_name</span><span class="s3">, </span><span class="s1">pyplot</span><span class="s3">, </span><span class="s1">iris_data_binary</span>
<span class="s3">):</span>
    <span class="s0"># Check that the `name` used when calling</span>
    <span class="s0"># `CalibrationDisplay.from_predictions` or</span>
    <span class="s0"># `CalibrationDisplay.from_estimator` is used when multiple</span>
    <span class="s0"># `CalibrationDisplay.viz.plot()` calls are made.</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">iris_data_binary</span>
    <span class="s1">clf_name </span><span class="s3">= </span><span class="s5">&quot;my hand-crafted name&quot;</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">y_prob </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)[:, </span><span class="s4">1</span><span class="s3">]</span>

    <span class="s1">constructor </span><span class="s3">= </span><span class="s1">getattr</span><span class="s3">(</span><span class="s1">CalibrationDisplay</span><span class="s3">, </span><span class="s1">constructor_name</span><span class="s3">)</span>
    <span class="s1">params </span><span class="s3">= (</span><span class="s1">clf</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">) </span><span class="s2">if </span><span class="s1">constructor_name </span><span class="s3">== </span><span class="s5">&quot;from_estimator&quot; </span><span class="s2">else </span><span class="s3">(</span><span class="s1">y</span><span class="s3">, </span><span class="s1">y_prob</span><span class="s3">)</span>

    <span class="s1">viz </span><span class="s3">= </span><span class="s1">constructor</span><span class="s3">(*</span><span class="s1">params</span><span class="s3">, </span><span class="s1">name</span><span class="s3">=</span><span class="s1">clf_name</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">viz</span><span class="s3">.</span><span class="s1">estimator_name </span><span class="s3">== </span><span class="s1">clf_name</span>
    <span class="s1">pyplot</span><span class="s3">.</span><span class="s1">close</span><span class="s3">(</span><span class="s5">&quot;all&quot;</span><span class="s3">)</span>
    <span class="s1">viz</span><span class="s3">.</span><span class="s1">plot</span><span class="s3">()</span>

    <span class="s1">expected_legend_labels </span><span class="s3">= [</span><span class="s1">clf_name</span><span class="s3">, </span><span class="s5">&quot;Perfectly calibrated&quot;</span><span class="s3">]</span>
    <span class="s1">legend_labels </span><span class="s3">= </span><span class="s1">viz</span><span class="s3">.</span><span class="s1">ax_</span><span class="s3">.</span><span class="s1">get_legend</span><span class="s3">().</span><span class="s1">get_texts</span><span class="s3">()</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">legend_labels</span><span class="s3">) == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">expected_legend_labels</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">labels </span><span class="s2">in </span><span class="s1">legend_labels</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">labels</span><span class="s3">.</span><span class="s1">get_text</span><span class="s3">() </span><span class="s2">in </span><span class="s1">expected_legend_labels</span>

    <span class="s1">pyplot</span><span class="s3">.</span><span class="s1">close</span><span class="s3">(</span><span class="s5">&quot;all&quot;</span><span class="s3">)</span>
    <span class="s1">clf_name </span><span class="s3">= </span><span class="s5">&quot;another_name&quot;</span>
    <span class="s1">viz</span><span class="s3">.</span><span class="s1">plot</span><span class="s3">(</span><span class="s1">name</span><span class="s3">=</span><span class="s1">clf_name</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">legend_labels</span><span class="s3">) == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">expected_legend_labels</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">labels </span><span class="s2">in </span><span class="s1">legend_labels</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">labels</span><span class="s3">.</span><span class="s1">get_text</span><span class="s3">() </span><span class="s2">in </span><span class="s1">expected_legend_labels</span>


<span class="s2">def </span><span class="s1">test_calibration_display_ref_line</span><span class="s3">(</span><span class="s1">pyplot</span><span class="s3">, </span><span class="s1">iris_data_binary</span><span class="s3">):</span>
    <span class="s0"># Check that `ref_line` only appears once</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">iris_data_binary</span>
    <span class="s1">lr </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">dt </span><span class="s3">= </span><span class="s1">DecisionTreeClassifier</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">viz </span><span class="s3">= </span><span class="s1">CalibrationDisplay</span><span class="s3">.</span><span class="s1">from_estimator</span><span class="s3">(</span><span class="s1">lr</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">viz2 </span><span class="s3">= </span><span class="s1">CalibrationDisplay</span><span class="s3">.</span><span class="s1">from_estimator</span><span class="s3">(</span><span class="s1">dt</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">ax</span><span class="s3">=</span><span class="s1">viz</span><span class="s3">.</span><span class="s1">ax_</span><span class="s3">)</span>

    <span class="s1">labels </span><span class="s3">= </span><span class="s1">viz2</span><span class="s3">.</span><span class="s1">ax_</span><span class="s3">.</span><span class="s1">get_legend_handles_labels</span><span class="s3">()[</span><span class="s4">1</span><span class="s3">]</span>
    <span class="s2">assert </span><span class="s1">labels</span><span class="s3">.</span><span class="s1">count</span><span class="s3">(</span><span class="s5">&quot;Perfectly calibrated&quot;</span><span class="s3">) == </span><span class="s4">1</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;dtype_y_str&quot;</span><span class="s3">, [</span><span class="s1">str</span><span class="s3">, </span><span class="s1">object</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_calibration_curve_pos_label_error_str</span><span class="s3">(</span><span class="s1">dtype_y_str</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Check error message when a `pos_label` is not specified with `str` targets.&quot;&quot;&quot;</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s4">42</span><span class="s3">)</span>
    <span class="s1">y1 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s5">&quot;spam&quot;</span><span class="s3">] * </span><span class="s4">3 </span><span class="s3">+ [</span><span class="s5">&quot;eggs&quot;</span><span class="s3">] * </span><span class="s4">2</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">dtype_y_str</span><span class="s3">)</span>
    <span class="s1">y2 </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randint</span><span class="s3">(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s1">size</span><span class="s3">=</span><span class="s1">y1</span><span class="s3">.</span><span class="s1">size</span><span class="s3">)</span>

    <span class="s1">err_msg </span><span class="s3">= (</span>
        <span class="s5">&quot;y_true takes value in {'eggs', 'spam'} and pos_label is not &quot;</span>
        <span class="s5">&quot;specified: either make y_true take value in {0, 1} or {-1, 1} or &quot;</span>
        <span class="s5">&quot;pass pos_label explicitly&quot;</span>
    <span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">err_msg</span><span class="s3">):</span>
        <span class="s1">calibration_curve</span><span class="s3">(</span><span class="s1">y1</span><span class="s3">, </span><span class="s1">y2</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;dtype_y_str&quot;</span><span class="s3">, [</span><span class="s1">str</span><span class="s3">, </span><span class="s1">object</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_calibration_curve_pos_label</span><span class="s3">(</span><span class="s1">dtype_y_str</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Check the behaviour when passing explicitly `pos_label`.&quot;&quot;&quot;</span>
    <span class="s1">y_true </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">])</span>
    <span class="s1">classes </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s5">&quot;spam&quot;</span><span class="s3">, </span><span class="s5">&quot;egg&quot;</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">dtype_y_str</span><span class="s3">)</span>
    <span class="s1">y_true_str </span><span class="s3">= </span><span class="s1">classes</span><span class="s3">[</span><span class="s1">y_true</span><span class="s3">]</span>
    <span class="s1">y_pred </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0.1</span><span class="s3">, </span><span class="s4">0.2</span><span class="s3">, </span><span class="s4">0.3</span><span class="s3">, </span><span class="s4">0.4</span><span class="s3">, </span><span class="s4">0.65</span><span class="s3">, </span><span class="s4">0.7</span><span class="s3">, </span><span class="s4">0.8</span><span class="s3">, </span><span class="s4">0.9</span><span class="s3">, </span><span class="s4">1.0</span><span class="s3">])</span>

    <span class="s0"># default case</span>
    <span class="s1">prob_true</span><span class="s3">, </span><span class="s1">_ </span><span class="s3">= </span><span class="s1">calibration_curve</span><span class="s3">(</span><span class="s1">y_true</span><span class="s3">, </span><span class="s1">y_pred</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">=</span><span class="s4">4</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">prob_true</span><span class="s3">, [</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">])</span>
    <span class="s0"># if `y_true` contains `str`, then `pos_label` is required</span>
    <span class="s1">prob_true</span><span class="s3">, </span><span class="s1">_ </span><span class="s3">= </span><span class="s1">calibration_curve</span><span class="s3">(</span><span class="s1">y_true_str</span><span class="s3">, </span><span class="s1">y_pred</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">=</span><span class="s4">4</span><span class="s3">, </span><span class="s1">pos_label</span><span class="s3">=</span><span class="s5">&quot;egg&quot;</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">prob_true</span><span class="s3">, [</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">])</span>

    <span class="s1">prob_true</span><span class="s3">, </span><span class="s1">_ </span><span class="s3">= </span><span class="s1">calibration_curve</span><span class="s3">(</span><span class="s1">y_true</span><span class="s3">, </span><span class="s4">1 </span><span class="s3">- </span><span class="s1">y_pred</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">=</span><span class="s4">4</span><span class="s3">, </span><span class="s1">pos_label</span><span class="s3">=</span><span class="s4">0</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">prob_true</span><span class="s3">, [</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">1</span><span class="s3">])</span>
    <span class="s1">prob_true</span><span class="s3">, </span><span class="s1">_ </span><span class="s3">= </span><span class="s1">calibration_curve</span><span class="s3">(</span><span class="s1">y_true_str</span><span class="s3">, </span><span class="s4">1 </span><span class="s3">- </span><span class="s1">y_pred</span><span class="s3">, </span><span class="s1">n_bins</span><span class="s3">=</span><span class="s4">4</span><span class="s3">, </span><span class="s1">pos_label</span><span class="s3">=</span><span class="s5">&quot;spam&quot;</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">prob_true</span><span class="s3">, [</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">1</span><span class="s3">])</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;pos_label, expected_pos_label&quot;</span><span class="s3">, [(</span><span class="s2">None</span><span class="s3">, </span><span class="s4">1</span><span class="s3">), (</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">), (</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">)])</span>
<span class="s2">def </span><span class="s1">test_calibration_display_pos_label</span><span class="s3">(</span>
    <span class="s1">pyplot</span><span class="s3">, </span><span class="s1">iris_data_binary</span><span class="s3">, </span><span class="s1">pos_label</span><span class="s3">, </span><span class="s1">expected_pos_label</span>
<span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Check the behaviour of `pos_label` in the `CalibrationDisplay`.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">iris_data_binary</span>

    <span class="s1">lr </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">viz </span><span class="s3">= </span><span class="s1">CalibrationDisplay</span><span class="s3">.</span><span class="s1">from_estimator</span><span class="s3">(</span><span class="s1">lr</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">pos_label</span><span class="s3">=</span><span class="s1">pos_label</span><span class="s3">)</span>

    <span class="s1">y_prob </span><span class="s3">= </span><span class="s1">lr</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)[:, </span><span class="s1">expected_pos_label</span><span class="s3">]</span>
    <span class="s1">prob_true</span><span class="s3">, </span><span class="s1">prob_pred </span><span class="s3">= </span><span class="s1">calibration_curve</span><span class="s3">(</span><span class="s1">y</span><span class="s3">, </span><span class="s1">y_prob</span><span class="s3">, </span><span class="s1">pos_label</span><span class="s3">=</span><span class="s1">pos_label</span><span class="s3">)</span>

    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">viz</span><span class="s3">.</span><span class="s1">prob_true</span><span class="s3">, </span><span class="s1">prob_true</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">viz</span><span class="s3">.</span><span class="s1">prob_pred</span><span class="s3">, </span><span class="s1">prob_pred</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">viz</span><span class="s3">.</span><span class="s1">y_prob</span><span class="s3">, </span><span class="s1">y_prob</span><span class="s3">)</span>

    <span class="s2">assert </span><span class="s3">(</span>
        <span class="s1">viz</span><span class="s3">.</span><span class="s1">ax_</span><span class="s3">.</span><span class="s1">get_xlabel</span><span class="s3">()</span>
        <span class="s3">== </span><span class="s5">f&quot;Mean predicted probability (Positive class: </span><span class="s2">{</span><span class="s1">expected_pos_label</span><span class="s2">}</span><span class="s5">)&quot;</span>
    <span class="s3">)</span>
    <span class="s2">assert </span><span class="s3">(</span>
        <span class="s1">viz</span><span class="s3">.</span><span class="s1">ax_</span><span class="s3">.</span><span class="s1">get_ylabel</span><span class="s3">()</span>
        <span class="s3">== </span><span class="s5">f&quot;Fraction of positives (Positive class: </span><span class="s2">{</span><span class="s1">expected_pos_label</span><span class="s2">}</span><span class="s5">)&quot;</span>
    <span class="s3">)</span>

    <span class="s1">expected_legend_labels </span><span class="s3">= [</span><span class="s1">lr</span><span class="s3">.</span><span class="s1">__class__</span><span class="s3">.</span><span class="s1">__name__</span><span class="s3">, </span><span class="s5">&quot;Perfectly calibrated&quot;</span><span class="s3">]</span>
    <span class="s1">legend_labels </span><span class="s3">= </span><span class="s1">viz</span><span class="s3">.</span><span class="s1">ax_</span><span class="s3">.</span><span class="s1">get_legend</span><span class="s3">().</span><span class="s1">get_texts</span><span class="s3">()</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">legend_labels</span><span class="s3">) == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">expected_legend_labels</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">labels </span><span class="s2">in </span><span class="s1">legend_labels</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">labels</span><span class="s3">.</span><span class="s1">get_text</span><span class="s3">() </span><span class="s2">in </span><span class="s1">expected_legend_labels</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;method&quot;</span><span class="s3">, [</span><span class="s5">&quot;sigmoid&quot;</span><span class="s3">, </span><span class="s5">&quot;isotonic&quot;</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;ensemble&quot;</span><span class="s3">, [</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_calibrated_classifier_cv_double_sample_weights_equivalence</span><span class="s3">(</span><span class="s1">method</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Check that passing repeating twice the dataset `X` is equivalent to 
    passing a `sample_weight` with a factor 2.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">load_iris</span><span class="s3">(</span><span class="s1">return_X_y</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s0"># Scale the data to avoid any convergence issue</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">StandardScaler</span><span class="s3">().</span><span class="s1">fit_transform</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s0"># Only use 2 classes</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[:</span><span class="s4">100</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[:</span><span class="s4">100</span><span class="s3">]</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones_like</span><span class="s3">(</span><span class="s1">y</span><span class="s3">) * </span><span class="s4">2</span>

    <span class="s0"># Interlace the data such that a 2-fold cross-validation will be equivalent</span>
    <span class="s0"># to using the original dataset with a sample weights of 2</span>
    <span class="s1">X_twice </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">((</span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">0</span><span class="s3">] * </span><span class="s4">2</span><span class="s3">, </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">1</span><span class="s3">]), </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">X</span><span class="s3">.</span><span class="s1">dtype</span><span class="s3">)</span>
    <span class="s1">X_twice</span><span class="s3">[::</span><span class="s4">2</span><span class="s3">, :] = </span><span class="s1">X</span>
    <span class="s1">X_twice</span><span class="s3">[</span><span class="s4">1</span><span class="s3">::</span><span class="s4">2</span><span class="s3">, :] = </span><span class="s1">X</span>
    <span class="s1">y_twice </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">y</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">0</span><span class="s3">] * </span><span class="s4">2</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">y</span><span class="s3">.</span><span class="s1">dtype</span><span class="s3">)</span>
    <span class="s1">y_twice</span><span class="s3">[::</span><span class="s4">2</span><span class="s3">] = </span><span class="s1">y</span>
    <span class="s1">y_twice</span><span class="s3">[</span><span class="s4">1</span><span class="s3">::</span><span class="s4">2</span><span class="s3">] = </span><span class="s1">y</span>

    <span class="s1">estimator </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">()</span>
    <span class="s1">calibrated_clf_without_weights </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span>
        <span class="s1">estimator</span><span class="s3">,</span>
        <span class="s1">method</span><span class="s3">=</span><span class="s1">method</span><span class="s3">,</span>
        <span class="s1">ensemble</span><span class="s3">=</span><span class="s1">ensemble</span><span class="s3">,</span>
        <span class="s1">cv</span><span class="s3">=</span><span class="s4">2</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">calibrated_clf_with_weights </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">calibrated_clf_without_weights</span><span class="s3">)</span>

    <span class="s1">calibrated_clf_with_weights</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>
    <span class="s1">calibrated_clf_without_weights</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_twice</span><span class="s3">, </span><span class="s1">y_twice</span><span class="s3">)</span>

    <span class="s0"># Check that the underlying fitted estimators have the same coefficients</span>
    <span class="s2">for </span><span class="s1">est_with_weights</span><span class="s3">, </span><span class="s1">est_without_weights </span><span class="s2">in </span><span class="s1">zip</span><span class="s3">(</span>
        <span class="s1">calibrated_clf_with_weights</span><span class="s3">.</span><span class="s1">calibrated_classifiers_</span><span class="s3">,</span>
        <span class="s1">calibrated_clf_without_weights</span><span class="s3">.</span><span class="s1">calibrated_classifiers_</span><span class="s3">,</span>
    <span class="s3">):</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span>
            <span class="s1">est_with_weights</span><span class="s3">.</span><span class="s1">estimator</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">,</span>
            <span class="s1">est_without_weights</span><span class="s3">.</span><span class="s1">estimator</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">,</span>
        <span class="s3">)</span>

    <span class="s0"># Check that the predictions are the same</span>
    <span class="s1">y_pred_with_weights </span><span class="s3">= </span><span class="s1">calibrated_clf_with_weights</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">y_pred_without_weights </span><span class="s3">= </span><span class="s1">calibrated_clf_without_weights</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>

    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">y_pred_with_weights</span><span class="s3">, </span><span class="s1">y_pred_without_weights</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;fit_params_type&quot;</span><span class="s3">, [</span><span class="s5">&quot;list&quot;</span><span class="s3">, </span><span class="s5">&quot;array&quot;</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_calibration_with_fit_params</span><span class="s3">(</span><span class="s1">fit_params_type</span><span class="s3">, </span><span class="s1">data</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Tests that fit_params are passed to the underlying base estimator. 
 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/12384 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">data</span>
    <span class="s1">fit_params </span><span class="s3">= {</span>
        <span class="s5">&quot;a&quot;</span><span class="s3">: </span><span class="s1">_convert_container</span><span class="s3">(</span><span class="s1">y</span><span class="s3">, </span><span class="s1">fit_params_type</span><span class="s3">),</span>
        <span class="s5">&quot;b&quot;</span><span class="s3">: </span><span class="s1">_convert_container</span><span class="s3">(</span><span class="s1">y</span><span class="s3">, </span><span class="s1">fit_params_type</span><span class="s3">),</span>
    <span class="s3">}</span>

    <span class="s1">clf </span><span class="s3">= </span><span class="s1">CheckingClassifier</span><span class="s3">(</span><span class="s1">expected_fit_params</span><span class="s3">=[</span><span class="s5">&quot;a&quot;</span><span class="s3">, </span><span class="s5">&quot;b&quot;</span><span class="s3">])</span>
    <span class="s1">pc_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">)</span>

    <span class="s1">pc_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, **</span><span class="s1">fit_params</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s5">&quot;sample_weight&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s3">[</span><span class="s4">1.0</span><span class="s3">] * </span><span class="s1">N_SAMPLES</span><span class="s3">,</span>
        <span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">(</span><span class="s1">N_SAMPLES</span><span class="s3">),</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_calibration_with_sample_weight_estimator</span><span class="s3">(</span><span class="s1">sample_weight</span><span class="s3">, </span><span class="s1">data</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Tests that sample_weight is passed to the underlying base 
    estimator. 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">data</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">CheckingClassifier</span><span class="s3">(</span><span class="s1">expected_sample_weight</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s1">pc_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">)</span>

    <span class="s1">pc_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_calibration_without_sample_weight_estimator</span><span class="s3">(</span><span class="s1">data</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Check that even if the estimator doesn't support 
    sample_weight, fitting with sample_weight still works. 
 
    There should be a warning, since the sample_weight is not passed 
    on to the estimator. 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">data</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones_like</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>

    <span class="s2">class </span><span class="s1">ClfWithoutSampleWeight</span><span class="s3">(</span><span class="s1">CheckingClassifier</span><span class="s3">):</span>
        <span class="s2">def </span><span class="s1">fit</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, **</span><span class="s1">fit_params</span><span class="s3">):</span>
            <span class="s2">assert </span><span class="s5">&quot;sample_weight&quot; </span><span class="s2">not in </span><span class="s1">fit_params</span>
            <span class="s2">return </span><span class="s1">super</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, **</span><span class="s1">fit_params</span><span class="s3">)</span>

    <span class="s1">clf </span><span class="s3">= </span><span class="s1">ClfWithoutSampleWeight</span><span class="s3">()</span>
    <span class="s1">pc_clf </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">)</span>

    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">warns</span><span class="s3">(</span><span class="s1">UserWarning</span><span class="s3">):</span>
        <span class="s1">pc_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;method&quot;</span><span class="s3">, [</span><span class="s5">&quot;sigmoid&quot;</span><span class="s3">, </span><span class="s5">&quot;isotonic&quot;</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;ensemble&quot;</span><span class="s3">, [</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_calibrated_classifier_cv_zeros_sample_weights_equivalence</span><span class="s3">(</span><span class="s1">method</span><span class="s3">, </span><span class="s1">ensemble</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Check that passing removing some sample from the dataset `X` is 
    equivalent to passing a `sample_weight` with a factor 0.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">load_iris</span><span class="s3">(</span><span class="s1">return_X_y</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s0"># Scale the data to avoid any convergence issue</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">StandardScaler</span><span class="s3">().</span><span class="s1">fit_transform</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s0"># Only use 2 classes and select samples such that 2-fold cross-validation</span>
    <span class="s0"># split will lead to an equivalence with a `sample_weight` of 0</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">vstack</span><span class="s3">((</span><span class="s1">X</span><span class="s3">[:</span><span class="s4">40</span><span class="s3">], </span><span class="s1">X</span><span class="s3">[</span><span class="s4">50</span><span class="s3">:</span><span class="s4">90</span><span class="s3">]))</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">hstack</span><span class="s3">((</span><span class="s1">y</span><span class="s3">[:</span><span class="s4">40</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[</span><span class="s4">50</span><span class="s3">:</span><span class="s4">90</span><span class="s3">]))</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros_like</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">sample_weight</span><span class="s3">[::</span><span class="s4">2</span><span class="s3">] = </span><span class="s4">1</span>

    <span class="s1">estimator </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">()</span>
    <span class="s1">calibrated_clf_without_weights </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span>
        <span class="s1">estimator</span><span class="s3">,</span>
        <span class="s1">method</span><span class="s3">=</span><span class="s1">method</span><span class="s3">,</span>
        <span class="s1">ensemble</span><span class="s3">=</span><span class="s1">ensemble</span><span class="s3">,</span>
        <span class="s1">cv</span><span class="s3">=</span><span class="s4">2</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">calibrated_clf_with_weights </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">calibrated_clf_without_weights</span><span class="s3">)</span>

    <span class="s1">calibrated_clf_with_weights</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>
    <span class="s1">calibrated_clf_without_weights</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">[::</span><span class="s4">2</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[::</span><span class="s4">2</span><span class="s3">])</span>

    <span class="s0"># Check that the underlying fitted estimators have the same coefficients</span>
    <span class="s2">for </span><span class="s1">est_with_weights</span><span class="s3">, </span><span class="s1">est_without_weights </span><span class="s2">in </span><span class="s1">zip</span><span class="s3">(</span>
        <span class="s1">calibrated_clf_with_weights</span><span class="s3">.</span><span class="s1">calibrated_classifiers_</span><span class="s3">,</span>
        <span class="s1">calibrated_clf_without_weights</span><span class="s3">.</span><span class="s1">calibrated_classifiers_</span><span class="s3">,</span>
    <span class="s3">):</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span>
            <span class="s1">est_with_weights</span><span class="s3">.</span><span class="s1">estimator</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">,</span>
            <span class="s1">est_without_weights</span><span class="s3">.</span><span class="s1">estimator</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">,</span>
        <span class="s3">)</span>

    <span class="s0"># Check that the predictions are the same</span>
    <span class="s1">y_pred_with_weights </span><span class="s3">= </span><span class="s1">calibrated_clf_with_weights</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">y_pred_without_weights </span><span class="s3">= </span><span class="s1">calibrated_clf_without_weights</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>

    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">y_pred_with_weights</span><span class="s3">, </span><span class="s1">y_pred_without_weights</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_calibration_with_non_sample_aligned_fit_param</span><span class="s3">(</span><span class="s1">data</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Check that CalibratedClassifierCV does not enforce sample alignment 
    for fit parameters.&quot;&quot;&quot;</span>

    <span class="s2">class </span><span class="s1">TestClassifier</span><span class="s3">(</span><span class="s1">LogisticRegression</span><span class="s3">):</span>
        <span class="s2">def </span><span class="s1">fit</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s2">None</span><span class="s3">, </span><span class="s1">fit_param</span><span class="s3">=</span><span class="s2">None</span><span class="s3">):</span>
            <span class="s2">assert </span><span class="s1">fit_param </span><span class="s2">is not None</span>
            <span class="s2">return </span><span class="s1">super</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>

    <span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">=</span><span class="s1">TestClassifier</span><span class="s3">()).</span><span class="s1">fit</span><span class="s3">(</span>
        <span class="s3">*</span><span class="s1">data</span><span class="s3">, </span><span class="s1">fit_param</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">(</span><span class="s1">len</span><span class="s3">(</span><span class="s1">data</span><span class="s3">[</span><span class="s4">1</span><span class="s3">]) + </span><span class="s4">1</span><span class="s3">)</span>
    <span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_calibrated_classifier_cv_works_with_large_confidence_scores</span><span class="s3">(</span>
    <span class="s1">global_random_seed</span><span class="s3">,</span>
<span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Test that :class:`CalibratedClassifierCV` works with large confidence 
    scores when using the `sigmoid` method, particularly with the 
    :class:`SGDClassifier`. 
 
    Non-regression test for issue #26766. 
    &quot;&quot;&quot;</span>
    <span class="s1">prob </span><span class="s3">= </span><span class="s4">0.67</span>
    <span class="s1">n </span><span class="s3">= </span><span class="s4">1000</span>
    <span class="s1">random_noise </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">default_rng</span><span class="s3">(</span><span class="s1">global_random_seed</span><span class="s3">).</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=</span><span class="s1">n</span><span class="s3">)</span>

    <span class="s1">y </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">1</span><span class="s3">] * </span><span class="s1">int</span><span class="s3">(</span><span class="s1">n </span><span class="s3">* </span><span class="s1">prob</span><span class="s3">) + [</span><span class="s4">0</span><span class="s3">] * (</span><span class="s1">n </span><span class="s3">- </span><span class="s1">int</span><span class="s3">(</span><span class="s1">n </span><span class="s3">* </span><span class="s1">prob</span><span class="s3">)))</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s4">1e5 </span><span class="s3">* </span><span class="s1">y</span><span class="s3">.</span><span class="s1">reshape</span><span class="s3">((-</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">)) + </span><span class="s1">random_noise</span>

    <span class="s0"># Check that the decision function of SGDClassifier produces predicted</span>
    <span class="s0"># values that are quite large, for the data under consideration.</span>
    <span class="s1">cv </span><span class="s3">= </span><span class="s1">check_cv</span><span class="s3">(</span><span class="s1">cv</span><span class="s3">=</span><span class="s2">None</span><span class="s3">, </span><span class="s1">y</span><span class="s3">=</span><span class="s1">y</span><span class="s3">, </span><span class="s1">classifier</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s1">indices </span><span class="s3">= </span><span class="s1">cv</span><span class="s3">.</span><span class="s1">split</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">train</span><span class="s3">, </span><span class="s1">test </span><span class="s2">in </span><span class="s1">indices</span><span class="s3">:</span>
        <span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s1">train</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[</span><span class="s1">train</span><span class="s3">]</span>
        <span class="s1">X_test </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s1">test</span><span class="s3">]</span>
        <span class="s1">sgd_clf </span><span class="s3">= </span><span class="s1">SGDClassifier</span><span class="s3">(</span><span class="s1">loss</span><span class="s3">=</span><span class="s5">&quot;squared_hinge&quot;</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s1">global_random_seed</span><span class="s3">)</span>
        <span class="s1">sgd_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">)</span>
        <span class="s1">predictions </span><span class="s3">= </span><span class="s1">sgd_clf</span><span class="s3">.</span><span class="s1">decision_function</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
        <span class="s2">assert </span><span class="s3">(</span><span class="s1">predictions </span><span class="s3">&gt; </span><span class="s4">1e4</span><span class="s3">).</span><span class="s1">any</span><span class="s3">()</span>

    <span class="s0"># Compare the CalibratedClassifierCV using the sigmoid method with the</span>
    <span class="s0"># CalibratedClassifierCV using the isotonic method. The isotonic method</span>
    <span class="s0"># is used for comparison because it is numerically stable.</span>
    <span class="s1">clf_sigmoid </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span>
        <span class="s1">SGDClassifier</span><span class="s3">(</span><span class="s1">loss</span><span class="s3">=</span><span class="s5">&quot;squared_hinge&quot;</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s1">global_random_seed</span><span class="s3">),</span>
        <span class="s1">method</span><span class="s3">=</span><span class="s5">&quot;sigmoid&quot;</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">score_sigmoid </span><span class="s3">= </span><span class="s1">cross_val_score</span><span class="s3">(</span><span class="s1">clf_sigmoid</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">scoring</span><span class="s3">=</span><span class="s5">&quot;roc_auc&quot;</span><span class="s3">)</span>

    <span class="s0"># The isotonic method is used for comparison because it is numerically</span>
    <span class="s0"># stable.</span>
    <span class="s1">clf_isotonic </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span>
        <span class="s1">SGDClassifier</span><span class="s3">(</span><span class="s1">loss</span><span class="s3">=</span><span class="s5">&quot;squared_hinge&quot;</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s1">global_random_seed</span><span class="s3">),</span>
        <span class="s1">method</span><span class="s3">=</span><span class="s5">&quot;isotonic&quot;</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">score_isotonic </span><span class="s3">= </span><span class="s1">cross_val_score</span><span class="s3">(</span><span class="s1">clf_isotonic</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">scoring</span><span class="s3">=</span><span class="s5">&quot;roc_auc&quot;</span><span class="s3">)</span>

    <span class="s0"># The AUC score should be the same because it is invariant under</span>
    <span class="s0"># strictly monotonic conditions</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">score_sigmoid</span><span class="s3">, </span><span class="s1">score_isotonic</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_sigmoid_calibration_max_abs_prediction_threshold</span><span class="s3">(</span><span class="s1">global_random_seed</span><span class="s3">):</span>
    <span class="s1">random_state </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s1">seed</span><span class="s3">=</span><span class="s1">global_random_seed</span><span class="s3">)</span>
    <span class="s1">n </span><span class="s3">= </span><span class="s4">100</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">random_state</span><span class="s3">.</span><span class="s1">randint</span><span class="s3">(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s1">size</span><span class="s3">=</span><span class="s1">n</span><span class="s3">)</span>

    <span class="s0"># Check that for small enough predictions ranging from -2 to 2, the</span>
    <span class="s0"># threshold value has no impact on the outcome</span>
    <span class="s1">predictions_small </span><span class="s3">= </span><span class="s1">random_state</span><span class="s3">.</span><span class="s1">uniform</span><span class="s3">(</span><span class="s1">low</span><span class="s3">=-</span><span class="s4">2</span><span class="s3">, </span><span class="s1">high</span><span class="s3">=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">size</span><span class="s3">=</span><span class="s4">100</span><span class="s3">)</span>

    <span class="s0"># Using a threshold lower than the maximum absolute value of the</span>
    <span class="s0"># predictions enables internal re-scaling by max(abs(predictions_small)).</span>
    <span class="s1">threshold_1 </span><span class="s3">= </span><span class="s4">0.1</span>
    <span class="s1">a1</span><span class="s3">, </span><span class="s1">b1 </span><span class="s3">= </span><span class="s1">_sigmoid_calibration</span><span class="s3">(</span>
        <span class="s1">predictions</span><span class="s3">=</span><span class="s1">predictions_small</span><span class="s3">,</span>
        <span class="s1">y</span><span class="s3">=</span><span class="s1">y</span><span class="s3">,</span>
        <span class="s1">max_abs_prediction_threshold</span><span class="s3">=</span><span class="s1">threshold_1</span><span class="s3">,</span>
    <span class="s3">)</span>

    <span class="s0"># Using a larger threshold disables rescaling.</span>
    <span class="s1">threshold_2 </span><span class="s3">= </span><span class="s4">10</span>
    <span class="s1">a2</span><span class="s3">, </span><span class="s1">b2 </span><span class="s3">= </span><span class="s1">_sigmoid_calibration</span><span class="s3">(</span>
        <span class="s1">predictions</span><span class="s3">=</span><span class="s1">predictions_small</span><span class="s3">,</span>
        <span class="s1">y</span><span class="s3">=</span><span class="s1">y</span><span class="s3">,</span>
        <span class="s1">max_abs_prediction_threshold</span><span class="s3">=</span><span class="s1">threshold_2</span><span class="s3">,</span>
    <span class="s3">)</span>

    <span class="s0"># Using default threshold of 30 also disables the scaling.</span>
    <span class="s1">a3</span><span class="s3">, </span><span class="s1">b3 </span><span class="s3">= </span><span class="s1">_sigmoid_calibration</span><span class="s3">(</span>
        <span class="s1">predictions</span><span class="s3">=</span><span class="s1">predictions_small</span><span class="s3">,</span>
        <span class="s1">y</span><span class="s3">=</span><span class="s1">y</span><span class="s3">,</span>
    <span class="s3">)</span>

    <span class="s0"># Depends on the tolerance of the underlying quasy-newton solver which is</span>
    <span class="s0"># not too strict by default.</span>
    <span class="s1">atol </span><span class="s3">= </span><span class="s4">1e-6</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">a1</span><span class="s3">, </span><span class="s1">a2</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s1">atol</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">a2</span><span class="s3">, </span><span class="s1">a3</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s1">atol</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">b1</span><span class="s3">, </span><span class="s1">b2</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s1">atol</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">b2</span><span class="s3">, </span><span class="s1">b3</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s1">atol</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_float32_predict_proba</span><span class="s3">(</span><span class="s1">data</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Check that CalibratedClassifierCV works with float32 predict proba. 
 
    Non-regression test for gh-28245. 
    &quot;&quot;&quot;</span>

    <span class="s2">class </span><span class="s1">DummyClassifer32</span><span class="s3">(</span><span class="s1">DummyClassifier</span><span class="s3">):</span>
        <span class="s2">def </span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">):</span>
            <span class="s2">return </span><span class="s1">super</span><span class="s3">().</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">).</span><span class="s1">astype</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float32</span><span class="s3">)</span>

    <span class="s1">model </span><span class="s3">= </span><span class="s1">DummyClassifer32</span><span class="s3">()</span>
    <span class="s1">calibrator </span><span class="s3">= </span><span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">model</span><span class="s3">)</span>
    <span class="s0"># Does not raise an error</span>
    <span class="s1">calibrator</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(*</span><span class="s1">data</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_error_less_class_samples_than_folds</span><span class="s3">():</span>
    <span class="s6">&quot;&quot;&quot;Check that CalibratedClassifierCV works with string targets. 
 
    non-regression test for issue #28841. 
    &quot;&quot;&quot;</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=(</span><span class="s4">20</span><span class="s3">, </span><span class="s4">3</span><span class="s3">))</span>
    <span class="s1">y </span><span class="s3">= [</span><span class="s5">&quot;a&quot;</span><span class="s3">] * </span><span class="s4">10 </span><span class="s3">+ [</span><span class="s5">&quot;b&quot;</span><span class="s3">] * </span><span class="s4">10</span>

    <span class="s1">CalibratedClassifierCV</span><span class="s3">(</span><span class="s1">cv</span><span class="s3">=</span><span class="s4">3</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
</pre>
</body>
</html>