<html>
<head>
<title>_nearest_centroid.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_nearest_centroid.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Nearest Centroid Classification 
&quot;&quot;&quot;</span>

<span class="s2"># Author: Robert Layton &lt;robertlayton@gmail.com&gt;</span>
<span class="s2">#         Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="s2">#</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">from </span><span class="s1">numbers </span><span class="s3">import </span><span class="s1">Real</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">sparse </span><span class="s3">as </span><span class="s1">sp</span>

<span class="s3">from </span><span class="s4">..</span><span class="s1">base </span><span class="s3">import </span><span class="s1">BaseEstimator</span><span class="s4">, </span><span class="s1">ClassifierMixin</span><span class="s4">, </span><span class="s1">_fit_context</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">metrics</span><span class="s4">.</span><span class="s1">pairwise </span><span class="s3">import </span><span class="s1">pairwise_distances_argmin</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">preprocessing </span><span class="s3">import </span><span class="s1">LabelEncoder</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_param_validation </span><span class="s3">import </span><span class="s1">Interval</span><span class="s4">, </span><span class="s1">StrOptions</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">multiclass </span><span class="s3">import </span><span class="s1">check_classification_targets</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">sparsefuncs </span><span class="s3">import </span><span class="s1">csc_median_axis_0</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">validation </span><span class="s3">import </span><span class="s1">check_is_fitted</span>


<span class="s3">class </span><span class="s1">NearestCentroid</span><span class="s4">(</span><span class="s1">ClassifierMixin</span><span class="s4">, </span><span class="s1">BaseEstimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Nearest centroid classifier. 
 
    Each class is represented by its centroid, with test samples classified to 
    the class with the nearest centroid. 
 
    Read more in the :ref:`User Guide &lt;nearest_centroid_classifier&gt;`. 
 
    Parameters 
    ---------- 
    metric : {&quot;euclidean&quot;, &quot;manhattan&quot;}, default=&quot;euclidean&quot; 
        Metric to use for distance computation. 
 
        If `metric=&quot;euclidean&quot;`, the centroid for the samples corresponding to each 
        class is the arithmetic mean, which minimizes the sum of squared L1 distances. 
        If `metric=&quot;manhattan&quot;`, the centroid is the feature-wise median, which 
        minimizes the sum of L1 distances. 
 
        .. versionchanged:: 1.5 
            All metrics but `&quot;euclidean&quot;` and `&quot;manhattan&quot;` were deprecated and 
            now raise an error. 
 
        .. versionchanged:: 0.19 
            `metric='precomputed'` was deprecated and now raises an error 
 
    shrink_threshold : float, default=None 
        Threshold for shrinking centroids to remove features. 
 
    Attributes 
    ---------- 
    centroids_ : array-like of shape (n_classes, n_features) 
        Centroid of each class. 
 
    classes_ : array of shape (n_classes,) 
        The unique classes labels. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    See Also 
    -------- 
    KNeighborsClassifier : Nearest neighbors classifier. 
 
    Notes 
    ----- 
    When used for text classification with tf-idf vectors, this classifier is 
    also known as the Rocchio classifier. 
 
    References 
    ---------- 
    Tibshirani, R., Hastie, T., Narasimhan, B., &amp; Chu, G. (2002). Diagnosis of 
    multiple cancer types by shrunken centroids of gene expression. Proceedings 
    of the National Academy of Sciences of the United States of America, 
    99(10), 6567-6572. The National Academy of Sciences. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.neighbors import NearestCentroid 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]]) 
    &gt;&gt;&gt; y = np.array([1, 1, 1, 2, 2, 2]) 
    &gt;&gt;&gt; clf = NearestCentroid() 
    &gt;&gt;&gt; clf.fit(X, y) 
    NearestCentroid() 
    &gt;&gt;&gt; print(clf.predict([[-0.8, -1]])) 
    [1] 
 
    For a more detailed example see: 
    :ref:`sphx_glr_auto_examples_neighbors_plot_nearest_centroid.py` 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s5">&quot;metric&quot;</span><span class="s4">: [</span><span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;manhattan&quot;</span><span class="s4">, </span><span class="s5">&quot;euclidean&quot;</span><span class="s4">})],</span>
        <span class="s5">&quot;shrink_threshold&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;neither&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
    <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">metric</span><span class="s4">=</span><span class="s5">&quot;euclidean&quot;</span><span class="s4">, *, </span><span class="s1">shrink_threshold</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">metric </span><span class="s4">= </span><span class="s1">metric</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">shrink_threshold </span><span class="s4">= </span><span class="s1">shrink_threshold</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Fit the NearestCentroid model according to the given training data. 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix} of shape (n_samples, n_features) 
            Training vector, where `n_samples` is the number of samples and 
            `n_features` is the number of features. 
            Note that centroid shrinking cannot be used with sparse matrices. 
        y : array-like of shape (n_samples,) 
            Target values. 
 
        Returns 
        ------- 
        self : object 
            Fitted estimator. 
        &quot;&quot;&quot;</span>
        <span class="s2"># If X is sparse and the metric is &quot;manhattan&quot;, store it in a csc</span>
        <span class="s2"># format is easier to calculate the median.</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">metric </span><span class="s4">== </span><span class="s5">&quot;manhattan&quot;</span><span class="s4">:</span>
            <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">accept_sparse</span><span class="s4">=[</span><span class="s5">&quot;csc&quot;</span><span class="s4">])</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">accept_sparse</span><span class="s4">=[</span><span class="s5">&quot;csr&quot;</span><span class="s4">, </span><span class="s5">&quot;csc&quot;</span><span class="s4">])</span>
        <span class="s1">is_X_sparse </span><span class="s4">= </span><span class="s1">sp</span><span class="s4">.</span><span class="s1">issparse</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s3">if </span><span class="s1">is_X_sparse </span><span class="s3">and </span><span class="s1">self</span><span class="s4">.</span><span class="s1">shrink_threshold</span><span class="s4">:</span>
            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span><span class="s5">&quot;threshold shrinking not supported for sparse input&quot;</span><span class="s4">)</span>
        <span class="s1">check_classification_targets</span><span class="s4">(</span><span class="s1">y</span><span class="s4">)</span>

        <span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_features </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span>
        <span class="s1">le </span><span class="s4">= </span><span class="s1">LabelEncoder</span><span class="s4">()</span>
        <span class="s1">y_ind </span><span class="s4">= </span><span class="s1">le</span><span class="s4">.</span><span class="s1">fit_transform</span><span class="s4">(</span><span class="s1">y</span><span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">classes_ </span><span class="s4">= </span><span class="s1">classes </span><span class="s4">= </span><span class="s1">le</span><span class="s4">.</span><span class="s1">classes_</span>
        <span class="s1">n_classes </span><span class="s4">= </span><span class="s1">classes</span><span class="s4">.</span><span class="s1">size</span>
        <span class="s3">if </span><span class="s1">n_classes </span><span class="s4">&lt; </span><span class="s6">2</span><span class="s4">:</span>
            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                <span class="s5">&quot;The number of classes has to be greater than one; got %d class&quot;</span>
                <span class="s4">% (</span><span class="s1">n_classes</span><span class="s4">)</span>
            <span class="s4">)</span>

        <span class="s2"># Mask mapping each class to its members.</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">centroids_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">empty</span><span class="s4">((</span><span class="s1">n_classes</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">), </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">)</span>
        <span class="s2"># Number of clusters in each class.</span>
        <span class="s1">nk </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span><span class="s1">n_classes</span><span class="s4">)</span>

        <span class="s3">for </span><span class="s1">cur_class </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">n_classes</span><span class="s4">):</span>
            <span class="s1">center_mask </span><span class="s4">= </span><span class="s1">y_ind </span><span class="s4">== </span><span class="s1">cur_class</span>
            <span class="s1">nk</span><span class="s4">[</span><span class="s1">cur_class</span><span class="s4">] = </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">center_mask</span><span class="s4">)</span>
            <span class="s3">if </span><span class="s1">is_X_sparse</span><span class="s4">:</span>
                <span class="s1">center_mask </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">where</span><span class="s4">(</span><span class="s1">center_mask</span><span class="s4">)[</span><span class="s6">0</span><span class="s4">]</span>

            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">metric </span><span class="s4">== </span><span class="s5">&quot;manhattan&quot;</span><span class="s4">:</span>
                <span class="s2"># NumPy does not calculate median of sparse matrices.</span>
                <span class="s3">if not </span><span class="s1">is_X_sparse</span><span class="s4">:</span>
                    <span class="s1">self</span><span class="s4">.</span><span class="s1">centroids_</span><span class="s4">[</span><span class="s1">cur_class</span><span class="s4">] = </span><span class="s1">np</span><span class="s4">.</span><span class="s1">median</span><span class="s4">(</span><span class="s1">X</span><span class="s4">[</span><span class="s1">center_mask</span><span class="s4">], </span><span class="s1">axis</span><span class="s4">=</span><span class="s6">0</span><span class="s4">)</span>
                <span class="s3">else</span><span class="s4">:</span>
                    <span class="s1">self</span><span class="s4">.</span><span class="s1">centroids_</span><span class="s4">[</span><span class="s1">cur_class</span><span class="s4">] = </span><span class="s1">csc_median_axis_0</span><span class="s4">(</span><span class="s1">X</span><span class="s4">[</span><span class="s1">center_mask</span><span class="s4">])</span>
            <span class="s3">else</span><span class="s4">:  </span><span class="s2"># metric == &quot;euclidean&quot;</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">centroids_</span><span class="s4">[</span><span class="s1">cur_class</span><span class="s4">] = </span><span class="s1">X</span><span class="s4">[</span><span class="s1">center_mask</span><span class="s4">].</span><span class="s1">mean</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">0</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">shrink_threshold</span><span class="s4">:</span>
            <span class="s3">if </span><span class="s1">np</span><span class="s4">.</span><span class="s1">all</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">ptp</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">=</span><span class="s6">0</span><span class="s4">) == </span><span class="s6">0</span><span class="s4">):</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span><span class="s5">&quot;All features have zero variance. Division by zero.&quot;</span><span class="s4">)</span>
            <span class="s1">dataset_centroid_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">mean</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">=</span><span class="s6">0</span><span class="s4">)</span>

            <span class="s2"># m parameter for determining deviation</span>
            <span class="s1">m </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sqrt</span><span class="s4">((</span><span class="s6">1.0 </span><span class="s4">/ </span><span class="s1">nk</span><span class="s4">) - (</span><span class="s6">1.0 </span><span class="s4">/ </span><span class="s1">n_samples</span><span class="s4">))</span>
            <span class="s2"># Calculate deviation using the standard deviation of centroids.</span>
            <span class="s1">variance </span><span class="s4">= (</span><span class="s1">X </span><span class="s4">- </span><span class="s1">self</span><span class="s4">.</span><span class="s1">centroids_</span><span class="s4">[</span><span class="s1">y_ind</span><span class="s4">]) ** </span><span class="s6">2</span>
            <span class="s1">variance </span><span class="s4">= </span><span class="s1">variance</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">0</span><span class="s4">)</span>
            <span class="s1">s </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sqrt</span><span class="s4">(</span><span class="s1">variance </span><span class="s4">/ (</span><span class="s1">n_samples </span><span class="s4">- </span><span class="s1">n_classes</span><span class="s4">))</span>
            <span class="s1">s </span><span class="s4">+= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">median</span><span class="s4">(</span><span class="s1">s</span><span class="s4">)  </span><span class="s2"># To deter outliers from affecting the results.</span>
            <span class="s1">mm </span><span class="s4">= </span><span class="s1">m</span><span class="s4">.</span><span class="s1">reshape</span><span class="s4">(</span><span class="s1">len</span><span class="s4">(</span><span class="s1">m</span><span class="s4">), </span><span class="s6">1</span><span class="s4">)  </span><span class="s2"># Reshape to allow broadcasting.</span>
            <span class="s1">ms </span><span class="s4">= </span><span class="s1">mm </span><span class="s4">* </span><span class="s1">s</span>
            <span class="s1">deviation </span><span class="s4">= (</span><span class="s1">self</span><span class="s4">.</span><span class="s1">centroids_ </span><span class="s4">- </span><span class="s1">dataset_centroid_</span><span class="s4">) / </span><span class="s1">ms</span>
            <span class="s2"># Soft thresholding: if the deviation crosses 0 during shrinking,</span>
            <span class="s2"># it becomes zero.</span>
            <span class="s1">signs </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sign</span><span class="s4">(</span><span class="s1">deviation</span><span class="s4">)</span>
            <span class="s1">deviation </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">abs</span><span class="s4">(</span><span class="s1">deviation</span><span class="s4">) - </span><span class="s1">self</span><span class="s4">.</span><span class="s1">shrink_threshold</span>
            <span class="s1">np</span><span class="s4">.</span><span class="s1">clip</span><span class="s4">(</span><span class="s1">deviation</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">out</span><span class="s4">=</span><span class="s1">deviation</span><span class="s4">)</span>
            <span class="s1">deviation </span><span class="s4">*= </span><span class="s1">signs</span>
            <span class="s2"># Now adjust the centroids using the deviation</span>
            <span class="s1">msd </span><span class="s4">= </span><span class="s1">ms </span><span class="s4">* </span><span class="s1">deviation</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">centroids_ </span><span class="s4">= </span><span class="s1">dataset_centroid_</span><span class="s4">[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">newaxis</span><span class="s4">, :] + </span><span class="s1">msd</span>
        <span class="s3">return </span><span class="s1">self</span>

    <span class="s3">def </span><span class="s1">predict</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Perform classification on an array of test vectors `X`. 
 
        The predicted class `C` for each sample in `X` is returned. 
 
        Parameters 
        ---------- 
        X : {array-like, sparse matrix} of shape (n_samples, n_features) 
            Test samples. 
 
        Returns 
        ------- 
        C : ndarray of shape (n_samples,) 
            The predicted classes. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>

        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">accept_sparse</span><span class="s4">=</span><span class="s5">&quot;csr&quot;</span><span class="s4">, </span><span class="s1">reset</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">classes_</span><span class="s4">[</span>
            <span class="s1">pairwise_distances_argmin</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">centroids_</span><span class="s4">, </span><span class="s1">metric</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">metric</span><span class="s4">)</span>
        <span class="s4">]</span>
</pre>
</body>
</html>