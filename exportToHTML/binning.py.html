<html>
<head>
<title>binning.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #2aacb8;}
.s6 { color: #6aab73;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
binning.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
This module contains the BinMapper class. 
 
BinMapper is used for mapping a real-valued dataset into integer-valued bins. 
Bin thresholds are computed with the quantiles so that each bin contains 
approximately the same number of samples. 
&quot;&quot;&quot;</span>

<span class="s2"># Author: Nicolas Hug</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>

<span class="s3">from </span><span class="s4">...</span><span class="s1">base </span><span class="s3">import </span><span class="s1">BaseEstimator</span><span class="s4">, </span><span class="s1">TransformerMixin</span>
<span class="s3">from </span><span class="s4">...</span><span class="s1">utils </span><span class="s3">import </span><span class="s1">check_array</span><span class="s4">, </span><span class="s1">check_random_state</span>
<span class="s3">from </span><span class="s4">...</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_openmp_helpers </span><span class="s3">import </span><span class="s1">_openmp_effective_n_threads</span>
<span class="s3">from </span><span class="s4">...</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">fixes </span><span class="s3">import </span><span class="s1">percentile</span>
<span class="s3">from </span><span class="s4">...</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">validation </span><span class="s3">import </span><span class="s1">check_is_fitted</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">_binning </span><span class="s3">import </span><span class="s1">_map_to_bins</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">_bitset </span><span class="s3">import </span><span class="s1">set_bitset_memoryview</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">common </span><span class="s3">import </span><span class="s1">ALMOST_INF</span><span class="s4">, </span><span class="s1">X_BINNED_DTYPE</span><span class="s4">, </span><span class="s1">X_BITSET_INNER_DTYPE</span><span class="s4">, </span><span class="s1">X_DTYPE</span>


<span class="s3">def </span><span class="s1">_find_binning_thresholds</span><span class="s4">(</span><span class="s1">col_data</span><span class="s4">, </span><span class="s1">max_bins</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Extract quantiles from a continuous feature. 
 
    Missing values are ignored for finding the thresholds. 
 
    Parameters 
    ---------- 
    col_data : array-like, shape (n_samples,) 
        The continuous feature to bin. 
    max_bins: int 
        The maximum number of bins to use for non-missing values. If for a 
        given feature the number of unique values is less than ``max_bins``, 
        then those unique values will be used to compute the bin thresholds, 
        instead of the quantiles 
 
    Return 
    ------ 
    binning_thresholds : ndarray of shape(min(max_bins, n_unique_values) - 1,) 
        The increasing numeric values that can be used to separate the bins. 
        A given value x will be mapped into bin value i iff 
        bining_thresholds[i - 1] &lt; x &lt;= binning_thresholds[i] 
    &quot;&quot;&quot;</span>
    <span class="s2"># ignore missing values when computing bin thresholds</span>
    <span class="s1">missing_mask </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">isnan</span><span class="s4">(</span><span class="s1">col_data</span><span class="s4">)</span>
    <span class="s3">if </span><span class="s1">missing_mask</span><span class="s4">.</span><span class="s1">any</span><span class="s4">():</span>
        <span class="s1">col_data </span><span class="s4">= </span><span class="s1">col_data</span><span class="s4">[~</span><span class="s1">missing_mask</span><span class="s4">]</span>
    <span class="s2"># The data will be sorted anyway in np.unique and again in percentile, so we do it</span>
    <span class="s2"># here. Sorting also returns a contiguous array.</span>
    <span class="s1">col_data </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sort</span><span class="s4">(</span><span class="s1">col_data</span><span class="s4">)</span>
    <span class="s1">distinct_values </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">unique</span><span class="s4">(</span><span class="s1">col_data</span><span class="s4">).</span><span class="s1">astype</span><span class="s4">(</span><span class="s1">X_DTYPE</span><span class="s4">)</span>
    <span class="s3">if </span><span class="s1">len</span><span class="s4">(</span><span class="s1">distinct_values</span><span class="s4">) &lt;= </span><span class="s1">max_bins</span><span class="s4">:</span>
        <span class="s1">midpoints </span><span class="s4">= </span><span class="s1">distinct_values</span><span class="s4">[:-</span><span class="s5">1</span><span class="s4">] + </span><span class="s1">distinct_values</span><span class="s4">[</span><span class="s5">1</span><span class="s4">:]</span>
        <span class="s1">midpoints </span><span class="s4">*= </span><span class="s5">0.5</span>
    <span class="s3">else</span><span class="s4">:</span>
        <span class="s2"># We could compute approximate midpoint percentiles using the output of</span>
        <span class="s2"># np.unique(col_data, return_counts) instead but this is more</span>
        <span class="s2"># work and the performance benefit will be limited because we</span>
        <span class="s2"># work on a fixed-size subsample of the full data.</span>
        <span class="s1">percentiles </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">linspace</span><span class="s4">(</span><span class="s5">0</span><span class="s4">, </span><span class="s5">100</span><span class="s4">, </span><span class="s1">num</span><span class="s4">=</span><span class="s1">max_bins </span><span class="s4">+ </span><span class="s5">1</span><span class="s4">)</span>
        <span class="s1">percentiles </span><span class="s4">= </span><span class="s1">percentiles</span><span class="s4">[</span><span class="s5">1</span><span class="s4">:-</span><span class="s5">1</span><span class="s4">]</span>
        <span class="s1">midpoints </span><span class="s4">= </span><span class="s1">percentile</span><span class="s4">(</span><span class="s1">col_data</span><span class="s4">, </span><span class="s1">percentiles</span><span class="s4">, </span><span class="s1">method</span><span class="s4">=</span><span class="s6">&quot;midpoint&quot;</span><span class="s4">).</span><span class="s1">astype</span><span class="s4">(</span><span class="s1">X_DTYPE</span><span class="s4">)</span>
        <span class="s3">assert </span><span class="s1">midpoints</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">] == </span><span class="s1">max_bins </span><span class="s4">- </span><span class="s5">1</span>

    <span class="s2"># We avoid having +inf thresholds: +inf thresholds are only allowed in</span>
    <span class="s2"># a &quot;split on nan&quot; situation.</span>
    <span class="s1">np</span><span class="s4">.</span><span class="s1">clip</span><span class="s4">(</span><span class="s1">midpoints</span><span class="s4">, </span><span class="s1">a_min</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, </span><span class="s1">a_max</span><span class="s4">=</span><span class="s1">ALMOST_INF</span><span class="s4">, </span><span class="s1">out</span><span class="s4">=</span><span class="s1">midpoints</span><span class="s4">)</span>
    <span class="s3">return </span><span class="s1">midpoints</span>


<span class="s3">class </span><span class="s1">_BinMapper</span><span class="s4">(</span><span class="s1">TransformerMixin</span><span class="s4">, </span><span class="s1">BaseEstimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Transformer that maps a dataset into integer-valued bins. 
 
    For continuous features, the bins are created in a feature-wise fashion, 
    using quantiles so that each bins contains approximately the same number 
    of samples. For large datasets, quantiles are computed on a subset of the 
    data to speed-up the binning, but the quantiles should remain stable. 
 
    For categorical features, the raw categorical values are expected to be 
    in [0, 254] (this is not validated here though) and each category 
    corresponds to a bin. All categorical values must be known at 
    initialization: transform() doesn't know how to bin unknown categorical 
    values. Note that transform() is only used on non-training data in the 
    case of early stopping. 
 
    Features with a small number of values may be binned into less than 
    ``n_bins`` bins. The last bin (at index ``n_bins - 1``) is always reserved 
    for missing values. 
 
    Parameters 
    ---------- 
    n_bins : int, default=256 
        The maximum number of bins to use (including the bin for missing 
        values). Should be in [3, 256]. Non-missing values are binned on 
        ``max_bins = n_bins - 1`` bins. The last bin is always reserved for 
        missing values. If for a given feature the number of unique values is 
        less than ``max_bins``, then those unique values will be used to 
        compute the bin thresholds, instead of the quantiles. For categorical 
        features indicated by ``is_categorical``, the docstring for 
        ``is_categorical`` details on this procedure. 
    subsample : int or None, default=2e5 
        If ``n_samples &gt; subsample``, then ``sub_samples`` samples will be 
        randomly chosen to compute the quantiles. If ``None``, the whole data 
        is used. 
    is_categorical : ndarray of bool of shape (n_features,), default=None 
        Indicates categorical features. By default, all features are 
        considered continuous. 
    known_categories : list of {ndarray, None} of shape (n_features,), \ 
            default=none 
        For each categorical feature, the array indicates the set of unique 
        categorical values. These should be the possible values over all the 
        data, not just the training data. For continuous features, the 
        corresponding entry should be None. 
    random_state: int, RandomState instance or None, default=None 
        Pseudo-random number generator to control the random sub-sampling. 
        Pass an int for reproducible output across multiple 
        function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
    n_threads : int, default=None 
        Number of OpenMP threads to use. `_openmp_effective_n_threads` is called 
        to determine the effective number of threads use, which takes cgroups CPU 
        quotes into account. See the docstring of `_openmp_effective_n_threads` 
        for details. 
 
    Attributes 
    ---------- 
    bin_thresholds_ : list of ndarray 
        For each feature, each array indicates how to map a feature into a 
        binned feature. The semantic and size depends on the nature of the 
        feature: 
        - for real-valued features, the array corresponds to the real-valued 
          bin thresholds (the upper bound of each bin). There are ``max_bins 
          - 1`` thresholds, where ``max_bins = n_bins - 1`` is the number of 
          bins used for non-missing values. 
        - for categorical features, the array is a map from a binned category 
          value to the raw category value. The size of the array is equal to 
          ``min(max_bins, category_cardinality)`` where we ignore missing 
          values in the cardinality. 
    n_bins_non_missing_ : ndarray, dtype=np.uint32 
        For each feature, gives the number of bins actually used for 
        non-missing values. For features with a lot of unique values, this is 
        equal to ``n_bins - 1``. 
    is_categorical_ : ndarray of shape (n_features,), dtype=np.uint8 
        Indicator for categorical features. 
    missing_values_bin_idx_ : np.uint8 
        The index of the bin where missing values are mapped. This is a 
        constant across all features. This corresponds to the last bin, and 
        it is always equal to ``n_bins - 1``. Note that if ``n_bins_non_missing_`` 
        is less than ``n_bins - 1`` for a given feature, then there are 
        empty (and unused) bins. 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">n_bins</span><span class="s4">=</span><span class="s5">256</span><span class="s4">,</span>
        <span class="s1">subsample</span><span class="s4">=</span><span class="s1">int</span><span class="s4">(</span><span class="s5">2e5</span><span class="s4">),</span>
        <span class="s1">is_categorical</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">known_categories</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">n_threads</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_bins </span><span class="s4">= </span><span class="s1">n_bins</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">subsample </span><span class="s4">= </span><span class="s1">subsample</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">is_categorical </span><span class="s4">= </span><span class="s1">is_categorical</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">known_categories </span><span class="s4">= </span><span class="s1">known_categories</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">random_state </span><span class="s4">= </span><span class="s1">random_state</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_threads </span><span class="s4">= </span><span class="s1">n_threads</span>

    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Fit data X by computing the binning thresholds. 
 
        The last bin is reserved for missing values, whether missing values 
        are present in the data or not. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            The data to bin. 
        y: None 
            Ignored. 
 
        Returns 
        ------- 
        self : object 
        &quot;&quot;&quot;</span>
        <span class="s3">if not </span><span class="s4">(</span><span class="s5">3 </span><span class="s4">&lt;= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_bins </span><span class="s4">&lt;= </span><span class="s5">256</span><span class="s4">):</span>
            <span class="s2"># min is 3: at least 2 distinct bins and a missing values bin</span>
            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                <span class="s6">&quot;n_bins={} should be no smaller than 3 and no larger than 256.&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span>
                    <span class="s1">self</span><span class="s4">.</span><span class="s1">n_bins</span>
                <span class="s4">)</span>
            <span class="s4">)</span>

        <span class="s1">X </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=[</span><span class="s1">X_DTYPE</span><span class="s4">], </span><span class="s1">force_all_finite</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>
        <span class="s1">max_bins </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_bins </span><span class="s4">- </span><span class="s5">1</span>

        <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">subsample </span><span class="s3">is not None and </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">] &gt; </span><span class="s1">self</span><span class="s4">.</span><span class="s1">subsample</span><span class="s4">:</span>
            <span class="s1">subset </span><span class="s4">= </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">choice</span><span class="s4">(</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">], </span><span class="s1">self</span><span class="s4">.</span><span class="s1">subsample</span><span class="s4">, </span><span class="s1">replace</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>
            <span class="s1">X </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">take</span><span class="s4">(</span><span class="s1">subset</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">=</span><span class="s5">0</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">is_categorical </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">is_categorical_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">1</span><span class="s4">], </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">uint8</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">is_categorical_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">asarray</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">is_categorical</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">uint8</span><span class="s4">)</span>

        <span class="s1">n_features </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">1</span><span class="s4">]</span>
        <span class="s1">known_categories </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">known_categories</span>
        <span class="s3">if </span><span class="s1">known_categories </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">known_categories </span><span class="s4">= [</span><span class="s3">None</span><span class="s4">] * </span><span class="s1">n_features</span>

        <span class="s2"># validate is_categorical and known_categories parameters</span>
        <span class="s3">for </span><span class="s1">f_idx </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">n_features</span><span class="s4">):</span>
            <span class="s1">is_categorical </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">is_categorical_</span><span class="s4">[</span><span class="s1">f_idx</span><span class="s4">]</span>
            <span class="s1">known_cats </span><span class="s4">= </span><span class="s1">known_categories</span><span class="s4">[</span><span class="s1">f_idx</span><span class="s4">]</span>
            <span class="s3">if </span><span class="s1">is_categorical </span><span class="s3">and </span><span class="s1">known_cats </span><span class="s3">is None</span><span class="s4">:</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                    <span class="s6">f&quot;Known categories for feature </span><span class="s3">{</span><span class="s1">f_idx</span><span class="s3">} </span><span class="s6">must be provided.&quot;</span>
                <span class="s4">)</span>
            <span class="s3">if not </span><span class="s1">is_categorical </span><span class="s3">and </span><span class="s1">known_cats </span><span class="s3">is not None</span><span class="s4">:</span>
                <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                    <span class="s6">f&quot;Feature </span><span class="s3">{</span><span class="s1">f_idx</span><span class="s3">} </span><span class="s6">isn't marked as a categorical feature, &quot;</span>
                    <span class="s6">&quot;but categories were passed.&quot;</span>
                <span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">missing_values_bin_idx_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_bins </span><span class="s4">- </span><span class="s5">1</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">bin_thresholds_ </span><span class="s4">= []</span>
        <span class="s1">n_bins_non_missing </span><span class="s4">= []</span>

        <span class="s3">for </span><span class="s1">f_idx </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">n_features</span><span class="s4">):</span>
            <span class="s3">if not </span><span class="s1">self</span><span class="s4">.</span><span class="s1">is_categorical_</span><span class="s4">[</span><span class="s1">f_idx</span><span class="s4">]:</span>
                <span class="s1">thresholds </span><span class="s4">= </span><span class="s1">_find_binning_thresholds</span><span class="s4">(</span><span class="s1">X</span><span class="s4">[:, </span><span class="s1">f_idx</span><span class="s4">], </span><span class="s1">max_bins</span><span class="s4">)</span>
                <span class="s1">n_bins_non_missing</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">thresholds</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">] + </span><span class="s5">1</span><span class="s4">)</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s2"># Since categories are assumed to be encoded in</span>
                <span class="s2"># [0, n_cats] and since n_cats &lt;= max_bins,</span>
                <span class="s2"># the thresholds *are* the unique categorical values. This will</span>
                <span class="s2"># lead to the correct mapping in transform()</span>
                <span class="s1">thresholds </span><span class="s4">= </span><span class="s1">known_categories</span><span class="s4">[</span><span class="s1">f_idx</span><span class="s4">]</span>
                <span class="s1">n_bins_non_missing</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">thresholds</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">])</span>

            <span class="s1">self</span><span class="s4">.</span><span class="s1">bin_thresholds_</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">thresholds</span><span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_bins_non_missing_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span><span class="s1">n_bins_non_missing</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">uint32</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span>

    <span class="s3">def </span><span class="s1">transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Bin data X. 
 
        Missing values will be mapped to the last bin. 
 
        For categorical features, the mapping will be incorrect for unknown 
        categories. Since the BinMapper is given known_categories of the 
        entire training data (i.e. before the call to train_test_split() in 
        case of early-stopping), this never happens. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            The data to bin. 
 
        Returns 
        ------- 
        X_binned : array-like of shape (n_samples, n_features) 
            The binned data (fortran-aligned). 
        &quot;&quot;&quot;</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=[</span><span class="s1">X_DTYPE</span><span class="s4">], </span><span class="s1">force_all_finite</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s3">if </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">1</span><span class="s4">] != </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_bins_non_missing_</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">]:</span>
            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                <span class="s6">&quot;This estimator was fitted with {} features but {} got passed &quot;</span>
                <span class="s6">&quot;to transform()&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_bins_non_missing_</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">], </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">1</span><span class="s4">])</span>
            <span class="s4">)</span>

        <span class="s1">n_threads </span><span class="s4">= </span><span class="s1">_openmp_effective_n_threads</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_threads</span><span class="s4">)</span>
        <span class="s1">binned </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros_like</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">X_BINNED_DTYPE</span><span class="s4">, </span><span class="s1">order</span><span class="s4">=</span><span class="s6">&quot;F&quot;</span><span class="s4">)</span>
        <span class="s1">_map_to_bins</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">,</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">bin_thresholds_</span><span class="s4">,</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">is_categorical_</span><span class="s4">,</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">missing_values_bin_idx_</span><span class="s4">,</span>
            <span class="s1">n_threads</span><span class="s4">,</span>
            <span class="s1">binned</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s3">return </span><span class="s1">binned</span>

    <span class="s3">def </span><span class="s1">make_known_categories_bitsets</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Create bitsets of known categories. 
 
        Returns 
        ------- 
        - known_cat_bitsets : ndarray of shape (n_categorical_features, 8) 
            Array of bitsets of known categories, for each categorical feature. 
        - f_idx_map : ndarray of shape (n_features,) 
            Map from original feature index to the corresponding index in the 
            known_cat_bitsets array. 
        &quot;&quot;&quot;</span>

        <span class="s1">categorical_features_indices </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">flatnonzero</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">is_categorical_</span><span class="s4">)</span>

        <span class="s1">n_features </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">is_categorical_</span><span class="s4">.</span><span class="s1">size</span>
        <span class="s1">n_categorical_features </span><span class="s4">= </span><span class="s1">categorical_features_indices</span><span class="s4">.</span><span class="s1">size</span>

        <span class="s1">f_idx_map </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span><span class="s1">n_features</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">uint32</span><span class="s4">)</span>
        <span class="s1">f_idx_map</span><span class="s4">[</span><span class="s1">categorical_features_indices</span><span class="s4">] = </span><span class="s1">np</span><span class="s4">.</span><span class="s1">arange</span><span class="s4">(</span>
            <span class="s1">n_categorical_features</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">uint32</span>
        <span class="s4">)</span>

        <span class="s1">known_categories </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">bin_thresholds_</span>

        <span class="s1">known_cat_bitsets </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span>
            <span class="s4">(</span><span class="s1">n_categorical_features</span><span class="s4">, </span><span class="s5">8</span><span class="s4">), </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">X_BITSET_INNER_DTYPE</span>
        <span class="s4">)</span>

        <span class="s2"># TODO: complexity is O(n_categorical_features * 255). Maybe this is</span>
        <span class="s2"># worth cythonizing</span>
        <span class="s3">for </span><span class="s1">mapped_f_idx</span><span class="s4">, </span><span class="s1">f_idx </span><span class="s3">in </span><span class="s1">enumerate</span><span class="s4">(</span><span class="s1">categorical_features_indices</span><span class="s4">):</span>
            <span class="s3">for </span><span class="s1">raw_cat_val </span><span class="s3">in </span><span class="s1">known_categories</span><span class="s4">[</span><span class="s1">f_idx</span><span class="s4">]:</span>
                <span class="s1">set_bitset_memoryview</span><span class="s4">(</span><span class="s1">known_cat_bitsets</span><span class="s4">[</span><span class="s1">mapped_f_idx</span><span class="s4">], </span><span class="s1">raw_cat_val</span><span class="s4">)</span>

        <span class="s3">return </span><span class="s1">known_cat_bitsets</span><span class="s4">, </span><span class="s1">f_idx_map</span>
</pre>
</body>
</html>