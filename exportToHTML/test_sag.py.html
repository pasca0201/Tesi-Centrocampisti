<html>
<head>
<title>test_sag.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #7a7e85;}
.s1 { color: #bcbec4;}
.s2 { color: #cf8e6d;}
.s3 { color: #bcbec4;}
.s4 { color: #2aacb8;}
.s5 { color: #6aab73;}
.s6 { color: #5f826b; font-style: italic;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_sag.py</font>
</center></td></tr></table>
<pre><span class="s0"># Authors: Danny Sullivan &lt;dbsullivan23@gmail.com&gt;</span>
<span class="s0">#          Tom Dupre la Tour &lt;tom.dupre-la-tour@m4x.org&gt;</span>
<span class="s0">#</span>
<span class="s0"># License: BSD 3 clause</span>

<span class="s2">import </span><span class="s1">math</span>
<span class="s2">import </span><span class="s1">re</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pytest</span>
<span class="s2">from </span><span class="s1">scipy</span><span class="s3">.</span><span class="s1">special </span><span class="s2">import </span><span class="s1">logsumexp</span>

<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">_loss</span><span class="s3">.</span><span class="s1">loss </span><span class="s2">import </span><span class="s1">HalfMultinomialLoss</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">base </span><span class="s2">import </span><span class="s1">clone</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">datasets </span><span class="s2">import </span><span class="s1">load_iris</span><span class="s3">, </span><span class="s1">make_blobs</span><span class="s3">, </span><span class="s1">make_classification</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">linear_model </span><span class="s2">import </span><span class="s1">LogisticRegression</span><span class="s3">, </span><span class="s1">Ridge</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">linear_model</span><span class="s3">.</span><span class="s1">_base </span><span class="s2">import </span><span class="s1">make_dataset</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">linear_model</span><span class="s3">.</span><span class="s1">_linear_loss </span><span class="s2">import </span><span class="s1">LinearModelLoss</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">linear_model</span><span class="s3">.</span><span class="s1">_sag </span><span class="s2">import </span><span class="s1">get_auto_step_size</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">linear_model</span><span class="s3">.</span><span class="s1">_sag_fast </span><span class="s2">import </span><span class="s1">_multinomial_grad_loss_all_samples</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">multiclass </span><span class="s2">import </span><span class="s1">OneVsRestClassifier</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">preprocessing </span><span class="s2">import </span><span class="s1">LabelBinarizer</span><span class="s3">, </span><span class="s1">LabelEncoder</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils </span><span class="s2">import </span><span class="s1">check_random_state</span><span class="s3">, </span><span class="s1">compute_class_weight</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">_testing </span><span class="s2">import </span><span class="s3">(</span>
    <span class="s1">assert_allclose</span><span class="s3">,</span>
    <span class="s1">assert_almost_equal</span><span class="s3">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">extmath </span><span class="s2">import </span><span class="s1">row_norms</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">fixes </span><span class="s2">import </span><span class="s1">CSR_CONTAINERS</span>

<span class="s1">iris </span><span class="s3">= </span><span class="s1">load_iris</span><span class="s3">()</span>


<span class="s0"># this is used for sag classification</span>
<span class="s2">def </span><span class="s1">log_dloss</span><span class="s3">(</span><span class="s1">p</span><span class="s3">, </span><span class="s1">y</span><span class="s3">):</span>
    <span class="s1">z </span><span class="s3">= </span><span class="s1">p </span><span class="s3">* </span><span class="s1">y</span>
    <span class="s0"># approximately equal and saves the computation of the log</span>
    <span class="s2">if </span><span class="s1">z </span><span class="s3">&gt; </span><span class="s4">18.0</span><span class="s3">:</span>
        <span class="s2">return </span><span class="s1">math</span><span class="s3">.</span><span class="s1">exp</span><span class="s3">(-</span><span class="s1">z</span><span class="s3">) * -</span><span class="s1">y</span>
    <span class="s2">if </span><span class="s1">z </span><span class="s3">&lt; -</span><span class="s4">18.0</span><span class="s3">:</span>
        <span class="s2">return </span><span class="s3">-</span><span class="s1">y</span>
    <span class="s2">return </span><span class="s3">-</span><span class="s1">y </span><span class="s3">/ (</span><span class="s1">math</span><span class="s3">.</span><span class="s1">exp</span><span class="s3">(</span><span class="s1">z</span><span class="s3">) + </span><span class="s4">1.0</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">log_loss</span><span class="s3">(</span><span class="s1">p</span><span class="s3">, </span><span class="s1">y</span><span class="s3">):</span>
    <span class="s2">return </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">log</span><span class="s3">(</span><span class="s4">1.0 </span><span class="s3">+ </span><span class="s1">np</span><span class="s3">.</span><span class="s1">exp</span><span class="s3">(-</span><span class="s1">y </span><span class="s3">* </span><span class="s1">p</span><span class="s3">)))</span>


<span class="s0"># this is used for sag regression</span>
<span class="s2">def </span><span class="s1">squared_dloss</span><span class="s3">(</span><span class="s1">p</span><span class="s3">, </span><span class="s1">y</span><span class="s3">):</span>
    <span class="s2">return </span><span class="s1">p </span><span class="s3">- </span><span class="s1">y</span>


<span class="s2">def </span><span class="s1">squared_loss</span><span class="s3">(</span><span class="s1">p</span><span class="s3">, </span><span class="s1">y</span><span class="s3">):</span>
    <span class="s2">return </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s4">0.5 </span><span class="s3">* (</span><span class="s1">p </span><span class="s3">- </span><span class="s1">y</span><span class="s3">) * (</span><span class="s1">p </span><span class="s3">- </span><span class="s1">y</span><span class="s3">))</span>


<span class="s0"># function for measuring the log loss</span>
<span class="s2">def </span><span class="s1">get_pobj</span><span class="s3">(</span><span class="s1">w</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">myX</span><span class="s3">, </span><span class="s1">myy</span><span class="s3">, </span><span class="s1">loss</span><span class="s3">):</span>
    <span class="s1">w </span><span class="s3">= </span><span class="s1">w</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">()</span>
    <span class="s1">pred </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">myX</span><span class="s3">, </span><span class="s1">w</span><span class="s3">)</span>
    <span class="s1">p </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">(</span><span class="s1">pred</span><span class="s3">, </span><span class="s1">myy</span><span class="s3">)</span>
    <span class="s1">p </span><span class="s3">+= </span><span class="s1">alpha </span><span class="s3">* </span><span class="s1">w</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">w</span><span class="s3">) / </span><span class="s4">2.0</span>
    <span class="s2">return </span><span class="s1">p</span>


<span class="s2">def </span><span class="s1">sag</span><span class="s3">(</span>
    <span class="s1">X</span><span class="s3">,</span>
    <span class="s1">y</span><span class="s3">,</span>
    <span class="s1">step_size</span><span class="s3">,</span>
    <span class="s1">alpha</span><span class="s3">,</span>
    <span class="s1">n_iter</span><span class="s3">=</span><span class="s4">1</span><span class="s3">,</span>
    <span class="s1">dloss</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
    <span class="s1">sparse</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
    <span class="s1">sample_weight</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
    <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
    <span class="s1">saga</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
<span class="s3">):</span>
    <span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">0</span><span class="s3">], </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">1</span><span class="s3">]</span>

    <span class="s1">weights </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">1</span><span class="s3">])</span>
    <span class="s1">sum_gradient </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">1</span><span class="s3">])</span>
    <span class="s1">gradient_memory </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">((</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">))</span>

    <span class="s1">intercept </span><span class="s3">= </span><span class="s4">0.0</span>
    <span class="s1">intercept_sum_gradient </span><span class="s3">= </span><span class="s4">0.0</span>
    <span class="s1">intercept_gradient_memory </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">)</span>

    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s4">77</span><span class="s3">)</span>
    <span class="s1">decay </span><span class="s3">= </span><span class="s4">1.0</span>
    <span class="s1">seen </span><span class="s3">= </span><span class="s1">set</span><span class="s3">()</span>

    <span class="s0"># sparse data has a fixed decay of .01</span>
    <span class="s2">if </span><span class="s1">sparse</span><span class="s3">:</span>
        <span class="s1">decay </span><span class="s3">= </span><span class="s4">0.01</span>

    <span class="s2">for </span><span class="s1">epoch </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">n_iter</span><span class="s3">):</span>
        <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">):</span>
            <span class="s1">idx </span><span class="s3">= </span><span class="s1">int</span><span class="s3">(</span><span class="s1">rng</span><span class="s3">.</span><span class="s1">rand</span><span class="s3">() * </span><span class="s1">n_samples</span><span class="s3">)</span>
            <span class="s0"># idx = k</span>
            <span class="s1">entry </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s1">idx</span><span class="s3">]</span>
            <span class="s1">seen</span><span class="s3">.</span><span class="s1">add</span><span class="s3">(</span><span class="s1">idx</span><span class="s3">)</span>
            <span class="s1">p </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">entry</span><span class="s3">, </span><span class="s1">weights</span><span class="s3">) + </span><span class="s1">intercept</span>
            <span class="s1">gradient </span><span class="s3">= </span><span class="s1">dloss</span><span class="s3">(</span><span class="s1">p</span><span class="s3">, </span><span class="s1">y</span><span class="s3">[</span><span class="s1">idx</span><span class="s3">])</span>
            <span class="s2">if </span><span class="s1">sample_weight </span><span class="s2">is not None</span><span class="s3">:</span>
                <span class="s1">gradient </span><span class="s3">*= </span><span class="s1">sample_weight</span><span class="s3">[</span><span class="s1">idx</span><span class="s3">]</span>
            <span class="s1">update </span><span class="s3">= </span><span class="s1">entry </span><span class="s3">* </span><span class="s1">gradient </span><span class="s3">+ </span><span class="s1">alpha </span><span class="s3">* </span><span class="s1">weights</span>
            <span class="s1">gradient_correction </span><span class="s3">= </span><span class="s1">update </span><span class="s3">- </span><span class="s1">gradient_memory</span><span class="s3">[</span><span class="s1">idx</span><span class="s3">]</span>
            <span class="s1">sum_gradient </span><span class="s3">+= </span><span class="s1">gradient_correction</span>
            <span class="s1">gradient_memory</span><span class="s3">[</span><span class="s1">idx</span><span class="s3">] = </span><span class="s1">update</span>
            <span class="s2">if </span><span class="s1">saga</span><span class="s3">:</span>
                <span class="s1">weights </span><span class="s3">-= </span><span class="s1">gradient_correction </span><span class="s3">* </span><span class="s1">step_size </span><span class="s3">* (</span><span class="s4">1 </span><span class="s3">- </span><span class="s4">1.0 </span><span class="s3">/ </span><span class="s1">len</span><span class="s3">(</span><span class="s1">seen</span><span class="s3">))</span>

            <span class="s2">if </span><span class="s1">fit_intercept</span><span class="s3">:</span>
                <span class="s1">gradient_correction </span><span class="s3">= </span><span class="s1">gradient </span><span class="s3">- </span><span class="s1">intercept_gradient_memory</span><span class="s3">[</span><span class="s1">idx</span><span class="s3">]</span>
                <span class="s1">intercept_gradient_memory</span><span class="s3">[</span><span class="s1">idx</span><span class="s3">] = </span><span class="s1">gradient</span>
                <span class="s1">intercept_sum_gradient </span><span class="s3">+= </span><span class="s1">gradient_correction</span>
                <span class="s1">gradient_correction </span><span class="s3">*= </span><span class="s1">step_size </span><span class="s3">* (</span><span class="s4">1.0 </span><span class="s3">- </span><span class="s4">1.0 </span><span class="s3">/ </span><span class="s1">len</span><span class="s3">(</span><span class="s1">seen</span><span class="s3">))</span>
                <span class="s2">if </span><span class="s1">saga</span><span class="s3">:</span>
                    <span class="s1">intercept </span><span class="s3">-= (</span>
                        <span class="s1">step_size </span><span class="s3">* </span><span class="s1">intercept_sum_gradient </span><span class="s3">/ </span><span class="s1">len</span><span class="s3">(</span><span class="s1">seen</span><span class="s3">) * </span><span class="s1">decay</span>
                    <span class="s3">) + </span><span class="s1">gradient_correction</span>
                <span class="s2">else</span><span class="s3">:</span>
                    <span class="s1">intercept </span><span class="s3">-= </span><span class="s1">step_size </span><span class="s3">* </span><span class="s1">intercept_sum_gradient </span><span class="s3">/ </span><span class="s1">len</span><span class="s3">(</span><span class="s1">seen</span><span class="s3">) * </span><span class="s1">decay</span>

            <span class="s1">weights </span><span class="s3">-= </span><span class="s1">step_size </span><span class="s3">* </span><span class="s1">sum_gradient </span><span class="s3">/ </span><span class="s1">len</span><span class="s3">(</span><span class="s1">seen</span><span class="s3">)</span>

    <span class="s2">return </span><span class="s1">weights</span><span class="s3">, </span><span class="s1">intercept</span>


<span class="s2">def </span><span class="s1">sag_sparse</span><span class="s3">(</span>
    <span class="s1">X</span><span class="s3">,</span>
    <span class="s1">y</span><span class="s3">,</span>
    <span class="s1">step_size</span><span class="s3">,</span>
    <span class="s1">alpha</span><span class="s3">,</span>
    <span class="s1">n_iter</span><span class="s3">=</span><span class="s4">1</span><span class="s3">,</span>
    <span class="s1">dloss</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
    <span class="s1">sample_weight</span><span class="s3">=</span><span class="s2">None</span><span class="s3">,</span>
    <span class="s1">sparse</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
    <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
    <span class="s1">saga</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
    <span class="s1">random_state</span><span class="s3">=</span><span class="s4">0</span><span class="s3">,</span>
<span class="s3">):</span>
    <span class="s2">if </span><span class="s1">step_size </span><span class="s3">* </span><span class="s1">alpha </span><span class="s3">== </span><span class="s4">1.0</span><span class="s3">:</span>
        <span class="s2">raise </span><span class="s1">ZeroDivisionError</span><span class="s3">(</span>
            <span class="s5">&quot;Sparse sag does not handle the case step_size * alpha == 1&quot;</span>
        <span class="s3">)</span>
    <span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">0</span><span class="s3">], </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">1</span><span class="s3">]</span>

    <span class="s1">weights </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">)</span>
    <span class="s1">sum_gradient </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">)</span>
    <span class="s1">last_updated </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">, </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">int</span><span class="s3">)</span>
    <span class="s1">gradient_memory </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">)</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">check_random_state</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">)</span>
    <span class="s1">intercept </span><span class="s3">= </span><span class="s4">0.0</span>
    <span class="s1">intercept_sum_gradient </span><span class="s3">= </span><span class="s4">0.0</span>
    <span class="s1">wscale </span><span class="s3">= </span><span class="s4">1.0</span>
    <span class="s1">decay </span><span class="s3">= </span><span class="s4">1.0</span>
    <span class="s1">seen </span><span class="s3">= </span><span class="s1">set</span><span class="s3">()</span>

    <span class="s1">c_sum </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">n_iter </span><span class="s3">* </span><span class="s1">n_samples</span><span class="s3">)</span>

    <span class="s0"># sparse data has a fixed decay of .01</span>
    <span class="s2">if </span><span class="s1">sparse</span><span class="s3">:</span>
        <span class="s1">decay </span><span class="s3">= </span><span class="s4">0.01</span>

    <span class="s1">counter </span><span class="s3">= </span><span class="s4">0</span>
    <span class="s2">for </span><span class="s1">epoch </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">n_iter</span><span class="s3">):</span>
        <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">):</span>
            <span class="s0"># idx = k</span>
            <span class="s1">idx </span><span class="s3">= </span><span class="s1">int</span><span class="s3">(</span><span class="s1">rng</span><span class="s3">.</span><span class="s1">rand</span><span class="s3">() * </span><span class="s1">n_samples</span><span class="s3">)</span>
            <span class="s1">entry </span><span class="s3">= </span><span class="s1">X</span><span class="s3">[</span><span class="s1">idx</span><span class="s3">]</span>
            <span class="s1">seen</span><span class="s3">.</span><span class="s1">add</span><span class="s3">(</span><span class="s1">idx</span><span class="s3">)</span>

            <span class="s2">if </span><span class="s1">counter </span><span class="s3">&gt;= </span><span class="s4">1</span><span class="s3">:</span>
                <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">):</span>
                    <span class="s2">if </span><span class="s1">last_updated</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] == </span><span class="s4">0</span><span class="s3">:</span>
                        <span class="s1">weights</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] -= </span><span class="s1">c_sum</span><span class="s3">[</span><span class="s1">counter </span><span class="s3">- </span><span class="s4">1</span><span class="s3">] * </span><span class="s1">sum_gradient</span><span class="s3">[</span><span class="s1">j</span><span class="s3">]</span>
                    <span class="s2">else</span><span class="s3">:</span>
                        <span class="s1">weights</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] -= (</span>
                            <span class="s1">c_sum</span><span class="s3">[</span><span class="s1">counter </span><span class="s3">- </span><span class="s4">1</span><span class="s3">] - </span><span class="s1">c_sum</span><span class="s3">[</span><span class="s1">last_updated</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] - </span><span class="s4">1</span><span class="s3">]</span>
                        <span class="s3">) * </span><span class="s1">sum_gradient</span><span class="s3">[</span><span class="s1">j</span><span class="s3">]</span>
                    <span class="s1">last_updated</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] = </span><span class="s1">counter</span>

            <span class="s1">p </span><span class="s3">= (</span><span class="s1">wscale </span><span class="s3">* </span><span class="s1">np</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">entry</span><span class="s3">, </span><span class="s1">weights</span><span class="s3">)) + </span><span class="s1">intercept</span>
            <span class="s1">gradient </span><span class="s3">= </span><span class="s1">dloss</span><span class="s3">(</span><span class="s1">p</span><span class="s3">, </span><span class="s1">y</span><span class="s3">[</span><span class="s1">idx</span><span class="s3">])</span>

            <span class="s2">if </span><span class="s1">sample_weight </span><span class="s2">is not None</span><span class="s3">:</span>
                <span class="s1">gradient </span><span class="s3">*= </span><span class="s1">sample_weight</span><span class="s3">[</span><span class="s1">idx</span><span class="s3">]</span>

            <span class="s1">update </span><span class="s3">= </span><span class="s1">entry </span><span class="s3">* </span><span class="s1">gradient</span>
            <span class="s1">gradient_correction </span><span class="s3">= </span><span class="s1">update </span><span class="s3">- (</span><span class="s1">gradient_memory</span><span class="s3">[</span><span class="s1">idx</span><span class="s3">] * </span><span class="s1">entry</span><span class="s3">)</span>
            <span class="s1">sum_gradient </span><span class="s3">+= </span><span class="s1">gradient_correction</span>
            <span class="s2">if </span><span class="s1">saga</span><span class="s3">:</span>
                <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">):</span>
                    <span class="s1">weights</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] -= (</span>
                        <span class="s1">gradient_correction</span><span class="s3">[</span><span class="s1">j</span><span class="s3">]</span>
                        <span class="s3">* </span><span class="s1">step_size</span>
                        <span class="s3">* (</span><span class="s4">1 </span><span class="s3">- </span><span class="s4">1.0 </span><span class="s3">/ </span><span class="s1">len</span><span class="s3">(</span><span class="s1">seen</span><span class="s3">))</span>
                        <span class="s3">/ </span><span class="s1">wscale</span>
                    <span class="s3">)</span>

            <span class="s2">if </span><span class="s1">fit_intercept</span><span class="s3">:</span>
                <span class="s1">gradient_correction </span><span class="s3">= </span><span class="s1">gradient </span><span class="s3">- </span><span class="s1">gradient_memory</span><span class="s3">[</span><span class="s1">idx</span><span class="s3">]</span>
                <span class="s1">intercept_sum_gradient </span><span class="s3">+= </span><span class="s1">gradient_correction</span>
                <span class="s1">gradient_correction </span><span class="s3">*= </span><span class="s1">step_size </span><span class="s3">* (</span><span class="s4">1.0 </span><span class="s3">- </span><span class="s4">1.0 </span><span class="s3">/ </span><span class="s1">len</span><span class="s3">(</span><span class="s1">seen</span><span class="s3">))</span>
                <span class="s2">if </span><span class="s1">saga</span><span class="s3">:</span>
                    <span class="s1">intercept </span><span class="s3">-= (</span>
                        <span class="s1">step_size </span><span class="s3">* </span><span class="s1">intercept_sum_gradient </span><span class="s3">/ </span><span class="s1">len</span><span class="s3">(</span><span class="s1">seen</span><span class="s3">) * </span><span class="s1">decay</span>
                    <span class="s3">) + </span><span class="s1">gradient_correction</span>
                <span class="s2">else</span><span class="s3">:</span>
                    <span class="s1">intercept </span><span class="s3">-= </span><span class="s1">step_size </span><span class="s3">* </span><span class="s1">intercept_sum_gradient </span><span class="s3">/ </span><span class="s1">len</span><span class="s3">(</span><span class="s1">seen</span><span class="s3">) * </span><span class="s1">decay</span>

            <span class="s1">gradient_memory</span><span class="s3">[</span><span class="s1">idx</span><span class="s3">] = </span><span class="s1">gradient</span>

            <span class="s1">wscale </span><span class="s3">*= </span><span class="s4">1.0 </span><span class="s3">- </span><span class="s1">alpha </span><span class="s3">* </span><span class="s1">step_size</span>
            <span class="s2">if </span><span class="s1">counter </span><span class="s3">== </span><span class="s4">0</span><span class="s3">:</span>
                <span class="s1">c_sum</span><span class="s3">[</span><span class="s4">0</span><span class="s3">] = </span><span class="s1">step_size </span><span class="s3">/ (</span><span class="s1">wscale </span><span class="s3">* </span><span class="s1">len</span><span class="s3">(</span><span class="s1">seen</span><span class="s3">))</span>
            <span class="s2">else</span><span class="s3">:</span>
                <span class="s1">c_sum</span><span class="s3">[</span><span class="s1">counter</span><span class="s3">] = </span><span class="s1">c_sum</span><span class="s3">[</span><span class="s1">counter </span><span class="s3">- </span><span class="s4">1</span><span class="s3">] + </span><span class="s1">step_size </span><span class="s3">/ (</span><span class="s1">wscale </span><span class="s3">* </span><span class="s1">len</span><span class="s3">(</span><span class="s1">seen</span><span class="s3">))</span>

            <span class="s2">if </span><span class="s1">counter </span><span class="s3">&gt;= </span><span class="s4">1 </span><span class="s2">and </span><span class="s1">wscale </span><span class="s3">&lt; </span><span class="s4">1e-9</span><span class="s3">:</span>
                <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">):</span>
                    <span class="s2">if </span><span class="s1">last_updated</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] == </span><span class="s4">0</span><span class="s3">:</span>
                        <span class="s1">weights</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] -= </span><span class="s1">c_sum</span><span class="s3">[</span><span class="s1">counter</span><span class="s3">] * </span><span class="s1">sum_gradient</span><span class="s3">[</span><span class="s1">j</span><span class="s3">]</span>
                    <span class="s2">else</span><span class="s3">:</span>
                        <span class="s1">weights</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] -= (</span>
                            <span class="s1">c_sum</span><span class="s3">[</span><span class="s1">counter</span><span class="s3">] - </span><span class="s1">c_sum</span><span class="s3">[</span><span class="s1">last_updated</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] - </span><span class="s4">1</span><span class="s3">]</span>
                        <span class="s3">) * </span><span class="s1">sum_gradient</span><span class="s3">[</span><span class="s1">j</span><span class="s3">]</span>
                    <span class="s1">last_updated</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] = </span><span class="s1">counter </span><span class="s3">+ </span><span class="s4">1</span>
                <span class="s1">c_sum</span><span class="s3">[</span><span class="s1">counter</span><span class="s3">] = </span><span class="s4">0</span>
                <span class="s1">weights </span><span class="s3">*= </span><span class="s1">wscale</span>
                <span class="s1">wscale </span><span class="s3">= </span><span class="s4">1.0</span>

            <span class="s1">counter </span><span class="s3">+= </span><span class="s4">1</span>

    <span class="s2">for </span><span class="s1">j </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">):</span>
        <span class="s2">if </span><span class="s1">last_updated</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] == </span><span class="s4">0</span><span class="s3">:</span>
            <span class="s1">weights</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] -= </span><span class="s1">c_sum</span><span class="s3">[</span><span class="s1">counter </span><span class="s3">- </span><span class="s4">1</span><span class="s3">] * </span><span class="s1">sum_gradient</span><span class="s3">[</span><span class="s1">j</span><span class="s3">]</span>
        <span class="s2">else</span><span class="s3">:</span>
            <span class="s1">weights</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] -= (</span>
                <span class="s1">c_sum</span><span class="s3">[</span><span class="s1">counter </span><span class="s3">- </span><span class="s4">1</span><span class="s3">] - </span><span class="s1">c_sum</span><span class="s3">[</span><span class="s1">last_updated</span><span class="s3">[</span><span class="s1">j</span><span class="s3">] - </span><span class="s4">1</span><span class="s3">]</span>
            <span class="s3">) * </span><span class="s1">sum_gradient</span><span class="s3">[</span><span class="s1">j</span><span class="s3">]</span>
    <span class="s1">weights </span><span class="s3">*= </span><span class="s1">wscale</span>
    <span class="s2">return </span><span class="s1">weights</span><span class="s3">, </span><span class="s1">intercept</span>


<span class="s2">def </span><span class="s1">get_step_size</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">classification</span><span class="s3">=</span><span class="s2">True</span><span class="s3">):</span>
    <span class="s2">if </span><span class="s1">classification</span><span class="s3">:</span>
        <span class="s2">return </span><span class="s4">4.0 </span><span class="s3">/ (</span><span class="s1">np</span><span class="s3">.</span><span class="s1">max</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">X </span><span class="s3">* </span><span class="s1">X</span><span class="s3">, </span><span class="s1">axis</span><span class="s3">=</span><span class="s4">1</span><span class="s3">)) + </span><span class="s1">fit_intercept </span><span class="s3">+ </span><span class="s4">4.0 </span><span class="s3">* </span><span class="s1">alpha</span><span class="s3">)</span>
    <span class="s2">else</span><span class="s3">:</span>
        <span class="s2">return </span><span class="s4">1.0 </span><span class="s3">/ (</span><span class="s1">np</span><span class="s3">.</span><span class="s1">max</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">X </span><span class="s3">* </span><span class="s1">X</span><span class="s3">, </span><span class="s1">axis</span><span class="s3">=</span><span class="s4">1</span><span class="s3">)) + </span><span class="s1">fit_intercept </span><span class="s3">+ </span><span class="s1">alpha</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_classifier_matching</span><span class="s3">():</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s4">20</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_blobs</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">centers</span><span class="s3">=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">cluster_std</span><span class="s3">=</span><span class="s4">0.1</span><span class="s3">)</span>
    <span class="s1">y</span><span class="s3">[</span><span class="s1">y </span><span class="s3">== </span><span class="s4">0</span><span class="s3">] = -</span><span class="s4">1</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">1.1</span>
    <span class="s1">fit_intercept </span><span class="s3">= </span><span class="s2">True</span>
    <span class="s1">step_size </span><span class="s3">= </span><span class="s1">get_step_size</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">solver </span><span class="s2">in </span><span class="s3">[</span><span class="s5">&quot;sag&quot;</span><span class="s3">, </span><span class="s5">&quot;saga&quot;</span><span class="s3">]:</span>
        <span class="s2">if </span><span class="s1">solver </span><span class="s3">== </span><span class="s5">&quot;sag&quot;</span><span class="s3">:</span>
            <span class="s1">n_iter </span><span class="s3">= </span><span class="s4">80</span>
        <span class="s2">else</span><span class="s3">:</span>
            <span class="s0"># SAGA variance w.r.t. stream order is higher</span>
            <span class="s1">n_iter </span><span class="s3">= </span><span class="s4">300</span>
        <span class="s1">clf </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">(</span>
            <span class="s1">solver</span><span class="s3">=</span><span class="s1">solver</span><span class="s3">,</span>
            <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
            <span class="s1">tol</span><span class="s3">=</span><span class="s4">1e-11</span><span class="s3">,</span>
            <span class="s1">C</span><span class="s3">=</span><span class="s4">1.0 </span><span class="s3">/ </span><span class="s1">alpha </span><span class="s3">/ </span><span class="s1">n_samples</span><span class="s3">,</span>
            <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
            <span class="s1">random_state</span><span class="s3">=</span><span class="s4">10</span><span class="s3">,</span>
        <span class="s3">)</span>
        <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

        <span class="s1">weights</span><span class="s3">, </span><span class="s1">intercept </span><span class="s3">= </span><span class="s1">sag_sparse</span><span class="s3">(</span>
            <span class="s1">X</span><span class="s3">,</span>
            <span class="s1">y</span><span class="s3">,</span>
            <span class="s1">step_size</span><span class="s3">,</span>
            <span class="s1">alpha</span><span class="s3">,</span>
            <span class="s1">n_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
            <span class="s1">dloss</span><span class="s3">=</span><span class="s1">log_dloss</span><span class="s3">,</span>
            <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
            <span class="s1">saga</span><span class="s3">=</span><span class="s1">solver </span><span class="s3">== </span><span class="s5">&quot;saga&quot;</span><span class="s3">,</span>
        <span class="s3">)</span>
        <span class="s1">weights2</span><span class="s3">, </span><span class="s1">intercept2 </span><span class="s3">= </span><span class="s1">sag</span><span class="s3">(</span>
            <span class="s1">X</span><span class="s3">,</span>
            <span class="s1">y</span><span class="s3">,</span>
            <span class="s1">step_size</span><span class="s3">,</span>
            <span class="s1">alpha</span><span class="s3">,</span>
            <span class="s1">n_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
            <span class="s1">dloss</span><span class="s3">=</span><span class="s1">log_dloss</span><span class="s3">,</span>
            <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
            <span class="s1">saga</span><span class="s3">=</span><span class="s1">solver </span><span class="s3">== </span><span class="s5">&quot;saga&quot;</span><span class="s3">,</span>
        <span class="s3">)</span>
        <span class="s1">weights </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">atleast_2d</span><span class="s3">(</span><span class="s1">weights</span><span class="s3">)</span>
        <span class="s1">intercept </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">atleast_1d</span><span class="s3">(</span><span class="s1">intercept</span><span class="s3">)</span>
        <span class="s1">weights2 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">atleast_2d</span><span class="s3">(</span><span class="s1">weights2</span><span class="s3">)</span>
        <span class="s1">intercept2 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">atleast_1d</span><span class="s3">(</span><span class="s1">intercept2</span><span class="s3">)</span>

        <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">weights</span><span class="s3">, </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">9</span><span class="s3">)</span>
        <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">intercept</span><span class="s3">, </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">9</span><span class="s3">)</span>
        <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">weights2</span><span class="s3">, </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">9</span><span class="s3">)</span>
        <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">intercept2</span><span class="s3">, </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">9</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_regressor_matching</span><span class="s3">():</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s4">10</span>
    <span class="s1">n_features </span><span class="s3">= </span><span class="s4">5</span>

    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s4">10</span><span class="s3">)</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=(</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">))</span>
    <span class="s1">true_w </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=</span><span class="s1">n_features</span><span class="s3">)</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">true_w</span><span class="s3">)</span>

    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">1.0</span>
    <span class="s1">n_iter </span><span class="s3">= </span><span class="s4">100</span>
    <span class="s1">fit_intercept </span><span class="s3">= </span><span class="s2">True</span>

    <span class="s1">step_size </span><span class="s3">= </span><span class="s1">get_step_size</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">classification</span><span class="s3">=</span><span class="s2">False</span><span class="s3">)</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">Ridge</span><span class="s3">(</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s4">0.00000000001</span><span class="s3">,</span>
        <span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;sag&quot;</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha </span><span class="s3">* </span><span class="s1">n_samples</span><span class="s3">,</span>
        <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">weights1</span><span class="s3">, </span><span class="s1">intercept1 </span><span class="s3">= </span><span class="s1">sag_sparse</span><span class="s3">(</span>
        <span class="s1">X</span><span class="s3">,</span>
        <span class="s1">y</span><span class="s3">,</span>
        <span class="s1">step_size</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">,</span>
        <span class="s1">n_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
        <span class="s1">dloss</span><span class="s3">=</span><span class="s1">squared_dloss</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">weights2</span><span class="s3">, </span><span class="s1">intercept2 </span><span class="s3">= </span><span class="s1">sag</span><span class="s3">(</span>
        <span class="s1">X</span><span class="s3">,</span>
        <span class="s1">y</span><span class="s3">,</span>
        <span class="s1">step_size</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">,</span>
        <span class="s1">n_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
        <span class="s1">dloss</span><span class="s3">=</span><span class="s1">squared_dloss</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
    <span class="s3">)</span>

    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">weights1</span><span class="s3">, </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">intercept1</span><span class="s3">, </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">weights2</span><span class="s3">, </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">intercept2</span><span class="s3">, </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s5">&quot;ignore:The max_iter was reached&quot;</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;csr_container&quot;</span><span class="s3">, </span><span class="s1">CSR_CONTAINERS</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_sag_pobj_matches_logistic_regression</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;tests if the sag pobj matches log reg&quot;&quot;&quot;</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s4">100</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">1.0</span>
    <span class="s1">max_iter </span><span class="s3">= </span><span class="s4">20</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_blobs</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">centers</span><span class="s3">=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">cluster_std</span><span class="s3">=</span><span class="s4">0.1</span><span class="s3">)</span>

    <span class="s1">clf1 </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">(</span>
        <span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;sag&quot;</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s4">0.0000001</span><span class="s3">,</span>
        <span class="s1">C</span><span class="s3">=</span><span class="s4">1.0 </span><span class="s3">/ </span><span class="s1">alpha </span><span class="s3">/ </span><span class="s1">n_samples</span><span class="s3">,</span>
        <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s4">10</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">clf2 </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">)</span>
    <span class="s1">clf3 </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">(</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s4">0.0000001</span><span class="s3">,</span>
        <span class="s1">C</span><span class="s3">=</span><span class="s4">1.0 </span><span class="s3">/ </span><span class="s1">alpha </span><span class="s3">/ </span><span class="s1">n_samples</span><span class="s3">,</span>
        <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s4">10</span><span class="s3">,</span>
    <span class="s3">)</span>

    <span class="s1">clf1</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf2</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X</span><span class="s3">), </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf3</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">pobj1 </span><span class="s3">= </span><span class="s1">get_pobj</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">log_loss</span><span class="s3">)</span>
    <span class="s1">pobj2 </span><span class="s3">= </span><span class="s1">get_pobj</span><span class="s3">(</span><span class="s1">clf2</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">log_loss</span><span class="s3">)</span>
    <span class="s1">pobj3 </span><span class="s3">= </span><span class="s1">get_pobj</span><span class="s3">(</span><span class="s1">clf3</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">log_loss</span><span class="s3">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">pobj1</span><span class="s3">, </span><span class="s1">pobj2</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">4</span><span class="s3">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">pobj2</span><span class="s3">, </span><span class="s1">pobj3</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">4</span><span class="s3">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">pobj3</span><span class="s3">, </span><span class="s1">pobj1</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">4</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s5">&quot;ignore:The max_iter was reached&quot;</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;csr_container&quot;</span><span class="s3">, </span><span class="s1">CSR_CONTAINERS</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_sag_pobj_matches_ridge_regression</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;tests if the sag pobj matches ridge reg&quot;&quot;&quot;</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s4">100</span>
    <span class="s1">n_features </span><span class="s3">= </span><span class="s4">10</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">1.0</span>
    <span class="s1">n_iter </span><span class="s3">= </span><span class="s4">100</span>
    <span class="s1">fit_intercept </span><span class="s3">= </span><span class="s2">False</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s4">10</span><span class="s3">)</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=(</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">))</span>
    <span class="s1">true_w </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=</span><span class="s1">n_features</span><span class="s3">)</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">true_w</span><span class="s3">)</span>

    <span class="s1">clf1 </span><span class="s3">= </span><span class="s1">Ridge</span><span class="s3">(</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s4">0.00000000001</span><span class="s3">,</span>
        <span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;sag&quot;</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha</span><span class="s3">,</span>
        <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s4">42</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">clf2 </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">)</span>
    <span class="s1">clf3 </span><span class="s3">= </span><span class="s1">Ridge</span><span class="s3">(</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s4">0.00001</span><span class="s3">,</span>
        <span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;lsqr&quot;</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha</span><span class="s3">,</span>
        <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s4">42</span><span class="s3">,</span>
    <span class="s3">)</span>

    <span class="s1">clf1</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf2</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X</span><span class="s3">), </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf3</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">pobj1 </span><span class="s3">= </span><span class="s1">get_pobj</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">squared_loss</span><span class="s3">)</span>
    <span class="s1">pobj2 </span><span class="s3">= </span><span class="s1">get_pobj</span><span class="s3">(</span><span class="s1">clf2</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">squared_loss</span><span class="s3">)</span>
    <span class="s1">pobj3 </span><span class="s3">= </span><span class="s1">get_pobj</span><span class="s3">(</span><span class="s1">clf3</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">squared_loss</span><span class="s3">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">pobj1</span><span class="s3">, </span><span class="s1">pobj2</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">4</span><span class="s3">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">pobj1</span><span class="s3">, </span><span class="s1">pobj3</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">4</span><span class="s3">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">pobj3</span><span class="s3">, </span><span class="s1">pobj2</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">4</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s5">&quot;ignore:The max_iter was reached&quot;</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;csr_container&quot;</span><span class="s3">, </span><span class="s1">CSR_CONTAINERS</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_sag_regressor_computed_correctly</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;tests if the sag regressor is computed correctly&quot;&quot;&quot;</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">0.1</span>
    <span class="s1">n_features </span><span class="s3">= </span><span class="s4">10</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s4">40</span>
    <span class="s1">max_iter </span><span class="s3">= </span><span class="s4">100</span>
    <span class="s1">tol </span><span class="s3">= </span><span class="s4">0.000001</span>
    <span class="s1">fit_intercept </span><span class="s3">= </span><span class="s2">True</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s4">0</span><span class="s3">)</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=(</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">))</span>
    <span class="s1">w </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=</span><span class="s1">n_features</span><span class="s3">)</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">w</span><span class="s3">) + </span><span class="s4">2.0</span>
    <span class="s1">step_size </span><span class="s3">= </span><span class="s1">get_step_size</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">classification</span><span class="s3">=</span><span class="s2">False</span><span class="s3">)</span>

    <span class="s1">clf1 </span><span class="s3">= </span><span class="s1">Ridge</span><span class="s3">(</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s1">tol</span><span class="s3">,</span>
        <span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;sag&quot;</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha </span><span class="s3">* </span><span class="s1">n_samples</span><span class="s3">,</span>
        <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s1">rng</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">clf2 </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">)</span>

    <span class="s1">clf1</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf2</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X</span><span class="s3">), </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">spweights1</span><span class="s3">, </span><span class="s1">spintercept1 </span><span class="s3">= </span><span class="s1">sag_sparse</span><span class="s3">(</span>
        <span class="s1">X</span><span class="s3">,</span>
        <span class="s1">y</span><span class="s3">,</span>
        <span class="s1">step_size</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">,</span>
        <span class="s1">n_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">,</span>
        <span class="s1">dloss</span><span class="s3">=</span><span class="s1">squared_dloss</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s1">rng</span><span class="s3">,</span>
    <span class="s3">)</span>

    <span class="s1">spweights2</span><span class="s3">, </span><span class="s1">spintercept2 </span><span class="s3">= </span><span class="s1">sag_sparse</span><span class="s3">(</span>
        <span class="s1">X</span><span class="s3">,</span>
        <span class="s1">y</span><span class="s3">,</span>
        <span class="s1">step_size</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">,</span>
        <span class="s1">n_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">,</span>
        <span class="s1">dloss</span><span class="s3">=</span><span class="s1">squared_dloss</span><span class="s3">,</span>
        <span class="s1">sparse</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s1">rng</span><span class="s3">,</span>
    <span class="s3">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(), </span><span class="s1">spweights1</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(), </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">3</span><span class="s3">)</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">spintercept1</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">1</span><span class="s3">)</span>

    <span class="s0"># TODO: uncomment when sparse Ridge with intercept will be fixed (#4710)</span>
    <span class="s0"># assert_array_almost_equal(clf2.coef_.ravel(),</span>
    <span class="s0">#                          spweights2.ravel(),</span>
    <span class="s0">#                          decimal=3)</span>
    <span class="s0"># assert_almost_equal(clf2.intercept_, spintercept2, decimal=1)'''</span>


<span class="s2">def </span><span class="s1">test_get_auto_step_size</span><span class="s3">():</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">], [</span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s3">], [</span><span class="s4">2</span><span class="s3">, </span><span class="s4">3</span><span class="s3">, </span><span class="s4">2</span><span class="s3">]], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float64</span><span class="s3">)</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">1.2</span>
    <span class="s1">fit_intercept </span><span class="s3">= </span><span class="s2">False</span>
    <span class="s0"># sum the squares of the second sample because that's the largest</span>
    <span class="s1">max_squared_sum </span><span class="s3">= </span><span class="s4">4 </span><span class="s3">+ </span><span class="s4">9 </span><span class="s3">+ </span><span class="s4">16</span>
    <span class="s1">max_squared_sum_ </span><span class="s3">= </span><span class="s1">row_norms</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">squared</span><span class="s3">=</span><span class="s2">True</span><span class="s3">).</span><span class="s1">max</span><span class="s3">()</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s4">0</span><span class="s3">]</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">max_squared_sum</span><span class="s3">, </span><span class="s1">max_squared_sum_</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">4</span><span class="s3">)</span>

    <span class="s2">for </span><span class="s1">saga </span><span class="s2">in </span><span class="s3">[</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">]:</span>
        <span class="s2">for </span><span class="s1">fit_intercept </span><span class="s2">in </span><span class="s3">(</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">):</span>
            <span class="s2">if </span><span class="s1">saga</span><span class="s3">:</span>
                <span class="s1">L_sqr </span><span class="s3">= </span><span class="s1">max_squared_sum </span><span class="s3">+ </span><span class="s1">alpha </span><span class="s3">+ </span><span class="s1">int</span><span class="s3">(</span><span class="s1">fit_intercept</span><span class="s3">)</span>
                <span class="s1">L_log </span><span class="s3">= (</span><span class="s1">max_squared_sum </span><span class="s3">+ </span><span class="s4">4.0 </span><span class="s3">* </span><span class="s1">alpha </span><span class="s3">+ </span><span class="s1">int</span><span class="s3">(</span><span class="s1">fit_intercept</span><span class="s3">)) / </span><span class="s4">4.0</span>
                <span class="s1">mun_sqr </span><span class="s3">= </span><span class="s1">min</span><span class="s3">(</span><span class="s4">2 </span><span class="s3">* </span><span class="s1">n_samples </span><span class="s3">* </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">L_sqr</span><span class="s3">)</span>
                <span class="s1">mun_log </span><span class="s3">= </span><span class="s1">min</span><span class="s3">(</span><span class="s4">2 </span><span class="s3">* </span><span class="s1">n_samples </span><span class="s3">* </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">L_log</span><span class="s3">)</span>
                <span class="s1">step_size_sqr </span><span class="s3">= </span><span class="s4">1 </span><span class="s3">/ (</span><span class="s4">2 </span><span class="s3">* </span><span class="s1">L_sqr </span><span class="s3">+ </span><span class="s1">mun_sqr</span><span class="s3">)</span>
                <span class="s1">step_size_log </span><span class="s3">= </span><span class="s4">1 </span><span class="s3">/ (</span><span class="s4">2 </span><span class="s3">* </span><span class="s1">L_log </span><span class="s3">+ </span><span class="s1">mun_log</span><span class="s3">)</span>
            <span class="s2">else</span><span class="s3">:</span>
                <span class="s1">step_size_sqr </span><span class="s3">= </span><span class="s4">1.0 </span><span class="s3">/ (</span><span class="s1">max_squared_sum </span><span class="s3">+ </span><span class="s1">alpha </span><span class="s3">+ </span><span class="s1">int</span><span class="s3">(</span><span class="s1">fit_intercept</span><span class="s3">))</span>
                <span class="s1">step_size_log </span><span class="s3">= </span><span class="s4">4.0 </span><span class="s3">/ (</span>
                    <span class="s1">max_squared_sum </span><span class="s3">+ </span><span class="s4">4.0 </span><span class="s3">* </span><span class="s1">alpha </span><span class="s3">+ </span><span class="s1">int</span><span class="s3">(</span><span class="s1">fit_intercept</span><span class="s3">)</span>
                <span class="s3">)</span>

            <span class="s1">step_size_sqr_ </span><span class="s3">= </span><span class="s1">get_auto_step_size</span><span class="s3">(</span>
                <span class="s1">max_squared_sum_</span><span class="s3">,</span>
                <span class="s1">alpha</span><span class="s3">,</span>
                <span class="s5">&quot;squared&quot;</span><span class="s3">,</span>
                <span class="s1">fit_intercept</span><span class="s3">,</span>
                <span class="s1">n_samples</span><span class="s3">=</span><span class="s1">n_samples</span><span class="s3">,</span>
                <span class="s1">is_saga</span><span class="s3">=</span><span class="s1">saga</span><span class="s3">,</span>
            <span class="s3">)</span>
            <span class="s1">step_size_log_ </span><span class="s3">= </span><span class="s1">get_auto_step_size</span><span class="s3">(</span>
                <span class="s1">max_squared_sum_</span><span class="s3">,</span>
                <span class="s1">alpha</span><span class="s3">,</span>
                <span class="s5">&quot;log&quot;</span><span class="s3">,</span>
                <span class="s1">fit_intercept</span><span class="s3">,</span>
                <span class="s1">n_samples</span><span class="s3">=</span><span class="s1">n_samples</span><span class="s3">,</span>
                <span class="s1">is_saga</span><span class="s3">=</span><span class="s1">saga</span><span class="s3">,</span>
            <span class="s3">)</span>

            <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">step_size_sqr</span><span class="s3">, </span><span class="s1">step_size_sqr_</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">4</span><span class="s3">)</span>
            <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">step_size_log</span><span class="s3">, </span><span class="s1">step_size_log_</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">4</span><span class="s3">)</span>

    <span class="s1">msg </span><span class="s3">= </span><span class="s5">&quot;Unknown loss function for SAG solver, got wrong instead of&quot;</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">msg</span><span class="s3">):</span>
        <span class="s1">get_auto_step_size</span><span class="s3">(</span><span class="s1">max_squared_sum_</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s5">&quot;wrong&quot;</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;seed&quot;</span><span class="s3">, </span><span class="s1">range</span><span class="s3">(</span><span class="s4">3</span><span class="s3">))  </span><span class="s0"># locally tested with 1000 seeds</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;csr_container&quot;</span><span class="s3">, </span><span class="s1">CSR_CONTAINERS</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_sag_regressor</span><span class="s3">(</span><span class="s1">seed</span><span class="s3">, </span><span class="s1">csr_container</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;tests if the sag regressor performs well&quot;&quot;&quot;</span>
    <span class="s1">xmin</span><span class="s3">, </span><span class="s1">xmax </span><span class="s3">= -</span><span class="s4">5</span><span class="s3">, </span><span class="s4">5</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s4">300</span>
    <span class="s1">tol </span><span class="s3">= </span><span class="s4">0.001</span>
    <span class="s1">max_iter </span><span class="s3">= </span><span class="s4">100</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">0.1</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s1">seed</span><span class="s3">)</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linspace</span><span class="s3">(</span><span class="s1">xmin</span><span class="s3">, </span><span class="s1">xmax</span><span class="s3">, </span><span class="s1">n_samples</span><span class="s3">).</span><span class="s1">reshape</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s4">1</span><span class="s3">)</span>

    <span class="s0"># simple linear function without noise</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s4">0.5 </span><span class="s3">* </span><span class="s1">X</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">()</span>

    <span class="s1">clf1 </span><span class="s3">= </span><span class="s1">Ridge</span><span class="s3">(</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s1">tol</span><span class="s3">,</span>
        <span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;sag&quot;</span><span class="s3">,</span>
        <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha </span><span class="s3">* </span><span class="s1">n_samples</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s1">rng</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">clf2 </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">)</span>
    <span class="s1">clf1</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf2</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X</span><span class="s3">), </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">score1 </span><span class="s3">= </span><span class="s1">clf1</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">score2 </span><span class="s3">= </span><span class="s1">clf2</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">score1 </span><span class="s3">&gt; </span><span class="s4">0.98</span>
    <span class="s2">assert </span><span class="s1">score2 </span><span class="s3">&gt; </span><span class="s4">0.98</span>

    <span class="s0"># simple linear function with noise</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s4">0.5 </span><span class="s3">* </span><span class="s1">X</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">() + </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s4">1</span><span class="s3">).</span><span class="s1">ravel</span><span class="s3">()</span>

    <span class="s1">clf1 </span><span class="s3">= </span><span class="s1">Ridge</span><span class="s3">(</span><span class="s1">tol</span><span class="s3">=</span><span class="s1">tol</span><span class="s3">, </span><span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;sag&quot;</span><span class="s3">, </span><span class="s1">max_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha </span><span class="s3">* </span><span class="s1">n_samples</span><span class="s3">)</span>
    <span class="s1">clf2 </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">)</span>
    <span class="s1">clf1</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf2</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X</span><span class="s3">), </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">score1 </span><span class="s3">= </span><span class="s1">clf1</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">score2 </span><span class="s3">= </span><span class="s1">clf2</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">score1 </span><span class="s3">&gt; </span><span class="s4">0.45</span>
    <span class="s2">assert </span><span class="s1">score2 </span><span class="s3">&gt; </span><span class="s4">0.45</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s5">&quot;ignore:The max_iter was reached&quot;</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;csr_container&quot;</span><span class="s3">, </span><span class="s1">CSR_CONTAINERS</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_sag_classifier_computed_correctly</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;tests if the binary classifier is computed correctly&quot;&quot;&quot;</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">0.1</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s4">50</span>
    <span class="s1">n_iter </span><span class="s3">= </span><span class="s4">50</span>
    <span class="s1">tol </span><span class="s3">= </span><span class="s4">0.00001</span>
    <span class="s1">fit_intercept </span><span class="s3">= </span><span class="s2">True</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_blobs</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">centers</span><span class="s3">=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">cluster_std</span><span class="s3">=</span><span class="s4">0.1</span><span class="s3">)</span>
    <span class="s1">step_size </span><span class="s3">= </span><span class="s1">get_step_size</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">classification</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s1">classes </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">unique</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">y_tmp </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">)</span>
    <span class="s1">y_tmp</span><span class="s3">[</span><span class="s1">y </span><span class="s3">!= </span><span class="s1">classes</span><span class="s3">[</span><span class="s4">1</span><span class="s3">]] = -</span><span class="s4">1</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">y_tmp</span>

    <span class="s1">clf1 </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">(</span>
        <span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;sag&quot;</span><span class="s3">,</span>
        <span class="s1">C</span><span class="s3">=</span><span class="s4">1.0 </span><span class="s3">/ </span><span class="s1">alpha </span><span class="s3">/ </span><span class="s1">n_samples</span><span class="s3">,</span>
        <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s1">tol</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s4">77</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">clf2 </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">)</span>

    <span class="s1">clf1</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf2</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X</span><span class="s3">), </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">spweights</span><span class="s3">, </span><span class="s1">spintercept </span><span class="s3">= </span><span class="s1">sag_sparse</span><span class="s3">(</span>
        <span class="s1">X</span><span class="s3">,</span>
        <span class="s1">y</span><span class="s3">,</span>
        <span class="s1">step_size</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">,</span>
        <span class="s1">n_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
        <span class="s1">dloss</span><span class="s3">=</span><span class="s1">log_dloss</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">spweights2</span><span class="s3">, </span><span class="s1">spintercept2 </span><span class="s3">= </span><span class="s1">sag_sparse</span><span class="s3">(</span>
        <span class="s1">X</span><span class="s3">,</span>
        <span class="s1">y</span><span class="s3">,</span>
        <span class="s1">step_size</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">,</span>
        <span class="s1">n_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
        <span class="s1">dloss</span><span class="s3">=</span><span class="s1">log_dloss</span><span class="s3">,</span>
        <span class="s1">sparse</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
    <span class="s3">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(), </span><span class="s1">spweights</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(), </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">2</span><span class="s3">)</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">spintercept</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">1</span><span class="s3">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">clf2</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(), </span><span class="s1">spweights2</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(), </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">2</span><span class="s3">)</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">clf2</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">spintercept2</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">1</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s5">&quot;ignore:The max_iter was reached&quot;</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;csr_container&quot;</span><span class="s3">, </span><span class="s1">CSR_CONTAINERS</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_sag_multiclass_computed_correctly</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;tests if the multiclass classifier is computed correctly&quot;&quot;&quot;</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">0.1</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s4">20</span>
    <span class="s1">tol </span><span class="s3">= </span><span class="s4">1e-5</span>
    <span class="s1">max_iter </span><span class="s3">= </span><span class="s4">70</span>
    <span class="s1">fit_intercept </span><span class="s3">= </span><span class="s2">True</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_blobs</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">centers</span><span class="s3">=</span><span class="s4">3</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">cluster_std</span><span class="s3">=</span><span class="s4">0.1</span><span class="s3">)</span>
    <span class="s1">step_size </span><span class="s3">= </span><span class="s1">get_step_size</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">classification</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s1">classes </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">unique</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">clf1 </span><span class="s3">= </span><span class="s1">OneVsRestClassifier</span><span class="s3">(</span>
        <span class="s1">LogisticRegression</span><span class="s3">(</span>
            <span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;sag&quot;</span><span class="s3">,</span>
            <span class="s1">C</span><span class="s3">=</span><span class="s4">1.0 </span><span class="s3">/ </span><span class="s1">alpha </span><span class="s3">/ </span><span class="s1">n_samples</span><span class="s3">,</span>
            <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">,</span>
            <span class="s1">tol</span><span class="s3">=</span><span class="s1">tol</span><span class="s3">,</span>
            <span class="s1">random_state</span><span class="s3">=</span><span class="s4">77</span><span class="s3">,</span>
            <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
        <span class="s3">)</span>
    <span class="s3">)</span>
    <span class="s1">clf2 </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">)</span>

    <span class="s1">clf1</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf2</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X</span><span class="s3">), </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">coef1 </span><span class="s3">= []</span>
    <span class="s1">intercept1 </span><span class="s3">= []</span>
    <span class="s1">coef2 </span><span class="s3">= []</span>
    <span class="s1">intercept2 </span><span class="s3">= []</span>
    <span class="s2">for </span><span class="s1">cl </span><span class="s2">in </span><span class="s1">classes</span><span class="s3">:</span>
        <span class="s1">y_encoded </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">)</span>
        <span class="s1">y_encoded</span><span class="s3">[</span><span class="s1">y </span><span class="s3">!= </span><span class="s1">cl</span><span class="s3">] = -</span><span class="s4">1</span>

        <span class="s1">spweights1</span><span class="s3">, </span><span class="s1">spintercept1 </span><span class="s3">= </span><span class="s1">sag_sparse</span><span class="s3">(</span>
            <span class="s1">X</span><span class="s3">,</span>
            <span class="s1">y_encoded</span><span class="s3">,</span>
            <span class="s1">step_size</span><span class="s3">,</span>
            <span class="s1">alpha</span><span class="s3">,</span>
            <span class="s1">dloss</span><span class="s3">=</span><span class="s1">log_dloss</span><span class="s3">,</span>
            <span class="s1">n_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">,</span>
            <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
        <span class="s3">)</span>
        <span class="s1">spweights2</span><span class="s3">, </span><span class="s1">spintercept2 </span><span class="s3">= </span><span class="s1">sag_sparse</span><span class="s3">(</span>
            <span class="s1">X</span><span class="s3">,</span>
            <span class="s1">y_encoded</span><span class="s3">,</span>
            <span class="s1">step_size</span><span class="s3">,</span>
            <span class="s1">alpha</span><span class="s3">,</span>
            <span class="s1">dloss</span><span class="s3">=</span><span class="s1">log_dloss</span><span class="s3">,</span>
            <span class="s1">n_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">,</span>
            <span class="s1">sparse</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
            <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
        <span class="s3">)</span>
        <span class="s1">coef1</span><span class="s3">.</span><span class="s1">append</span><span class="s3">(</span><span class="s1">spweights1</span><span class="s3">)</span>
        <span class="s1">intercept1</span><span class="s3">.</span><span class="s1">append</span><span class="s3">(</span><span class="s1">spintercept1</span><span class="s3">)</span>

        <span class="s1">coef2</span><span class="s3">.</span><span class="s1">append</span><span class="s3">(</span><span class="s1">spweights2</span><span class="s3">)</span>
        <span class="s1">intercept2</span><span class="s3">.</span><span class="s1">append</span><span class="s3">(</span><span class="s1">spintercept2</span><span class="s3">)</span>

    <span class="s1">coef1 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">vstack</span><span class="s3">(</span><span class="s1">coef1</span><span class="s3">)</span>
    <span class="s1">intercept1 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">(</span><span class="s1">intercept1</span><span class="s3">)</span>
    <span class="s1">coef2 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">vstack</span><span class="s3">(</span><span class="s1">coef2</span><span class="s3">)</span>
    <span class="s1">intercept2 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">(</span><span class="s1">intercept2</span><span class="s3">)</span>

    <span class="s2">for </span><span class="s1">i</span><span class="s3">, </span><span class="s1">cl </span><span class="s2">in </span><span class="s1">enumerate</span><span class="s3">(</span><span class="s1">classes</span><span class="s3">):</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">.</span><span class="s1">estimators_</span><span class="s3">[</span><span class="s1">i</span><span class="s3">].</span><span class="s1">coef_</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(), </span><span class="s1">coef1</span><span class="s3">[</span><span class="s1">i</span><span class="s3">], </span><span class="s1">rtol</span><span class="s3">=</span><span class="s4">1e-2</span><span class="s3">)</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">.</span><span class="s1">estimators_</span><span class="s3">[</span><span class="s1">i</span><span class="s3">].</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">intercept1</span><span class="s3">[</span><span class="s1">i</span><span class="s3">], </span><span class="s1">rtol</span><span class="s3">=</span><span class="s4">1e-1</span><span class="s3">)</span>

        <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">clf2</span><span class="s3">.</span><span class="s1">estimators_</span><span class="s3">[</span><span class="s1">i</span><span class="s3">].</span><span class="s1">coef_</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(), </span><span class="s1">coef2</span><span class="s3">[</span><span class="s1">i</span><span class="s3">], </span><span class="s1">rtol</span><span class="s3">=</span><span class="s4">1e-2</span><span class="s3">)</span>
        <span class="s0"># Note the very crude accuracy, i.e. high rtol.</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">clf2</span><span class="s3">.</span><span class="s1">estimators_</span><span class="s3">[</span><span class="s1">i</span><span class="s3">].</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">intercept2</span><span class="s3">[</span><span class="s1">i</span><span class="s3">], </span><span class="s1">rtol</span><span class="s3">=</span><span class="s4">5e-1</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;csr_container&quot;</span><span class="s3">, </span><span class="s1">CSR_CONTAINERS</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_classifier_results</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;tests if classifier results match target&quot;&quot;&quot;</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">0.1</span>
    <span class="s1">n_features </span><span class="s3">= </span><span class="s4">20</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s4">10</span>
    <span class="s1">tol </span><span class="s3">= </span><span class="s4">0.01</span>
    <span class="s1">max_iter </span><span class="s3">= </span><span class="s4">200</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s4">0</span><span class="s3">)</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=(</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">))</span>
    <span class="s1">w </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=</span><span class="s1">n_features</span><span class="s3">)</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">w</span><span class="s3">)</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sign</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf1 </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">(</span>
        <span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;sag&quot;</span><span class="s3">,</span>
        <span class="s1">C</span><span class="s3">=</span><span class="s4">1.0 </span><span class="s3">/ </span><span class="s1">alpha </span><span class="s3">/ </span><span class="s1">n_samples</span><span class="s3">,</span>
        <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">max_iter</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s1">tol</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s4">77</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">clf2 </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">)</span>

    <span class="s1">clf1</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf2</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X</span><span class="s3">), </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">pred1 </span><span class="s3">= </span><span class="s1">clf1</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">pred2 </span><span class="s3">= </span><span class="s1">clf2</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">pred1</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">12</span><span class="s3">)</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">pred2</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">12</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s5">&quot;ignore:The max_iter was reached&quot;</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;csr_container&quot;</span><span class="s3">, </span><span class="s1">CSR_CONTAINERS</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_binary_classifier_class_weight</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;tests binary classifier with classweights for each class&quot;&quot;&quot;</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">0.1</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s4">50</span>
    <span class="s1">n_iter </span><span class="s3">= </span><span class="s4">20</span>
    <span class="s1">tol </span><span class="s3">= </span><span class="s4">0.00001</span>
    <span class="s1">fit_intercept </span><span class="s3">= </span><span class="s2">True</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_blobs</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">centers</span><span class="s3">=</span><span class="s4">2</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">cluster_std</span><span class="s3">=</span><span class="s4">0.1</span><span class="s3">)</span>
    <span class="s1">step_size </span><span class="s3">= </span><span class="s1">get_step_size</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">classification</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s1">classes </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">unique</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">y_tmp </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">)</span>
    <span class="s1">y_tmp</span><span class="s3">[</span><span class="s1">y </span><span class="s3">!= </span><span class="s1">classes</span><span class="s3">[</span><span class="s4">1</span><span class="s3">]] = -</span><span class="s4">1</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">y_tmp</span>

    <span class="s1">class_weight </span><span class="s3">= {</span><span class="s4">1</span><span class="s3">: </span><span class="s4">0.45</span><span class="s3">, -</span><span class="s4">1</span><span class="s3">: </span><span class="s4">0.55</span><span class="s3">}</span>
    <span class="s1">clf1 </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">(</span>
        <span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;sag&quot;</span><span class="s3">,</span>
        <span class="s1">C</span><span class="s3">=</span><span class="s4">1.0 </span><span class="s3">/ </span><span class="s1">alpha </span><span class="s3">/ </span><span class="s1">n_samples</span><span class="s3">,</span>
        <span class="s1">max_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s1">tol</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s4">77</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
        <span class="s1">class_weight</span><span class="s3">=</span><span class="s1">class_weight</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">clf2 </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">)</span>

    <span class="s1">clf1</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">clf2</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">csr_container</span><span class="s3">(</span><span class="s1">X</span><span class="s3">), </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">le </span><span class="s3">= </span><span class="s1">LabelEncoder</span><span class="s3">()</span>
    <span class="s1">class_weight_ </span><span class="s3">= </span><span class="s1">compute_class_weight</span><span class="s3">(</span><span class="s1">class_weight</span><span class="s3">, </span><span class="s1">classes</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">unique</span><span class="s3">(</span><span class="s1">y</span><span class="s3">), </span><span class="s1">y</span><span class="s3">=</span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">class_weight_</span><span class="s3">[</span><span class="s1">le</span><span class="s3">.</span><span class="s1">fit_transform</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)]</span>
    <span class="s1">spweights</span><span class="s3">, </span><span class="s1">spintercept </span><span class="s3">= </span><span class="s1">sag_sparse</span><span class="s3">(</span>
        <span class="s1">X</span><span class="s3">,</span>
        <span class="s1">y</span><span class="s3">,</span>
        <span class="s1">step_size</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">,</span>
        <span class="s1">n_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
        <span class="s1">dloss</span><span class="s3">=</span><span class="s1">log_dloss</span><span class="s3">,</span>
        <span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">spweights2</span><span class="s3">, </span><span class="s1">spintercept2 </span><span class="s3">= </span><span class="s1">sag_sparse</span><span class="s3">(</span>
        <span class="s1">X</span><span class="s3">,</span>
        <span class="s1">y</span><span class="s3">,</span>
        <span class="s1">step_size</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">,</span>
        <span class="s1">n_iter</span><span class="s3">=</span><span class="s1">n_iter</span><span class="s3">,</span>
        <span class="s1">dloss</span><span class="s3">=</span><span class="s1">log_dloss</span><span class="s3">,</span>
        <span class="s1">sparse</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
        <span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">,</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">,</span>
    <span class="s3">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(), </span><span class="s1">spweights</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(), </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">2</span><span class="s3">)</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">clf1</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">spintercept</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">1</span><span class="s3">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">clf2</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(), </span><span class="s1">spweights2</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(), </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">2</span><span class="s3">)</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">clf2</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">spintercept2</span><span class="s3">, </span><span class="s1">decimal</span><span class="s3">=</span><span class="s4">1</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_classifier_single_class</span><span class="s3">():</span>
    <span class="s6">&quot;&quot;&quot;tests if ValueError is thrown with only one class&quot;&quot;&quot;</span>
    <span class="s1">X </span><span class="s3">= [[</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">], [</span><span class="s4">3</span><span class="s3">, </span><span class="s4">4</span><span class="s3">]]</span>
    <span class="s1">y </span><span class="s3">= [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">]</span>

    <span class="s1">msg </span><span class="s3">= </span><span class="s5">&quot;This solver needs samples of at least 2 classes in the data&quot;</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">msg</span><span class="s3">):</span>
        <span class="s1">LogisticRegression</span><span class="s3">(</span><span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;sag&quot;</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_step_size_alpha_error</span><span class="s3">():</span>
    <span class="s1">X </span><span class="s3">= [[</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">], [</span><span class="s4">0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">]]</span>
    <span class="s1">y </span><span class="s3">= [</span><span class="s4">1</span><span class="s3">, -</span><span class="s4">1</span><span class="s3">]</span>
    <span class="s1">fit_intercept </span><span class="s3">= </span><span class="s2">False</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">1.0</span>
    <span class="s1">msg </span><span class="s3">= </span><span class="s1">re</span><span class="s3">.</span><span class="s1">escape</span><span class="s3">(</span>
        <span class="s5">&quot;Current sag implementation does not handle the case&quot;</span>
        <span class="s5">&quot; step_size * alpha_scaled == 1&quot;</span>
    <span class="s3">)</span>

    <span class="s1">clf1 </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">(</span><span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;sag&quot;</span><span class="s3">, </span><span class="s1">C</span><span class="s3">=</span><span class="s4">1.0 </span><span class="s3">/ </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ZeroDivisionError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">msg</span><span class="s3">):</span>
        <span class="s1">clf1</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">clf2 </span><span class="s3">= </span><span class="s1">Ridge</span><span class="s3">(</span><span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;sag&quot;</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ZeroDivisionError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">msg</span><span class="s3">):</span>
        <span class="s1">clf2</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_multinomial_loss</span><span class="s3">():</span>
    <span class="s0"># test if the multinomial loss and gradient computations are consistent</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">.</span><span class="s1">astype</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float64</span><span class="s3">)</span>
    <span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span>
    <span class="s1">n_classes </span><span class="s3">= </span><span class="s1">len</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">unique</span><span class="s3">(</span><span class="s1">y</span><span class="s3">))</span>

    <span class="s1">rng </span><span class="s3">= </span><span class="s1">check_random_state</span><span class="s3">(</span><span class="s4">42</span><span class="s3">)</span>
    <span class="s1">weights </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">, </span><span class="s1">n_classes</span><span class="s3">)</span>
    <span class="s1">intercept </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s1">n_classes</span><span class="s3">)</span>
    <span class="s1">sample_weights </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">abs</span><span class="s3">(</span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">))</span>

    <span class="s0"># compute loss and gradient like in multinomial SAG</span>
    <span class="s1">dataset</span><span class="s3">, </span><span class="s1">_ </span><span class="s3">= </span><span class="s1">make_dataset</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weights</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">42</span><span class="s3">)</span>
    <span class="s1">loss_1</span><span class="s3">, </span><span class="s1">grad_1 </span><span class="s3">= </span><span class="s1">_multinomial_grad_loss_all_samples</span><span class="s3">(</span>
        <span class="s1">dataset</span><span class="s3">, </span><span class="s1">weights</span><span class="s3">, </span><span class="s1">intercept</span><span class="s3">, </span><span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">, </span><span class="s1">n_classes</span>
    <span class="s3">)</span>
    <span class="s0"># compute loss and gradient like in multinomial LogisticRegression</span>
    <span class="s1">loss </span><span class="s3">= </span><span class="s1">LinearModelLoss</span><span class="s3">(</span>
        <span class="s1">base_loss</span><span class="s3">=</span><span class="s1">HalfMultinomialLoss</span><span class="s3">(</span><span class="s1">n_classes</span><span class="s3">=</span><span class="s1">n_classes</span><span class="s3">),</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">weights_intercept </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">vstack</span><span class="s3">((</span><span class="s1">weights</span><span class="s3">, </span><span class="s1">intercept</span><span class="s3">)).</span><span class="s1">T</span>
    <span class="s1">loss_2</span><span class="s3">, </span><span class="s1">grad_2 </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">loss_gradient</span><span class="s3">(</span>
        <span class="s1">weights_intercept</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s4">0.0</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weights</span>
    <span class="s3">)</span>
    <span class="s1">grad_2 </span><span class="s3">= </span><span class="s1">grad_2</span><span class="s3">[:, :-</span><span class="s4">1</span><span class="s3">].</span><span class="s1">T</span>
    <span class="s0"># convert to same convention, i.e. LinearModelLoss uses average(loss, weight=sw)</span>
    <span class="s1">loss_2 </span><span class="s3">*= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">sample_weights</span><span class="s3">)</span>
    <span class="s1">grad_2 </span><span class="s3">*= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">sample_weights</span><span class="s3">)</span>

    <span class="s0"># comparison</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">grad_1</span><span class="s3">, </span><span class="s1">grad_2</span><span class="s3">)</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">loss_1</span><span class="s3">, </span><span class="s1">loss_2</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_multinomial_loss_ground_truth</span><span class="s3">():</span>
    <span class="s0"># n_samples, n_features, n_classes = 4, 2, 3</span>
    <span class="s1">n_classes </span><span class="s3">= </span><span class="s4">3</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[</span><span class="s4">1.1</span><span class="s3">, </span><span class="s4">2.2</span><span class="s3">], [</span><span class="s4">2.2</span><span class="s3">, -</span><span class="s4">4.4</span><span class="s3">], [</span><span class="s4">3.3</span><span class="s3">, -</span><span class="s4">2.2</span><span class="s3">], [</span><span class="s4">1.1</span><span class="s3">, </span><span class="s4">1.1</span><span class="s3">]])</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">0</span><span class="s3">], </span><span class="s1">dtype</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">float64</span><span class="s3">)</span>
    <span class="s1">lbin </span><span class="s3">= </span><span class="s1">LabelBinarizer</span><span class="s3">()</span>
    <span class="s1">Y_bin </span><span class="s3">= </span><span class="s1">lbin</span><span class="s3">.</span><span class="s1">fit_transform</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">weights </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([[</span><span class="s4">0.1</span><span class="s3">, </span><span class="s4">0.2</span><span class="s3">, </span><span class="s4">0.3</span><span class="s3">], [</span><span class="s4">1.1</span><span class="s3">, </span><span class="s4">1.2</span><span class="s3">, -</span><span class="s4">1.3</span><span class="s3">]])</span>
    <span class="s1">intercept </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">1.0</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, -</span><span class="s4">0.2</span><span class="s3">])</span>
    <span class="s1">sample_weights </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0.8</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">0.8</span><span class="s3">])</span>

    <span class="s1">prediction </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">weights</span><span class="s3">) + </span><span class="s1">intercept</span>
    <span class="s1">logsumexp_prediction </span><span class="s3">= </span><span class="s1">logsumexp</span><span class="s3">(</span><span class="s1">prediction</span><span class="s3">, </span><span class="s1">axis</span><span class="s3">=</span><span class="s4">1</span><span class="s3">)</span>
    <span class="s1">p </span><span class="s3">= </span><span class="s1">prediction </span><span class="s3">- </span><span class="s1">logsumexp_prediction</span><span class="s3">[:, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">newaxis</span><span class="s3">]</span>
    <span class="s1">loss_1 </span><span class="s3">= -(</span><span class="s1">sample_weights</span><span class="s3">[:, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">newaxis</span><span class="s3">] * </span><span class="s1">p </span><span class="s3">* </span><span class="s1">Y_bin</span><span class="s3">).</span><span class="s1">sum</span><span class="s3">()</span>
    <span class="s1">diff </span><span class="s3">= </span><span class="s1">sample_weights</span><span class="s3">[:, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">newaxis</span><span class="s3">] * (</span><span class="s1">np</span><span class="s3">.</span><span class="s1">exp</span><span class="s3">(</span><span class="s1">p</span><span class="s3">) - </span><span class="s1">Y_bin</span><span class="s3">)</span>
    <span class="s1">grad_1 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">X</span><span class="s3">.</span><span class="s1">T</span><span class="s3">, </span><span class="s1">diff</span><span class="s3">)</span>

    <span class="s1">loss </span><span class="s3">= </span><span class="s1">LinearModelLoss</span><span class="s3">(</span>
        <span class="s1">base_loss</span><span class="s3">=</span><span class="s1">HalfMultinomialLoss</span><span class="s3">(</span><span class="s1">n_classes</span><span class="s3">=</span><span class="s1">n_classes</span><span class="s3">),</span>
        <span class="s1">fit_intercept</span><span class="s3">=</span><span class="s2">True</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">weights_intercept </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">vstack</span><span class="s3">((</span><span class="s1">weights</span><span class="s3">, </span><span class="s1">intercept</span><span class="s3">)).</span><span class="s1">T</span>
    <span class="s1">loss_2</span><span class="s3">, </span><span class="s1">grad_2 </span><span class="s3">= </span><span class="s1">loss</span><span class="s3">.</span><span class="s1">loss_gradient</span><span class="s3">(</span>
        <span class="s1">weights_intercept</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">l2_reg_strength</span><span class="s3">=</span><span class="s4">0.0</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weights</span>
    <span class="s3">)</span>
    <span class="s1">grad_2 </span><span class="s3">= </span><span class="s1">grad_2</span><span class="s3">[:, :-</span><span class="s4">1</span><span class="s3">].</span><span class="s1">T</span>
    <span class="s0"># convert to same convention, i.e. LinearModelLoss uses average(loss, weight=sw)</span>
    <span class="s1">loss_2 </span><span class="s3">*= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">sample_weights</span><span class="s3">)</span>
    <span class="s1">grad_2 </span><span class="s3">*= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">sample_weights</span><span class="s3">)</span>

    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">loss_1</span><span class="s3">, </span><span class="s1">loss_2</span><span class="s3">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">grad_1</span><span class="s3">, </span><span class="s1">grad_2</span><span class="s3">)</span>

    <span class="s0"># ground truth</span>
    <span class="s1">loss_gt </span><span class="s3">= </span><span class="s4">11.680360354325961</span>
    <span class="s1">grad_gt </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">(</span>
        <span class="s3">[[-</span><span class="s4">0.557487</span><span class="s3">, -</span><span class="s4">1.619151</span><span class="s3">, +</span><span class="s4">2.176638</span><span class="s3">], [-</span><span class="s4">0.903942</span><span class="s3">, +</span><span class="s4">5.258745</span><span class="s3">, -</span><span class="s4">4.354803</span><span class="s3">]]</span>
    <span class="s3">)</span>
    <span class="s1">assert_almost_equal</span><span class="s3">(</span><span class="s1">loss_1</span><span class="s3">, </span><span class="s1">loss_gt</span><span class="s3">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">grad_1</span><span class="s3">, </span><span class="s1">grad_gt</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;solver&quot;</span><span class="s3">, [</span><span class="s5">&quot;sag&quot;</span><span class="s3">, </span><span class="s5">&quot;saga&quot;</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_sag_classifier_raises_error</span><span class="s3">(</span><span class="s1">solver</span><span class="s3">):</span>
    <span class="s0"># Following #13316, the error handling behavior changed in cython sag. This</span>
    <span class="s0"># is simply a non-regression test to make sure numerical errors are</span>
    <span class="s0"># properly raised.</span>

    <span class="s0"># Train a classifier on a simple problem</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s4">42</span><span class="s3">)</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_classification</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s1">rng</span><span class="s3">)</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">LogisticRegression</span><span class="s3">(</span><span class="s1">solver</span><span class="s3">=</span><span class="s1">solver</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s1">rng</span><span class="s3">, </span><span class="s1">warm_start</span><span class="s3">=</span><span class="s2">True</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s0"># Trigger a numerical error by:</span>
    <span class="s0"># - corrupting the fitted coefficients of the classifier</span>
    <span class="s0"># - fit it again starting from its current state thanks to warm_start</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">[:] = </span><span class="s1">np</span><span class="s3">.</span><span class="s1">nan</span>

    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s5">&quot;Floating-point under-/overflow&quot;</span><span class="s3">):</span>
        <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
</pre>
</body>
</html>