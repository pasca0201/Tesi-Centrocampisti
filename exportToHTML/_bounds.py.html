<html>
<head>
<title>_bounds.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_bounds.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Determination of parameter bounds&quot;&quot;&quot;</span>

<span class="s2"># Author: Paolo Losi</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">from </span><span class="s1">numbers </span><span class="s3">import </span><span class="s1">Real</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>

<span class="s3">from </span><span class="s4">..</span><span class="s1">preprocessing </span><span class="s3">import </span><span class="s1">LabelBinarizer</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_param_validation </span><span class="s3">import </span><span class="s1">Interval</span><span class="s4">, </span><span class="s1">StrOptions</span><span class="s4">, </span><span class="s1">validate_params</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">extmath </span><span class="s3">import </span><span class="s1">safe_sparse_dot</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">validation </span><span class="s3">import </span><span class="s1">check_array</span><span class="s4">, </span><span class="s1">check_consistent_length</span>


<span class="s4">@</span><span class="s1">validate_params</span><span class="s4">(</span>
    <span class="s4">{</span>
        <span class="s5">&quot;X&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">, </span><span class="s5">&quot;sparse matrix&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;y&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;loss&quot;</span><span class="s4">: [</span><span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;squared_hinge&quot;</span><span class="s4">, </span><span class="s5">&quot;log&quot;</span><span class="s4">})],</span>
        <span class="s5">&quot;fit_intercept&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;intercept_scaling&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;neither&quot;</span><span class="s4">)],</span>
    <span class="s4">},</span>
    <span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">def </span><span class="s1">l1_min_c</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, *, </span><span class="s1">loss</span><span class="s4">=</span><span class="s5">&quot;squared_hinge&quot;</span><span class="s4">, </span><span class="s1">fit_intercept</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">intercept_scaling</span><span class="s4">=</span><span class="s6">1.0</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Return the lowest bound for C. 
 
    The lower bound for C is computed such that for C in (l1_min_C, infinity) 
    the model is guaranteed not to be empty. This applies to l1 penalized 
    classifiers, such as LinearSVC with penalty='l1' and 
    linear_model.LogisticRegression with penalty='l1'. 
 
    This value is valid if class_weight parameter in fit() is not set. 
 
    Parameters 
    ---------- 
    X : {array-like, sparse matrix} of shape (n_samples, n_features) 
        Training vector, where `n_samples` is the number of samples and 
        `n_features` is the number of features. 
 
    y : array-like of shape (n_samples,) 
        Target vector relative to X. 
 
    loss : {'squared_hinge', 'log'}, default='squared_hinge' 
        Specifies the loss function. 
        With 'squared_hinge' it is the squared hinge loss (a.k.a. L2 loss). 
        With 'log' it is the loss of logistic regression models. 
 
    fit_intercept : bool, default=True 
        Specifies if the intercept should be fitted by the model. 
        It must match the fit() method parameter. 
 
    intercept_scaling : float, default=1.0 
        When fit_intercept is True, instance vector x becomes 
        [x, intercept_scaling], 
        i.e. a &quot;synthetic&quot; feature with constant value equals to 
        intercept_scaling is appended to the instance vector. 
        It must match the fit() method parameter. 
 
    Returns 
    ------- 
    l1_min_c : float 
        Minimum value for C. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.svm import l1_min_c 
    &gt;&gt;&gt; from sklearn.datasets import make_classification 
    &gt;&gt;&gt; X, y = make_classification(n_samples=100, n_features=20, random_state=42) 
    &gt;&gt;&gt; print(f&quot;{l1_min_c(X, y, loss='squared_hinge', fit_intercept=True):.4f}&quot;) 
    0.0044 
    &quot;&quot;&quot;</span>

    <span class="s1">X </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">accept_sparse</span><span class="s4">=</span><span class="s5">&quot;csc&quot;</span><span class="s4">)</span>
    <span class="s1">check_consistent_length</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

    <span class="s1">Y </span><span class="s4">= </span><span class="s1">LabelBinarizer</span><span class="s4">(</span><span class="s1">neg_label</span><span class="s4">=-</span><span class="s6">1</span><span class="s4">).</span><span class="s1">fit_transform</span><span class="s4">(</span><span class="s1">y</span><span class="s4">).</span><span class="s1">T</span>
    <span class="s2"># maximum absolute value over classes and features</span>
    <span class="s1">den </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">max</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">abs</span><span class="s4">(</span><span class="s1">safe_sparse_dot</span><span class="s4">(</span><span class="s1">Y</span><span class="s4">, </span><span class="s1">X</span><span class="s4">)))</span>
    <span class="s3">if </span><span class="s1">fit_intercept</span><span class="s4">:</span>
        <span class="s1">bias </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">full</span><span class="s4">(</span>
            <span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">size</span><span class="s4">(</span><span class="s1">y</span><span class="s4">), </span><span class="s6">1</span><span class="s4">), </span><span class="s1">intercept_scaling</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span><span class="s1">intercept_scaling</span><span class="s4">).</span><span class="s1">dtype</span>
        <span class="s4">)</span>
        <span class="s1">den </span><span class="s4">= </span><span class="s1">max</span><span class="s4">(</span><span class="s1">den</span><span class="s4">, </span><span class="s1">abs</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">dot</span><span class="s4">(</span><span class="s1">Y</span><span class="s4">, </span><span class="s1">bias</span><span class="s4">)).</span><span class="s1">max</span><span class="s4">())</span>

    <span class="s3">if </span><span class="s1">den </span><span class="s4">== </span><span class="s6">0.0</span><span class="s4">:</span>
        <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
            <span class="s5">&quot;Ill-posed l1_min_c calculation: l1 will always &quot;</span>
            <span class="s5">&quot;select zero coefficients for this data&quot;</span>
        <span class="s4">)</span>
    <span class="s3">if </span><span class="s1">loss </span><span class="s4">== </span><span class="s5">&quot;squared_hinge&quot;</span><span class="s4">:</span>
        <span class="s3">return </span><span class="s6">0.5 </span><span class="s4">/ </span><span class="s1">den</span>
    <span class="s3">else</span><span class="s4">:  </span><span class="s2"># loss == 'log':</span>
        <span class="s3">return </span><span class="s6">2.0 </span><span class="s4">/ </span><span class="s1">den</span>
</pre>
</body>
</html>