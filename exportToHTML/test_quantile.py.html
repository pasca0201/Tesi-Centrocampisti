<html>
<head>
<title>test_quantile.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #7a7e85;}
.s1 { color: #bcbec4;}
.s2 { color: #cf8e6d;}
.s3 { color: #bcbec4;}
.s4 { color: #2aacb8;}
.s5 { color: #6aab73;}
.s6 { color: #5f826b; font-style: italic;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_quantile.py</font>
</center></td></tr></table>
<pre><span class="s0"># Authors: David Dale &lt;dale.david@mail.ru&gt;</span>
<span class="s0">#          Christian Lorentzen &lt;lorentzen.ch@gmail.com&gt;</span>
<span class="s0"># License: BSD 3 clause</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pytest</span>
<span class="s2">from </span><span class="s1">pytest </span><span class="s2">import </span><span class="s1">approx</span>
<span class="s2">from </span><span class="s1">scipy</span><span class="s3">.</span><span class="s1">optimize </span><span class="s2">import </span><span class="s1">minimize</span>

<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">datasets </span><span class="s2">import </span><span class="s1">make_regression</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">exceptions </span><span class="s2">import </span><span class="s1">ConvergenceWarning</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">linear_model </span><span class="s2">import </span><span class="s1">HuberRegressor</span><span class="s3">, </span><span class="s1">QuantileRegressor</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">metrics </span><span class="s2">import </span><span class="s1">mean_pinball_loss</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">_testing </span><span class="s2">import </span><span class="s1">assert_allclose</span><span class="s3">, </span><span class="s1">skip_if_32bit</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">fixes </span><span class="s2">import </span><span class="s3">(</span>
    <span class="s1">COO_CONTAINERS</span><span class="s3">,</span>
    <span class="s1">CSC_CONTAINERS</span><span class="s3">,</span>
    <span class="s1">CSR_CONTAINERS</span><span class="s3">,</span>
    <span class="s1">parse_version</span><span class="s3">,</span>
    <span class="s1">sp_version</span><span class="s3">,</span>
<span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">fixture</span>
<span class="s2">def </span><span class="s1">X_y_data</span><span class="s3">():</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_regression</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s4">10</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">noise</span><span class="s3">=</span><span class="s4">1</span><span class="s3">)</span>
    <span class="s2">return </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">fixture</span>
<span class="s2">def </span><span class="s1">default_solver</span><span class="s3">():</span>
    <span class="s2">return </span><span class="s5">&quot;highs&quot; </span><span class="s2">if </span><span class="s1">sp_version </span><span class="s3">&gt;= </span><span class="s1">parse_version</span><span class="s3">(</span><span class="s5">&quot;1.6.0&quot;</span><span class="s3">) </span><span class="s2">else </span><span class="s5">&quot;interior-point&quot;</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">skipif</span><span class="s3">(</span>
    <span class="s1">parse_version</span><span class="s3">(</span><span class="s1">sp_version</span><span class="s3">.</span><span class="s1">base_version</span><span class="s3">) &gt;= </span><span class="s1">parse_version</span><span class="s3">(</span><span class="s5">&quot;1.11&quot;</span><span class="s3">),</span>
    <span class="s1">reason</span><span class="s3">=</span><span class="s5">&quot;interior-point solver is not available in SciPy 1.11&quot;</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;solver&quot;</span><span class="s3">, [</span><span class="s5">&quot;interior-point&quot;</span><span class="s3">, </span><span class="s5">&quot;revised simplex&quot;</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;csc_container&quot;</span><span class="s3">, </span><span class="s1">CSC_CONTAINERS</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_incompatible_solver_for_sparse_input</span><span class="s3">(</span><span class="s1">X_y_data</span><span class="s3">, </span><span class="s1">solver</span><span class="s3">, </span><span class="s1">csc_container</span><span class="s3">):</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">X_y_data</span>
    <span class="s1">X_sparse </span><span class="s3">= </span><span class="s1">csc_container</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">err_msg </span><span class="s3">= (</span>
        <span class="s5">f&quot;Solver </span><span class="s2">{</span><span class="s1">solver</span><span class="s2">} </span><span class="s5">does not support sparse X. Use solver 'highs' for example.&quot;</span>
    <span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">err_msg</span><span class="s3">):</span>
        <span class="s1">QuantileRegressor</span><span class="s3">(</span><span class="s1">solver</span><span class="s3">=</span><span class="s1">solver</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_sparse</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;solver&quot;</span><span class="s3">, (</span><span class="s5">&quot;highs-ds&quot;</span><span class="s3">, </span><span class="s5">&quot;highs-ipm&quot;</span><span class="s3">, </span><span class="s5">&quot;highs&quot;</span><span class="s3">))</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">skipif</span><span class="s3">(</span>
    <span class="s1">sp_version </span><span class="s3">&gt;= </span><span class="s1">parse_version</span><span class="s3">(</span><span class="s5">&quot;1.6.0&quot;</span><span class="s3">),</span>
    <span class="s1">reason</span><span class="s3">=</span><span class="s5">&quot;Solvers are available as of scipy 1.6.0&quot;</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_too_new_solver_methods_raise_error</span><span class="s3">(</span><span class="s1">X_y_data</span><span class="s3">, </span><span class="s1">solver</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Test that highs solver raises for scipy&lt;1.6.0.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">X_y_data</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s5">&quot;scipy&gt;=1.6.0&quot;</span><span class="s3">):</span>
        <span class="s1">QuantileRegressor</span><span class="s3">(</span><span class="s1">solver</span><span class="s3">=</span><span class="s1">solver</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s5">&quot;quantile, alpha, intercept, coef&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s0"># for 50% quantile w/o regularization, any slope in [1, 10] is okay</span>
        <span class="s3">[</span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s2">None</span><span class="s3">],</span>
        <span class="s0"># if positive error costs more, the slope is maximal</span>
        <span class="s3">[</span><span class="s4">0.51</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">10</span><span class="s3">],</span>
        <span class="s0"># if negative error costs more, the slope is minimal</span>
        <span class="s3">[</span><span class="s4">0.49</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">],</span>
        <span class="s0"># for a small lasso penalty, the slope is also minimal</span>
        <span class="s3">[</span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">0.01</span><span class="s3">, </span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">],</span>
        <span class="s0"># for a large lasso penalty, the model predicts the constant median</span>
        <span class="s3">[</span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">100</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">0</span><span class="s3">],</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_quantile_toy_example</span><span class="s3">(</span><span class="s1">quantile</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">intercept</span><span class="s3">, </span><span class="s1">coef</span><span class="s3">, </span><span class="s1">default_solver</span><span class="s3">):</span>
    <span class="s0"># test how different parameters affect a small intuitive example</span>
    <span class="s1">X </span><span class="s3">= [[</span><span class="s4">0</span><span class="s3">], [</span><span class="s4">1</span><span class="s3">], [</span><span class="s4">1</span><span class="s3">]]</span>
    <span class="s1">y </span><span class="s3">= [</span><span class="s4">1</span><span class="s3">, </span><span class="s4">2</span><span class="s3">, </span><span class="s4">11</span><span class="s3">]</span>
    <span class="s1">model </span><span class="s3">= </span><span class="s1">QuantileRegressor</span><span class="s3">(</span>
        <span class="s1">quantile</span><span class="s3">=</span><span class="s1">quantile</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">solver</span><span class="s3">=</span><span class="s1">default_solver</span>
    <span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">model</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">intercept</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s4">1e-2</span><span class="s3">)</span>
    <span class="s2">if </span><span class="s1">coef </span><span class="s2">is not None</span><span class="s3">:</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">model</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">[</span><span class="s4">0</span><span class="s3">], </span><span class="s1">coef</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s4">1e-2</span><span class="s3">)</span>
    <span class="s2">if </span><span class="s1">alpha </span><span class="s3">&lt; </span><span class="s4">100</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">model</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">[</span><span class="s4">0</span><span class="s3">] &gt;= </span><span class="s4">1</span>
    <span class="s2">assert </span><span class="s1">model</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">[</span><span class="s4">0</span><span class="s3">] &lt;= </span><span class="s4">10</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;fit_intercept&quot;</span><span class="s3">, [</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_quantile_equals_huber_for_low_epsilon</span><span class="s3">(</span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">default_solver</span><span class="s3">):</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_regression</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s4">100</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">20</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">noise</span><span class="s3">=</span><span class="s4">1.0</span><span class="s3">)</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">1e-4</span>
    <span class="s1">huber </span><span class="s3">= </span><span class="s1">HuberRegressor</span><span class="s3">(</span>
        <span class="s1">epsilon</span><span class="s3">=</span><span class="s4">1 </span><span class="s3">+ </span><span class="s4">1e-4</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span>
    <span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">quant </span><span class="s3">= </span><span class="s1">QuantileRegressor</span><span class="s3">(</span>
        <span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">solver</span><span class="s3">=</span><span class="s1">default_solver</span>
    <span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">huber</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">quant</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s4">1e-1</span><span class="s3">)</span>
    <span class="s2">if </span><span class="s1">fit_intercept</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">huber</span><span class="s3">.</span><span class="s1">intercept_ </span><span class="s3">== </span><span class="s1">approx</span><span class="s3">(</span><span class="s1">quant</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">abs</span><span class="s3">=</span><span class="s4">1e-1</span><span class="s3">)</span>
        <span class="s0"># check that we still predict fraction</span>
        <span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">y </span><span class="s3">&lt; </span><span class="s1">quant</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)) == </span><span class="s1">approx</span><span class="s3">(</span><span class="s4">0.5</span><span class="s3">, </span><span class="s1">abs</span><span class="s3">=</span><span class="s4">1e-1</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;q&quot;</span><span class="s3">, [</span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">0.9</span><span class="s3">, </span><span class="s4">0.05</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_quantile_estimates_calibration</span><span class="s3">(</span><span class="s1">q</span><span class="s3">, </span><span class="s1">default_solver</span><span class="s3">):</span>
    <span class="s0"># Test that model estimates percentage of points below the prediction</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_regression</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s4">1000</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">20</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">noise</span><span class="s3">=</span><span class="s4">1.0</span><span class="s3">)</span>
    <span class="s1">quant </span><span class="s3">= </span><span class="s1">QuantileRegressor</span><span class="s3">(</span>
        <span class="s1">quantile</span><span class="s3">=</span><span class="s1">q</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">=</span><span class="s4">0</span><span class="s3">,</span>
        <span class="s1">solver</span><span class="s3">=</span><span class="s1">default_solver</span><span class="s3">,</span>
    <span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">y </span><span class="s3">&lt; </span><span class="s1">quant</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)) == </span><span class="s1">approx</span><span class="s3">(</span><span class="s1">q</span><span class="s3">, </span><span class="s1">abs</span><span class="s3">=</span><span class="s4">1e-2</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_quantile_sample_weight</span><span class="s3">(</span><span class="s1">default_solver</span><span class="s3">):</span>
    <span class="s0"># test that with unequal sample weights we still estimate weighted fraction</span>
    <span class="s1">n </span><span class="s3">= </span><span class="s4">1000</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_regression</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s1">n</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">5</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">noise</span><span class="s3">=</span><span class="s4">10.0</span><span class="s3">)</span>
    <span class="s1">weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">(</span><span class="s1">n</span><span class="s3">)</span>
    <span class="s0"># when we increase weight of upper observations,</span>
    <span class="s0"># estimate of quantile should go up</span>
    <span class="s1">weight</span><span class="s3">[</span><span class="s1">y </span><span class="s3">&gt; </span><span class="s1">y</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">()] = </span><span class="s4">100</span>
    <span class="s1">quant </span><span class="s3">= </span><span class="s1">QuantileRegressor</span><span class="s3">(</span><span class="s1">quantile</span><span class="s3">=</span><span class="s4">0.5</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">=</span><span class="s4">1e-8</span><span class="s3">, </span><span class="s1">solver</span><span class="s3">=</span><span class="s1">default_solver</span><span class="s3">)</span>
    <span class="s1">quant</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">weight</span><span class="s3">)</span>
    <span class="s1">fraction_below </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">y </span><span class="s3">&lt; </span><span class="s1">quant</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X</span><span class="s3">))</span>
    <span class="s2">assert </span><span class="s1">fraction_below </span><span class="s3">&gt; </span><span class="s4">0.5</span>
    <span class="s1">weighted_fraction_below </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">average</span><span class="s3">(</span><span class="s1">y </span><span class="s3">&lt; </span><span class="s1">quant</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X</span><span class="s3">), </span><span class="s1">weights</span><span class="s3">=</span><span class="s1">weight</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">weighted_fraction_below </span><span class="s3">== </span><span class="s1">approx</span><span class="s3">(</span><span class="s4">0.5</span><span class="s3">, </span><span class="s1">abs</span><span class="s3">=</span><span class="s4">3e-2</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">skipif</span><span class="s3">(</span>
    <span class="s1">sp_version </span><span class="s3">&lt; </span><span class="s1">parse_version</span><span class="s3">(</span><span class="s5">&quot;1.6.0&quot;</span><span class="s3">),</span>
    <span class="s1">reason</span><span class="s3">=</span><span class="s5">&quot;The `highs` solver is available from the 1.6.0 scipy version&quot;</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;quantile&quot;</span><span class="s3">, [</span><span class="s4">0.2</span><span class="s3">, </span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">0.8</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_asymmetric_error</span><span class="s3">(</span><span class="s1">quantile</span><span class="s3">, </span><span class="s1">default_solver</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Test quantile regression for asymmetric distributed targets.&quot;&quot;&quot;</span>
    <span class="s1">n_samples </span><span class="s3">= </span><span class="s4">1000</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s4">42</span><span class="s3">)</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">concatenate</span><span class="s3">(</span>
        <span class="s3">(</span>
            <span class="s1">np</span><span class="s3">.</span><span class="s1">abs</span><span class="s3">(</span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">)[:, </span><span class="s2">None</span><span class="s3">]),</span>
            <span class="s3">-</span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randint</span><span class="s3">(</span><span class="s4">2</span><span class="s3">, </span><span class="s1">size</span><span class="s3">=(</span><span class="s1">n_samples</span><span class="s3">, </span><span class="s4">1</span><span class="s3">)),</span>
        <span class="s3">),</span>
        <span class="s1">axis</span><span class="s3">=</span><span class="s4">1</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s1">intercept </span><span class="s3">= </span><span class="s4">1.23</span>
    <span class="s1">coef </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">([</span><span class="s4">0.5</span><span class="s3">, -</span><span class="s4">2</span><span class="s3">])</span>
    <span class="s0">#  Take care that X @ coef + intercept &gt; 0</span>
    <span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">min</span><span class="s3">(</span><span class="s1">X </span><span class="s3">@ </span><span class="s1">coef </span><span class="s3">+ </span><span class="s1">intercept</span><span class="s3">) &gt; </span><span class="s4">0</span>
    <span class="s0"># For an exponential distribution with rate lambda, e.g. exp(-lambda * x),</span>
    <span class="s0"># the quantile at level q is:</span>
    <span class="s0">#   quantile(q) = - log(1 - q) / lambda</span>
    <span class="s0">#   scale = 1/lambda = -quantile(q) / log(1 - q)</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">exponential</span><span class="s3">(</span>
        <span class="s1">scale</span><span class="s3">=-(</span><span class="s1">X </span><span class="s3">@ </span><span class="s1">coef </span><span class="s3">+ </span><span class="s1">intercept</span><span class="s3">) / </span><span class="s1">np</span><span class="s3">.</span><span class="s1">log</span><span class="s3">(</span><span class="s4">1 </span><span class="s3">- </span><span class="s1">quantile</span><span class="s3">), </span><span class="s1">size</span><span class="s3">=</span><span class="s1">n_samples</span>
    <span class="s3">)</span>
    <span class="s1">model </span><span class="s3">= </span><span class="s1">QuantileRegressor</span><span class="s3">(</span>
        <span class="s1">quantile</span><span class="s3">=</span><span class="s1">quantile</span><span class="s3">,</span>
        <span class="s1">alpha</span><span class="s3">=</span><span class="s4">0</span><span class="s3">,</span>
        <span class="s1">solver</span><span class="s3">=</span><span class="s1">default_solver</span><span class="s3">,</span>
    <span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s0"># This test can be made to pass with any solver but in the interest</span>
    <span class="s0"># of sparing continuous integration resources, the test is performed</span>
    <span class="s0"># with the fastest solver only.</span>

    <span class="s2">assert </span><span class="s1">model</span><span class="s3">.</span><span class="s1">intercept_ </span><span class="s3">== </span><span class="s1">approx</span><span class="s3">(</span><span class="s1">intercept</span><span class="s3">, </span><span class="s1">rel</span><span class="s3">=</span><span class="s4">0.2</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">model</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">coef</span><span class="s3">, </span><span class="s1">rtol</span><span class="s3">=</span><span class="s4">0.6</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">model</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X</span><span class="s3">) &gt; </span><span class="s1">y</span><span class="s3">), </span><span class="s1">quantile</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s4">1e-2</span><span class="s3">)</span>

    <span class="s0"># Now compare to Nelder-Mead optimization with L1 penalty</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">0.01</span>
    <span class="s1">model</span><span class="s3">.</span><span class="s1">set_params</span><span class="s3">(</span><span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">model_coef </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">r_</span><span class="s3">[</span><span class="s1">model</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">model</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">]</span>

    <span class="s2">def </span><span class="s1">func</span><span class="s3">(</span><span class="s1">coef</span><span class="s3">):</span>
        <span class="s1">loss </span><span class="s3">= </span><span class="s1">mean_pinball_loss</span><span class="s3">(</span><span class="s1">y</span><span class="s3">, </span><span class="s1">X </span><span class="s3">@ </span><span class="s1">coef</span><span class="s3">[</span><span class="s4">1</span><span class="s3">:] + </span><span class="s1">coef</span><span class="s3">[</span><span class="s4">0</span><span class="s3">], </span><span class="s1">alpha</span><span class="s3">=</span><span class="s1">quantile</span><span class="s3">)</span>
        <span class="s1">L1 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">abs</span><span class="s3">(</span><span class="s1">coef</span><span class="s3">[</span><span class="s4">1</span><span class="s3">:]))</span>
        <span class="s2">return </span><span class="s1">loss </span><span class="s3">+ </span><span class="s1">alpha </span><span class="s3">* </span><span class="s1">L1</span>

    <span class="s1">res </span><span class="s3">= </span><span class="s1">minimize</span><span class="s3">(</span>
        <span class="s1">fun</span><span class="s3">=</span><span class="s1">func</span><span class="s3">,</span>
        <span class="s1">x0</span><span class="s3">=[</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s3">, -</span><span class="s4">1</span><span class="s3">],</span>
        <span class="s1">method</span><span class="s3">=</span><span class="s5">&quot;Nelder-Mead&quot;</span><span class="s3">,</span>
        <span class="s1">tol</span><span class="s3">=</span><span class="s4">1e-12</span><span class="s3">,</span>
        <span class="s1">options</span><span class="s3">={</span><span class="s5">&quot;maxiter&quot;</span><span class="s3">: </span><span class="s4">2000</span><span class="s3">},</span>
    <span class="s3">)</span>

    <span class="s2">assert </span><span class="s1">func</span><span class="s3">(</span><span class="s1">model_coef</span><span class="s3">) == </span><span class="s1">approx</span><span class="s3">(</span><span class="s1">func</span><span class="s3">(</span><span class="s1">res</span><span class="s3">.</span><span class="s1">x</span><span class="s3">))</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">model</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">res</span><span class="s3">.</span><span class="s1">x</span><span class="s3">[</span><span class="s4">0</span><span class="s3">])</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">model</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">res</span><span class="s3">.</span><span class="s1">x</span><span class="s3">[</span><span class="s4">1</span><span class="s3">:])</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">model</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X</span><span class="s3">) &gt; </span><span class="s1">y</span><span class="s3">), </span><span class="s1">quantile</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s4">1e-2</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;quantile&quot;</span><span class="s3">, [</span><span class="s4">0.2</span><span class="s3">, </span><span class="s4">0.5</span><span class="s3">, </span><span class="s4">0.8</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_equivariance</span><span class="s3">(</span><span class="s1">quantile</span><span class="s3">, </span><span class="s1">default_solver</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Test equivariace of quantile regression. 
 
    See Koenker (2005) Quantile Regression, Chapter 2.2.3. 
    &quot;&quot;&quot;</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s4">42</span><span class="s3">)</span>
    <span class="s1">n_samples</span><span class="s3">, </span><span class="s1">n_features </span><span class="s3">= </span><span class="s4">100</span><span class="s3">, </span><span class="s4">5</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_regression</span><span class="s3">(</span>
        <span class="s1">n_samples</span><span class="s3">=</span><span class="s1">n_samples</span><span class="s3">,</span>
        <span class="s1">n_features</span><span class="s3">=</span><span class="s1">n_features</span><span class="s3">,</span>
        <span class="s1">n_informative</span><span class="s3">=</span><span class="s1">n_features</span><span class="s3">,</span>
        <span class="s1">noise</span><span class="s3">=</span><span class="s4">0</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s1">rng</span><span class="s3">,</span>
        <span class="s1">shuffle</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
    <span class="s3">)</span>
    <span class="s0"># make y asymmetric</span>
    <span class="s1">y </span><span class="s3">+= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">exponential</span><span class="s3">(</span><span class="s1">scale</span><span class="s3">=</span><span class="s4">100</span><span class="s3">, </span><span class="s1">size</span><span class="s3">=</span><span class="s1">y</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">)</span>
    <span class="s1">params </span><span class="s3">= </span><span class="s1">dict</span><span class="s3">(</span><span class="s1">alpha</span><span class="s3">=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">solver</span><span class="s3">=</span><span class="s1">default_solver</span><span class="s3">)</span>
    <span class="s1">model1 </span><span class="s3">= </span><span class="s1">QuantileRegressor</span><span class="s3">(</span><span class="s1">quantile</span><span class="s3">=</span><span class="s1">quantile</span><span class="s3">, **</span><span class="s1">params</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s0"># coef(q; a*y, X) = a * coef(q; y, X)</span>
    <span class="s1">a </span><span class="s3">= </span><span class="s4">2.5</span>
    <span class="s1">model2 </span><span class="s3">= </span><span class="s1">QuantileRegressor</span><span class="s3">(</span><span class="s1">quantile</span><span class="s3">=</span><span class="s1">quantile</span><span class="s3">, **</span><span class="s1">params</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">a </span><span class="s3">* </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">model2</span><span class="s3">.</span><span class="s1">intercept_ </span><span class="s3">== </span><span class="s1">approx</span><span class="s3">(</span><span class="s1">a </span><span class="s3">* </span><span class="s1">model1</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">rel</span><span class="s3">=</span><span class="s4">1e-5</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">model2</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">a </span><span class="s3">* </span><span class="s1">model1</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">rtol</span><span class="s3">=</span><span class="s4">1e-5</span><span class="s3">)</span>

    <span class="s0"># coef(1-q; -a*y, X) = -a * coef(q; y, X)</span>
    <span class="s1">model2 </span><span class="s3">= </span><span class="s1">QuantileRegressor</span><span class="s3">(</span><span class="s1">quantile</span><span class="s3">=</span><span class="s4">1 </span><span class="s3">- </span><span class="s1">quantile</span><span class="s3">, **</span><span class="s1">params</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, -</span><span class="s1">a </span><span class="s3">* </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">model2</span><span class="s3">.</span><span class="s1">intercept_ </span><span class="s3">== </span><span class="s1">approx</span><span class="s3">(-</span><span class="s1">a </span><span class="s3">* </span><span class="s1">model1</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">rel</span><span class="s3">=</span><span class="s4">1e-5</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">model2</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, -</span><span class="s1">a </span><span class="s3">* </span><span class="s1">model1</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">rtol</span><span class="s3">=</span><span class="s4">1e-5</span><span class="s3">)</span>

    <span class="s0"># coef(q; y + X @ g, X) = coef(q; y, X) + g</span>
    <span class="s1">g_intercept</span><span class="s3">, </span><span class="s1">g_coef </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(), </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">)</span>
    <span class="s1">model2 </span><span class="s3">= </span><span class="s1">QuantileRegressor</span><span class="s3">(</span><span class="s1">quantile</span><span class="s3">=</span><span class="s1">quantile</span><span class="s3">, **</span><span class="s1">params</span><span class="s3">)</span>
    <span class="s1">model2</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">+ </span><span class="s1">X </span><span class="s3">@ </span><span class="s1">g_coef </span><span class="s3">+ </span><span class="s1">g_intercept</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">model2</span><span class="s3">.</span><span class="s1">intercept_ </span><span class="s3">== </span><span class="s1">approx</span><span class="s3">(</span><span class="s1">model1</span><span class="s3">.</span><span class="s1">intercept_ </span><span class="s3">+ </span><span class="s1">g_intercept</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">model2</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">model1</span><span class="s3">.</span><span class="s1">coef_ </span><span class="s3">+ </span><span class="s1">g_coef</span><span class="s3">, </span><span class="s1">rtol</span><span class="s3">=</span><span class="s4">1e-6</span><span class="s3">)</span>

    <span class="s0"># coef(q; y, X @ A) = A^-1 @ coef(q; y, X)</span>
    <span class="s1">A </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s1">n_features</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">)</span>
    <span class="s1">model2 </span><span class="s3">= </span><span class="s1">QuantileRegressor</span><span class="s3">(</span><span class="s1">quantile</span><span class="s3">=</span><span class="s1">quantile</span><span class="s3">, **</span><span class="s1">params</span><span class="s3">)</span>
    <span class="s1">model2</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X </span><span class="s3">@ </span><span class="s1">A</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">model2</span><span class="s3">.</span><span class="s1">intercept_ </span><span class="s3">== </span><span class="s1">approx</span><span class="s3">(</span><span class="s1">model1</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">, </span><span class="s1">rel</span><span class="s3">=</span><span class="s4">1e-5</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">model2</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linalg</span><span class="s3">.</span><span class="s1">solve</span><span class="s3">(</span><span class="s1">A</span><span class="s3">, </span><span class="s1">model1</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">), </span><span class="s1">rtol</span><span class="s3">=</span><span class="s4">1e-5</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">skipif</span><span class="s3">(</span>
    <span class="s1">parse_version</span><span class="s3">(</span><span class="s1">sp_version</span><span class="s3">.</span><span class="s1">base_version</span><span class="s3">) &gt;= </span><span class="s1">parse_version</span><span class="s3">(</span><span class="s5">&quot;1.11&quot;</span><span class="s3">),</span>
    <span class="s1">reason</span><span class="s3">=</span><span class="s5">&quot;interior-point solver is not available in SciPy 1.11&quot;</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s5">&quot;ignore:`method='interior-point'` is deprecated&quot;</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_linprog_failure</span><span class="s3">():</span>
    <span class="s6">&quot;&quot;&quot;Test that linprog fails.&quot;&quot;&quot;</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linspace</span><span class="s3">(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">10</span><span class="s3">, </span><span class="s1">num</span><span class="s3">=</span><span class="s4">10</span><span class="s3">).</span><span class="s1">reshape</span><span class="s3">(-</span><span class="s4">1</span><span class="s3">, </span><span class="s4">1</span><span class="s3">)</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linspace</span><span class="s3">(</span><span class="s4">0</span><span class="s3">, </span><span class="s4">10</span><span class="s3">, </span><span class="s1">num</span><span class="s3">=</span><span class="s4">10</span><span class="s3">)</span>
    <span class="s1">reg </span><span class="s3">= </span><span class="s1">QuantileRegressor</span><span class="s3">(</span>
        <span class="s1">alpha</span><span class="s3">=</span><span class="s4">0</span><span class="s3">, </span><span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;interior-point&quot;</span><span class="s3">, </span><span class="s1">solver_options</span><span class="s3">={</span><span class="s5">&quot;maxiter&quot;</span><span class="s3">: </span><span class="s4">1</span><span class="s3">}</span>
    <span class="s3">)</span>

    <span class="s1">msg </span><span class="s3">= </span><span class="s5">&quot;Linear programming for QuantileRegressor did not succeed.&quot;</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">warns</span><span class="s3">(</span><span class="s1">ConvergenceWarning</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">msg</span><span class="s3">):</span>
        <span class="s1">reg</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">skip_if_32bit</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">skipif</span><span class="s3">(</span>
    <span class="s1">sp_version </span><span class="s3">&lt;= </span><span class="s1">parse_version</span><span class="s3">(</span><span class="s5">&quot;1.6.0&quot;</span><span class="s3">),</span>
    <span class="s1">reason</span><span class="s3">=</span><span class="s5">&quot;Solvers are available as of scipy 1.6.0&quot;</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s5">&quot;sparse_container&quot;</span><span class="s3">, </span><span class="s1">CSC_CONTAINERS </span><span class="s3">+ </span><span class="s1">CSR_CONTAINERS </span><span class="s3">+ </span><span class="s1">COO_CONTAINERS</span>
<span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;solver&quot;</span><span class="s3">, [</span><span class="s5">&quot;highs&quot;</span><span class="s3">, </span><span class="s5">&quot;highs-ds&quot;</span><span class="s3">, </span><span class="s5">&quot;highs-ipm&quot;</span><span class="s3">])</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s5">&quot;fit_intercept&quot;</span><span class="s3">, [</span><span class="s2">True</span><span class="s3">, </span><span class="s2">False</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_sparse_input</span><span class="s3">(</span><span class="s1">sparse_container</span><span class="s3">, </span><span class="s1">solver</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">default_solver</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Test that sparse and dense X give same results.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">make_regression</span><span class="s3">(</span><span class="s1">n_samples</span><span class="s3">=</span><span class="s4">100</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s4">20</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">1</span><span class="s3">, </span><span class="s1">noise</span><span class="s3">=</span><span class="s4">1.0</span><span class="s3">)</span>
    <span class="s1">X_sparse </span><span class="s3">= </span><span class="s1">sparse_container</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">alpha </span><span class="s3">= </span><span class="s4">1e-4</span>
    <span class="s1">quant_dense </span><span class="s3">= </span><span class="s1">QuantileRegressor</span><span class="s3">(</span>
        <span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">solver</span><span class="s3">=</span><span class="s1">default_solver</span>
    <span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">quant_sparse </span><span class="s3">= </span><span class="s1">QuantileRegressor</span><span class="s3">(</span>
        <span class="s1">alpha</span><span class="s3">=</span><span class="s1">alpha</span><span class="s3">, </span><span class="s1">fit_intercept</span><span class="s3">=</span><span class="s1">fit_intercept</span><span class="s3">, </span><span class="s1">solver</span><span class="s3">=</span><span class="s1">solver</span>
    <span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_sparse</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">quant_sparse</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">quant_dense</span><span class="s3">.</span><span class="s1">coef_</span><span class="s3">, </span><span class="s1">rtol</span><span class="s3">=</span><span class="s4">1e-2</span><span class="s3">)</span>
    <span class="s2">if </span><span class="s1">fit_intercept</span><span class="s3">:</span>
        <span class="s2">assert </span><span class="s1">quant_sparse</span><span class="s3">.</span><span class="s1">intercept_ </span><span class="s3">== </span><span class="s1">approx</span><span class="s3">(</span><span class="s1">quant_dense</span><span class="s3">.</span><span class="s1">intercept_</span><span class="s3">)</span>
        <span class="s0"># check that we still predict fraction</span>
        <span class="s2">assert </span><span class="s4">0.45 </span><span class="s3">&lt;= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">mean</span><span class="s3">(</span><span class="s1">y </span><span class="s3">&lt; </span><span class="s1">quant_sparse</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X_sparse</span><span class="s3">)) &lt;= </span><span class="s4">0.57</span>


<span class="s2">def </span><span class="s1">test_error_interior_point_future</span><span class="s3">(</span><span class="s1">X_y_data</span><span class="s3">, </span><span class="s1">monkeypatch</span><span class="s3">):</span>
    <span class="s6">&quot;&quot;&quot;Check that we will raise a proper error when requesting 
    `solver='interior-point'` in SciPy &gt;= 1.11. 
    &quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">X_y_data</span>
    <span class="s2">import </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">linear_model</span><span class="s3">.</span><span class="s1">_quantile</span>

    <span class="s2">with </span><span class="s1">monkeypatch</span><span class="s3">.</span><span class="s1">context</span><span class="s3">() </span><span class="s2">as </span><span class="s1">m</span><span class="s3">:</span>
        <span class="s1">m</span><span class="s3">.</span><span class="s1">setattr</span><span class="s3">(</span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">linear_model</span><span class="s3">.</span><span class="s1">_quantile</span><span class="s3">, </span><span class="s5">&quot;sp_version&quot;</span><span class="s3">, </span><span class="s1">parse_version</span><span class="s3">(</span><span class="s5">&quot;1.11.0&quot;</span><span class="s3">))</span>
        <span class="s1">err_msg </span><span class="s3">= </span><span class="s5">&quot;Solver interior-point is not anymore available in SciPy &gt;= 1.11.0.&quot;</span>
        <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">err_msg</span><span class="s3">):</span>
            <span class="s1">QuantileRegressor</span><span class="s3">(</span><span class="s1">solver</span><span class="s3">=</span><span class="s5">&quot;interior-point&quot;</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
</pre>
</body>
</html>