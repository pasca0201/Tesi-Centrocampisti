<html>
<head>
<title>_search.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_search.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
The :mod:`sklearn.model_selection._search` includes utilities to fine-tune the 
parameters of an estimator. 
&quot;&quot;&quot;</span>

<span class="s2"># Author: Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;,</span>
<span class="s2">#         Gael Varoquaux &lt;gael.varoquaux@normalesup.org&gt;</span>
<span class="s2">#         Andreas Mueller &lt;amueller@ais.uni-bonn.de&gt;</span>
<span class="s2">#         Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="s2">#         Raghav RV &lt;rvraghav93@gmail.com&gt;</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">numbers</span>
<span class="s3">import </span><span class="s1">operator</span>
<span class="s3">import </span><span class="s1">time</span>
<span class="s3">import </span><span class="s1">warnings</span>
<span class="s3">from </span><span class="s1">abc </span><span class="s3">import </span><span class="s1">ABCMeta</span><span class="s4">, </span><span class="s1">abstractmethod</span>
<span class="s3">from </span><span class="s1">collections </span><span class="s3">import </span><span class="s1">defaultdict</span>
<span class="s3">from </span><span class="s1">collections</span><span class="s4">.</span><span class="s1">abc </span><span class="s3">import </span><span class="s1">Iterable</span><span class="s4">, </span><span class="s1">Mapping</span><span class="s4">, </span><span class="s1">Sequence</span>
<span class="s3">from </span><span class="s1">functools </span><span class="s3">import </span><span class="s1">partial</span><span class="s4">, </span><span class="s1">reduce</span>
<span class="s3">from </span><span class="s1">itertools </span><span class="s3">import </span><span class="s1">product</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">numpy</span><span class="s4">.</span><span class="s1">ma </span><span class="s3">import </span><span class="s1">MaskedArray</span>
<span class="s3">from </span><span class="s1">scipy</span><span class="s4">.</span><span class="s1">stats </span><span class="s3">import </span><span class="s1">rankdata</span>

<span class="s3">from </span><span class="s4">..</span><span class="s1">base </span><span class="s3">import </span><span class="s1">BaseEstimator</span><span class="s4">, </span><span class="s1">MetaEstimatorMixin</span><span class="s4">, </span><span class="s1">_fit_context</span><span class="s4">, </span><span class="s1">clone</span><span class="s4">, </span><span class="s1">is_classifier</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">exceptions </span><span class="s3">import </span><span class="s1">NotFittedError</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">metrics </span><span class="s3">import </span><span class="s1">check_scoring</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">metrics</span><span class="s4">.</span><span class="s1">_scorer </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">_check_multimetric_scoring</span><span class="s4">,</span>
    <span class="s1">_MultimetricScorer</span><span class="s4">,</span>
    <span class="s1">get_scorer_names</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils </span><span class="s3">import </span><span class="s1">Bunch</span><span class="s4">, </span><span class="s1">check_random_state</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_estimator_html_repr </span><span class="s3">import </span><span class="s1">_VisualBlock</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_param_validation </span><span class="s3">import </span><span class="s1">HasMethods</span><span class="s4">, </span><span class="s1">Interval</span><span class="s4">, </span><span class="s1">StrOptions</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_tags </span><span class="s3">import </span><span class="s1">_safe_tags</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">deprecation </span><span class="s3">import </span><span class="s1">_deprecate_Xt_in_inverse_transform</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">metadata_routing </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">MetadataRouter</span><span class="s4">,</span>
    <span class="s1">MethodMapping</span><span class="s4">,</span>
    <span class="s1">_raise_for_params</span><span class="s4">,</span>
    <span class="s1">_routing_enabled</span><span class="s4">,</span>
    <span class="s1">process_routing</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">metaestimators </span><span class="s3">import </span><span class="s1">available_if</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">parallel </span><span class="s3">import </span><span class="s1">Parallel</span><span class="s4">, </span><span class="s1">delayed</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">random </span><span class="s3">import </span><span class="s1">sample_without_replacement</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">validation </span><span class="s3">import </span><span class="s1">_check_method_params</span><span class="s4">, </span><span class="s1">check_is_fitted</span><span class="s4">, </span><span class="s1">indexable</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">_split </span><span class="s3">import </span><span class="s1">check_cv</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">_validation </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">_aggregate_score_dicts</span><span class="s4">,</span>
    <span class="s1">_fit_and_score</span><span class="s4">,</span>
    <span class="s1">_insert_error_scores</span><span class="s4">,</span>
    <span class="s1">_normalize_score_results</span><span class="s4">,</span>
    <span class="s1">_warn_or_raise_about_fit_failures</span><span class="s4">,</span>
<span class="s4">)</span>

<span class="s1">__all__ </span><span class="s4">= [</span><span class="s5">&quot;GridSearchCV&quot;</span><span class="s4">, </span><span class="s5">&quot;ParameterGrid&quot;</span><span class="s4">, </span><span class="s5">&quot;ParameterSampler&quot;</span><span class="s4">, </span><span class="s5">&quot;RandomizedSearchCV&quot;</span><span class="s4">]</span>


<span class="s3">class </span><span class="s1">ParameterGrid</span><span class="s4">:</span>
    <span class="s0">&quot;&quot;&quot;Grid of parameters with a discrete number of values for each. 
 
    Can be used to iterate over parameter value combinations with the 
    Python built-in function iter. 
    The order of the generated parameter combinations is deterministic. 
 
    Read more in the :ref:`User Guide &lt;grid_search&gt;`. 
 
    Parameters 
    ---------- 
    param_grid : dict of str to sequence, or sequence of such 
        The parameter grid to explore, as a dictionary mapping estimator 
        parameters to sequences of allowed values. 
 
        An empty dict signifies default parameters. 
 
        A sequence of dicts signifies a sequence of grids to search, and is 
        useful to avoid exploring parameter combinations that make no sense 
        or have no effect. See the examples below. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.model_selection import ParameterGrid 
    &gt;&gt;&gt; param_grid = {'a': [1, 2], 'b': [True, False]} 
    &gt;&gt;&gt; list(ParameterGrid(param_grid)) == ( 
    ...    [{'a': 1, 'b': True}, {'a': 1, 'b': False}, 
    ...     {'a': 2, 'b': True}, {'a': 2, 'b': False}]) 
    True 
 
    &gt;&gt;&gt; grid = [{'kernel': ['linear']}, {'kernel': ['rbf'], 'gamma': [1, 10]}] 
    &gt;&gt;&gt; list(ParameterGrid(grid)) == [{'kernel': 'linear'}, 
    ...                               {'kernel': 'rbf', 'gamma': 1}, 
    ...                               {'kernel': 'rbf', 'gamma': 10}] 
    True 
    &gt;&gt;&gt; ParameterGrid(grid)[1] == {'kernel': 'rbf', 'gamma': 1} 
    True 
 
    See Also 
    -------- 
    GridSearchCV : Uses :class:`ParameterGrid` to perform a full parallelized 
        parameter search. 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">param_grid</span><span class="s4">):</span>
        <span class="s3">if not </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">param_grid</span><span class="s4">, (</span><span class="s1">Mapping</span><span class="s4">, </span><span class="s1">Iterable</span><span class="s4">)):</span>
            <span class="s3">raise </span><span class="s1">TypeError</span><span class="s4">(</span>
                <span class="s5">f&quot;Parameter grid should be a dict or a list, got: </span><span class="s3">{</span><span class="s1">param_grid</span><span class="s3">!r} </span><span class="s5">of&quot;</span>
                <span class="s5">f&quot; type </span><span class="s3">{</span><span class="s1">type</span><span class="s4">(</span><span class="s1">param_grid</span><span class="s4">).</span><span class="s1">__name__</span><span class="s3">}</span><span class="s5">&quot;</span>
            <span class="s4">)</span>

        <span class="s3">if </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">param_grid</span><span class="s4">, </span><span class="s1">Mapping</span><span class="s4">):</span>
            <span class="s2"># wrap dictionary in a singleton list to support either dict</span>
            <span class="s2"># or list of dicts</span>
            <span class="s1">param_grid </span><span class="s4">= [</span><span class="s1">param_grid</span><span class="s4">]</span>

        <span class="s2"># check if all entries are dictionaries of lists</span>
        <span class="s3">for </span><span class="s1">grid </span><span class="s3">in </span><span class="s1">param_grid</span><span class="s4">:</span>
            <span class="s3">if not </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">grid</span><span class="s4">, </span><span class="s1">dict</span><span class="s4">):</span>
                <span class="s3">raise </span><span class="s1">TypeError</span><span class="s4">(</span><span class="s5">f&quot;Parameter grid is not a dict (</span><span class="s3">{</span><span class="s1">grid</span><span class="s3">!r}</span><span class="s5">)&quot;</span><span class="s4">)</span>
            <span class="s3">for </span><span class="s1">key</span><span class="s4">, </span><span class="s1">value </span><span class="s3">in </span><span class="s1">grid</span><span class="s4">.</span><span class="s1">items</span><span class="s4">():</span>
                <span class="s3">if </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">value</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ndarray</span><span class="s4">) </span><span class="s3">and </span><span class="s1">value</span><span class="s4">.</span><span class="s1">ndim </span><span class="s4">&gt; </span><span class="s6">1</span><span class="s4">:</span>
                    <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                        <span class="s5">f&quot;Parameter array for </span><span class="s3">{</span><span class="s1">key</span><span class="s3">!r} </span><span class="s5">should be one-dimensional, got:&quot;</span>
                        <span class="s5">f&quot; </span><span class="s3">{</span><span class="s1">value</span><span class="s3">!r} </span><span class="s5">with shape </span><span class="s3">{</span><span class="s1">value</span><span class="s4">.</span><span class="s1">shape</span><span class="s3">}</span><span class="s5">&quot;</span>
                    <span class="s4">)</span>
                <span class="s3">if </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">value</span><span class="s4">, </span><span class="s1">str</span><span class="s4">) </span><span class="s3">or not </span><span class="s1">isinstance</span><span class="s4">(</span>
                    <span class="s1">value</span><span class="s4">, (</span><span class="s1">np</span><span class="s4">.</span><span class="s1">ndarray</span><span class="s4">, </span><span class="s1">Sequence</span><span class="s4">)</span>
                <span class="s4">):</span>
                    <span class="s3">raise </span><span class="s1">TypeError</span><span class="s4">(</span>
                        <span class="s5">f&quot;Parameter grid for parameter </span><span class="s3">{</span><span class="s1">key</span><span class="s3">!r} </span><span class="s5">needs to be a list or a&quot;</span>
                        <span class="s5">f&quot; numpy array, but got </span><span class="s3">{</span><span class="s1">value</span><span class="s3">!r} </span><span class="s5">(of type &quot;</span>
                        <span class="s5">f&quot;</span><span class="s3">{</span><span class="s1">type</span><span class="s4">(</span><span class="s1">value</span><span class="s4">).</span><span class="s1">__name__</span><span class="s3">}</span><span class="s5">) instead. Single values &quot;</span>
                        <span class="s5">&quot;need to be wrapped in a list with one element.&quot;</span>
                    <span class="s4">)</span>
                <span class="s3">if </span><span class="s1">len</span><span class="s4">(</span><span class="s1">value</span><span class="s4">) == </span><span class="s6">0</span><span class="s4">:</span>
                    <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                        <span class="s5">f&quot;Parameter grid for parameter </span><span class="s3">{</span><span class="s1">key</span><span class="s3">!r} </span><span class="s5">need &quot;</span>
                        <span class="s5">f&quot;to be a non-empty sequence, got: </span><span class="s3">{</span><span class="s1">value</span><span class="s3">!r}</span><span class="s5">&quot;</span>
                    <span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">param_grid </span><span class="s4">= </span><span class="s1">param_grid</span>

    <span class="s3">def </span><span class="s1">__iter__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Iterate over the points in the grid. 
 
        Returns 
        ------- 
        params : iterator over dict of str to any 
            Yields dictionaries mapping each estimator parameter to one of its 
            allowed values. 
        &quot;&quot;&quot;</span>
        <span class="s3">for </span><span class="s1">p </span><span class="s3">in </span><span class="s1">self</span><span class="s4">.</span><span class="s1">param_grid</span><span class="s4">:</span>
            <span class="s2"># Always sort the keys of a dictionary, for reproducibility</span>
            <span class="s1">items </span><span class="s4">= </span><span class="s1">sorted</span><span class="s4">(</span><span class="s1">p</span><span class="s4">.</span><span class="s1">items</span><span class="s4">())</span>
            <span class="s3">if not </span><span class="s1">items</span><span class="s4">:</span>
                <span class="s3">yield </span><span class="s4">{}</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s1">keys</span><span class="s4">, </span><span class="s1">values </span><span class="s4">= </span><span class="s1">zip</span><span class="s4">(*</span><span class="s1">items</span><span class="s4">)</span>
                <span class="s3">for </span><span class="s1">v </span><span class="s3">in </span><span class="s1">product</span><span class="s4">(*</span><span class="s1">values</span><span class="s4">):</span>
                    <span class="s1">params </span><span class="s4">= </span><span class="s1">dict</span><span class="s4">(</span><span class="s1">zip</span><span class="s4">(</span><span class="s1">keys</span><span class="s4">, </span><span class="s1">v</span><span class="s4">))</span>
                    <span class="s3">yield </span><span class="s1">params</span>

    <span class="s3">def </span><span class="s1">__len__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Number of points on the grid.&quot;&quot;&quot;</span>
        <span class="s2"># Product function that can handle iterables (np.prod can't).</span>
        <span class="s1">product </span><span class="s4">= </span><span class="s1">partial</span><span class="s4">(</span><span class="s1">reduce</span><span class="s4">, </span><span class="s1">operator</span><span class="s4">.</span><span class="s1">mul</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">sum</span><span class="s4">(</span>
            <span class="s1">product</span><span class="s4">(</span><span class="s1">len</span><span class="s4">(</span><span class="s1">v</span><span class="s4">) </span><span class="s3">for </span><span class="s1">v </span><span class="s3">in </span><span class="s1">p</span><span class="s4">.</span><span class="s1">values</span><span class="s4">()) </span><span class="s3">if </span><span class="s1">p </span><span class="s3">else </span><span class="s6">1 </span><span class="s3">for </span><span class="s1">p </span><span class="s3">in </span><span class="s1">self</span><span class="s4">.</span><span class="s1">param_grid</span>
        <span class="s4">)</span>

    <span class="s3">def </span><span class="s1">__getitem__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">ind</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Get the parameters that would be ``ind``th in iteration 
 
        Parameters 
        ---------- 
        ind : int 
            The iteration index 
 
        Returns 
        ------- 
        params : dict of str to any 
            Equal to list(self)[ind] 
        &quot;&quot;&quot;</span>
        <span class="s2"># This is used to make discrete sampling without replacement memory</span>
        <span class="s2"># efficient.</span>
        <span class="s3">for </span><span class="s1">sub_grid </span><span class="s3">in </span><span class="s1">self</span><span class="s4">.</span><span class="s1">param_grid</span><span class="s4">:</span>
            <span class="s2"># XXX: could memoize information used here</span>
            <span class="s3">if not </span><span class="s1">sub_grid</span><span class="s4">:</span>
                <span class="s3">if </span><span class="s1">ind </span><span class="s4">== </span><span class="s6">0</span><span class="s4">:</span>
                    <span class="s3">return </span><span class="s4">{}</span>
                <span class="s3">else</span><span class="s4">:</span>
                    <span class="s1">ind </span><span class="s4">-= </span><span class="s6">1</span>
                    <span class="s3">continue</span>

            <span class="s2"># Reverse so most frequent cycling parameter comes first</span>
            <span class="s1">keys</span><span class="s4">, </span><span class="s1">values_lists </span><span class="s4">= </span><span class="s1">zip</span><span class="s4">(*</span><span class="s1">sorted</span><span class="s4">(</span><span class="s1">sub_grid</span><span class="s4">.</span><span class="s1">items</span><span class="s4">())[::-</span><span class="s6">1</span><span class="s4">])</span>
            <span class="s1">sizes </span><span class="s4">= [</span><span class="s1">len</span><span class="s4">(</span><span class="s1">v_list</span><span class="s4">) </span><span class="s3">for </span><span class="s1">v_list </span><span class="s3">in </span><span class="s1">values_lists</span><span class="s4">]</span>
            <span class="s1">total </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">prod</span><span class="s4">(</span><span class="s1">sizes</span><span class="s4">)</span>

            <span class="s3">if </span><span class="s1">ind </span><span class="s4">&gt;= </span><span class="s1">total</span><span class="s4">:</span>
                <span class="s2"># Try the next grid</span>
                <span class="s1">ind </span><span class="s4">-= </span><span class="s1">total</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s1">out </span><span class="s4">= {}</span>
                <span class="s3">for </span><span class="s1">key</span><span class="s4">, </span><span class="s1">v_list</span><span class="s4">, </span><span class="s1">n </span><span class="s3">in </span><span class="s1">zip</span><span class="s4">(</span><span class="s1">keys</span><span class="s4">, </span><span class="s1">values_lists</span><span class="s4">, </span><span class="s1">sizes</span><span class="s4">):</span>
                    <span class="s1">ind</span><span class="s4">, </span><span class="s1">offset </span><span class="s4">= </span><span class="s1">divmod</span><span class="s4">(</span><span class="s1">ind</span><span class="s4">, </span><span class="s1">n</span><span class="s4">)</span>
                    <span class="s1">out</span><span class="s4">[</span><span class="s1">key</span><span class="s4">] = </span><span class="s1">v_list</span><span class="s4">[</span><span class="s1">offset</span><span class="s4">]</span>
                <span class="s3">return </span><span class="s1">out</span>

        <span class="s3">raise </span><span class="s1">IndexError</span><span class="s4">(</span><span class="s5">&quot;ParameterGrid index out of range&quot;</span><span class="s4">)</span>


<span class="s3">class </span><span class="s1">ParameterSampler</span><span class="s4">:</span>
    <span class="s0">&quot;&quot;&quot;Generator on parameters sampled from given distributions. 
 
    Non-deterministic iterable over random candidate combinations for hyper- 
    parameter search. If all parameters are presented as a list, 
    sampling without replacement is performed. If at least one parameter 
    is given as a distribution, sampling with replacement is used. 
    It is highly recommended to use continuous distributions for continuous 
    parameters. 
 
    Read more in the :ref:`User Guide &lt;grid_search&gt;`. 
 
    Parameters 
    ---------- 
    param_distributions : dict 
        Dictionary with parameters names (`str`) as keys and distributions 
        or lists of parameters to try. Distributions must provide a ``rvs`` 
        method for sampling (such as those from scipy.stats.distributions). 
        If a list is given, it is sampled uniformly. 
        If a list of dicts is given, first a dict is sampled uniformly, and 
        then a parameter is sampled using that dict as above. 
 
    n_iter : int 
        Number of parameter settings that are produced. 
 
    random_state : int, RandomState instance or None, default=None 
        Pseudo random number generator state used for random uniform sampling 
        from lists of possible values instead of scipy.stats distributions. 
        Pass an int for reproducible output across multiple 
        function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    Returns 
    ------- 
    params : dict of str to any 
        **Yields** dictionaries mapping each estimator parameter to 
        as sampled value. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.model_selection import ParameterSampler 
    &gt;&gt;&gt; from scipy.stats.distributions import expon 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; rng = np.random.RandomState(0) 
    &gt;&gt;&gt; param_grid = {'a':[1, 2], 'b': expon()} 
    &gt;&gt;&gt; param_list = list(ParameterSampler(param_grid, n_iter=4, 
    ...                                    random_state=rng)) 
    &gt;&gt;&gt; rounded_list = [dict((k, round(v, 6)) for (k, v) in d.items()) 
    ...                 for d in param_list] 
    &gt;&gt;&gt; rounded_list == [{'b': 0.89856, 'a': 1}, 
    ...                  {'b': 0.923223, 'a': 1}, 
    ...                  {'b': 1.878964, 'a': 2}, 
    ...                  {'b': 1.038159, 'a': 2}] 
    True 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">param_distributions</span><span class="s4">, </span><span class="s1">n_iter</span><span class="s4">, *, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s3">if not </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">param_distributions</span><span class="s4">, (</span><span class="s1">Mapping</span><span class="s4">, </span><span class="s1">Iterable</span><span class="s4">)):</span>
            <span class="s3">raise </span><span class="s1">TypeError</span><span class="s4">(</span>
                <span class="s5">&quot;Parameter distribution is not a dict or a list,&quot;</span>
                <span class="s5">f&quot; got: </span><span class="s3">{</span><span class="s1">param_distributions</span><span class="s3">!r} </span><span class="s5">of type &quot;</span>
                <span class="s5">f&quot;</span><span class="s3">{</span><span class="s1">type</span><span class="s4">(</span><span class="s1">param_distributions</span><span class="s4">).</span><span class="s1">__name__</span><span class="s3">}</span><span class="s5">&quot;</span>
            <span class="s4">)</span>

        <span class="s3">if </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">param_distributions</span><span class="s4">, </span><span class="s1">Mapping</span><span class="s4">):</span>
            <span class="s2"># wrap dictionary in a singleton list to support either dict</span>
            <span class="s2"># or list of dicts</span>
            <span class="s1">param_distributions </span><span class="s4">= [</span><span class="s1">param_distributions</span><span class="s4">]</span>

        <span class="s3">for </span><span class="s1">dist </span><span class="s3">in </span><span class="s1">param_distributions</span><span class="s4">:</span>
            <span class="s3">if not </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">dist</span><span class="s4">, </span><span class="s1">dict</span><span class="s4">):</span>
                <span class="s3">raise </span><span class="s1">TypeError</span><span class="s4">(</span>
                    <span class="s5">&quot;Parameter distribution is not a dict ({!r})&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span><span class="s1">dist</span><span class="s4">)</span>
                <span class="s4">)</span>
            <span class="s3">for </span><span class="s1">key </span><span class="s3">in </span><span class="s1">dist</span><span class="s4">:</span>
                <span class="s3">if not </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">dist</span><span class="s4">[</span><span class="s1">key</span><span class="s4">], </span><span class="s1">Iterable</span><span class="s4">) </span><span class="s3">and not </span><span class="s1">hasattr</span><span class="s4">(</span>
                    <span class="s1">dist</span><span class="s4">[</span><span class="s1">key</span><span class="s4">], </span><span class="s5">&quot;rvs&quot;</span>
                <span class="s4">):</span>
                    <span class="s3">raise </span><span class="s1">TypeError</span><span class="s4">(</span>
                        <span class="s5">f&quot;Parameter grid for parameter </span><span class="s3">{</span><span class="s1">key</span><span class="s3">!r} </span><span class="s5">is not iterable &quot;</span>
                        <span class="s5">f&quot;or a distribution (value=</span><span class="s3">{</span><span class="s1">dist</span><span class="s4">[</span><span class="s1">key</span><span class="s4">]</span><span class="s3">}</span><span class="s5">)&quot;</span>
                    <span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter </span><span class="s4">= </span><span class="s1">n_iter</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">random_state </span><span class="s4">= </span><span class="s1">random_state</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">param_distributions </span><span class="s4">= </span><span class="s1">param_distributions</span>

    <span class="s3">def </span><span class="s1">_is_all_lists</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s1">all</span><span class="s4">(</span>
            <span class="s1">all</span><span class="s4">(</span><span class="s3">not </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">v</span><span class="s4">, </span><span class="s5">&quot;rvs&quot;</span><span class="s4">) </span><span class="s3">for </span><span class="s1">v </span><span class="s3">in </span><span class="s1">dist</span><span class="s4">.</span><span class="s1">values</span><span class="s4">())</span>
            <span class="s3">for </span><span class="s1">dist </span><span class="s3">in </span><span class="s1">self</span><span class="s4">.</span><span class="s1">param_distributions</span>
        <span class="s4">)</span>

    <span class="s3">def </span><span class="s1">__iter__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s1">rng </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>

        <span class="s2"># if all distributions are given as lists, we want to sample without</span>
        <span class="s2"># replacement</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_is_all_lists</span><span class="s4">():</span>
            <span class="s2"># look up sampled parameter settings in parameter grid</span>
            <span class="s1">param_grid </span><span class="s4">= </span><span class="s1">ParameterGrid</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">param_distributions</span><span class="s4">)</span>
            <span class="s1">grid_size </span><span class="s4">= </span><span class="s1">len</span><span class="s4">(</span><span class="s1">param_grid</span><span class="s4">)</span>
            <span class="s1">n_iter </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter</span>

            <span class="s3">if </span><span class="s1">grid_size </span><span class="s4">&lt; </span><span class="s1">n_iter</span><span class="s4">:</span>
                <span class="s1">warnings</span><span class="s4">.</span><span class="s1">warn</span><span class="s4">(</span>
                    <span class="s5">&quot;The total space of parameters %d is smaller &quot;</span>
                    <span class="s5">&quot;than n_iter=%d. Running %d iterations. For exhaustive &quot;</span>
                    <span class="s5">&quot;searches, use GridSearchCV.&quot; </span><span class="s4">% (</span><span class="s1">grid_size</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter</span><span class="s4">, </span><span class="s1">grid_size</span><span class="s4">),</span>
                    <span class="s1">UserWarning</span><span class="s4">,</span>
                <span class="s4">)</span>
                <span class="s1">n_iter </span><span class="s4">= </span><span class="s1">grid_size</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">sample_without_replacement</span><span class="s4">(</span><span class="s1">grid_size</span><span class="s4">, </span><span class="s1">n_iter</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">):</span>
                <span class="s3">yield </span><span class="s1">param_grid</span><span class="s4">[</span><span class="s1">i</span><span class="s4">]</span>

        <span class="s3">else</span><span class="s4">:</span>
            <span class="s3">for </span><span class="s1">_ </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter</span><span class="s4">):</span>
                <span class="s1">dist </span><span class="s4">= </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">choice</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">param_distributions</span><span class="s4">)</span>
                <span class="s2"># Always sort the keys of a dictionary, for reproducibility</span>
                <span class="s1">items </span><span class="s4">= </span><span class="s1">sorted</span><span class="s4">(</span><span class="s1">dist</span><span class="s4">.</span><span class="s1">items</span><span class="s4">())</span>
                <span class="s1">params </span><span class="s4">= </span><span class="s1">dict</span><span class="s4">()</span>
                <span class="s3">for </span><span class="s1">k</span><span class="s4">, </span><span class="s1">v </span><span class="s3">in </span><span class="s1">items</span><span class="s4">:</span>
                    <span class="s3">if </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">v</span><span class="s4">, </span><span class="s5">&quot;rvs&quot;</span><span class="s4">):</span>
                        <span class="s1">params</span><span class="s4">[</span><span class="s1">k</span><span class="s4">] = </span><span class="s1">v</span><span class="s4">.</span><span class="s1">rvs</span><span class="s4">(</span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">)</span>
                    <span class="s3">else</span><span class="s4">:</span>
                        <span class="s1">params</span><span class="s4">[</span><span class="s1">k</span><span class="s4">] = </span><span class="s1">v</span><span class="s4">[</span><span class="s1">rng</span><span class="s4">.</span><span class="s1">randint</span><span class="s4">(</span><span class="s1">len</span><span class="s4">(</span><span class="s1">v</span><span class="s4">))]</span>
                <span class="s3">yield </span><span class="s1">params</span>

    <span class="s3">def </span><span class="s1">__len__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Number of points that will be sampled.&quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_is_all_lists</span><span class="s4">():</span>
            <span class="s1">grid_size </span><span class="s4">= </span><span class="s1">len</span><span class="s4">(</span><span class="s1">ParameterGrid</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">param_distributions</span><span class="s4">))</span>
            <span class="s3">return </span><span class="s1">min</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter</span><span class="s4">, </span><span class="s1">grid_size</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter</span>


<span class="s3">def </span><span class="s1">_check_refit</span><span class="s4">(</span><span class="s1">search_cv</span><span class="s4">, </span><span class="s1">attr</span><span class="s4">):</span>
    <span class="s3">if not </span><span class="s1">search_cv</span><span class="s4">.</span><span class="s1">refit</span><span class="s4">:</span>
        <span class="s3">raise </span><span class="s1">AttributeError</span><span class="s4">(</span>
            <span class="s5">f&quot;This </span><span class="s3">{</span><span class="s1">type</span><span class="s4">(</span><span class="s1">search_cv</span><span class="s4">).</span><span class="s1">__name__</span><span class="s3">} </span><span class="s5">instance was initialized with &quot;</span>
            <span class="s5">f&quot;`refit=False`. </span><span class="s3">{</span><span class="s1">attr</span><span class="s3">} </span><span class="s5">is available only after refitting on the best &quot;</span>
            <span class="s5">&quot;parameters. You can refit an estimator manually using the &quot;</span>
            <span class="s5">&quot;`best_params_` attribute&quot;</span>
        <span class="s4">)</span>


<span class="s3">def </span><span class="s1">_estimator_has</span><span class="s4">(</span><span class="s1">attr</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Check if we can delegate a method to the underlying estimator. 
 
    Calling a prediction method will only be available if `refit=True`. In 
    such case, we check first the fitted best estimator. If it is not 
    fitted, we check the unfitted estimator. 
 
    Checking the unfitted estimator allows to use `hasattr` on the `SearchCV` 
    instance even before calling `fit`. 
    &quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">check</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s1">_check_refit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">attr</span><span class="s4">)</span>
        <span class="s3">if </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;best_estimator_&quot;</span><span class="s4">):</span>
            <span class="s2"># raise an AttributeError if `attr` does not exist</span>
            <span class="s1">getattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">, </span><span class="s1">attr</span><span class="s4">)</span>
            <span class="s3">return True</span>
        <span class="s2"># raise an AttributeError if `attr` does not exist</span>
        <span class="s1">getattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">estimator</span><span class="s4">, </span><span class="s1">attr</span><span class="s4">)</span>
        <span class="s3">return True</span>

    <span class="s3">return </span><span class="s1">check</span>


<span class="s3">def </span><span class="s1">_yield_masked_array_for_each_param</span><span class="s4">(</span><span class="s1">candidate_params</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Yield a masked array for each candidate param. 
 
    `candidate_params` is a sequence of params which were used in 
    a `GridSearchCV`. We use masked arrays for the results, as not 
    all params are necessarily present in each element of 
    `candidate_params`. For example, if using `GridSearchCV` with 
    a `SVC` model, then one might search over params like: 
 
        - kernel=[&quot;rbf&quot;], gamma=[0.1, 1] 
        - kernel=[&quot;poly&quot;], degree=[1, 2] 
 
    and then param `'gamma'` would not be present in entries of 
    `candidate_params` corresponding to `kernel='poly'`. 
    &quot;&quot;&quot;</span>
    <span class="s1">n_candidates </span><span class="s4">= </span><span class="s1">len</span><span class="s4">(</span><span class="s1">candidate_params</span><span class="s4">)</span>
    <span class="s1">param_results </span><span class="s4">= </span><span class="s1">defaultdict</span><span class="s4">(</span><span class="s1">dict</span><span class="s4">)</span>

    <span class="s3">for </span><span class="s1">cand_idx</span><span class="s4">, </span><span class="s1">params </span><span class="s3">in </span><span class="s1">enumerate</span><span class="s4">(</span><span class="s1">candidate_params</span><span class="s4">):</span>
        <span class="s3">for </span><span class="s1">name</span><span class="s4">, </span><span class="s1">value </span><span class="s3">in </span><span class="s1">params</span><span class="s4">.</span><span class="s1">items</span><span class="s4">():</span>
            <span class="s1">param_results</span><span class="s4">[</span><span class="s5">&quot;param_%s&quot; </span><span class="s4">% </span><span class="s1">name</span><span class="s4">][</span><span class="s1">cand_idx</span><span class="s4">] = </span><span class="s1">value</span>

    <span class="s3">for </span><span class="s1">key</span><span class="s4">, </span><span class="s1">param_result </span><span class="s3">in </span><span class="s1">param_results</span><span class="s4">.</span><span class="s1">items</span><span class="s4">():</span>
        <span class="s1">param_list </span><span class="s4">= </span><span class="s1">list</span><span class="s4">(</span><span class="s1">param_result</span><span class="s4">.</span><span class="s1">values</span><span class="s4">())</span>
        <span class="s3">try</span><span class="s4">:</span>
            <span class="s1">arr </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span><span class="s1">param_list</span><span class="s4">)</span>
        <span class="s3">except </span><span class="s1">ValueError</span><span class="s4">:</span>
            <span class="s2"># This can happen when param_list contains lists of different</span>
            <span class="s2"># lengths, for example:</span>
            <span class="s2"># param_list=[[1], [2, 3]]</span>
            <span class="s1">arr_dtype </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">(</span><span class="s1">object</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s2"># There are two cases when we don't use the automatically inferred</span>
            <span class="s2"># dtype when creating the array and we use object instead:</span>
            <span class="s2"># - string dtype</span>
            <span class="s2"># - when array.ndim &gt; 1, that means that param_list was something</span>
            <span class="s2">#   like a list of same-size sequences, which gets turned into a</span>
            <span class="s2">#   multi-dimensional array but we want a 1d array</span>
            <span class="s1">arr_dtype </span><span class="s4">= </span><span class="s1">arr</span><span class="s4">.</span><span class="s1">dtype </span><span class="s3">if </span><span class="s1">arr</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">.</span><span class="s1">kind </span><span class="s4">!= </span><span class="s5">&quot;U&quot; </span><span class="s3">and </span><span class="s1">arr</span><span class="s4">.</span><span class="s1">ndim </span><span class="s4">== </span><span class="s6">1 </span><span class="s3">else </span><span class="s1">object</span>

        <span class="s2"># Use one MaskedArray and mask all the places where the param is not</span>
        <span class="s2"># applicable for that candidate (which may not contain all the params).</span>
        <span class="s1">ma </span><span class="s4">= </span><span class="s1">MaskedArray</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">empty</span><span class="s4">(</span><span class="s1">n_candidates</span><span class="s4">), </span><span class="s1">mask</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">arr_dtype</span><span class="s4">)</span>
        <span class="s3">for </span><span class="s1">index</span><span class="s4">, </span><span class="s1">value </span><span class="s3">in </span><span class="s1">param_result</span><span class="s4">.</span><span class="s1">items</span><span class="s4">():</span>
            <span class="s2"># Setting the value at an index unmasks that index</span>
            <span class="s1">ma</span><span class="s4">[</span><span class="s1">index</span><span class="s4">] = </span><span class="s1">value</span>
        <span class="s3">yield </span><span class="s4">(</span><span class="s1">key</span><span class="s4">, </span><span class="s1">ma</span><span class="s4">)</span>


<span class="s3">class </span><span class="s1">BaseSearchCV</span><span class="s4">(</span><span class="s1">MetaEstimatorMixin</span><span class="s4">, </span><span class="s1">BaseEstimator</span><span class="s4">, </span><span class="s1">metaclass</span><span class="s4">=</span><span class="s1">ABCMeta</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Abstract base class for hyper parameter search with cross-validation.&quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s5">&quot;estimator&quot;</span><span class="s4">: [</span><span class="s1">HasMethods</span><span class="s4">([</span><span class="s5">&quot;fit&quot;</span><span class="s4">])],</span>
        <span class="s5">&quot;scoring&quot;</span><span class="s4">: [</span>
            <span class="s1">StrOptions</span><span class="s4">(</span><span class="s1">set</span><span class="s4">(</span><span class="s1">get_scorer_names</span><span class="s4">())),</span>
            <span class="s1">callable</span><span class="s4">,</span>
            <span class="s1">list</span><span class="s4">,</span>
            <span class="s1">tuple</span><span class="s4">,</span>
            <span class="s1">dict</span><span class="s4">,</span>
            <span class="s3">None</span><span class="s4">,</span>
        <span class="s4">],</span>
        <span class="s5">&quot;n_jobs&quot;</span><span class="s4">: [</span><span class="s1">numbers</span><span class="s4">.</span><span class="s1">Integral</span><span class="s4">, </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;refit&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">, </span><span class="s1">str</span><span class="s4">, </span><span class="s1">callable</span><span class="s4">],</span>
        <span class="s5">&quot;cv&quot;</span><span class="s4">: [</span><span class="s5">&quot;cv_object&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;verbose&quot;</span><span class="s4">: [</span><span class="s5">&quot;verbose&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;pre_dispatch&quot;</span><span class="s4">: [</span><span class="s1">numbers</span><span class="s4">.</span><span class="s1">Integral</span><span class="s4">, </span><span class="s1">str</span><span class="s4">],</span>
        <span class="s5">&quot;error_score&quot;</span><span class="s4">: [</span><span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;raise&quot;</span><span class="s4">}), </span><span class="s1">numbers</span><span class="s4">.</span><span class="s1">Real</span><span class="s4">],</span>
        <span class="s5">&quot;return_train_score&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
    <span class="s4">}</span>

    <span class="s4">@</span><span class="s1">abstractmethod</span>
    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">estimator</span><span class="s4">,</span>
        <span class="s4">*,</span>
        <span class="s1">scoring</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">n_jobs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">refit</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
        <span class="s1">cv</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
        <span class="s1">pre_dispatch</span><span class="s4">=</span><span class="s5">&quot;2*n_jobs&quot;</span><span class="s4">,</span>
        <span class="s1">error_score</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">nan</span><span class="s4">,</span>
        <span class="s1">return_train_score</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">scoring </span><span class="s4">= </span><span class="s1">scoring</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">estimator </span><span class="s4">= </span><span class="s1">estimator</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_jobs </span><span class="s4">= </span><span class="s1">n_jobs</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">refit </span><span class="s4">= </span><span class="s1">refit</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">cv </span><span class="s4">= </span><span class="s1">cv</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">verbose </span><span class="s4">= </span><span class="s1">verbose</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">pre_dispatch </span><span class="s4">= </span><span class="s1">pre_dispatch</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">error_score </span><span class="s4">= </span><span class="s1">error_score</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">return_train_score </span><span class="s4">= </span><span class="s1">return_train_score</span>

    <span class="s4">@</span><span class="s1">property</span>
    <span class="s3">def </span><span class="s1">_estimator_type</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">_estimator_type</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s2"># allows cross-validation to see 'precomputed' metrics</span>
        <span class="s3">return </span><span class="s4">{</span>
            <span class="s5">&quot;pairwise&quot;</span><span class="s4">: </span><span class="s1">_safe_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">estimator</span><span class="s4">, </span><span class="s5">&quot;pairwise&quot;</span><span class="s4">),</span>
            <span class="s5">&quot;_xfail_checks&quot;</span><span class="s4">: {</span>
                <span class="s5">&quot;check_supervised_y_2d&quot;</span><span class="s4">: </span><span class="s5">&quot;DataConversionWarning not caught&quot;</span>
            <span class="s4">},</span>
        <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">score</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, **</span><span class="s1">params</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Return the score on the given data, if the estimator has been refit. 
 
        This uses the score defined by ``scoring`` where provided, and the 
        ``best_estimator_.score`` method otherwise. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Input data, where `n_samples` is the number of samples and 
            `n_features` is the number of features. 
 
        y : array-like of shape (n_samples, n_output) \ 
            or (n_samples,), default=None 
            Target relative to X for classification or regression; 
            None for unsupervised learning. 
 
        **params : dict 
            Parameters to be passed to the underlying scorer(s). 
 
            ..versionadded:: 1.4 
                Only available if `enable_metadata_routing=True`. See 
                :ref:`Metadata Routing User Guide &lt;metadata_routing&gt;` for more 
                details. 
 
        Returns 
        ------- 
        score : float 
            The score defined by ``scoring`` if provided, and the 
            ``best_estimator_.score`` method otherwise. 
        &quot;&quot;&quot;</span>
        <span class="s1">_check_refit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;score&quot;</span><span class="s4">)</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>

        <span class="s1">_raise_for_params</span><span class="s4">(</span><span class="s1">params</span><span class="s4">, </span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;score&quot;</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">_routing_enabled</span><span class="s4">():</span>
            <span class="s1">score_params </span><span class="s4">= </span><span class="s1">process_routing</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;score&quot;</span><span class="s4">, **</span><span class="s1">params</span><span class="s4">).</span><span class="s1">scorer</span><span class="s4">[</span><span class="s5">&quot;score&quot;</span><span class="s4">]</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">score_params </span><span class="s4">= </span><span class="s1">dict</span><span class="s4">()</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">scorer_ </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                <span class="s5">&quot;No score function explicitly defined, &quot;</span>
                <span class="s5">&quot;and the estimator doesn't provide one %s&quot; </span><span class="s4">% </span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span>
            <span class="s4">)</span>
        <span class="s3">if </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">scorer_</span><span class="s4">, </span><span class="s1">dict</span><span class="s4">):</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">multimetric_</span><span class="s4">:</span>
                <span class="s1">scorer </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">scorer_</span><span class="s4">[</span><span class="s1">self</span><span class="s4">.</span><span class="s1">refit</span><span class="s4">]</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s1">scorer </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">scorer_</span>
            <span class="s3">return </span><span class="s1">scorer</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, **</span><span class="s1">score_params</span><span class="s4">)</span>

        <span class="s2"># callable</span>
        <span class="s1">score </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">scorer_</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, **</span><span class="s1">score_params</span><span class="s4">)</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">multimetric_</span><span class="s4">:</span>
            <span class="s1">score </span><span class="s4">= </span><span class="s1">score</span><span class="s4">[</span><span class="s1">self</span><span class="s4">.</span><span class="s1">refit</span><span class="s4">]</span>
        <span class="s3">return </span><span class="s1">score</span>

    <span class="s4">@</span><span class="s1">available_if</span><span class="s4">(</span><span class="s1">_estimator_has</span><span class="s4">(</span><span class="s5">&quot;score_samples&quot;</span><span class="s4">))</span>
    <span class="s3">def </span><span class="s1">score_samples</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Call score_samples on the estimator with the best found parameters. 
 
        Only available if ``refit=True`` and the underlying estimator supports 
        ``score_samples``. 
 
        .. versionadded:: 0.24 
 
        Parameters 
        ---------- 
        X : iterable 
            Data to predict on. Must fulfill input requirements 
            of the underlying estimator. 
 
        Returns 
        ------- 
        y_score : ndarray of shape (n_samples,) 
            The ``best_estimator_.score_samples`` method. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">.</span><span class="s1">score_samples</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s4">@</span><span class="s1">available_if</span><span class="s4">(</span><span class="s1">_estimator_has</span><span class="s4">(</span><span class="s5">&quot;predict&quot;</span><span class="s4">))</span>
    <span class="s3">def </span><span class="s1">predict</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Call predict on the estimator with the best found parameters. 
 
        Only available if ``refit=True`` and the underlying estimator supports 
        ``predict``. 
 
        Parameters 
        ---------- 
        X : indexable, length n_samples 
            Must fulfill the input assumptions of the 
            underlying estimator. 
 
        Returns 
        ------- 
        y_pred : ndarray of shape (n_samples,) 
            The predicted labels or values for `X` based on the estimator with 
            the best found parameters. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s4">@</span><span class="s1">available_if</span><span class="s4">(</span><span class="s1">_estimator_has</span><span class="s4">(</span><span class="s5">&quot;predict_proba&quot;</span><span class="s4">))</span>
    <span class="s3">def </span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Call predict_proba on the estimator with the best found parameters. 
 
        Only available if ``refit=True`` and the underlying estimator supports 
        ``predict_proba``. 
 
        Parameters 
        ---------- 
        X : indexable, length n_samples 
            Must fulfill the input assumptions of the 
            underlying estimator. 
 
        Returns 
        ------- 
        y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes) 
            Predicted class probabilities for `X` based on the estimator with 
            the best found parameters. The order of the classes corresponds 
            to that in the fitted attribute :term:`classes_`. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s4">@</span><span class="s1">available_if</span><span class="s4">(</span><span class="s1">_estimator_has</span><span class="s4">(</span><span class="s5">&quot;predict_log_proba&quot;</span><span class="s4">))</span>
    <span class="s3">def </span><span class="s1">predict_log_proba</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Call predict_log_proba on the estimator with the best found parameters. 
 
        Only available if ``refit=True`` and the underlying estimator supports 
        ``predict_log_proba``. 
 
        Parameters 
        ---------- 
        X : indexable, length n_samples 
            Must fulfill the input assumptions of the 
            underlying estimator. 
 
        Returns 
        ------- 
        y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes) 
            Predicted class log-probabilities for `X` based on the estimator 
            with the best found parameters. The order of the classes 
            corresponds to that in the fitted attribute :term:`classes_`. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">.</span><span class="s1">predict_log_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s4">@</span><span class="s1">available_if</span><span class="s4">(</span><span class="s1">_estimator_has</span><span class="s4">(</span><span class="s5">&quot;decision_function&quot;</span><span class="s4">))</span>
    <span class="s3">def </span><span class="s1">decision_function</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Call decision_function on the estimator with the best found parameters. 
 
        Only available if ``refit=True`` and the underlying estimator supports 
        ``decision_function``. 
 
        Parameters 
        ---------- 
        X : indexable, length n_samples 
            Must fulfill the input assumptions of the 
            underlying estimator. 
 
        Returns 
        ------- 
        y_score : ndarray of shape (n_samples,) or (n_samples, n_classes) \ 
                or (n_samples, n_classes * (n_classes-1) / 2) 
            Result of the decision function for `X` based on the estimator with 
            the best found parameters. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">.</span><span class="s1">decision_function</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s4">@</span><span class="s1">available_if</span><span class="s4">(</span><span class="s1">_estimator_has</span><span class="s4">(</span><span class="s5">&quot;transform&quot;</span><span class="s4">))</span>
    <span class="s3">def </span><span class="s1">transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Call transform on the estimator with the best found parameters. 
 
        Only available if the underlying estimator supports ``transform`` and 
        ``refit=True``. 
 
        Parameters 
        ---------- 
        X : indexable, length n_samples 
            Must fulfill the input assumptions of the 
            underlying estimator. 
 
        Returns 
        ------- 
        Xt : {ndarray, sparse matrix} of shape (n_samples, n_features) 
            `X` transformed in the new space based on the estimator with 
            the best found parameters. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">.</span><span class="s1">transform</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s4">@</span><span class="s1">available_if</span><span class="s4">(</span><span class="s1">_estimator_has</span><span class="s4">(</span><span class="s5">&quot;inverse_transform&quot;</span><span class="s4">))</span>
    <span class="s3">def </span><span class="s1">inverse_transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, </span><span class="s1">Xt</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Call inverse_transform on the estimator with the best found params. 
 
        Only available if the underlying estimator implements 
        ``inverse_transform`` and ``refit=True``. 
 
        Parameters 
        ---------- 
        X : indexable, length n_samples 
            Must fulfill the input assumptions of the 
            underlying estimator. 
 
        Xt : indexable, length n_samples 
            Must fulfill the input assumptions of the 
            underlying estimator. 
 
            .. deprecated:: 1.5 
                `Xt` was deprecated in 1.5 and will be removed in 1.7. Use `X` instead. 
 
        Returns 
        ------- 
        X : {ndarray, sparse matrix} of shape (n_samples, n_features) 
            Result of the `inverse_transform` function for `Xt` based on the 
            estimator with the best found parameters. 
        &quot;&quot;&quot;</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">_deprecate_Xt_in_inverse_transform</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">Xt</span><span class="s4">)</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">.</span><span class="s1">inverse_transform</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s4">@</span><span class="s1">property</span>
    <span class="s3">def </span><span class="s1">n_features_in_</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Number of features seen during :term:`fit`. 
 
        Only available when `refit=True`. 
        &quot;&quot;&quot;</span>
        <span class="s2"># For consistency with other estimators we raise a AttributeError so</span>
        <span class="s2"># that hasattr() fails if the search estimator isn't fitted.</span>
        <span class="s3">try</span><span class="s4">:</span>
            <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s3">except </span><span class="s1">NotFittedError </span><span class="s3">as </span><span class="s1">nfe</span><span class="s4">:</span>
            <span class="s3">raise </span><span class="s1">AttributeError</span><span class="s4">(</span>
                <span class="s5">&quot;{} object has no n_features_in_ attribute.&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span>
                    <span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span>
                <span class="s4">)</span>
            <span class="s4">) </span><span class="s3">from </span><span class="s1">nfe</span>

        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">.</span><span class="s1">n_features_in_</span>

    <span class="s4">@</span><span class="s1">property</span>
    <span class="s3">def </span><span class="s1">classes_</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Class labels. 
 
        Only available when `refit=True` and the estimator is a classifier. 
        &quot;&quot;&quot;</span>
        <span class="s1">_estimator_has</span><span class="s4">(</span><span class="s5">&quot;classes_&quot;</span><span class="s4">)(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">.</span><span class="s1">classes_</span>

    <span class="s3">def </span><span class="s1">_run_search</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">evaluate_candidates</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Repeatedly calls `evaluate_candidates` to conduct a search. 
 
        This method, implemented in sub-classes, makes it possible to 
        customize the scheduling of evaluations: GridSearchCV and 
        RandomizedSearchCV schedule evaluations for their whole parameter 
        search space at once but other more sequential approaches are also 
        possible: for instance is possible to iteratively schedule evaluations 
        for new regions of the parameter search space based on previously 
        collected evaluation results. This makes it possible to implement 
        Bayesian optimization or more generally sequential model-based 
        optimization by deriving from the BaseSearchCV abstract base class. 
        For example, Successive Halving is implemented by calling 
        `evaluate_candidates` multiples times (once per iteration of the SH 
        process), each time passing a different set of candidates with `X` 
        and `y` of increasing sizes. 
 
        Parameters 
        ---------- 
        evaluate_candidates : callable 
            This callback accepts: 
                - a list of candidates, where each candidate is a dict of 
                  parameter settings. 
                - an optional `cv` parameter which can be used to e.g. 
                  evaluate candidates on different dataset splits, or 
                  evaluate candidates on subsampled data (as done in the 
                  SucessiveHaling estimators). By default, the original `cv` 
                  parameter is used, and it is available as a private 
                  `_checked_cv_orig` attribute. 
                - an optional `more_results` dict. Each key will be added to 
                  the `cv_results_` attribute. Values should be lists of 
                  length `n_candidates` 
 
            It returns a dict of all results so far, formatted like 
            ``cv_results_``. 
 
            Important note (relevant whether the default cv is used or not): 
            in randomized splitters, and unless the random_state parameter of 
            cv was set to an int, calling cv.split() multiple times will 
            yield different splits. Since cv.split() is called in 
            evaluate_candidates, this means that candidates will be evaluated 
            on different splits each time evaluate_candidates is called. This 
            might be a methodological issue depending on the search strategy 
            that you're implementing. To prevent randomized splitters from 
            being used, you may use _split._yields_constant_splits() 
 
        Examples 
        -------- 
 
        :: 
 
            def _run_search(self, evaluate_candidates): 
                'Try C=0.1 only if C=1 is better than C=10' 
                all_results = evaluate_candidates([{'C': 1}, {'C': 10}]) 
                score = all_results['mean_test_score'] 
                if score[0] &lt; score[1]: 
                    evaluate_candidates([{'C': 0.1}]) 
        &quot;&quot;&quot;</span>
        <span class="s3">raise </span><span class="s1">NotImplementedError</span><span class="s4">(</span><span class="s5">&quot;_run_search not implemented.&quot;</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_check_refit_for_multimetric</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">scores</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Check `refit` is compatible with `scores` is valid&quot;&quot;&quot;</span>
        <span class="s1">multimetric_refit_msg </span><span class="s4">= (</span>
            <span class="s5">&quot;For multi-metric scoring, the parameter refit must be set to a &quot;</span>
            <span class="s5">&quot;scorer key or a callable to refit an estimator with the best &quot;</span>
            <span class="s5">&quot;parameter setting on the whole data and make the best_* &quot;</span>
            <span class="s5">&quot;attributes available for that metric. If this is not needed, &quot;</span>
            <span class="s5">f&quot;refit should be set to False explicitly. </span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">refit</span><span class="s3">!r} </span><span class="s5">was &quot;</span>
            <span class="s5">&quot;passed.&quot;</span>
        <span class="s4">)</span>

        <span class="s1">valid_refit_dict </span><span class="s4">= </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">refit</span><span class="s4">, </span><span class="s1">str</span><span class="s4">) </span><span class="s3">and </span><span class="s1">self</span><span class="s4">.</span><span class="s1">refit </span><span class="s3">in </span><span class="s1">scores</span>

        <span class="s3">if </span><span class="s4">(</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">refit </span><span class="s3">is not False</span>
            <span class="s3">and not </span><span class="s1">valid_refit_dict</span>
            <span class="s3">and not </span><span class="s1">callable</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">refit</span><span class="s4">)</span>
        <span class="s4">):</span>
            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span><span class="s1">multimetric_refit_msg</span><span class="s4">)</span>

    <span class="s4">@</span><span class="s1">staticmethod</span>
    <span class="s3">def </span><span class="s1">_select_best_index</span><span class="s4">(</span><span class="s1">refit</span><span class="s4">, </span><span class="s1">refit_metric</span><span class="s4">, </span><span class="s1">results</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Select index of the best combination of hyperparemeters.&quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">callable</span><span class="s4">(</span><span class="s1">refit</span><span class="s4">):</span>
            <span class="s2"># If callable, refit is expected to return the index of the best</span>
            <span class="s2"># parameter set.</span>
            <span class="s1">best_index </span><span class="s4">= </span><span class="s1">refit</span><span class="s4">(</span><span class="s1">results</span><span class="s4">)</span>
            <span class="s3">if not </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">best_index</span><span class="s4">, </span><span class="s1">numbers</span><span class="s4">.</span><span class="s1">Integral</span><span class="s4">):</span>
                <span class="s3">raise </span><span class="s1">TypeError</span><span class="s4">(</span><span class="s5">&quot;best_index_ returned is not an integer&quot;</span><span class="s4">)</span>
            <span class="s3">if </span><span class="s1">best_index </span><span class="s4">&lt; </span><span class="s6">0 </span><span class="s3">or </span><span class="s1">best_index </span><span class="s4">&gt;= </span><span class="s1">len</span><span class="s4">(</span><span class="s1">results</span><span class="s4">[</span><span class="s5">&quot;params&quot;</span><span class="s4">]):</span>
                <span class="s3">raise </span><span class="s1">IndexError</span><span class="s4">(</span><span class="s5">&quot;best_index_ index out of range&quot;</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">best_index </span><span class="s4">= </span><span class="s1">results</span><span class="s4">[</span><span class="s5">f&quot;rank_test_</span><span class="s3">{</span><span class="s1">refit_metric</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s4">].</span><span class="s1">argmin</span><span class="s4">()</span>
        <span class="s3">return </span><span class="s1">best_index</span>

    <span class="s3">def </span><span class="s1">_get_scorers</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Get the scorer(s) to be used. 
 
        This is used in ``fit`` and ``get_metadata_routing``. 
 
        Returns 
        ------- 
        scorers, refit_metric 
        &quot;&quot;&quot;</span>
        <span class="s1">refit_metric </span><span class="s4">= </span><span class="s5">&quot;score&quot;</span>

        <span class="s3">if </span><span class="s1">callable</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">scoring</span><span class="s4">):</span>
            <span class="s1">scorers </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">scoring</span>
        <span class="s3">elif </span><span class="s1">self</span><span class="s4">.</span><span class="s1">scoring </span><span class="s3">is None or </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">scoring</span><span class="s4">, </span><span class="s1">str</span><span class="s4">):</span>
            <span class="s1">scorers </span><span class="s4">= </span><span class="s1">check_scoring</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">estimator</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">scoring</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">scorers </span><span class="s4">= </span><span class="s1">_check_multimetric_scoring</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">estimator</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">scoring</span><span class="s4">)</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_check_refit_for_multimetric</span><span class="s4">(</span><span class="s1">scorers</span><span class="s4">)</span>
            <span class="s1">refit_metric </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">refit</span>
            <span class="s1">scorers </span><span class="s4">= </span><span class="s1">_MultimetricScorer</span><span class="s4">(</span>
                <span class="s1">scorers</span><span class="s4">=</span><span class="s1">scorers</span><span class="s4">, </span><span class="s1">raise_exc</span><span class="s4">=(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">error_score </span><span class="s4">== </span><span class="s5">&quot;raise&quot;</span><span class="s4">)</span>
            <span class="s4">)</span>

        <span class="s3">return </span><span class="s1">scorers</span><span class="s4">, </span><span class="s1">refit_metric</span>

    <span class="s3">def </span><span class="s1">_get_routed_params_for_fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">params</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Get the parameters to be used for routing. 
 
        This is a method instead of a snippet in ``fit`` since it's used twice, 
        here in ``fit``, and in ``HalvingRandomSearchCV.fit``. 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">_routing_enabled</span><span class="s4">():</span>
            <span class="s1">routed_params </span><span class="s4">= </span><span class="s1">process_routing</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;fit&quot;</span><span class="s4">, **</span><span class="s1">params</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">params </span><span class="s4">= </span><span class="s1">params</span><span class="s4">.</span><span class="s1">copy</span><span class="s4">()</span>
            <span class="s1">groups </span><span class="s4">= </span><span class="s1">params</span><span class="s4">.</span><span class="s1">pop</span><span class="s4">(</span><span class="s5">&quot;groups&quot;</span><span class="s4">, </span><span class="s3">None</span><span class="s4">)</span>
            <span class="s1">routed_params </span><span class="s4">= </span><span class="s1">Bunch</span><span class="s4">(</span>
                <span class="s1">estimator</span><span class="s4">=</span><span class="s1">Bunch</span><span class="s4">(</span><span class="s1">fit</span><span class="s4">=</span><span class="s1">params</span><span class="s4">),</span>
                <span class="s1">splitter</span><span class="s4">=</span><span class="s1">Bunch</span><span class="s4">(</span><span class="s1">split</span><span class="s4">={</span><span class="s5">&quot;groups&quot;</span><span class="s4">: </span><span class="s1">groups</span><span class="s4">}),</span>
                <span class="s1">scorer</span><span class="s4">=</span><span class="s1">Bunch</span><span class="s4">(</span><span class="s1">score</span><span class="s4">={}),</span>
            <span class="s4">)</span>
        <span class="s3">return </span><span class="s1">routed_params</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span>
        <span class="s2"># *SearchCV.estimator is not validated yet</span>
        <span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">False</span>
    <span class="s4">)</span>
    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, **</span><span class="s1">params</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Run fit with all sets of parameters. 
 
        Parameters 
        ---------- 
 
        X : array-like of shape (n_samples, n_features) or (n_samples, n_samples) 
            Training vectors, where `n_samples` is the number of samples and 
            `n_features` is the number of features. For precomputed kernel or 
            distance matrix, the expected shape of X is (n_samples, n_samples). 
 
        y : array-like of shape (n_samples, n_output) \ 
            or (n_samples,), default=None 
            Target relative to X for classification or regression; 
            None for unsupervised learning. 
 
        **params : dict of str -&gt; object 
            Parameters passed to the ``fit`` method of the estimator, the scorer, 
            and the CV splitter. 
 
            If a fit parameter is an array-like whose length is equal to 
            `num_samples` then it will be split across CV groups along with `X` 
            and `y`. For example, the :term:`sample_weight` parameter is split 
            because `len(sample_weights) = len(X)`. 
 
        Returns 
        ------- 
        self : object 
            Instance of fitted estimator. 
        &quot;&quot;&quot;</span>
        <span class="s1">estimator </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">estimator</span>
        <span class="s1">scorers</span><span class="s4">, </span><span class="s1">refit_metric </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_get_scorers</span><span class="s4">()</span>

        <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">indexable</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
        <span class="s1">params </span><span class="s4">= </span><span class="s1">_check_method_params</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">params</span><span class="s4">=</span><span class="s1">params</span><span class="s4">)</span>

        <span class="s1">routed_params </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_get_routed_params_for_fit</span><span class="s4">(</span><span class="s1">params</span><span class="s4">)</span>

        <span class="s1">cv_orig </span><span class="s4">= </span><span class="s1">check_cv</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">cv</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">classifier</span><span class="s4">=</span><span class="s1">is_classifier</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">))</span>
        <span class="s1">n_splits </span><span class="s4">= </span><span class="s1">cv_orig</span><span class="s4">.</span><span class="s1">get_n_splits</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, **</span><span class="s1">routed_params</span><span class="s4">.</span><span class="s1">splitter</span><span class="s4">.</span><span class="s1">split</span><span class="s4">)</span>

        <span class="s1">base_estimator </span><span class="s4">= </span><span class="s1">clone</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">estimator</span><span class="s4">)</span>

        <span class="s1">parallel </span><span class="s4">= </span><span class="s1">Parallel</span><span class="s4">(</span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_jobs</span><span class="s4">, </span><span class="s1">pre_dispatch</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">pre_dispatch</span><span class="s4">)</span>

        <span class="s1">fit_and_score_kwargs </span><span class="s4">= </span><span class="s1">dict</span><span class="s4">(</span>
            <span class="s1">scorer</span><span class="s4">=</span><span class="s1">scorers</span><span class="s4">,</span>
            <span class="s1">fit_params</span><span class="s4">=</span><span class="s1">routed_params</span><span class="s4">.</span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">,</span>
            <span class="s1">score_params</span><span class="s4">=</span><span class="s1">routed_params</span><span class="s4">.</span><span class="s1">scorer</span><span class="s4">.</span><span class="s1">score</span><span class="s4">,</span>
            <span class="s1">return_train_score</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">return_train_score</span><span class="s4">,</span>
            <span class="s1">return_n_test_samples</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">return_times</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">return_parameters</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
            <span class="s1">error_score</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">error_score</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">results </span><span class="s4">= {}</span>
        <span class="s3">with </span><span class="s1">parallel</span><span class="s4">:</span>
            <span class="s1">all_candidate_params </span><span class="s4">= []</span>
            <span class="s1">all_out </span><span class="s4">= []</span>
            <span class="s1">all_more_results </span><span class="s4">= </span><span class="s1">defaultdict</span><span class="s4">(</span><span class="s1">list</span><span class="s4">)</span>

            <span class="s3">def </span><span class="s1">evaluate_candidates</span><span class="s4">(</span><span class="s1">candidate_params</span><span class="s4">, </span><span class="s1">cv</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, </span><span class="s1">more_results</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
                <span class="s1">cv </span><span class="s4">= </span><span class="s1">cv </span><span class="s3">or </span><span class="s1">cv_orig</span>
                <span class="s1">candidate_params </span><span class="s4">= </span><span class="s1">list</span><span class="s4">(</span><span class="s1">candidate_params</span><span class="s4">)</span>
                <span class="s1">n_candidates </span><span class="s4">= </span><span class="s1">len</span><span class="s4">(</span><span class="s1">candidate_params</span><span class="s4">)</span>

                <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose </span><span class="s4">&gt; </span><span class="s6">0</span><span class="s4">:</span>
                    <span class="s1">print</span><span class="s4">(</span>
                        <span class="s5">&quot;Fitting {0} folds for each of {1} candidates,&quot;</span>
                        <span class="s5">&quot; totalling {2} fits&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span>
                            <span class="s1">n_splits</span><span class="s4">, </span><span class="s1">n_candidates</span><span class="s4">, </span><span class="s1">n_candidates </span><span class="s4">* </span><span class="s1">n_splits</span>
                        <span class="s4">)</span>
                    <span class="s4">)</span>

                <span class="s1">out </span><span class="s4">= </span><span class="s1">parallel</span><span class="s4">(</span>
                    <span class="s1">delayed</span><span class="s4">(</span><span class="s1">_fit_and_score</span><span class="s4">)(</span>
                        <span class="s1">clone</span><span class="s4">(</span><span class="s1">base_estimator</span><span class="s4">),</span>
                        <span class="s1">X</span><span class="s4">,</span>
                        <span class="s1">y</span><span class="s4">,</span>
                        <span class="s1">train</span><span class="s4">=</span><span class="s1">train</span><span class="s4">,</span>
                        <span class="s1">test</span><span class="s4">=</span><span class="s1">test</span><span class="s4">,</span>
                        <span class="s1">parameters</span><span class="s4">=</span><span class="s1">parameters</span><span class="s4">,</span>
                        <span class="s1">split_progress</span><span class="s4">=(</span><span class="s1">split_idx</span><span class="s4">, </span><span class="s1">n_splits</span><span class="s4">),</span>
                        <span class="s1">candidate_progress</span><span class="s4">=(</span><span class="s1">cand_idx</span><span class="s4">, </span><span class="s1">n_candidates</span><span class="s4">),</span>
                        <span class="s4">**</span><span class="s1">fit_and_score_kwargs</span><span class="s4">,</span>
                    <span class="s4">)</span>
                    <span class="s3">for </span><span class="s4">(</span><span class="s1">cand_idx</span><span class="s4">, </span><span class="s1">parameters</span><span class="s4">), (</span><span class="s1">split_idx</span><span class="s4">, (</span><span class="s1">train</span><span class="s4">, </span><span class="s1">test</span><span class="s4">)) </span><span class="s3">in </span><span class="s1">product</span><span class="s4">(</span>
                        <span class="s1">enumerate</span><span class="s4">(</span><span class="s1">candidate_params</span><span class="s4">),</span>
                        <span class="s1">enumerate</span><span class="s4">(</span><span class="s1">cv</span><span class="s4">.</span><span class="s1">split</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, **</span><span class="s1">routed_params</span><span class="s4">.</span><span class="s1">splitter</span><span class="s4">.</span><span class="s1">split</span><span class="s4">)),</span>
                    <span class="s4">)</span>
                <span class="s4">)</span>

                <span class="s3">if </span><span class="s1">len</span><span class="s4">(</span><span class="s1">out</span><span class="s4">) &lt; </span><span class="s6">1</span><span class="s4">:</span>
                    <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                        <span class="s5">&quot;No fits were performed. &quot;</span>
                        <span class="s5">&quot;Was the CV iterator empty? &quot;</span>
                        <span class="s5">&quot;Were there no candidates?&quot;</span>
                    <span class="s4">)</span>
                <span class="s3">elif </span><span class="s1">len</span><span class="s4">(</span><span class="s1">out</span><span class="s4">) != </span><span class="s1">n_candidates </span><span class="s4">* </span><span class="s1">n_splits</span><span class="s4">:</span>
                    <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
                        <span class="s5">&quot;cv.split and cv.get_n_splits returned &quot;</span>
                        <span class="s5">&quot;inconsistent results. Expected {} &quot;</span>
                        <span class="s5">&quot;splits, got {}&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span><span class="s1">n_splits</span><span class="s4">, </span><span class="s1">len</span><span class="s4">(</span><span class="s1">out</span><span class="s4">) // </span><span class="s1">n_candidates</span><span class="s4">)</span>
                    <span class="s4">)</span>

                <span class="s1">_warn_or_raise_about_fit_failures</span><span class="s4">(</span><span class="s1">out</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">error_score</span><span class="s4">)</span>

                <span class="s2"># For callable self.scoring, the return type is only know after</span>
                <span class="s2"># calling. If the return type is a dictionary, the error scores</span>
                <span class="s2"># can now be inserted with the correct key. The type checking</span>
                <span class="s2"># of out will be done in `_insert_error_scores`.</span>
                <span class="s3">if </span><span class="s1">callable</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">scoring</span><span class="s4">):</span>
                    <span class="s1">_insert_error_scores</span><span class="s4">(</span><span class="s1">out</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">error_score</span><span class="s4">)</span>

                <span class="s1">all_candidate_params</span><span class="s4">.</span><span class="s1">extend</span><span class="s4">(</span><span class="s1">candidate_params</span><span class="s4">)</span>
                <span class="s1">all_out</span><span class="s4">.</span><span class="s1">extend</span><span class="s4">(</span><span class="s1">out</span><span class="s4">)</span>

                <span class="s3">if </span><span class="s1">more_results </span><span class="s3">is not None</span><span class="s4">:</span>
                    <span class="s3">for </span><span class="s1">key</span><span class="s4">, </span><span class="s1">value </span><span class="s3">in </span><span class="s1">more_results</span><span class="s4">.</span><span class="s1">items</span><span class="s4">():</span>
                        <span class="s1">all_more_results</span><span class="s4">[</span><span class="s1">key</span><span class="s4">].</span><span class="s1">extend</span><span class="s4">(</span><span class="s1">value</span><span class="s4">)</span>

                <span class="s3">nonlocal </span><span class="s1">results</span>
                <span class="s1">results </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_format_results</span><span class="s4">(</span>
                    <span class="s1">all_candidate_params</span><span class="s4">, </span><span class="s1">n_splits</span><span class="s4">, </span><span class="s1">all_out</span><span class="s4">, </span><span class="s1">all_more_results</span>
                <span class="s4">)</span>

                <span class="s3">return </span><span class="s1">results</span>

            <span class="s1">self</span><span class="s4">.</span><span class="s1">_run_search</span><span class="s4">(</span><span class="s1">evaluate_candidates</span><span class="s4">)</span>

            <span class="s2"># multimetric is determined here because in the case of a callable</span>
            <span class="s2"># self.scoring the return type is only known after calling</span>
            <span class="s1">first_test_score </span><span class="s4">= </span><span class="s1">all_out</span><span class="s4">[</span><span class="s6">0</span><span class="s4">][</span><span class="s5">&quot;test_scores&quot;</span><span class="s4">]</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">multimetric_ </span><span class="s4">= </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">first_test_score</span><span class="s4">, </span><span class="s1">dict</span><span class="s4">)</span>

            <span class="s2"># check refit_metric now for a callabe scorer that is multimetric</span>
            <span class="s3">if </span><span class="s1">callable</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">scoring</span><span class="s4">) </span><span class="s3">and </span><span class="s1">self</span><span class="s4">.</span><span class="s1">multimetric_</span><span class="s4">:</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">_check_refit_for_multimetric</span><span class="s4">(</span><span class="s1">first_test_score</span><span class="s4">)</span>
                <span class="s1">refit_metric </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">refit</span>

        <span class="s2"># For multi-metric evaluation, store the best_index_, best_params_ and</span>
        <span class="s2"># best_score_ iff refit is one of the scorer names</span>
        <span class="s2"># In single metric evaluation, refit_metric is &quot;score&quot;</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">refit </span><span class="s3">or not </span><span class="s1">self</span><span class="s4">.</span><span class="s1">multimetric_</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">best_index_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_select_best_index</span><span class="s4">(</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">refit</span><span class="s4">, </span><span class="s1">refit_metric</span><span class="s4">, </span><span class="s1">results</span>
            <span class="s4">)</span>
            <span class="s3">if not </span><span class="s1">callable</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">refit</span><span class="s4">):</span>
                <span class="s2"># With a non-custom callable, we can select the best score</span>
                <span class="s2"># based on the best index</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">best_score_ </span><span class="s4">= </span><span class="s1">results</span><span class="s4">[</span><span class="s5">f&quot;mean_test_</span><span class="s3">{</span><span class="s1">refit_metric</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s4">][</span>
                    <span class="s1">self</span><span class="s4">.</span><span class="s1">best_index_</span>
                <span class="s4">]</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">best_params_ </span><span class="s4">= </span><span class="s1">results</span><span class="s4">[</span><span class="s5">&quot;params&quot;</span><span class="s4">][</span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_index_</span><span class="s4">]</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">refit</span><span class="s4">:</span>
            <span class="s2"># here we clone the estimator as well as the parameters, since</span>
            <span class="s2"># sometimes the parameters themselves might be estimators, e.g.</span>
            <span class="s2"># when we search over different estimators in a pipeline.</span>
            <span class="s2"># ref: https://github.com/scikit-learn/scikit-learn/pull/26786</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_ </span><span class="s4">= </span><span class="s1">clone</span><span class="s4">(</span><span class="s1">base_estimator</span><span class="s4">).</span><span class="s1">set_params</span><span class="s4">(</span>
                <span class="s4">**</span><span class="s1">clone</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_params_</span><span class="s4">, </span><span class="s1">safe</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>
            <span class="s4">)</span>

            <span class="s1">refit_start_time </span><span class="s4">= </span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">()</span>
            <span class="s3">if </span><span class="s1">y </span><span class="s3">is not None</span><span class="s4">:</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, **</span><span class="s1">routed_params</span><span class="s4">.</span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">)</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, **</span><span class="s1">routed_params</span><span class="s4">.</span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">)</span>
            <span class="s1">refit_end_time </span><span class="s4">= </span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">()</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">refit_time_ </span><span class="s4">= </span><span class="s1">refit_end_time </span><span class="s4">- </span><span class="s1">refit_start_time</span>

            <span class="s3">if </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">, </span><span class="s5">&quot;feature_names_in_&quot;</span><span class="s4">):</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">feature_names_in_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span><span class="s4">.</span><span class="s1">feature_names_in_</span>

        <span class="s2"># Store the only scorer not as a dict for single metric evaluation</span>
        <span class="s3">if </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">scorers</span><span class="s4">, </span><span class="s1">_MultimetricScorer</span><span class="s4">):</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">scorer_ </span><span class="s4">= </span><span class="s1">scorers</span><span class="s4">.</span><span class="s1">_scorers</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">scorer_ </span><span class="s4">= </span><span class="s1">scorers</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">cv_results_ </span><span class="s4">= </span><span class="s1">results</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_splits_ </span><span class="s4">= </span><span class="s1">n_splits</span>

        <span class="s3">return </span><span class="s1">self</span>

    <span class="s3">def </span><span class="s1">_format_results</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">candidate_params</span><span class="s4">, </span><span class="s1">n_splits</span><span class="s4">, </span><span class="s1">out</span><span class="s4">, </span><span class="s1">more_results</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s1">n_candidates </span><span class="s4">= </span><span class="s1">len</span><span class="s4">(</span><span class="s1">candidate_params</span><span class="s4">)</span>
        <span class="s1">out </span><span class="s4">= </span><span class="s1">_aggregate_score_dicts</span><span class="s4">(</span><span class="s1">out</span><span class="s4">)</span>

        <span class="s1">results </span><span class="s4">= </span><span class="s1">dict</span><span class="s4">(</span><span class="s1">more_results </span><span class="s3">or </span><span class="s4">{})</span>
        <span class="s3">for </span><span class="s1">key</span><span class="s4">, </span><span class="s1">val </span><span class="s3">in </span><span class="s1">results</span><span class="s4">.</span><span class="s1">items</span><span class="s4">():</span>
            <span class="s2"># each value is a list (as per evaluate_candidate's convention)</span>
            <span class="s2"># we convert it to an array for consistency with the other keys</span>
            <span class="s1">results</span><span class="s4">[</span><span class="s1">key</span><span class="s4">] = </span><span class="s1">np</span><span class="s4">.</span><span class="s1">asarray</span><span class="s4">(</span><span class="s1">val</span><span class="s4">)</span>

        <span class="s3">def </span><span class="s1">_store</span><span class="s4">(</span><span class="s1">key_name</span><span class="s4">, </span><span class="s1">array</span><span class="s4">, </span><span class="s1">weights</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, </span><span class="s1">splits</span><span class="s4">=</span><span class="s3">False</span><span class="s4">, </span><span class="s1">rank</span><span class="s4">=</span><span class="s3">False</span><span class="s4">):</span>
            <span class="s0">&quot;&quot;&quot;A small helper to store the scores/times to the cv_results_&quot;&quot;&quot;</span>
            <span class="s2"># When iterated first by splits, then by parameters</span>
            <span class="s2"># We want `array` to have `n_candidates` rows and `n_splits` cols.</span>
            <span class="s1">array </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span><span class="s1">array</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">).</span><span class="s1">reshape</span><span class="s4">(</span><span class="s1">n_candidates</span><span class="s4">, </span><span class="s1">n_splits</span><span class="s4">)</span>
            <span class="s3">if </span><span class="s1">splits</span><span class="s4">:</span>
                <span class="s3">for </span><span class="s1">split_idx </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">n_splits</span><span class="s4">):</span>
                    <span class="s2"># Uses closure to alter the results</span>
                    <span class="s1">results</span><span class="s4">[</span><span class="s5">&quot;split%d_%s&quot; </span><span class="s4">% (</span><span class="s1">split_idx</span><span class="s4">, </span><span class="s1">key_name</span><span class="s4">)] = </span><span class="s1">array</span><span class="s4">[:, </span><span class="s1">split_idx</span><span class="s4">]</span>

            <span class="s1">array_means </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">average</span><span class="s4">(</span><span class="s1">array</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">weights</span><span class="s4">=</span><span class="s1">weights</span><span class="s4">)</span>
            <span class="s1">results</span><span class="s4">[</span><span class="s5">&quot;mean_%s&quot; </span><span class="s4">% </span><span class="s1">key_name</span><span class="s4">] = </span><span class="s1">array_means</span>

            <span class="s3">if </span><span class="s1">key_name</span><span class="s4">.</span><span class="s1">startswith</span><span class="s4">((</span><span class="s5">&quot;train_&quot;</span><span class="s4">, </span><span class="s5">&quot;test_&quot;</span><span class="s4">)) </span><span class="s3">and </span><span class="s1">np</span><span class="s4">.</span><span class="s1">any</span><span class="s4">(</span>
                <span class="s4">~</span><span class="s1">np</span><span class="s4">.</span><span class="s1">isfinite</span><span class="s4">(</span><span class="s1">array_means</span><span class="s4">)</span>
            <span class="s4">):</span>
                <span class="s1">warnings</span><span class="s4">.</span><span class="s1">warn</span><span class="s4">(</span>
                    <span class="s4">(</span>
                        <span class="s5">f&quot;One or more of the </span><span class="s3">{</span><span class="s1">key_name</span><span class="s4">.</span><span class="s1">split</span><span class="s4">(</span><span class="s5">'_'</span><span class="s4">)[</span><span class="s6">0</span><span class="s4">]</span><span class="s3">} </span><span class="s5">scores &quot;</span>
                        <span class="s5">f&quot;are non-finite: </span><span class="s3">{</span><span class="s1">array_means</span><span class="s3">}</span><span class="s5">&quot;</span>
                    <span class="s4">),</span>
                    <span class="s1">category</span><span class="s4">=</span><span class="s1">UserWarning</span><span class="s4">,</span>
                <span class="s4">)</span>

            <span class="s2"># Weighted std is not directly available in numpy</span>
            <span class="s1">array_stds </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sqrt</span><span class="s4">(</span>
                <span class="s1">np</span><span class="s4">.</span><span class="s1">average</span><span class="s4">(</span>
                    <span class="s4">(</span><span class="s1">array </span><span class="s4">- </span><span class="s1">array_means</span><span class="s4">[:, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">newaxis</span><span class="s4">]) ** </span><span class="s6">2</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">weights</span><span class="s4">=</span><span class="s1">weights</span>
                <span class="s4">)</span>
            <span class="s4">)</span>
            <span class="s1">results</span><span class="s4">[</span><span class="s5">&quot;std_%s&quot; </span><span class="s4">% </span><span class="s1">key_name</span><span class="s4">] = </span><span class="s1">array_stds</span>

            <span class="s3">if </span><span class="s1">rank</span><span class="s4">:</span>
                <span class="s2"># When the fit/scoring fails `array_means` contains NaNs, we</span>
                <span class="s2"># will exclude them from the ranking process and consider them</span>
                <span class="s2"># as tied with the worst performers.</span>
                <span class="s3">if </span><span class="s1">np</span><span class="s4">.</span><span class="s1">isnan</span><span class="s4">(</span><span class="s1">array_means</span><span class="s4">).</span><span class="s1">all</span><span class="s4">():</span>
                    <span class="s2"># All fit/scoring routines failed.</span>
                    <span class="s1">rank_result </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ones_like</span><span class="s4">(</span><span class="s1">array_means</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">int32</span><span class="s4">)</span>
                <span class="s3">else</span><span class="s4">:</span>
                    <span class="s1">min_array_means </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">nanmin</span><span class="s4">(</span><span class="s1">array_means</span><span class="s4">) - </span><span class="s6">1</span>
                    <span class="s1">array_means </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">nan_to_num</span><span class="s4">(</span><span class="s1">array_means</span><span class="s4">, </span><span class="s1">nan</span><span class="s4">=</span><span class="s1">min_array_means</span><span class="s4">)</span>
                    <span class="s1">rank_result </span><span class="s4">= </span><span class="s1">rankdata</span><span class="s4">(-</span><span class="s1">array_means</span><span class="s4">, </span><span class="s1">method</span><span class="s4">=</span><span class="s5">&quot;min&quot;</span><span class="s4">).</span><span class="s1">astype</span><span class="s4">(</span>
                        <span class="s1">np</span><span class="s4">.</span><span class="s1">int32</span><span class="s4">, </span><span class="s1">copy</span><span class="s4">=</span><span class="s3">False</span>
                    <span class="s4">)</span>
                <span class="s1">results</span><span class="s4">[</span><span class="s5">&quot;rank_%s&quot; </span><span class="s4">% </span><span class="s1">key_name</span><span class="s4">] = </span><span class="s1">rank_result</span>

        <span class="s1">_store</span><span class="s4">(</span><span class="s5">&quot;fit_time&quot;</span><span class="s4">, </span><span class="s1">out</span><span class="s4">[</span><span class="s5">&quot;fit_time&quot;</span><span class="s4">])</span>
        <span class="s1">_store</span><span class="s4">(</span><span class="s5">&quot;score_time&quot;</span><span class="s4">, </span><span class="s1">out</span><span class="s4">[</span><span class="s5">&quot;score_time&quot;</span><span class="s4">])</span>
        <span class="s2"># Store a list of param dicts at the key 'params'</span>
        <span class="s3">for </span><span class="s1">param</span><span class="s4">, </span><span class="s1">ma </span><span class="s3">in </span><span class="s1">_yield_masked_array_for_each_param</span><span class="s4">(</span><span class="s1">candidate_params</span><span class="s4">):</span>
            <span class="s1">results</span><span class="s4">[</span><span class="s1">param</span><span class="s4">] = </span><span class="s1">ma</span>
        <span class="s1">results</span><span class="s4">[</span><span class="s5">&quot;params&quot;</span><span class="s4">] = </span><span class="s1">candidate_params</span>

        <span class="s1">test_scores_dict </span><span class="s4">= </span><span class="s1">_normalize_score_results</span><span class="s4">(</span><span class="s1">out</span><span class="s4">[</span><span class="s5">&quot;test_scores&quot;</span><span class="s4">])</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">return_train_score</span><span class="s4">:</span>
            <span class="s1">train_scores_dict </span><span class="s4">= </span><span class="s1">_normalize_score_results</span><span class="s4">(</span><span class="s1">out</span><span class="s4">[</span><span class="s5">&quot;train_scores&quot;</span><span class="s4">])</span>

        <span class="s3">for </span><span class="s1">scorer_name </span><span class="s3">in </span><span class="s1">test_scores_dict</span><span class="s4">:</span>
            <span class="s2"># Computed the (weighted) mean and std for test scores alone</span>
            <span class="s1">_store</span><span class="s4">(</span>
                <span class="s5">&quot;test_%s&quot; </span><span class="s4">% </span><span class="s1">scorer_name</span><span class="s4">,</span>
                <span class="s1">test_scores_dict</span><span class="s4">[</span><span class="s1">scorer_name</span><span class="s4">],</span>
                <span class="s1">splits</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
                <span class="s1">rank</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
                <span class="s1">weights</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
            <span class="s4">)</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">return_train_score</span><span class="s4">:</span>
                <span class="s1">_store</span><span class="s4">(</span>
                    <span class="s5">&quot;train_%s&quot; </span><span class="s4">% </span><span class="s1">scorer_name</span><span class="s4">,</span>
                    <span class="s1">train_scores_dict</span><span class="s4">[</span><span class="s1">scorer_name</span><span class="s4">],</span>
                    <span class="s1">splits</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
                <span class="s4">)</span>

        <span class="s3">return </span><span class="s1">results</span>

    <span class="s3">def </span><span class="s1">get_metadata_routing</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Get metadata routing of this object. 
 
        Please check :ref:`User Guide &lt;metadata_routing&gt;` on how the routing 
        mechanism works. 
 
        .. versionadded:: 1.4 
 
        Returns 
        ------- 
        routing : MetadataRouter 
            A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating 
            routing information. 
        &quot;&quot;&quot;</span>
        <span class="s1">router </span><span class="s4">= </span><span class="s1">MetadataRouter</span><span class="s4">(</span><span class="s1">owner</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s4">)</span>
        <span class="s1">router</span><span class="s4">.</span><span class="s1">add</span><span class="s4">(</span>
            <span class="s1">estimator</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">estimator</span><span class="s4">,</span>
            <span class="s1">method_mapping</span><span class="s4">=</span><span class="s1">MethodMapping</span><span class="s4">().</span><span class="s1">add</span><span class="s4">(</span><span class="s1">caller</span><span class="s4">=</span><span class="s5">&quot;fit&quot;</span><span class="s4">, </span><span class="s1">callee</span><span class="s4">=</span><span class="s5">&quot;fit&quot;</span><span class="s4">),</span>
        <span class="s4">)</span>

        <span class="s1">scorer</span><span class="s4">, </span><span class="s1">_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_get_scorers</span><span class="s4">()</span>
        <span class="s1">router</span><span class="s4">.</span><span class="s1">add</span><span class="s4">(</span>
            <span class="s1">scorer</span><span class="s4">=</span><span class="s1">scorer</span><span class="s4">,</span>
            <span class="s1">method_mapping</span><span class="s4">=</span><span class="s1">MethodMapping</span><span class="s4">()</span>
            <span class="s4">.</span><span class="s1">add</span><span class="s4">(</span><span class="s1">caller</span><span class="s4">=</span><span class="s5">&quot;score&quot;</span><span class="s4">, </span><span class="s1">callee</span><span class="s4">=</span><span class="s5">&quot;score&quot;</span><span class="s4">)</span>
            <span class="s4">.</span><span class="s1">add</span><span class="s4">(</span><span class="s1">caller</span><span class="s4">=</span><span class="s5">&quot;fit&quot;</span><span class="s4">, </span><span class="s1">callee</span><span class="s4">=</span><span class="s5">&quot;score&quot;</span><span class="s4">),</span>
        <span class="s4">)</span>
        <span class="s1">router</span><span class="s4">.</span><span class="s1">add</span><span class="s4">(</span>
            <span class="s1">splitter</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">cv</span><span class="s4">,</span>
            <span class="s1">method_mapping</span><span class="s4">=</span><span class="s1">MethodMapping</span><span class="s4">().</span><span class="s1">add</span><span class="s4">(</span><span class="s1">caller</span><span class="s4">=</span><span class="s5">&quot;fit&quot;</span><span class="s4">, </span><span class="s1">callee</span><span class="s4">=</span><span class="s5">&quot;split&quot;</span><span class="s4">),</span>
        <span class="s4">)</span>
        <span class="s3">return </span><span class="s1">router</span>

    <span class="s3">def </span><span class="s1">_sk_visual_block_</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">if </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;best_estimator_&quot;</span><span class="s4">):</span>
            <span class="s1">key</span><span class="s4">, </span><span class="s1">estimator </span><span class="s4">= </span><span class="s5">&quot;best_estimator_&quot;</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">best_estimator_</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">key</span><span class="s4">, </span><span class="s1">estimator </span><span class="s4">= </span><span class="s5">&quot;estimator&quot;</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">estimator</span>

        <span class="s3">return </span><span class="s1">_VisualBlock</span><span class="s4">(</span>
            <span class="s5">&quot;parallel&quot;</span><span class="s4">,</span>
            <span class="s4">[</span><span class="s1">estimator</span><span class="s4">],</span>
            <span class="s1">names</span><span class="s4">=[</span><span class="s5">f&quot;</span><span class="s3">{</span><span class="s1">key</span><span class="s3">}</span><span class="s5">: </span><span class="s3">{</span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s4">],</span>
            <span class="s1">name_details</span><span class="s4">=[</span><span class="s1">str</span><span class="s4">(</span><span class="s1">estimator</span><span class="s4">)],</span>
        <span class="s4">)</span>


<span class="s3">class </span><span class="s1">GridSearchCV</span><span class="s4">(</span><span class="s1">BaseSearchCV</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Exhaustive search over specified parameter values for an estimator. 
 
    Important members are fit, predict. 
 
    GridSearchCV implements a &quot;fit&quot; and a &quot;score&quot; method. 
    It also implements &quot;score_samples&quot;, &quot;predict&quot;, &quot;predict_proba&quot;, 
    &quot;decision_function&quot;, &quot;transform&quot; and &quot;inverse_transform&quot; if they are 
    implemented in the estimator used. 
 
    The parameters of the estimator used to apply these methods are optimized 
    by cross-validated grid-search over a parameter grid. 
 
    Read more in the :ref:`User Guide &lt;grid_search&gt;`. 
 
    Parameters 
    ---------- 
    estimator : estimator object 
        This is assumed to implement the scikit-learn estimator interface. 
        Either estimator needs to provide a ``score`` function, 
        or ``scoring`` must be passed. 
 
    param_grid : dict or list of dictionaries 
        Dictionary with parameters names (`str`) as keys and lists of 
        parameter settings to try as values, or a list of such 
        dictionaries, in which case the grids spanned by each dictionary 
        in the list are explored. This enables searching over any sequence 
        of parameter settings. 
 
    scoring : str, callable, list, tuple or dict, default=None 
        Strategy to evaluate the performance of the cross-validated model on 
        the test set. 
 
        If `scoring` represents a single score, one can use: 
 
        - a single string (see :ref:`scoring_parameter`); 
        - a callable (see :ref:`scoring`) that returns a single value. 
 
        If `scoring` represents multiple scores, one can use: 
 
        - a list or tuple of unique strings; 
        - a callable returning a dictionary where the keys are the metric 
          names and the values are the metric scores; 
        - a dictionary with metric names as keys and callables a values. 
 
        See :ref:`multimetric_grid_search` for an example. 
 
    n_jobs : int, default=None 
        Number of jobs to run in parallel. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
        .. versionchanged:: v0.20 
           `n_jobs` default changed from 1 to None 
 
    refit : bool, str, or callable, default=True 
        Refit an estimator using the best found parameters on the whole 
        dataset. 
 
        For multiple metric evaluation, this needs to be a `str` denoting the 
        scorer that would be used to find the best parameters for refitting 
        the estimator at the end. 
 
        Where there are considerations other than maximum score in 
        choosing a best estimator, ``refit`` can be set to a function which 
        returns the selected ``best_index_`` given ``cv_results_``. In that 
        case, the ``best_estimator_`` and ``best_params_`` will be set 
        according to the returned ``best_index_`` while the ``best_score_`` 
        attribute will not be available. 
 
        The refitted estimator is made available at the ``best_estimator_`` 
        attribute and permits using ``predict`` directly on this 
        ``GridSearchCV`` instance. 
 
        Also for multiple metric evaluation, the attributes ``best_index_``, 
        ``best_score_`` and ``best_params_`` will only be available if 
        ``refit`` is set and all of them will be determined w.r.t this specific 
        scorer. 
 
        See ``scoring`` parameter to know more about multiple metric 
        evaluation. 
 
        See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py` 
        to see how to design a custom selection strategy using a callable 
        via `refit`. 
 
        .. versionchanged:: 0.20 
            Support for callable added. 
 
    cv : int, cross-validation generator or an iterable, default=None 
        Determines the cross-validation splitting strategy. 
        Possible inputs for cv are: 
 
        - None, to use the default 5-fold cross validation, 
        - integer, to specify the number of folds in a `(Stratified)KFold`, 
        - :term:`CV splitter`, 
        - An iterable yielding (train, test) splits as arrays of indices. 
 
        For integer/None inputs, if the estimator is a classifier and ``y`` is 
        either binary or multiclass, :class:`StratifiedKFold` is used. In all 
        other cases, :class:`KFold` is used. These splitters are instantiated 
        with `shuffle=False` so the splits will be the same across calls. 
 
        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various 
        cross-validation strategies that can be used here. 
 
        .. versionchanged:: 0.22 
            ``cv`` default value if None changed from 3-fold to 5-fold. 
 
    verbose : int 
        Controls the verbosity: the higher, the more messages. 
 
        - &gt;1 : the computation time for each fold and parameter candidate is 
          displayed; 
        - &gt;2 : the score is also displayed; 
        - &gt;3 : the fold and candidate parameter indexes are also displayed 
          together with the starting time of the computation. 
 
    pre_dispatch : int, or str, default='2*n_jobs' 
        Controls the number of jobs that get dispatched during parallel 
        execution. Reducing this number can be useful to avoid an 
        explosion of memory consumption when more jobs get dispatched 
        than CPUs can process. This parameter can be: 
 
            - None, in which case all the jobs are immediately 
              created and spawned. Use this for lightweight and 
              fast-running jobs, to avoid delays due to on-demand 
              spawning of the jobs 
 
            - An int, giving the exact number of total jobs that are 
              spawned 
 
            - A str, giving an expression as a function of n_jobs, 
              as in '2*n_jobs' 
 
    error_score : 'raise' or numeric, default=np.nan 
        Value to assign to the score if an error occurs in estimator fitting. 
        If set to 'raise', the error is raised. If a numeric value is given, 
        FitFailedWarning is raised. This parameter does not affect the refit 
        step, which will always raise the error. 
 
    return_train_score : bool, default=False 
        If ``False``, the ``cv_results_`` attribute will not include training 
        scores. 
        Computing training scores is used to get insights on how different 
        parameter settings impact the overfitting/underfitting trade-off. 
        However computing the scores on the training set can be computationally 
        expensive and is not strictly required to select the parameters that 
        yield the best generalization performance. 
 
        .. versionadded:: 0.19 
 
        .. versionchanged:: 0.21 
            Default value was changed from ``True`` to ``False`` 
 
    Attributes 
    ---------- 
    cv_results_ : dict of numpy (masked) ndarrays 
        A dict with keys as column headers and values as columns, that can be 
        imported into a pandas ``DataFrame``. 
 
        For instance the below given table 
 
        +------------+-----------+------------+-----------------+---+---------+ 
        |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...| 
        +============+===========+============+=================+===+=========+ 
        |  'poly'    |     --    |      2     |       0.80      |...|    2    | 
        +------------+-----------+------------+-----------------+---+---------+ 
        |  'poly'    |     --    |      3     |       0.70      |...|    4    | 
        +------------+-----------+------------+-----------------+---+---------+ 
        |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    | 
        +------------+-----------+------------+-----------------+---+---------+ 
        |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    | 
        +------------+-----------+------------+-----------------+---+---------+ 
 
        will be represented by a ``cv_results_`` dict of:: 
 
            { 
            'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'], 
                                         mask = [False False False False]...) 
            'param_gamma': masked_array(data = [-- -- 0.1 0.2], 
                                        mask = [ True  True False False]...), 
            'param_degree': masked_array(data = [2.0 3.0 -- --], 
                                         mask = [False False  True  True]...), 
            'split0_test_score'  : [0.80, 0.70, 0.80, 0.93], 
            'split1_test_score'  : [0.82, 0.50, 0.70, 0.78], 
            'mean_test_score'    : [0.81, 0.60, 0.75, 0.85], 
            'std_test_score'     : [0.01, 0.10, 0.05, 0.08], 
            'rank_test_score'    : [2, 4, 3, 1], 
            'split0_train_score' : [0.80, 0.92, 0.70, 0.93], 
            'split1_train_score' : [0.82, 0.55, 0.70, 0.87], 
            'mean_train_score'   : [0.81, 0.74, 0.70, 0.90], 
            'std_train_score'    : [0.01, 0.19, 0.00, 0.03], 
            'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49], 
            'std_fit_time'       : [0.01, 0.02, 0.01, 0.01], 
            'mean_score_time'    : [0.01, 0.06, 0.04, 0.04], 
            'std_score_time'     : [0.00, 0.00, 0.00, 0.01], 
            'params'             : [{'kernel': 'poly', 'degree': 2}, ...], 
            } 
 
        NOTE 
 
        The key ``'params'`` is used to store a list of parameter 
        settings dicts for all the parameter candidates. 
 
        The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and 
        ``std_score_time`` are all in seconds. 
 
        For multi-metric evaluation, the scores for all the scorers are 
        available in the ``cv_results_`` dict at the keys ending with that 
        scorer's name (``'_&lt;scorer_name&gt;'``) instead of ``'_score'`` shown 
        above. ('split0_test_precision', 'mean_train_precision' etc.) 
 
    best_estimator_ : estimator 
        Estimator that was chosen by the search, i.e. estimator 
        which gave highest score (or smallest loss if specified) 
        on the left out data. Not available if ``refit=False``. 
 
        See ``refit`` parameter for more information on allowed values. 
 
    best_score_ : float 
        Mean cross-validated score of the best_estimator 
 
        For multi-metric evaluation, this is present only if ``refit`` is 
        specified. 
 
        This attribute is not available if ``refit`` is a function. 
 
    best_params_ : dict 
        Parameter setting that gave the best results on the hold out data. 
 
        For multi-metric evaluation, this is present only if ``refit`` is 
        specified. 
 
    best_index_ : int 
        The index (of the ``cv_results_`` arrays) which corresponds to the best 
        candidate parameter setting. 
 
        The dict at ``search.cv_results_['params'][search.best_index_]`` gives 
        the parameter setting for the best model, that gives the highest 
        mean score (``search.best_score_``). 
 
        For multi-metric evaluation, this is present only if ``refit`` is 
        specified. 
 
    scorer_ : function or a dict 
        Scorer function used on the held out data to choose the best 
        parameters for the model. 
 
        For multi-metric evaluation, this attribute holds the validated 
        ``scoring`` dict which maps the scorer key to the scorer callable. 
 
    n_splits_ : int 
        The number of cross-validation splits (folds/iterations). 
 
    refit_time_ : float 
        Seconds used for refitting the best model on the whole dataset. 
 
        This is present only if ``refit`` is not False. 
 
        .. versionadded:: 0.20 
 
    multimetric_ : bool 
        Whether or not the scorers compute several metrics. 
 
    classes_ : ndarray of shape (n_classes,) 
        The classes labels. This is present only if ``refit`` is specified and 
        the underlying estimator is a classifier. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. Only defined if 
        `best_estimator_` is defined (see the documentation for the `refit` 
        parameter for more details) and that `best_estimator_` exposes 
        `n_features_in_` when fit. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Only defined if 
        `best_estimator_` is defined (see the documentation for the `refit` 
        parameter for more details) and that `best_estimator_` exposes 
        `feature_names_in_` when fit. 
 
        .. versionadded:: 1.0 
 
    See Also 
    -------- 
    ParameterGrid : Generates all the combinations of a hyperparameter grid. 
    train_test_split : Utility function to split the data into a development 
        set usable for fitting a GridSearchCV instance and an evaluation set 
        for its final evaluation. 
    sklearn.metrics.make_scorer : Make a scorer from a performance metric or 
        loss function. 
 
    Notes 
    ----- 
    The parameters selected are those that maximize the score of the left out 
    data, unless an explicit score is passed in which case it is used instead. 
 
    If `n_jobs` was set to a value higher than one, the data is copied for each 
    point in the grid (and not `n_jobs` times). This is done for efficiency 
    reasons if individual jobs take very little time, but may raise errors if 
    the dataset is large and not enough memory is available.  A workaround in 
    this case is to set `pre_dispatch`. Then, the memory is copied only 
    `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 * 
    n_jobs`. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn import svm, datasets 
    &gt;&gt;&gt; from sklearn.model_selection import GridSearchCV 
    &gt;&gt;&gt; iris = datasets.load_iris() 
    &gt;&gt;&gt; parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]} 
    &gt;&gt;&gt; svc = svm.SVC() 
    &gt;&gt;&gt; clf = GridSearchCV(svc, parameters) 
    &gt;&gt;&gt; clf.fit(iris.data, iris.target) 
    GridSearchCV(estimator=SVC(), 
                 param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')}) 
    &gt;&gt;&gt; sorted(clf.cv_results_.keys()) 
    ['mean_fit_time', 'mean_score_time', 'mean_test_score',... 
     'param_C', 'param_kernel', 'params',... 
     'rank_test_score', 'split0_test_score',... 
     'split2_test_score', ... 
     'std_fit_time', 'std_score_time', 'std_test_score'] 
    &quot;&quot;&quot;</span>

    <span class="s1">_required_parameters </span><span class="s4">= [</span><span class="s5">&quot;estimator&quot;</span><span class="s4">, </span><span class="s5">&quot;param_grid&quot;</span><span class="s4">]</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s4">**</span><span class="s1">BaseSearchCV</span><span class="s4">.</span><span class="s1">_parameter_constraints</span><span class="s4">,</span>
        <span class="s5">&quot;param_grid&quot;</span><span class="s4">: [</span><span class="s1">dict</span><span class="s4">, </span><span class="s1">list</span><span class="s4">],</span>
    <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">estimator</span><span class="s4">,</span>
        <span class="s1">param_grid</span><span class="s4">,</span>
        <span class="s4">*,</span>
        <span class="s1">scoring</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">n_jobs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">refit</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
        <span class="s1">cv</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
        <span class="s1">pre_dispatch</span><span class="s4">=</span><span class="s5">&quot;2*n_jobs&quot;</span><span class="s4">,</span>
        <span class="s1">error_score</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">nan</span><span class="s4">,</span>
        <span class="s1">return_train_score</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">super</span><span class="s4">().</span><span class="s1">__init__</span><span class="s4">(</span>
            <span class="s1">estimator</span><span class="s4">=</span><span class="s1">estimator</span><span class="s4">,</span>
            <span class="s1">scoring</span><span class="s4">=</span><span class="s1">scoring</span><span class="s4">,</span>
            <span class="s1">n_jobs</span><span class="s4">=</span><span class="s1">n_jobs</span><span class="s4">,</span>
            <span class="s1">refit</span><span class="s4">=</span><span class="s1">refit</span><span class="s4">,</span>
            <span class="s1">cv</span><span class="s4">=</span><span class="s1">cv</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
            <span class="s1">pre_dispatch</span><span class="s4">=</span><span class="s1">pre_dispatch</span><span class="s4">,</span>
            <span class="s1">error_score</span><span class="s4">=</span><span class="s1">error_score</span><span class="s4">,</span>
            <span class="s1">return_train_score</span><span class="s4">=</span><span class="s1">return_train_score</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">param_grid </span><span class="s4">= </span><span class="s1">param_grid</span>

    <span class="s3">def </span><span class="s1">_run_search</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">evaluate_candidates</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Search all candidates in param_grid&quot;&quot;&quot;</span>
        <span class="s1">evaluate_candidates</span><span class="s4">(</span><span class="s1">ParameterGrid</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">param_grid</span><span class="s4">))</span>


<span class="s3">class </span><span class="s1">RandomizedSearchCV</span><span class="s4">(</span><span class="s1">BaseSearchCV</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Randomized search on hyper parameters. 
 
    RandomizedSearchCV implements a &quot;fit&quot; and a &quot;score&quot; method. 
    It also implements &quot;score_samples&quot;, &quot;predict&quot;, &quot;predict_proba&quot;, 
    &quot;decision_function&quot;, &quot;transform&quot; and &quot;inverse_transform&quot; if they are 
    implemented in the estimator used. 
 
    The parameters of the estimator used to apply these methods are optimized 
    by cross-validated search over parameter settings. 
 
    In contrast to GridSearchCV, not all parameter values are tried out, but 
    rather a fixed number of parameter settings is sampled from the specified 
    distributions. The number of parameter settings that are tried is 
    given by n_iter. 
 
    If all parameters are presented as a list, 
    sampling without replacement is performed. If at least one parameter 
    is given as a distribution, sampling with replacement is used. 
    It is highly recommended to use continuous distributions for continuous 
    parameters. 
 
    Read more in the :ref:`User Guide &lt;randomized_parameter_search&gt;`. 
 
    .. versionadded:: 0.14 
 
    Parameters 
    ---------- 
    estimator : estimator object 
        An object of that type is instantiated for each grid point. 
        This is assumed to implement the scikit-learn estimator interface. 
        Either estimator needs to provide a ``score`` function, 
        or ``scoring`` must be passed. 
 
    param_distributions : dict or list of dicts 
        Dictionary with parameters names (`str`) as keys and distributions 
        or lists of parameters to try. Distributions must provide a ``rvs`` 
        method for sampling (such as those from scipy.stats.distributions). 
        If a list is given, it is sampled uniformly. 
        If a list of dicts is given, first a dict is sampled uniformly, and 
        then a parameter is sampled using that dict as above. 
 
    n_iter : int, default=10 
        Number of parameter settings that are sampled. n_iter trades 
        off runtime vs quality of the solution. 
 
    scoring : str, callable, list, tuple or dict, default=None 
        Strategy to evaluate the performance of the cross-validated model on 
        the test set. 
 
        If `scoring` represents a single score, one can use: 
 
        - a single string (see :ref:`scoring_parameter`); 
        - a callable (see :ref:`scoring`) that returns a single value. 
 
        If `scoring` represents multiple scores, one can use: 
 
        - a list or tuple of unique strings; 
        - a callable returning a dictionary where the keys are the metric 
          names and the values are the metric scores; 
        - a dictionary with metric names as keys and callables a values. 
 
        See :ref:`multimetric_grid_search` for an example. 
 
        If None, the estimator's score method is used. 
 
    n_jobs : int, default=None 
        Number of jobs to run in parallel. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
        .. versionchanged:: v0.20 
           `n_jobs` default changed from 1 to None 
 
    refit : bool, str, or callable, default=True 
        Refit an estimator using the best found parameters on the whole 
        dataset. 
 
        For multiple metric evaluation, this needs to be a `str` denoting the 
        scorer that would be used to find the best parameters for refitting 
        the estimator at the end. 
 
        Where there are considerations other than maximum score in 
        choosing a best estimator, ``refit`` can be set to a function which 
        returns the selected ``best_index_`` given the ``cv_results``. In that 
        case, the ``best_estimator_`` and ``best_params_`` will be set 
        according to the returned ``best_index_`` while the ``best_score_`` 
        attribute will not be available. 
 
        The refitted estimator is made available at the ``best_estimator_`` 
        attribute and permits using ``predict`` directly on this 
        ``RandomizedSearchCV`` instance. 
 
        Also for multiple metric evaluation, the attributes ``best_index_``, 
        ``best_score_`` and ``best_params_`` will only be available if 
        ``refit`` is set and all of them will be determined w.r.t this specific 
        scorer. 
 
        See ``scoring`` parameter to know more about multiple metric 
        evaluation. 
 
        .. versionchanged:: 0.20 
            Support for callable added. 
 
    cv : int, cross-validation generator or an iterable, default=None 
        Determines the cross-validation splitting strategy. 
        Possible inputs for cv are: 
 
        - None, to use the default 5-fold cross validation, 
        - integer, to specify the number of folds in a `(Stratified)KFold`, 
        - :term:`CV splitter`, 
        - An iterable yielding (train, test) splits as arrays of indices. 
 
        For integer/None inputs, if the estimator is a classifier and ``y`` is 
        either binary or multiclass, :class:`StratifiedKFold` is used. In all 
        other cases, :class:`KFold` is used. These splitters are instantiated 
        with `shuffle=False` so the splits will be the same across calls. 
 
        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various 
        cross-validation strategies that can be used here. 
 
        .. versionchanged:: 0.22 
            ``cv`` default value if None changed from 3-fold to 5-fold. 
 
    verbose : int 
        Controls the verbosity: the higher, the more messages. 
 
        - &gt;1 : the computation time for each fold and parameter candidate is 
          displayed; 
        - &gt;2 : the score is also displayed; 
        - &gt;3 : the fold and candidate parameter indexes are also displayed 
          together with the starting time of the computation. 
 
    pre_dispatch : int, or str, default='2*n_jobs' 
        Controls the number of jobs that get dispatched during parallel 
        execution. Reducing this number can be useful to avoid an 
        explosion of memory consumption when more jobs get dispatched 
        than CPUs can process. This parameter can be: 
 
            - None, in which case all the jobs are immediately 
              created and spawned. Use this for lightweight and 
              fast-running jobs, to avoid delays due to on-demand 
              spawning of the jobs 
 
            - An int, giving the exact number of total jobs that are 
              spawned 
 
            - A str, giving an expression as a function of n_jobs, 
              as in '2*n_jobs' 
 
    random_state : int, RandomState instance or None, default=None 
        Pseudo random number generator state used for random uniform sampling 
        from lists of possible values instead of scipy.stats distributions. 
        Pass an int for reproducible output across multiple 
        function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    error_score : 'raise' or numeric, default=np.nan 
        Value to assign to the score if an error occurs in estimator fitting. 
        If set to 'raise', the error is raised. If a numeric value is given, 
        FitFailedWarning is raised. This parameter does not affect the refit 
        step, which will always raise the error. 
 
    return_train_score : bool, default=False 
        If ``False``, the ``cv_results_`` attribute will not include training 
        scores. 
        Computing training scores is used to get insights on how different 
        parameter settings impact the overfitting/underfitting trade-off. 
        However computing the scores on the training set can be computationally 
        expensive and is not strictly required to select the parameters that 
        yield the best generalization performance. 
 
        .. versionadded:: 0.19 
 
        .. versionchanged:: 0.21 
            Default value was changed from ``True`` to ``False`` 
 
    Attributes 
    ---------- 
    cv_results_ : dict of numpy (masked) ndarrays 
        A dict with keys as column headers and values as columns, that can be 
        imported into a pandas ``DataFrame``. 
 
        For instance the below given table 
 
        +--------------+-------------+-------------------+---+---------------+ 
        | param_kernel | param_gamma | split0_test_score |...|rank_test_score| 
        +==============+=============+===================+===+===============+ 
        |    'rbf'     |     0.1     |       0.80        |...|       1       | 
        +--------------+-------------+-------------------+---+---------------+ 
        |    'rbf'     |     0.2     |       0.84        |...|       3       | 
        +--------------+-------------+-------------------+---+---------------+ 
        |    'rbf'     |     0.3     |       0.70        |...|       2       | 
        +--------------+-------------+-------------------+---+---------------+ 
 
        will be represented by a ``cv_results_`` dict of:: 
 
            { 
            'param_kernel' : masked_array(data = ['rbf', 'rbf', 'rbf'], 
                                          mask = False), 
            'param_gamma'  : masked_array(data = [0.1 0.2 0.3], mask = False), 
            'split0_test_score'  : [0.80, 0.84, 0.70], 
            'split1_test_score'  : [0.82, 0.50, 0.70], 
            'mean_test_score'    : [0.81, 0.67, 0.70], 
            'std_test_score'     : [0.01, 0.24, 0.00], 
            'rank_test_score'    : [1, 3, 2], 
            'split0_train_score' : [0.80, 0.92, 0.70], 
            'split1_train_score' : [0.82, 0.55, 0.70], 
            'mean_train_score'   : [0.81, 0.74, 0.70], 
            'std_train_score'    : [0.01, 0.19, 0.00], 
            'mean_fit_time'      : [0.73, 0.63, 0.43], 
            'std_fit_time'       : [0.01, 0.02, 0.01], 
            'mean_score_time'    : [0.01, 0.06, 0.04], 
            'std_score_time'     : [0.00, 0.00, 0.00], 
            'params'             : [{'kernel' : 'rbf', 'gamma' : 0.1}, ...], 
            } 
 
        NOTE 
 
        The key ``'params'`` is used to store a list of parameter 
        settings dicts for all the parameter candidates. 
 
        The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and 
        ``std_score_time`` are all in seconds. 
 
        For multi-metric evaluation, the scores for all the scorers are 
        available in the ``cv_results_`` dict at the keys ending with that 
        scorer's name (``'_&lt;scorer_name&gt;'``) instead of ``'_score'`` shown 
        above. ('split0_test_precision', 'mean_train_precision' etc.) 
 
    best_estimator_ : estimator 
        Estimator that was chosen by the search, i.e. estimator 
        which gave highest score (or smallest loss if specified) 
        on the left out data. Not available if ``refit=False``. 
 
        For multi-metric evaluation, this attribute is present only if 
        ``refit`` is specified. 
 
        See ``refit`` parameter for more information on allowed values. 
 
    best_score_ : float 
        Mean cross-validated score of the best_estimator. 
 
        For multi-metric evaluation, this is not available if ``refit`` is 
        ``False``. See ``refit`` parameter for more information. 
 
        This attribute is not available if ``refit`` is a function. 
 
    best_params_ : dict 
        Parameter setting that gave the best results on the hold out data. 
 
        For multi-metric evaluation, this is not available if ``refit`` is 
        ``False``. See ``refit`` parameter for more information. 
 
    best_index_ : int 
        The index (of the ``cv_results_`` arrays) which corresponds to the best 
        candidate parameter setting. 
 
        The dict at ``search.cv_results_['params'][search.best_index_]`` gives 
        the parameter setting for the best model, that gives the highest 
        mean score (``search.best_score_``). 
 
        For multi-metric evaluation, this is not available if ``refit`` is 
        ``False``. See ``refit`` parameter for more information. 
 
    scorer_ : function or a dict 
        Scorer function used on the held out data to choose the best 
        parameters for the model. 
 
        For multi-metric evaluation, this attribute holds the validated 
        ``scoring`` dict which maps the scorer key to the scorer callable. 
 
    n_splits_ : int 
        The number of cross-validation splits (folds/iterations). 
 
    refit_time_ : float 
        Seconds used for refitting the best model on the whole dataset. 
 
        This is present only if ``refit`` is not False. 
 
        .. versionadded:: 0.20 
 
    multimetric_ : bool 
        Whether or not the scorers compute several metrics. 
 
    classes_ : ndarray of shape (n_classes,) 
        The classes labels. This is present only if ``refit`` is specified and 
        the underlying estimator is a classifier. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. Only defined if 
        `best_estimator_` is defined (see the documentation for the `refit` 
        parameter for more details) and that `best_estimator_` exposes 
        `n_features_in_` when fit. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Only defined if 
        `best_estimator_` is defined (see the documentation for the `refit` 
        parameter for more details) and that `best_estimator_` exposes 
        `feature_names_in_` when fit. 
 
        .. versionadded:: 1.0 
 
    See Also 
    -------- 
    GridSearchCV : Does exhaustive search over a grid of parameters. 
    ParameterSampler : A generator over parameter settings, constructed from 
        param_distributions. 
 
    Notes 
    ----- 
    The parameters selected are those that maximize the score of the held-out 
    data, according to the scoring parameter. 
 
    If `n_jobs` was set to a value higher than one, the data is copied for each 
    parameter setting(and not `n_jobs` times). This is done for efficiency 
    reasons if individual jobs take very little time, but may raise errors if 
    the dataset is large and not enough memory is available.  A workaround in 
    this case is to set `pre_dispatch`. Then, the memory is copied only 
    `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 * 
    n_jobs`. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.datasets import load_iris 
    &gt;&gt;&gt; from sklearn.linear_model import LogisticRegression 
    &gt;&gt;&gt; from sklearn.model_selection import RandomizedSearchCV 
    &gt;&gt;&gt; from scipy.stats import uniform 
    &gt;&gt;&gt; iris = load_iris() 
    &gt;&gt;&gt; logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200, 
    ...                               random_state=0) 
    &gt;&gt;&gt; distributions = dict(C=uniform(loc=0, scale=4), 
    ...                      penalty=['l2', 'l1']) 
    &gt;&gt;&gt; clf = RandomizedSearchCV(logistic, distributions, random_state=0) 
    &gt;&gt;&gt; search = clf.fit(iris.data, iris.target) 
    &gt;&gt;&gt; search.best_params_ 
    {'C': np.float64(2...), 'penalty': 'l1'} 
    &quot;&quot;&quot;</span>

    <span class="s1">_required_parameters </span><span class="s4">= [</span><span class="s5">&quot;estimator&quot;</span><span class="s4">, </span><span class="s5">&quot;param_distributions&quot;</span><span class="s4">]</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s4">**</span><span class="s1">BaseSearchCV</span><span class="s4">.</span><span class="s1">_parameter_constraints</span><span class="s4">,</span>
        <span class="s5">&quot;param_distributions&quot;</span><span class="s4">: [</span><span class="s1">dict</span><span class="s4">, </span><span class="s1">list</span><span class="s4">],</span>
        <span class="s5">&quot;n_iter&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">numbers</span><span class="s4">.</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;random_state&quot;</span><span class="s4">: [</span><span class="s5">&quot;random_state&quot;</span><span class="s4">],</span>
    <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">estimator</span><span class="s4">,</span>
        <span class="s1">param_distributions</span><span class="s4">,</span>
        <span class="s4">*,</span>
        <span class="s1">n_iter</span><span class="s4">=</span><span class="s6">10</span><span class="s4">,</span>
        <span class="s1">scoring</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">n_jobs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">refit</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
        <span class="s1">cv</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
        <span class="s1">pre_dispatch</span><span class="s4">=</span><span class="s5">&quot;2*n_jobs&quot;</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">error_score</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">nan</span><span class="s4">,</span>
        <span class="s1">return_train_score</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">param_distributions </span><span class="s4">= </span><span class="s1">param_distributions</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter </span><span class="s4">= </span><span class="s1">n_iter</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">random_state </span><span class="s4">= </span><span class="s1">random_state</span>
        <span class="s1">super</span><span class="s4">().</span><span class="s1">__init__</span><span class="s4">(</span>
            <span class="s1">estimator</span><span class="s4">=</span><span class="s1">estimator</span><span class="s4">,</span>
            <span class="s1">scoring</span><span class="s4">=</span><span class="s1">scoring</span><span class="s4">,</span>
            <span class="s1">n_jobs</span><span class="s4">=</span><span class="s1">n_jobs</span><span class="s4">,</span>
            <span class="s1">refit</span><span class="s4">=</span><span class="s1">refit</span><span class="s4">,</span>
            <span class="s1">cv</span><span class="s4">=</span><span class="s1">cv</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
            <span class="s1">pre_dispatch</span><span class="s4">=</span><span class="s1">pre_dispatch</span><span class="s4">,</span>
            <span class="s1">error_score</span><span class="s4">=</span><span class="s1">error_score</span><span class="s4">,</span>
            <span class="s1">return_train_score</span><span class="s4">=</span><span class="s1">return_train_score</span><span class="s4">,</span>
        <span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_run_search</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">evaluate_candidates</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Search n_iter candidates from param_distributions&quot;&quot;&quot;</span>
        <span class="s1">evaluate_candidates</span><span class="s4">(</span>
            <span class="s1">ParameterSampler</span><span class="s4">(</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">param_distributions</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span>
            <span class="s4">)</span>
        <span class="s4">)</span>
</pre>
</body>
</html>