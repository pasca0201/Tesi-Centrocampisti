<html>
<head>
<title>isotonic.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
isotonic.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Isotonic regression for obtaining monotonic fit to data.&quot;&quot;&quot;</span>

<span class="s2"># Authors: Fabian Pedregosa &lt;fabian@fseoane.net&gt;</span>
<span class="s2">#          Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;</span>
<span class="s2">#          Nelle Varoquaux &lt;nelle.varoquaux@gmail.com&gt;</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">math</span>
<span class="s3">import </span><span class="s1">warnings</span>
<span class="s3">from </span><span class="s1">numbers </span><span class="s3">import </span><span class="s1">Real</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">interpolate</span>
<span class="s3">from </span><span class="s1">scipy</span><span class="s4">.</span><span class="s1">stats </span><span class="s3">import </span><span class="s1">spearmanr</span>

<span class="s3">from </span><span class="s4">.</span><span class="s1">_isotonic </span><span class="s3">import </span><span class="s1">_inplace_contiguous_isotonic_regression</span><span class="s4">, </span><span class="s1">_make_unique</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">base </span><span class="s3">import </span><span class="s1">BaseEstimator</span><span class="s4">, </span><span class="s1">RegressorMixin</span><span class="s4">, </span><span class="s1">TransformerMixin</span><span class="s4">, </span><span class="s1">_fit_context</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils </span><span class="s3">import </span><span class="s1">check_array</span><span class="s4">, </span><span class="s1">check_consistent_length</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_param_validation </span><span class="s3">import </span><span class="s1">Interval</span><span class="s4">, </span><span class="s1">StrOptions</span><span class="s4">, </span><span class="s1">validate_params</span>
<span class="s3">from </span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">validation </span><span class="s3">import </span><span class="s1">_check_sample_weight</span><span class="s4">, </span><span class="s1">check_is_fitted</span>

<span class="s1">__all__ </span><span class="s4">= [</span><span class="s5">&quot;check_increasing&quot;</span><span class="s4">, </span><span class="s5">&quot;isotonic_regression&quot;</span><span class="s4">, </span><span class="s5">&quot;IsotonicRegression&quot;</span><span class="s4">]</span>


<span class="s4">@</span><span class="s1">validate_params</span><span class="s4">(</span>
    <span class="s4">{</span>
        <span class="s5">&quot;x&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;y&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">],</span>
    <span class="s4">},</span>
    <span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">def </span><span class="s1">check_increasing</span><span class="s4">(</span><span class="s1">x</span><span class="s4">, </span><span class="s1">y</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Determine whether y is monotonically correlated with x. 
 
    y is found increasing or decreasing with respect to x based on a Spearman 
    correlation test. 
 
    Parameters 
    ---------- 
    x : array-like of shape (n_samples,) 
            Training data. 
 
    y : array-like of shape (n_samples,) 
        Training target. 
 
    Returns 
    ------- 
    increasing_bool : boolean 
        Whether the relationship is increasing or decreasing. 
 
    Notes 
    ----- 
    The Spearman correlation coefficient is estimated from the data, and the 
    sign of the resulting estimate is used as the result. 
 
    In the event that the 95% confidence interval based on Fisher transform 
    spans zero, a warning is raised. 
 
    References 
    ---------- 
    Fisher transformation. Wikipedia. 
    https://en.wikipedia.org/wiki/Fisher_transformation 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.isotonic import check_increasing 
    &gt;&gt;&gt; x, y = [1, 2, 3, 4, 5], [2, 4, 6, 8, 10] 
    &gt;&gt;&gt; check_increasing(x, y) 
    np.True_ 
    &gt;&gt;&gt; y = [10, 8, 6, 4, 2] 
    &gt;&gt;&gt; check_increasing(x, y) 
    np.False_ 
    &quot;&quot;&quot;</span>

    <span class="s2"># Calculate Spearman rho estimate and set return accordingly.</span>
    <span class="s1">rho</span><span class="s4">, </span><span class="s1">_ </span><span class="s4">= </span><span class="s1">spearmanr</span><span class="s4">(</span><span class="s1">x</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">increasing_bool </span><span class="s4">= </span><span class="s1">rho </span><span class="s4">&gt;= </span><span class="s6">0</span>

    <span class="s2"># Run Fisher transform to get the rho CI, but handle rho=+/-1</span>
    <span class="s3">if </span><span class="s1">rho </span><span class="s3">not in </span><span class="s4">[-</span><span class="s6">1.0</span><span class="s4">, </span><span class="s6">1.0</span><span class="s4">] </span><span class="s3">and </span><span class="s1">len</span><span class="s4">(</span><span class="s1">x</span><span class="s4">) &gt; </span><span class="s6">3</span><span class="s4">:</span>
        <span class="s1">F </span><span class="s4">= </span><span class="s6">0.5 </span><span class="s4">* </span><span class="s1">math</span><span class="s4">.</span><span class="s1">log</span><span class="s4">((</span><span class="s6">1.0 </span><span class="s4">+ </span><span class="s1">rho</span><span class="s4">) / (</span><span class="s6">1.0 </span><span class="s4">- </span><span class="s1">rho</span><span class="s4">))</span>
        <span class="s1">F_se </span><span class="s4">= </span><span class="s6">1 </span><span class="s4">/ </span><span class="s1">math</span><span class="s4">.</span><span class="s1">sqrt</span><span class="s4">(</span><span class="s1">len</span><span class="s4">(</span><span class="s1">x</span><span class="s4">) - </span><span class="s6">3</span><span class="s4">)</span>

        <span class="s2"># Use a 95% CI, i.e., +/-1.96 S.E.</span>
        <span class="s2"># https://en.wikipedia.org/wiki/Fisher_transformation</span>
        <span class="s1">rho_0 </span><span class="s4">= </span><span class="s1">math</span><span class="s4">.</span><span class="s1">tanh</span><span class="s4">(</span><span class="s1">F </span><span class="s4">- </span><span class="s6">1.96 </span><span class="s4">* </span><span class="s1">F_se</span><span class="s4">)</span>
        <span class="s1">rho_1 </span><span class="s4">= </span><span class="s1">math</span><span class="s4">.</span><span class="s1">tanh</span><span class="s4">(</span><span class="s1">F </span><span class="s4">+ </span><span class="s6">1.96 </span><span class="s4">* </span><span class="s1">F_se</span><span class="s4">)</span>

        <span class="s2"># Warn if the CI spans zero.</span>
        <span class="s3">if </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sign</span><span class="s4">(</span><span class="s1">rho_0</span><span class="s4">) != </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sign</span><span class="s4">(</span><span class="s1">rho_1</span><span class="s4">):</span>
            <span class="s1">warnings</span><span class="s4">.</span><span class="s1">warn</span><span class="s4">(</span>
                <span class="s5">&quot;Confidence interval of the Spearman &quot;</span>
                <span class="s5">&quot;correlation coefficient spans zero. &quot;</span>
                <span class="s5">&quot;Determination of ``increasing`` may be &quot;</span>
                <span class="s5">&quot;suspect.&quot;</span>
            <span class="s4">)</span>

    <span class="s3">return </span><span class="s1">increasing_bool</span>


<span class="s4">@</span><span class="s1">validate_params</span><span class="s4">(</span>
    <span class="s4">{</span>
        <span class="s5">&quot;y&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;sample_weight&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">, </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;y_min&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;both&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;y_max&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;both&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;increasing&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
    <span class="s4">},</span>
    <span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">def </span><span class="s1">isotonic_regression</span><span class="s4">(</span>
    <span class="s1">y</span><span class="s4">, *, </span><span class="s1">sample_weight</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, </span><span class="s1">y_min</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, </span><span class="s1">y_max</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, </span><span class="s1">increasing</span><span class="s4">=</span><span class="s3">True</span>
<span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Solve the isotonic regression model. 
 
    Read more in the :ref:`User Guide &lt;isotonic&gt;`. 
 
    Parameters 
    ---------- 
    y : array-like of shape (n_samples,) 
        The data. 
 
    sample_weight : array-like of shape (n_samples,), default=None 
        Weights on each point of the regression. 
        If None, weight is set to 1 (equal weights). 
 
    y_min : float, default=None 
        Lower bound on the lowest predicted value (the minimum value may 
        still be higher). If not set, defaults to -inf. 
 
    y_max : float, default=None 
        Upper bound on the highest predicted value (the maximum may still be 
        lower). If not set, defaults to +inf. 
 
    increasing : bool, default=True 
        Whether to compute ``y_`` is increasing (if set to True) or decreasing 
        (if set to False). 
 
    Returns 
    ------- 
    y_ : ndarray of shape (n_samples,) 
        Isotonic fit of y. 
 
    References 
    ---------- 
    &quot;Active set algorithms for isotonic regression; A unifying framework&quot; 
    by Michael J. Best and Nilotpal Chakravarti, section 3. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.isotonic import isotonic_regression 
    &gt;&gt;&gt; isotonic_regression([5, 3, 1, 2, 8, 10, 7, 9, 6, 4]) 
    array([2.75   , 2.75   , 2.75   , 2.75   , 7.33..., 
           7.33..., 7.33..., 7.33..., 7.33..., 7.33...]) 
    &quot;&quot;&quot;</span>
    <span class="s1">order </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">s_</span><span class="s4">[:] </span><span class="s3">if </span><span class="s1">increasing </span><span class="s3">else </span><span class="s1">np</span><span class="s4">.</span><span class="s1">s_</span><span class="s4">[::-</span><span class="s6">1</span><span class="s4">]</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">ensure_2d</span><span class="s4">=</span><span class="s3">False</span><span class="s4">, </span><span class="s1">input_name</span><span class="s4">=</span><span class="s5">&quot;y&quot;</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">])</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span><span class="s1">y</span><span class="s4">[</span><span class="s1">order</span><span class="s4">], </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">y</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">)</span>
    <span class="s1">sample_weight </span><span class="s4">= </span><span class="s1">_check_sample_weight</span><span class="s4">(</span><span class="s1">sample_weight</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">y</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">, </span><span class="s1">copy</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s1">sample_weight </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ascontiguousarray</span><span class="s4">(</span><span class="s1">sample_weight</span><span class="s4">[</span><span class="s1">order</span><span class="s4">])</span>

    <span class="s1">_inplace_contiguous_isotonic_regression</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">)</span>
    <span class="s3">if </span><span class="s1">y_min </span><span class="s3">is not None or </span><span class="s1">y_max </span><span class="s3">is not None</span><span class="s4">:</span>
        <span class="s2"># Older versions of np.clip don't accept None as a bound, so use np.inf</span>
        <span class="s3">if </span><span class="s1">y_min </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">y_min </span><span class="s4">= -</span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span>
        <span class="s3">if </span><span class="s1">y_max </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">y_max </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span>
        <span class="s1">np</span><span class="s4">.</span><span class="s1">clip</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">y_min</span><span class="s4">, </span><span class="s1">y_max</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s3">return </span><span class="s1">y</span><span class="s4">[</span><span class="s1">order</span><span class="s4">]</span>


<span class="s3">class </span><span class="s1">IsotonicRegression</span><span class="s4">(</span><span class="s1">RegressorMixin</span><span class="s4">, </span><span class="s1">TransformerMixin</span><span class="s4">, </span><span class="s1">BaseEstimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Isotonic regression model. 
 
    Read more in the :ref:`User Guide &lt;isotonic&gt;`. 
 
    .. versionadded:: 0.13 
 
    Parameters 
    ---------- 
    y_min : float, default=None 
        Lower bound on the lowest predicted value (the minimum value may 
        still be higher). If not set, defaults to -inf. 
 
    y_max : float, default=None 
        Upper bound on the highest predicted value (the maximum may still be 
        lower). If not set, defaults to +inf. 
 
    increasing : bool or 'auto', default=True 
        Determines whether the predictions should be constrained to increase 
        or decrease with `X`. 'auto' will decide based on the Spearman 
        correlation estimate's sign. 
 
    out_of_bounds : {'nan', 'clip', 'raise'}, default='nan' 
        Handles how `X` values outside of the training domain are handled 
        during prediction. 
 
        - 'nan', predictions will be NaN. 
        - 'clip', predictions will be set to the value corresponding to 
          the nearest train interval endpoint. 
        - 'raise', a `ValueError` is raised. 
 
    Attributes 
    ---------- 
    X_min_ : float 
        Minimum value of input array `X_` for left bound. 
 
    X_max_ : float 
        Maximum value of input array `X_` for right bound. 
 
    X_thresholds_ : ndarray of shape (n_thresholds,) 
        Unique ascending `X` values used to interpolate 
        the y = f(X) monotonic function. 
 
        .. versionadded:: 0.24 
 
    y_thresholds_ : ndarray of shape (n_thresholds,) 
        De-duplicated `y` values suitable to interpolate the y = f(X) 
        monotonic function. 
 
        .. versionadded:: 0.24 
 
    f_ : function 
        The stepwise interpolating function that covers the input domain ``X``. 
 
    increasing_ : bool 
        Inferred value for ``increasing``. 
 
    See Also 
    -------- 
    sklearn.linear_model.LinearRegression : Ordinary least squares Linear 
        Regression. 
    sklearn.ensemble.HistGradientBoostingRegressor : Gradient boosting that 
        is a non-parametric model accepting monotonicity constraints. 
    isotonic_regression : Function to solve the isotonic regression model. 
 
    Notes 
    ----- 
    Ties are broken using the secondary method from de Leeuw, 1977. 
 
    References 
    ---------- 
    Isotonic Median Regression: A Linear Programming Approach 
    Nilotpal Chakravarti 
    Mathematics of Operations Research 
    Vol. 14, No. 2 (May, 1989), pp. 303-308 
 
    Isotone Optimization in R : Pool-Adjacent-Violators 
    Algorithm (PAVA) and Active Set Methods 
    de Leeuw, Hornik, Mair 
    Journal of Statistical Software 2009 
 
    Correctness of Kruskal's algorithms for monotone regression with ties 
    de Leeuw, Psychometrica, 1977 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from sklearn.datasets import make_regression 
    &gt;&gt;&gt; from sklearn.isotonic import IsotonicRegression 
    &gt;&gt;&gt; X, y = make_regression(n_samples=10, n_features=1, random_state=41) 
    &gt;&gt;&gt; iso_reg = IsotonicRegression().fit(X, y) 
    &gt;&gt;&gt; iso_reg.predict([.1, .2]) 
    array([1.8628..., 3.7256...]) 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s5">&quot;y_min&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;both&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;y_max&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;both&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;increasing&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">, </span><span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;auto&quot;</span><span class="s4">})],</span>
        <span class="s5">&quot;out_of_bounds&quot;</span><span class="s4">: [</span><span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;nan&quot;</span><span class="s4">, </span><span class="s5">&quot;clip&quot;</span><span class="s4">, </span><span class="s5">&quot;raise&quot;</span><span class="s4">})],</span>
    <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, *, </span><span class="s1">y_min</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, </span><span class="s1">y_max</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, </span><span class="s1">increasing</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">out_of_bounds</span><span class="s4">=</span><span class="s5">&quot;nan&quot;</span><span class="s4">):</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">y_min </span><span class="s4">= </span><span class="s1">y_min</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">y_max </span><span class="s4">= </span><span class="s1">y_max</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">increasing </span><span class="s4">= </span><span class="s1">increasing</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">out_of_bounds </span><span class="s4">= </span><span class="s1">out_of_bounds</span>

    <span class="s3">def </span><span class="s1">_check_input_data_shape</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s3">if not </span><span class="s4">(</span><span class="s1">X</span><span class="s4">.</span><span class="s1">ndim </span><span class="s4">== </span><span class="s6">1 </span><span class="s3">or </span><span class="s4">(</span><span class="s1">X</span><span class="s4">.</span><span class="s1">ndim </span><span class="s4">== </span><span class="s6">2 </span><span class="s3">and </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">] == </span><span class="s6">1</span><span class="s4">)):</span>
            <span class="s1">msg </span><span class="s4">= (</span>
                <span class="s5">&quot;Isotonic regression input X should be a 1d array or &quot;</span>
                <span class="s5">&quot;2d array with 1 feature&quot;</span>
            <span class="s4">)</span>
            <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span><span class="s1">msg</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_build_f</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Build the f_ interp1d function.&quot;&quot;&quot;</span>

        <span class="s1">bounds_error </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">out_of_bounds </span><span class="s4">== </span><span class="s5">&quot;raise&quot;</span>
        <span class="s3">if </span><span class="s1">len</span><span class="s4">(</span><span class="s1">y</span><span class="s4">) == </span><span class="s6">1</span><span class="s4">:</span>
            <span class="s2"># single y, constant prediction</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">f_ </span><span class="s4">= </span><span class="s3">lambda </span><span class="s1">x</span><span class="s4">: </span><span class="s1">y</span><span class="s4">.</span><span class="s1">repeat</span><span class="s4">(</span><span class="s1">x</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">f_ </span><span class="s4">= </span><span class="s1">interpolate</span><span class="s4">.</span><span class="s1">interp1d</span><span class="s4">(</span>
                <span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">kind</span><span class="s4">=</span><span class="s5">&quot;linear&quot;</span><span class="s4">, </span><span class="s1">bounds_error</span><span class="s4">=</span><span class="s1">bounds_error</span>
            <span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_build_y</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">, </span><span class="s1">trim_duplicates</span><span class="s4">=</span><span class="s3">True</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Build the y_ IsotonicRegression.&quot;&quot;&quot;</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_check_input_data_shape</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">reshape</span><span class="s4">(-</span><span class="s6">1</span><span class="s4">)  </span><span class="s2"># use 1d view</span>

        <span class="s2"># Determine increasing if auto-determination requested</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">increasing </span><span class="s4">== </span><span class="s5">&quot;auto&quot;</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">increasing_ </span><span class="s4">= </span><span class="s1">check_increasing</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">increasing_ </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">increasing</span>

        <span class="s2"># If sample_weights is passed, removed zero-weight values and clean</span>
        <span class="s2"># order</span>
        <span class="s1">sample_weight </span><span class="s4">= </span><span class="s1">_check_sample_weight</span><span class="s4">(</span><span class="s1">sample_weight</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">X</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">)</span>
        <span class="s1">mask </span><span class="s4">= </span><span class="s1">sample_weight </span><span class="s4">&gt; </span><span class="s6">0</span>
        <span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight </span><span class="s4">= </span><span class="s1">X</span><span class="s4">[</span><span class="s1">mask</span><span class="s4">], </span><span class="s1">y</span><span class="s4">[</span><span class="s1">mask</span><span class="s4">], </span><span class="s1">sample_weight</span><span class="s4">[</span><span class="s1">mask</span><span class="s4">]</span>

        <span class="s1">order </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">lexsort</span><span class="s4">((</span><span class="s1">y</span><span class="s4">, </span><span class="s1">X</span><span class="s4">))</span>
        <span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight </span><span class="s4">= [</span><span class="s1">array</span><span class="s4">[</span><span class="s1">order</span><span class="s4">] </span><span class="s3">for </span><span class="s1">array </span><span class="s3">in </span><span class="s4">[</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">]]</span>
        <span class="s1">unique_X</span><span class="s4">, </span><span class="s1">unique_y</span><span class="s4">, </span><span class="s1">unique_sample_weight </span><span class="s4">= </span><span class="s1">_make_unique</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">)</span>

        <span class="s1">X </span><span class="s4">= </span><span class="s1">unique_X</span>
        <span class="s1">y </span><span class="s4">= </span><span class="s1">isotonic_regression</span><span class="s4">(</span>
            <span class="s1">unique_y</span><span class="s4">,</span>
            <span class="s1">sample_weight</span><span class="s4">=</span><span class="s1">unique_sample_weight</span><span class="s4">,</span>
            <span class="s1">y_min</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">y_min</span><span class="s4">,</span>
            <span class="s1">y_max</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">y_max</span><span class="s4">,</span>
            <span class="s1">increasing</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">increasing_</span><span class="s4">,</span>
        <span class="s4">)</span>

        <span class="s2"># Handle the left and right bounds on X</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">X_min_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">X_max_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">min</span><span class="s4">(</span><span class="s1">X</span><span class="s4">), </span><span class="s1">np</span><span class="s4">.</span><span class="s1">max</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">trim_duplicates</span><span class="s4">:</span>
            <span class="s2"># Remove unnecessary points for faster prediction</span>
            <span class="s1">keep_data </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ones</span><span class="s4">((</span><span class="s1">len</span><span class="s4">(</span><span class="s1">y</span><span class="s4">),), </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">bool</span><span class="s4">)</span>
            <span class="s2"># Aside from the 1st and last point, remove points whose y values</span>
            <span class="s2"># are equal to both the point before and the point after it.</span>
            <span class="s1">keep_data</span><span class="s4">[</span><span class="s6">1</span><span class="s4">:-</span><span class="s6">1</span><span class="s4">] = </span><span class="s1">np</span><span class="s4">.</span><span class="s1">logical_or</span><span class="s4">(</span>
                <span class="s1">np</span><span class="s4">.</span><span class="s1">not_equal</span><span class="s4">(</span><span class="s1">y</span><span class="s4">[</span><span class="s6">1</span><span class="s4">:-</span><span class="s6">1</span><span class="s4">], </span><span class="s1">y</span><span class="s4">[:-</span><span class="s6">2</span><span class="s4">]), </span><span class="s1">np</span><span class="s4">.</span><span class="s1">not_equal</span><span class="s4">(</span><span class="s1">y</span><span class="s4">[</span><span class="s6">1</span><span class="s4">:-</span><span class="s6">1</span><span class="s4">], </span><span class="s1">y</span><span class="s4">[</span><span class="s6">2</span><span class="s4">:])</span>
            <span class="s4">)</span>
            <span class="s3">return </span><span class="s1">X</span><span class="s4">[</span><span class="s1">keep_data</span><span class="s4">], </span><span class="s1">y</span><span class="s4">[</span><span class="s1">keep_data</span><span class="s4">]</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s2"># The ability to turn off trim_duplicates is only used to it make</span>
            <span class="s2"># easier to unit test that removing duplicates in y does not have</span>
            <span class="s2"># any impact the resulting interpolation function (besides</span>
            <span class="s2"># prediction speed).</span>
            <span class="s3">return </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Fit the model using X, y as training data. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples,) or (n_samples, 1) 
            Training data. 
 
            .. versionchanged:: 0.24 
               Also accepts 2d array with 1 feature. 
 
        y : array-like of shape (n_samples,) 
            Training target. 
 
        sample_weight : array-like of shape (n_samples,), default=None 
            Weights. If set to None, all weights will be set to 1 (equal 
            weights). 
 
        Returns 
        ------- 
        self : object 
            Returns an instance of self. 
 
        Notes 
        ----- 
        X is stored for future use, as :meth:`transform` needs X to interpolate 
        new input data. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_params </span><span class="s4">= </span><span class="s1">dict</span><span class="s4">(</span><span class="s1">accept_sparse</span><span class="s4">=</span><span class="s3">False</span><span class="s4">, </span><span class="s1">ensure_2d</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">, </span><span class="s1">input_name</span><span class="s4">=</span><span class="s5">&quot;X&quot;</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">], **</span><span class="s1">check_params</span>
        <span class="s4">)</span>
        <span class="s1">y </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">input_name</span><span class="s4">=</span><span class="s5">&quot;y&quot;</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">X</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">, **</span><span class="s1">check_params</span><span class="s4">)</span>
        <span class="s1">check_consistent_length</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">)</span>

        <span class="s2"># Transform y by running the isotonic regression algorithm and</span>
        <span class="s2"># transform X accordingly.</span>
        <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_build_y</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">sample_weight</span><span class="s4">)</span>

        <span class="s2"># It is necessary to store the non-redundant part of the training set</span>
        <span class="s2"># on the model to make it possible to support model persistence via</span>
        <span class="s2"># the pickle module as the object built by scipy.interp1d is not</span>
        <span class="s2"># picklable directly.</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">X_thresholds_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">y_thresholds_ </span><span class="s4">= </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span>

        <span class="s2"># Build the interpolation function</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_build_f</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span>

    <span class="s3">def </span><span class="s1">_transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">T</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;`_transform` is called by both `transform` and `predict` methods. 
 
        Since `transform` is wrapped to output arrays of specific types (e.g. 
        NumPy arrays, pandas DataFrame), we cannot make `predict` call `transform` 
        directly. 
 
        The above behaviour could be changed in the future, if we decide to output 
        other type of arrays when calling `predict`. 
        &quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;X_thresholds_&quot;</span><span class="s4">):</span>
            <span class="s1">dtype </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">X_thresholds_</span><span class="s4">.</span><span class="s1">dtype</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">dtype </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span>

        <span class="s1">T </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">T</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">dtype</span><span class="s4">, </span><span class="s1">ensure_2d</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">_check_input_data_shape</span><span class="s4">(</span><span class="s1">T</span><span class="s4">)</span>
        <span class="s1">T </span><span class="s4">= </span><span class="s1">T</span><span class="s4">.</span><span class="s1">reshape</span><span class="s4">(-</span><span class="s6">1</span><span class="s4">)  </span><span class="s2"># use 1d view</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">out_of_bounds </span><span class="s4">== </span><span class="s5">&quot;clip&quot;</span><span class="s4">:</span>
            <span class="s1">T </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">clip</span><span class="s4">(</span><span class="s1">T</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">X_min_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">X_max_</span><span class="s4">)</span>

        <span class="s1">res </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">f_</span><span class="s4">(</span><span class="s1">T</span><span class="s4">)</span>

        <span class="s2"># on scipy 0.17, interp1d up-casts to float64, so we cast back</span>
        <span class="s1">res </span><span class="s4">= </span><span class="s1">res</span><span class="s4">.</span><span class="s1">astype</span><span class="s4">(</span><span class="s1">T</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">)</span>

        <span class="s3">return </span><span class="s1">res</span>

    <span class="s3">def </span><span class="s1">transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">T</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Transform new data by linear interpolation. 
 
        Parameters 
        ---------- 
        T : array-like of shape (n_samples,) or (n_samples, 1) 
            Data to transform. 
 
            .. versionchanged:: 0.24 
               Also accepts 2d array with 1 feature. 
 
        Returns 
        ------- 
        y_pred : ndarray of shape (n_samples,) 
            The transformed data. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_transform</span><span class="s4">(</span><span class="s1">T</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">predict</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">T</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Predict new data by linear interpolation. 
 
        Parameters 
        ---------- 
        T : array-like of shape (n_samples,) or (n_samples, 1) 
            Data to transform. 
 
        Returns 
        ------- 
        y_pred : ndarray of shape (n_samples,) 
            Transformed data. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_transform</span><span class="s4">(</span><span class="s1">T</span><span class="s4">)</span>

    <span class="s2"># We implement get_feature_names_out here instead of using</span>
    <span class="s2"># `ClassNamePrefixFeaturesOutMixin`` because `input_features` are ignored.</span>
    <span class="s2"># `input_features` are ignored because `IsotonicRegression` accepts 1d</span>
    <span class="s2"># arrays and the semantics of `feature_names_in_` are not clear for 1d arrays.</span>
    <span class="s3">def </span><span class="s1">get_feature_names_out</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">input_features</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Get output feature names for transformation. 
 
        Parameters 
        ---------- 
        input_features : array-like of str or None, default=None 
            Ignored. 
 
        Returns 
        ------- 
        feature_names_out : ndarray of str objects 
            An ndarray with one string i.e. [&quot;isotonicregression0&quot;]. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;f_&quot;</span><span class="s4">)</span>
        <span class="s1">class_name </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s4">.</span><span class="s1">lower</span><span class="s4">()</span>
        <span class="s3">return </span><span class="s1">np</span><span class="s4">.</span><span class="s1">asarray</span><span class="s4">([</span><span class="s5">f&quot;</span><span class="s3">{</span><span class="s1">class_name</span><span class="s3">}</span><span class="s5">0&quot;</span><span class="s4">], </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">object</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">__getstate__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Pickle-protocol - return state of the estimator.&quot;&quot;&quot;</span>
        <span class="s1">state </span><span class="s4">= </span><span class="s1">super</span><span class="s4">().</span><span class="s1">__getstate__</span><span class="s4">()</span>
        <span class="s2"># remove interpolation method</span>
        <span class="s1">state</span><span class="s4">.</span><span class="s1">pop</span><span class="s4">(</span><span class="s5">&quot;f_&quot;</span><span class="s4">, </span><span class="s3">None</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">state</span>

    <span class="s3">def </span><span class="s1">__setstate__</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">state</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Pickle-protocol - set state of the estimator. 
 
        We need to rebuild the interpolation function. 
        &quot;&quot;&quot;</span>
        <span class="s1">super</span><span class="s4">().</span><span class="s1">__setstate__</span><span class="s4">(</span><span class="s1">state</span><span class="s4">)</span>
        <span class="s3">if </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;X_thresholds_&quot;</span><span class="s4">) </span><span class="s3">and </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;y_thresholds_&quot;</span><span class="s4">):</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_build_f</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">X_thresholds_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">y_thresholds_</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span><span class="s5">&quot;X_types&quot;</span><span class="s4">: [</span><span class="s5">&quot;1darray&quot;</span><span class="s4">]}</span>
</pre>
</body>
</html>