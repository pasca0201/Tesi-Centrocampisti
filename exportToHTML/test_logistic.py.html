<html>
<head>
<title>test_logistic.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #6aab73;}
.s4 { color: #7a7e85;}
.s5 { color: #2aacb8;}
.s6 { color: #5f826b; font-style: italic;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_logistic.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">itertools</span>
<span class="s0">import </span><span class="s1">os</span>
<span class="s0">import </span><span class="s1">warnings</span>
<span class="s0">from </span><span class="s1">functools </span><span class="s0">import </span><span class="s1">partial</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>
<span class="s0">from </span><span class="s1">numpy</span><span class="s2">.</span><span class="s1">testing </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">assert_allclose</span><span class="s2">,</span>
    <span class="s1">assert_almost_equal</span><span class="s2">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">,</span>
    <span class="s1">assert_array_equal</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">scipy </span><span class="s0">import </span><span class="s1">sparse</span>

<span class="s0">from </span><span class="s1">sklearn </span><span class="s0">import </span><span class="s1">config_context</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">base </span><span class="s0">import </span><span class="s1">clone</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">datasets </span><span class="s0">import </span><span class="s1">load_iris</span><span class="s2">, </span><span class="s1">make_classification</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">exceptions </span><span class="s0">import </span><span class="s1">ConvergenceWarning</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">linear_model </span><span class="s0">import </span><span class="s1">SGDClassifier</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">_logistic </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">LogisticRegression </span><span class="s0">as </span><span class="s1">LogisticRegressionDefault</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">_logistic </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">LogisticRegressionCV </span><span class="s0">as </span><span class="s1">LogisticRegressionCVDefault</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">linear_model</span><span class="s2">.</span><span class="s1">_logistic </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">_log_reg_scoring_path</span><span class="s2">,</span>
    <span class="s1">_logistic_regression_path</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">metrics </span><span class="s0">import </span><span class="s1">get_scorer</span><span class="s2">, </span><span class="s1">log_loss</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">model_selection </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">GridSearchCV</span><span class="s2">,</span>
    <span class="s1">StratifiedKFold</span><span class="s2">,</span>
    <span class="s1">cross_val_score</span><span class="s2">,</span>
    <span class="s1">train_test_split</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">multiclass </span><span class="s0">import </span><span class="s1">OneVsRestClassifier</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">preprocessing </span><span class="s0">import </span><span class="s1">LabelEncoder</span><span class="s2">, </span><span class="s1">StandardScaler</span><span class="s2">, </span><span class="s1">scale</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">svm </span><span class="s0">import </span><span class="s1">l1_min_c</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils </span><span class="s0">import </span><span class="s1">compute_class_weight</span><span class="s2">, </span><span class="s1">shuffle</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">_testing </span><span class="s0">import </span><span class="s1">ignore_warnings</span><span class="s2">, </span><span class="s1">skip_if_no_parallel</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">fixes </span><span class="s0">import </span><span class="s1">_IS_32BIT</span><span class="s2">, </span><span class="s1">COO_CONTAINERS</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span>

<span class="s1">pytestmark </span><span class="s2">= </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span>
    <span class="s3">&quot;error::sklearn.exceptions.ConvergenceWarning:sklearn.*&quot;</span>
<span class="s2">)</span>
<span class="s4"># Fixing random_state helps prevent ConvergenceWarnings</span>
<span class="s1">LogisticRegression </span><span class="s2">= </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">LogisticRegressionDefault</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
<span class="s1">LogisticRegressionCV </span><span class="s2">= </span><span class="s1">partial</span><span class="s2">(</span><span class="s1">LogisticRegressionCVDefault</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>


<span class="s1">SOLVERS </span><span class="s2">= (</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">, </span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cg&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">)</span>
<span class="s1">X </span><span class="s2">= [[-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">], [</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">], [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">]]</span>
<span class="s1">Y1 </span><span class="s2">= [</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">]</span>
<span class="s1">Y2 </span><span class="s2">= [</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">]</span>
<span class="s1">iris </span><span class="s2">= </span><span class="s1">load_iris</span><span class="s2">()</span>


<span class="s0">def </span><span class="s1">check_predictions</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">):</span>
    <span class="s6">&quot;&quot;&quot;Check that the model is able to fit the classification data&quot;&quot;&quot;</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">classes </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">n_classes </span><span class="s2">= </span><span class="s1">classes</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">]</span>

    <span class="s1">predicted </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">).</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">, </span><span class="s1">classes</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">predicted</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_samples</span><span class="s2">,)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">predicted</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">probabilities </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">probabilities</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_classes</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">probabilities</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s5">1</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">))</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">probabilities</span><span class="s2">.</span><span class="s1">argmax</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s5">1</span><span class="s2">), </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_predict_2_classes</span><span class="s2">(</span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s4"># Simple sanity check on a 2 classes dataset</span>
    <span class="s4"># Make sure it predicts the correct result on simple datasets.</span>
    <span class="s1">check_predictions</span><span class="s2">(</span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">), </span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y1</span><span class="s2">)</span>
    <span class="s1">check_predictions</span><span class="s2">(</span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">), </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">Y1</span><span class="s2">)</span>

    <span class="s1">check_predictions</span><span class="s2">(</span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">C</span><span class="s2">=</span><span class="s5">100</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">), </span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y1</span><span class="s2">)</span>
    <span class="s1">check_predictions</span><span class="s2">(</span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">C</span><span class="s2">=</span><span class="s5">100</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">), </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">Y1</span><span class="s2">)</span>

    <span class="s1">check_predictions</span><span class="s2">(</span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">), </span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y1</span><span class="s2">)</span>
    <span class="s1">check_predictions</span><span class="s2">(</span>
        <span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">), </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">Y1</span>
    <span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_logistic_cv_mock_scorer</span><span class="s2">():</span>
    <span class="s0">class </span><span class="s1">MockScorer</span><span class="s2">:</span>
        <span class="s0">def </span><span class="s1">__init__</span><span class="s2">(</span><span class="s1">self</span><span class="s2">):</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">calls </span><span class="s2">= </span><span class="s5">0</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">scores </span><span class="s2">= [</span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">0.4</span><span class="s2">, </span><span class="s5">0.8</span><span class="s2">, </span><span class="s5">0.5</span><span class="s2">]</span>

        <span class="s0">def </span><span class="s1">__call__</span><span class="s2">(</span><span class="s1">self</span><span class="s2">, </span><span class="s1">model</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">):</span>
            <span class="s1">score </span><span class="s2">= </span><span class="s1">self</span><span class="s2">.</span><span class="s1">scores</span><span class="s2">[</span><span class="s1">self</span><span class="s2">.</span><span class="s1">calls </span><span class="s2">% </span><span class="s1">len</span><span class="s2">(</span><span class="s1">self</span><span class="s2">.</span><span class="s1">scores</span><span class="s2">)]</span>
            <span class="s1">self</span><span class="s2">.</span><span class="s1">calls </span><span class="s2">+= </span><span class="s5">1</span>
            <span class="s0">return </span><span class="s1">score</span>

    <span class="s1">mock_scorer </span><span class="s2">= </span><span class="s1">MockScorer</span><span class="s2">()</span>
    <span class="s1">Cs </span><span class="s2">= [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">4</span><span class="s2">]</span>
    <span class="s1">cv </span><span class="s2">= </span><span class="s5">2</span>

    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">Cs</span><span class="s2">=</span><span class="s1">Cs</span><span class="s2">, </span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">mock_scorer</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">)</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s4"># Cs[2] has the highest score (0.8) from MockScorer</span>
    <span class="s0">assert </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">C_</span><span class="s2">[</span><span class="s5">0</span><span class="s2">] == </span><span class="s1">Cs</span><span class="s2">[</span><span class="s5">2</span><span class="s2">]</span>

    <span class="s4"># scorer called 8 times (cv*len(Cs))</span>
    <span class="s0">assert </span><span class="s1">mock_scorer</span><span class="s2">.</span><span class="s1">calls </span><span class="s2">== </span><span class="s1">cv </span><span class="s2">* </span><span class="s1">len</span><span class="s2">(</span><span class="s1">Cs</span><span class="s2">)</span>

    <span class="s4"># reset mock_scorer</span>
    <span class="s1">mock_scorer</span><span class="s2">.</span><span class="s1">calls </span><span class="s2">= </span><span class="s5">0</span>
    <span class="s1">custom_score </span><span class="s2">= </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">))</span>

    <span class="s0">assert </span><span class="s1">custom_score </span><span class="s2">== </span><span class="s1">mock_scorer</span><span class="s2">.</span><span class="s1">scores</span><span class="s2">[</span><span class="s5">0</span><span class="s2">]</span>
    <span class="s0">assert </span><span class="s1">mock_scorer</span><span class="s2">.</span><span class="s1">calls </span><span class="s2">== </span><span class="s5">1</span>


<span class="s2">@</span><span class="s1">skip_if_no_parallel</span>
<span class="s0">def </span><span class="s1">test_lr_liblinear_warning</span><span class="s2">():</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">.</span><span class="s1">shape</span>
    <span class="s1">target </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target_names</span><span class="s2">[</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">]</span>

    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s1">n_jobs</span><span class="s2">=</span><span class="s5">2</span><span class="s2">)</span>
    <span class="s1">warning_message </span><span class="s2">= (</span>
        <span class="s3">&quot;'n_jobs' &gt; 1 does not have any effect when&quot;</span>
        <span class="s3">&quot; 'solver' is set to 'liblinear'. Got 'n_jobs'&quot;</span>
        <span class="s3">&quot; = 2.&quot;</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">UserWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">warning_message</span><span class="s2">):</span>
        <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">target</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_predict_3_classes</span><span class="s2">(</span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s1">check_predictions</span><span class="s2">(</span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">C</span><span class="s2">=</span><span class="s5">10</span><span class="s2">), </span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y2</span><span class="s2">)</span>
    <span class="s1">check_predictions</span><span class="s2">(</span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">C</span><span class="s2">=</span><span class="s5">10</span><span class="s2">), </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">Y2</span><span class="s2">)</span>


<span class="s4"># TODO(1.7): remove filterwarnings after the deprecation of multi_class</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*'multi_class' was deprecated.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;clf&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">C</span><span class="s2">=</span><span class="s1">len</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">), </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">),</span>
        <span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">C</span><span class="s2">=</span><span class="s1">len</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">), </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">),</span>
        <span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">C</span><span class="s2">=</span><span class="s1">len</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">), </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;newton-cg&quot;</span><span class="s2">),</span>
        <span class="s1">LogisticRegression</span><span class="s2">(</span>
            <span class="s1">C</span><span class="s2">=</span><span class="s1">len</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">), </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span>
        <span class="s2">),</span>
        <span class="s1">LogisticRegression</span><span class="s2">(</span>
            <span class="s1">C</span><span class="s2">=</span><span class="s1">len</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">),</span>
            <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
            <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">,</span>
            <span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">,</span>
            <span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s1">LogisticRegression</span><span class="s2">(</span>
            <span class="s1">C</span><span class="s2">=</span><span class="s1">len</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">), </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span>
        <span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_predict_iris</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">):</span>
    <span class="s6">&quot;&quot;&quot;Test logistic regression with the iris dataset. 
 
    Test that both multinomial and OvR solvers handle multiclass data correctly and 
    give good accuracy score (&gt;0.95) for the training data. 
    &quot;&quot;&quot;</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">.</span><span class="s1">shape</span>
    <span class="s1">target </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target_names</span><span class="s2">[</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">]</span>

    <span class="s0">if </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">:</span>
        <span class="s4"># lbfgs has convergence issues on the iris data with its default max_iter=100</span>
        <span class="s0">with </span><span class="s1">warnings</span><span class="s2">.</span><span class="s1">catch_warnings</span><span class="s2">():</span>
            <span class="s1">warnings</span><span class="s2">.</span><span class="s1">simplefilter</span><span class="s2">(</span><span class="s3">&quot;ignore&quot;</span><span class="s2">, </span><span class="s1">ConvergenceWarning</span><span class="s2">)</span>
            <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">target</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">target</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">target</span><span class="s2">), </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">)</span>

    <span class="s1">pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">pred </span><span class="s2">== </span><span class="s1">target</span><span class="s2">) &gt; </span><span class="s5">0.95</span>

    <span class="s1">probabilities </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">probabilities</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s5">1</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">))</span>

    <span class="s1">pred </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target_names</span><span class="s2">[</span><span class="s1">probabilities</span><span class="s2">.</span><span class="s1">argmax</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s5">1</span><span class="s2">)]</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">pred </span><span class="s2">== </span><span class="s1">target</span><span class="s2">) &gt; </span><span class="s5">0.95</span>


<span class="s4"># TODO(1.7): remove filterwarnings after the deprecation of multi_class</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*'multi_class' was deprecated.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;LR&quot;</span><span class="s2">, [</span><span class="s1">LogisticRegression</span><span class="s2">, </span><span class="s1">LogisticRegressionCV</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_check_solver_option</span><span class="s2">(</span><span class="s1">LR</span><span class="s2">):</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span>

    <span class="s4"># only 'liblinear' and 'newton-cholesky' solver</span>
    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">]:</span>
        <span class="s1">msg </span><span class="s2">= </span><span class="s3">f&quot;Solver </span><span class="s0">{</span><span class="s1">solver</span><span class="s0">} </span><span class="s3">does not support a multinomial backend.&quot;</span>
        <span class="s1">lr </span><span class="s2">= </span><span class="s1">LR</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;multinomial&quot;</span><span class="s2">)</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
            <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s4"># all solvers except 'liblinear' and 'saga'</span>
    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cg&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">]:</span>
        <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Solver %s supports only 'l2' or None penalties,&quot; </span><span class="s2">% </span><span class="s1">solver</span>
        <span class="s1">lr </span><span class="s2">= </span><span class="s1">LR</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">)</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
            <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cg&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">]:</span>
        <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Solver %s supports only dual=False, got dual=True&quot; </span><span class="s2">% </span><span class="s1">solver</span>
        <span class="s1">lr </span><span class="s2">= </span><span class="s1">LR</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">dual</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">)</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
            <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s4"># only saga supports elasticnet. We only test for liblinear because the</span>
    <span class="s4"># error is raised before for the other solvers (solver %s supports only l2</span>
    <span class="s4"># penalties)</span>
    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">]:</span>
        <span class="s1">msg </span><span class="s2">= </span><span class="s3">f&quot;Only 'saga' solver supports elasticnet penalty, got solver=</span><span class="s0">{</span><span class="s1">solver</span><span class="s0">}</span><span class="s3">.&quot;</span>
        <span class="s1">lr </span><span class="s2">= </span><span class="s1">LR</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">)</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
            <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s4"># liblinear does not support penalty='none'</span>
    <span class="s4"># (LogisticRegressionCV does not supports penalty='none' at all)</span>
    <span class="s0">if </span><span class="s1">LR </span><span class="s0">is </span><span class="s1">LogisticRegression</span><span class="s2">:</span>
        <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;penalty=None is not supported for the liblinear solver&quot;</span>
        <span class="s1">lr </span><span class="s2">= </span><span class="s1">LR</span><span class="s2">(</span><span class="s1">penalty</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">)</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
            <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;LR&quot;</span><span class="s2">, [</span><span class="s1">LogisticRegression</span><span class="s2">, </span><span class="s1">LogisticRegressionCV</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_elasticnet_l1_ratio_err_helpful</span><span class="s2">(</span><span class="s1">LR</span><span class="s2">):</span>
    <span class="s4"># Check that an informative error message is raised when penalty=&quot;elasticnet&quot;</span>
    <span class="s4"># but l1_ratio is not specified.</span>
    <span class="s1">model </span><span class="s2">= </span><span class="s1">LR</span><span class="s2">(</span><span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s3">r&quot;.*l1_ratio.*&quot;</span><span class="s2">):</span>
        <span class="s1">model</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">], [</span><span class="s5">3</span><span class="s2">, </span><span class="s5">4</span><span class="s2">]]), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">]))</span>


<span class="s4"># TODO(1.7): remove whole test with deprecation of multi_class</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*'multi_class' was deprecated.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, [</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cg&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_multinomial_binary</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">):</span>
    <span class="s4"># Test multinomial LR on a binary problem.</span>
    <span class="s1">target </span><span class="s2">= (</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target </span><span class="s2">&gt; </span><span class="s5">0</span><span class="s2">).</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">intp</span><span class="s2">)</span>
    <span class="s1">target </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s3">&quot;setosa&quot;</span><span class="s2">, </span><span class="s3">&quot;not-setosa&quot;</span><span class="s2">])[</span><span class="s1">target</span><span class="s2">]</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;multinomial&quot;</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s5">2000</span>
    <span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">target</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s5">1</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s5">1</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s5">1</span><span class="s2">,)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">), </span><span class="s1">target</span><span class="s2">)</span>

    <span class="s1">mlr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;multinomial&quot;</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span>
    <span class="s2">)</span>
    <span class="s1">mlr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">target</span><span class="s2">)</span>
    <span class="s1">pred </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">[</span><span class="s1">np</span><span class="s2">.</span><span class="s1">argmax</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_log_proba</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">), </span><span class="s1">axis</span><span class="s2">=</span><span class="s5">1</span><span class="s2">)]</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">pred </span><span class="s2">== </span><span class="s1">target</span><span class="s2">) &gt; </span><span class="s5">0.9</span>


<span class="s4"># TODO(1.7): remove filterwarnings after the deprecation of multi_class</span>
<span class="s4"># Maybe even remove this whole test as correctness of multinomial loss is tested</span>
<span class="s4"># elsewhere.</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*'multi_class' was deprecated.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_multinomial_binary_probabilities</span><span class="s2">(</span><span class="s1">global_random_seed</span><span class="s2">):</span>
    <span class="s4"># Test multinomial LR gives expected probabilities based on the</span>
    <span class="s4"># decision function, for a binary problem.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;multinomial&quot;</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-3</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">decision </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">proba </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">expected_proba_class_1 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(</span><span class="s1">decision</span><span class="s2">) / (</span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(</span><span class="s1">decision</span><span class="s2">) + </span><span class="s1">np</span><span class="s2">.</span><span class="s1">exp</span><span class="s2">(-</span><span class="s1">decision</span><span class="s2">))</span>
    <span class="s1">expected_proba </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">c_</span><span class="s2">[</span><span class="s5">1 </span><span class="s2">- </span><span class="s1">expected_proba_class_1</span><span class="s2">, </span><span class="s1">expected_proba_class_1</span><span class="s2">]</span>

    <span class="s1">assert_almost_equal</span><span class="s2">(</span><span class="s1">proba</span><span class="s2">, </span><span class="s1">expected_proba</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;coo_container&quot;</span><span class="s2">, </span><span class="s1">COO_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_sparsify</span><span class="s2">(</span><span class="s1">coo_container</span><span class="s2">):</span>
    <span class="s4"># Test sparsify and densify members.</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">.</span><span class="s1">shape</span>
    <span class="s1">target </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target_names</span><span class="s2">[</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">]</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">scale</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">target</span><span class="s2">)</span>

    <span class="s1">pred_d_d </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">sparsify</span><span class="s2">()</span>
    <span class="s0">assert </span><span class="s1">sparse</span><span class="s2">.</span><span class="s1">issparse</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>
    <span class="s1">pred_s_d </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">sp_data </span><span class="s2">= </span><span class="s1">coo_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">pred_s_s </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">sp_data</span><span class="s2">)</span>

    <span class="s1">clf</span><span class="s2">.</span><span class="s1">densify</span><span class="s2">()</span>
    <span class="s1">pred_d_s </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">sp_data</span><span class="s2">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">pred_d_d</span><span class="s2">, </span><span class="s1">pred_s_d</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">pred_d_d</span><span class="s2">, </span><span class="s1">pred_s_s</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">pred_d_d</span><span class="s2">, </span><span class="s1">pred_d_s</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_inconsistent_input</span><span class="s2">():</span>
    <span class="s4"># Test that an exception is raised on inconsistent input</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">X_ </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">random_sample</span><span class="s2">((</span><span class="s5">5</span><span class="s2">, </span><span class="s5">10</span><span class="s2">))</span>
    <span class="s1">y_ </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">X_</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">])</span>
    <span class="s1">y_</span><span class="s2">[</span><span class="s5">0</span><span class="s2">] = </span><span class="s5">0</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>

    <span class="s4"># Wrong dimensions for training data</span>
    <span class="s1">y_wrong </span><span class="s2">= </span><span class="s1">y_</span><span class="s2">[:-</span><span class="s5">1</span><span class="s2">]</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_wrong</span><span class="s2">)</span>

    <span class="s4"># Wrong dimensions for test data</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_</span><span class="s2">, </span><span class="s1">y_</span><span class="s2">).</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">rng</span><span class="s2">.</span><span class="s1">random_sample</span><span class="s2">((</span><span class="s5">3</span><span class="s2">, </span><span class="s5">12</span><span class="s2">)))</span>


<span class="s0">def </span><span class="s1">test_write_parameters</span><span class="s2">():</span>
    <span class="s4"># Test that we can write to coef_ and intercept_</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y1</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">[:] = </span><span class="s5">0</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">[:] = </span><span class="s5">0</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s5">0</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_nan</span><span class="s2">():</span>
    <span class="s4"># Test proper NaN handling.</span>
    <span class="s4"># Regression test for Issue #252: fit used to go into an infinite loop.</span>
    <span class="s1">Xnan </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
    <span class="s1">Xnan</span><span class="s2">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">] = </span><span class="s1">np</span><span class="s2">.</span><span class="s1">nan</span>
    <span class="s1">logistic </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">):</span>
        <span class="s1">logistic</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">Xnan</span><span class="s2">, </span><span class="s1">Y1</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_consistency_path</span><span class="s2">():</span>
    <span class="s4"># Test that the path algorithm is consistent</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">((</span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s5">100</span><span class="s2">, </span><span class="s5">2</span><span class="s2">) + [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">], </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s5">100</span><span class="s2">, </span><span class="s5">2</span><span class="s2">)))</span>
    <span class="s1">y </span><span class="s2">= [</span><span class="s5">1</span><span class="s2">] * </span><span class="s5">100 </span><span class="s2">+ [-</span><span class="s5">1</span><span class="s2">] * </span><span class="s5">100</span>
    <span class="s1">Cs </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">logspace</span><span class="s2">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">4</span><span class="s2">, </span><span class="s5">10</span><span class="s2">)</span>

    <span class="s1">f </span><span class="s2">= </span><span class="s1">ignore_warnings</span>
    <span class="s4"># can't test with fit_intercept=True since LIBLINEAR</span>
    <span class="s4"># penalizes the intercept</span>
    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">]:</span>
        <span class="s1">coefs</span><span class="s2">, </span><span class="s1">Cs</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">= </span><span class="s1">f</span><span class="s2">(</span><span class="s1">_logistic_regression_path</span><span class="s2">)(</span>
            <span class="s1">X</span><span class="s2">,</span>
            <span class="s1">y</span><span class="s2">,</span>
            <span class="s1">Cs</span><span class="s2">=</span><span class="s1">Cs</span><span class="s2">,</span>
            <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
            <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-5</span><span class="s2">,</span>
            <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
            <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">1000</span><span class="s2">,</span>
            <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s2">)</span>
        <span class="s0">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">C </span><span class="s0">in </span><span class="s1">enumerate</span><span class="s2">(</span><span class="s1">Cs</span><span class="s2">):</span>
            <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
                <span class="s1">C</span><span class="s2">=</span><span class="s1">C</span><span class="s2">,</span>
                <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
                <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-5</span><span class="s2">,</span>
                <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
                <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
                <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">1000</span><span class="s2">,</span>
            <span class="s2">)</span>
            <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
            <span class="s1">lr_coef </span><span class="s2">= </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">()</span>
            <span class="s1">assert_array_almost_equal</span><span class="s2">(</span>
                <span class="s1">lr_coef</span><span class="s2">, </span><span class="s1">coefs</span><span class="s2">[</span><span class="s1">i</span><span class="s2">], </span><span class="s1">decimal</span><span class="s2">=</span><span class="s5">4</span><span class="s2">, </span><span class="s1">err_msg</span><span class="s2">=</span><span class="s3">&quot;with solver = %s&quot; </span><span class="s2">% </span><span class="s1">solver</span>
            <span class="s2">)</span>

    <span class="s4"># test for fit_intercept=True</span>
    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cg&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">):</span>
        <span class="s1">Cs </span><span class="s2">= [</span><span class="s5">1e3</span><span class="s2">]</span>
        <span class="s1">coefs</span><span class="s2">, </span><span class="s1">Cs</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">= </span><span class="s1">f</span><span class="s2">(</span><span class="s1">_logistic_regression_path</span><span class="s2">)(</span>
            <span class="s1">X</span><span class="s2">,</span>
            <span class="s1">y</span><span class="s2">,</span>
            <span class="s1">Cs</span><span class="s2">=</span><span class="s1">Cs</span><span class="s2">,</span>
            <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-6</span><span class="s2">,</span>
            <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
            <span class="s1">intercept_scaling</span><span class="s2">=</span><span class="s5">10000.0</span><span class="s2">,</span>
            <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s2">)</span>
        <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
            <span class="s1">C</span><span class="s2">=</span><span class="s1">Cs</span><span class="s2">[</span><span class="s5">0</span><span class="s2">],</span>
            <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-6</span><span class="s2">,</span>
            <span class="s1">intercept_scaling</span><span class="s2">=</span><span class="s5">10000.0</span><span class="s2">,</span>
            <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
            <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
        <span class="s2">)</span>
        <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s1">lr_coef </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">([</span><span class="s1">lr</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">(), </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">])</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span>
            <span class="s1">lr_coef</span><span class="s2">, </span><span class="s1">coefs</span><span class="s2">[</span><span class="s5">0</span><span class="s2">], </span><span class="s1">decimal</span><span class="s2">=</span><span class="s5">4</span><span class="s2">, </span><span class="s1">err_msg</span><span class="s2">=</span><span class="s3">&quot;with solver = %s&quot; </span><span class="s2">% </span><span class="s1">solver</span>
        <span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_logistic_regression_path_convergence_fail</span><span class="s2">():</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">((</span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s5">100</span><span class="s2">, </span><span class="s5">2</span><span class="s2">) + [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">], </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s5">100</span><span class="s2">, </span><span class="s5">2</span><span class="s2">)))</span>
    <span class="s1">y </span><span class="s2">= [</span><span class="s5">1</span><span class="s2">] * </span><span class="s5">100 </span><span class="s2">+ [-</span><span class="s5">1</span><span class="s2">] * </span><span class="s5">100</span>
    <span class="s1">Cs </span><span class="s2">= [</span><span class="s5">1e3</span><span class="s2">]</span>

    <span class="s4"># Check that the convergence message points to both a model agnostic</span>
    <span class="s4"># advice (scaling the data) and to the logistic regression specific</span>
    <span class="s4"># documentation that includes hints on the solver configuration.</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">ConvergenceWarning</span><span class="s2">) </span><span class="s0">as </span><span class="s1">record</span><span class="s2">:</span>
        <span class="s1">_logistic_regression_path</span><span class="s2">(</span>
            <span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">Cs</span><span class="s2">=</span><span class="s1">Cs</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s5">0.0</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">verbose</span><span class="s2">=</span><span class="s5">0</span>
        <span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">len</span><span class="s2">(</span><span class="s1">record</span><span class="s2">) == </span><span class="s5">1</span>
    <span class="s1">warn_msg </span><span class="s2">= </span><span class="s1">record</span><span class="s2">[</span><span class="s5">0</span><span class="s2">].</span><span class="s1">message</span><span class="s2">.</span><span class="s1">args</span><span class="s2">[</span><span class="s5">0</span><span class="s2">]</span>
    <span class="s0">assert </span><span class="s3">&quot;lbfgs failed to converge&quot; </span><span class="s0">in </span><span class="s1">warn_msg</span>
    <span class="s0">assert </span><span class="s3">&quot;Increase the number of iterations&quot; </span><span class="s0">in </span><span class="s1">warn_msg</span>
    <span class="s0">assert </span><span class="s3">&quot;scale the data&quot; </span><span class="s0">in </span><span class="s1">warn_msg</span>
    <span class="s0">assert </span><span class="s3">&quot;linear_model.html#logistic-regression&quot; </span><span class="s0">in </span><span class="s1">warn_msg</span>


<span class="s0">def </span><span class="s1">test_liblinear_dual_random_state</span><span class="s2">():</span>
    <span class="s4"># random_state is relevant for liblinear solver only if dual=True</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">lr1 </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">dual</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-3</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lr1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">lr2 </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">dual</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-3</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lr2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">lr3 </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">8</span><span class="s2">,</span>
        <span class="s1">dual</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-3</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lr3</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s4"># same result for same random state</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">lr2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>
    <span class="s4"># different results for different random states</span>
    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Arrays are not almost equal to 6 decimals&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">AssertionError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">lr3</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_logistic_cv</span><span class="s2">():</span>
    <span class="s4"># test for LogisticRegressionCV object</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s5">50</span><span class="s2">, </span><span class="s5">5</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">X_ref </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sign</span><span class="s2">(</span><span class="s1">X_ref</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s5">5 </span><span class="s2">* </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s1">n_features</span><span class="s2">)))</span>
    <span class="s1">X_ref </span><span class="s2">-= </span><span class="s1">X_ref</span><span class="s2">.</span><span class="s1">mean</span><span class="s2">()</span>
    <span class="s1">X_ref </span><span class="s2">/= </span><span class="s1">X_ref</span><span class="s2">.</span><span class="s1">std</span><span class="s2">()</span>
    <span class="s1">lr_cv </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span>
        <span class="s1">Cs</span><span class="s2">=[</span><span class="s5">1.0</span><span class="s2">], </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s5">3</span>
    <span class="s2">)</span>
    <span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_ref</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">C</span><span class="s2">=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">)</span>
    <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_ref</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>

    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">, (</span><span class="s5">1</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">))</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">, [-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">len</span><span class="s2">(</span><span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">) == </span><span class="s5">2</span>

    <span class="s1">coefs_paths </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">list</span><span class="s2">(</span><span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">coefs_paths_</span><span class="s2">.</span><span class="s1">values</span><span class="s2">()))</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">coefs_paths</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">, (</span><span class="s5">1</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">))</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">Cs_</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">, (</span><span class="s5">1</span><span class="s2">,))</span>
    <span class="s1">scores </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">list</span><span class="s2">(</span><span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">scores_</span><span class="s2">.</span><span class="s1">values</span><span class="s2">()))</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">scores</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">, (</span><span class="s5">1</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">1</span><span class="s2">))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;scoring, multiclass_agg_list&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">(</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">, [</span><span class="s3">&quot;&quot;</span><span class="s2">]),</span>
        <span class="s2">(</span><span class="s3">&quot;precision&quot;</span><span class="s2">, [</span><span class="s3">&quot;_macro&quot;</span><span class="s2">, </span><span class="s3">&quot;_weighted&quot;</span><span class="s2">]),</span>
        <span class="s4"># no need to test for micro averaging because it</span>
        <span class="s4"># is the same as accuracy for f1, precision,</span>
        <span class="s4"># and recall (see https://github.com/</span>
        <span class="s4"># scikit-learn/scikit-learn/pull/</span>
        <span class="s4"># 11578#discussion_r203250062)</span>
        <span class="s2">(</span><span class="s3">&quot;f1&quot;</span><span class="s2">, [</span><span class="s3">&quot;_macro&quot;</span><span class="s2">, </span><span class="s3">&quot;_weighted&quot;</span><span class="s2">]),</span>
        <span class="s2">(</span><span class="s3">&quot;neg_log_loss&quot;</span><span class="s2">, [</span><span class="s3">&quot;&quot;</span><span class="s2">]),</span>
        <span class="s2">(</span><span class="s3">&quot;recall&quot;</span><span class="s2">, [</span><span class="s3">&quot;_macro&quot;</span><span class="s2">, </span><span class="s3">&quot;_weighted&quot;</span><span class="s2">]),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_logistic_cv_multinomial_score</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">, </span><span class="s1">multiclass_agg_list</span><span class="s2">):</span>
    <span class="s4"># test that LogisticRegressionCV uses the right score to compute its</span>
    <span class="s4"># cross-validation scores when using a multinomial scoring</span>
    <span class="s4"># see https://github.com/scikit-learn/scikit-learn/issues/8720</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s5">100</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">n_classes</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s5">6</span>
    <span class="s2">)</span>
    <span class="s1">train</span><span class="s2">, </span><span class="s1">test </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s5">80</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s5">80</span><span class="s2">, </span><span class="s5">100</span><span class="s2">)</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">C</span><span class="s2">=</span><span class="s5">1.0</span><span class="s2">)</span>
    <span class="s4"># we use lbfgs to support multinomial</span>
    <span class="s1">params </span><span class="s2">= </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">get_params</span><span class="s2">()</span>
    <span class="s4"># we store the params to set them further in _log_reg_scoring_path</span>
    <span class="s0">for </span><span class="s1">key </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;C&quot;</span><span class="s2">, </span><span class="s3">&quot;n_jobs&quot;</span><span class="s2">, </span><span class="s3">&quot;warm_start&quot;</span><span class="s2">]:</span>
        <span class="s0">del </span><span class="s1">params</span><span class="s2">[</span><span class="s1">key</span><span class="s2">]</span>
    <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[</span><span class="s1">train</span><span class="s2">], </span><span class="s1">y</span><span class="s2">[</span><span class="s1">train</span><span class="s2">])</span>
    <span class="s0">for </span><span class="s1">averaging </span><span class="s0">in </span><span class="s1">multiclass_agg_list</span><span class="s2">:</span>
        <span class="s1">scorer </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s1">scoring </span><span class="s2">+ </span><span class="s1">averaging</span><span class="s2">)</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span>
            <span class="s1">_log_reg_scoring_path</span><span class="s2">(</span>
                <span class="s1">X</span><span class="s2">,</span>
                <span class="s1">y</span><span class="s2">,</span>
                <span class="s1">train</span><span class="s2">,</span>
                <span class="s1">test</span><span class="s2">,</span>
                <span class="s1">Cs</span><span class="s2">=[</span><span class="s5">1.0</span><span class="s2">],</span>
                <span class="s1">scoring</span><span class="s2">=</span><span class="s1">scorer</span><span class="s2">,</span>
                <span class="s1">pos_class</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
                <span class="s1">max_squared_sum</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
                <span class="s1">sample_weight</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
                <span class="s1">score_params</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
                <span class="s2">**(</span><span class="s1">params </span><span class="s2">| {</span><span class="s3">&quot;multi_class&quot;</span><span class="s2">: </span><span class="s3">&quot;multinomial&quot;</span><span class="s2">}),</span>
            <span class="s2">)[</span><span class="s5">2</span><span class="s2">][</span><span class="s5">0</span><span class="s2">],</span>
            <span class="s1">scorer</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">X</span><span class="s2">[</span><span class="s1">test</span><span class="s2">], </span><span class="s1">y</span><span class="s2">[</span><span class="s1">test</span><span class="s2">]),</span>
        <span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_multinomial_logistic_regression_string_inputs</span><span class="s2">():</span>
    <span class="s4"># Test with string labels for LogisticRegression(CV)</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">n_classes </span><span class="s2">= </span><span class="s5">50</span><span class="s2">, </span><span class="s5">5</span><span class="s2">, </span><span class="s5">3</span>
    <span class="s1">X_ref</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">,</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s1">n_classes</span><span class="s2">,</span>
        <span class="s1">n_informative</span><span class="s2">=</span><span class="s5">3</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">y_str </span><span class="s2">= </span><span class="s1">LabelEncoder</span><span class="s2">().</span><span class="s1">fit</span><span class="s2">([</span><span class="s3">&quot;bar&quot;</span><span class="s2">, </span><span class="s3">&quot;baz&quot;</span><span class="s2">, </span><span class="s3">&quot;foo&quot;</span><span class="s2">]).</span><span class="s1">inverse_transform</span><span class="s2">(</span><span class="s1">y</span><span class="s2">)</span>
    <span class="s4"># For numerical labels, let y values be taken from set (-1, 0, 1)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">y</span><span class="s2">) - </span><span class="s5">1</span>
    <span class="s4"># Test for string labels</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">()</span>
    <span class="s1">lr_cv </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">Cs</span><span class="s2">=</span><span class="s5">3</span><span class="s2">)</span>
    <span class="s1">lr_str </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">()</span>
    <span class="s1">lr_cv_str </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">Cs</span><span class="s2">=</span><span class="s5">3</span><span class="s2">)</span>

    <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_ref</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_ref</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">lr_str</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_ref</span><span class="s2">, </span><span class="s1">y_str</span><span class="s2">)</span>
    <span class="s1">lr_cv_str</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_ref</span><span class="s2">, </span><span class="s1">y_str</span><span class="s2">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">lr_str</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">sorted</span><span class="s2">(</span><span class="s1">lr_str</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">) == [</span><span class="s3">&quot;bar&quot;</span><span class="s2">, </span><span class="s3">&quot;baz&quot;</span><span class="s2">, </span><span class="s3">&quot;foo&quot;</span><span class="s2">]</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">lr_cv_str</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">sorted</span><span class="s2">(</span><span class="s1">lr_str</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">) == [</span><span class="s3">&quot;bar&quot;</span><span class="s2">, </span><span class="s3">&quot;baz&quot;</span><span class="s2">, </span><span class="s3">&quot;foo&quot;</span><span class="s2">]</span>
    <span class="s0">assert </span><span class="s1">sorted</span><span class="s2">(</span><span class="s1">lr_cv_str</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">) == [</span><span class="s3">&quot;bar&quot;</span><span class="s2">, </span><span class="s3">&quot;baz&quot;</span><span class="s2">, </span><span class="s3">&quot;foo&quot;</span><span class="s2">]</span>

    <span class="s4"># The predictions should be in original labels</span>
    <span class="s0">assert </span><span class="s1">sorted</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">lr_str</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_ref</span><span class="s2">))) == [</span><span class="s3">&quot;bar&quot;</span><span class="s2">, </span><span class="s3">&quot;baz&quot;</span><span class="s2">, </span><span class="s3">&quot;foo&quot;</span><span class="s2">]</span>
    <span class="s0">assert </span><span class="s1">sorted</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">lr_cv_str</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_ref</span><span class="s2">))) == [</span><span class="s3">&quot;bar&quot;</span><span class="s2">, </span><span class="s3">&quot;baz&quot;</span><span class="s2">, </span><span class="s3">&quot;foo&quot;</span><span class="s2">]</span>

    <span class="s4"># Make sure class weights can be given with string labels</span>
    <span class="s1">lr_cv_str </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">={</span><span class="s3">&quot;bar&quot;</span><span class="s2">: </span><span class="s5">1</span><span class="s2">, </span><span class="s3">&quot;baz&quot;</span><span class="s2">: </span><span class="s5">2</span><span class="s2">, </span><span class="s3">&quot;foo&quot;</span><span class="s2">: </span><span class="s5">0</span><span class="s2">}).</span><span class="s1">fit</span><span class="s2">(</span>
        <span class="s1">X_ref</span><span class="s2">, </span><span class="s1">y_str</span>
    <span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">sorted</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">lr_cv_str</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_ref</span><span class="s2">))) == [</span><span class="s3">&quot;bar&quot;</span><span class="s2">, </span><span class="s3">&quot;baz&quot;</span><span class="s2">]</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_logistic_cv_sparse</span><span class="s2">(</span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">50</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s5">5</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">X</span><span class="s2">[</span><span class="s1">X </span><span class="s2">&lt; </span><span class="s5">1.0</span><span class="s2">] = </span><span class="s5">0.0</span>
    <span class="s1">csr </span><span class="s2">= </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">()</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">clfs </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">()</span>
    <span class="s1">clfs</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">csr</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clfs</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clfs</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clfs</span><span class="s2">.</span><span class="s1">C_ </span><span class="s2">== </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">C_</span>


<span class="s4"># TODO(1.7): remove filterwarnings after the deprecation of multi_class</span>
<span class="s4"># Best remove this whole test.</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*'multi_class' was deprecated.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_ovr_multinomial_iris</span><span class="s2">():</span>
    <span class="s4"># Test that OvR and multinomial are correct using the iris dataset.</span>
    <span class="s1">train</span><span class="s2">, </span><span class="s1">target </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s1">train</span><span class="s2">.</span><span class="s1">shape</span>

    <span class="s4"># The cv indices from stratified kfold (where stratification is done based</span>
    <span class="s4"># on the fine-grained iris classes, i.e, before the classes 0 and 1 are</span>
    <span class="s4"># conflated) is used for both clf and clf1</span>
    <span class="s1">n_cv </span><span class="s2">= </span><span class="s5">2</span>
    <span class="s1">cv </span><span class="s2">= </span><span class="s1">StratifiedKFold</span><span class="s2">(</span><span class="s1">n_cv</span><span class="s2">)</span>
    <span class="s1">precomputed_folds </span><span class="s2">= </span><span class="s1">list</span><span class="s2">(</span><span class="s1">cv</span><span class="s2">.</span><span class="s1">split</span><span class="s2">(</span><span class="s1">train</span><span class="s2">, </span><span class="s1">target</span><span class="s2">))</span>

    <span class="s4"># Train clf on the original dataset where classes 0 and 1 are separated</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">cv</span><span class="s2">=</span><span class="s1">precomputed_folds</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">train</span><span class="s2">, </span><span class="s1">target</span><span class="s2">)</span>

    <span class="s4"># Conflate classes 0 and 1 and train clf1 on this modified dataset</span>
    <span class="s1">clf1 </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">cv</span><span class="s2">=</span><span class="s1">precomputed_folds</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">)</span>
    <span class="s1">target_copy </span><span class="s2">= </span><span class="s1">target</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">()</span>
    <span class="s1">target_copy</span><span class="s2">[</span><span class="s1">target_copy </span><span class="s2">== </span><span class="s5">0</span><span class="s2">] = </span><span class="s5">1</span>
    <span class="s1">clf1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">train</span><span class="s2">, </span><span class="s1">target_copy</span><span class="s2">)</span>

    <span class="s4"># Ensure that what OvR learns for class2 is same regardless of whether</span>
    <span class="s4"># classes 0 and 1 are separated or not</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">scores_</span><span class="s2">[</span><span class="s5">2</span><span class="s2">], </span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">scores_</span><span class="s2">[</span><span class="s5">2</span><span class="s2">])</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">[</span><span class="s5">2</span><span class="s2">:], </span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">[</span><span class="s5">2</span><span class="s2">][</span><span class="s1">np</span><span class="s2">.</span><span class="s1">newaxis</span><span class="s2">, :], </span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>

    <span class="s4"># Test the shape of various attributes.</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s5">3</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">, [</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">])</span>
    <span class="s1">coefs_paths </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">list</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coefs_paths_</span><span class="s2">.</span><span class="s1">values</span><span class="s2">()))</span>
    <span class="s0">assert </span><span class="s1">coefs_paths</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s5">3</span><span class="s2">, </span><span class="s1">n_cv</span><span class="s2">, </span><span class="s5">10</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">+ </span><span class="s5">1</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">Cs_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s5">10</span><span class="s2">,)</span>
    <span class="s1">scores </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">list</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">scores_</span><span class="s2">.</span><span class="s1">values</span><span class="s2">()))</span>
    <span class="s0">assert </span><span class="s1">scores</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s5">3</span><span class="s2">, </span><span class="s1">n_cv</span><span class="s2">, </span><span class="s5">10</span><span class="s2">)</span>

    <span class="s4"># Test that for the iris data multinomial gives a better accuracy than OvR</span>
    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cg&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">]:</span>
        <span class="s1">max_iter </span><span class="s2">= </span><span class="s5">500 </span><span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">] </span><span class="s0">else </span><span class="s5">30</span>
        <span class="s1">clf_multi </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span>
            <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
            <span class="s1">max_iter</span><span class="s2">=</span><span class="s1">max_iter</span><span class="s2">,</span>
            <span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">,</span>
            <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-3 </span><span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">] </span><span class="s0">else </span><span class="s5">1e-2</span><span class="s2">,</span>
            <span class="s1">cv</span><span class="s2">=</span><span class="s5">2</span><span class="s2">,</span>
        <span class="s2">)</span>
        <span class="s0">if </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">:</span>
            <span class="s4"># lbfgs requires scaling to avoid convergence warnings</span>
            <span class="s1">train </span><span class="s2">= </span><span class="s1">scale</span><span class="s2">(</span><span class="s1">train</span><span class="s2">)</span>

        <span class="s1">clf_multi</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">train</span><span class="s2">, </span><span class="s1">target</span><span class="s2">)</span>
        <span class="s1">multi_score </span><span class="s2">= </span><span class="s1">clf_multi</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">train</span><span class="s2">, </span><span class="s1">target</span><span class="s2">)</span>
        <span class="s1">ovr_score </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">train</span><span class="s2">, </span><span class="s1">target</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">multi_score </span><span class="s2">&gt; </span><span class="s1">ovr_score</span>

        <span class="s4"># Test attributes of LogisticRegressionCV</span>
        <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== </span><span class="s1">clf_multi</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape</span>
        <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf_multi</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">, [</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">])</span>
        <span class="s1">coefs_paths </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">list</span><span class="s2">(</span><span class="s1">clf_multi</span><span class="s2">.</span><span class="s1">coefs_paths_</span><span class="s2">.</span><span class="s1">values</span><span class="s2">()))</span>
        <span class="s0">assert </span><span class="s1">coefs_paths</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s5">3</span><span class="s2">, </span><span class="s1">n_cv</span><span class="s2">, </span><span class="s5">10</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">+ </span><span class="s5">1</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">clf_multi</span><span class="s2">.</span><span class="s1">Cs_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s5">10</span><span class="s2">,)</span>
        <span class="s1">scores </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">list</span><span class="s2">(</span><span class="s1">clf_multi</span><span class="s2">.</span><span class="s1">scores_</span><span class="s2">.</span><span class="s1">values</span><span class="s2">()))</span>
        <span class="s0">assert </span><span class="s1">scores</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s5">3</span><span class="s2">, </span><span class="s1">n_cv</span><span class="s2">, </span><span class="s5">10</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_logistic_regression_solvers</span><span class="s2">():</span>
    <span class="s6">&quot;&quot;&quot;Test solvers converge to the same result.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_features</span><span class="s2">=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s5">5</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>

    <span class="s1">params </span><span class="s2">= </span><span class="s1">dict</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">)</span>

    <span class="s1">regressors </span><span class="s2">= {</span>
        <span class="s1">solver</span><span class="s2">: </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, **</span><span class="s1">params</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s1">SOLVERS</span>
    <span class="s2">}</span>

    <span class="s0">for </span><span class="s1">solver_1</span><span class="s2">, </span><span class="s1">solver_2 </span><span class="s0">in </span><span class="s1">itertools</span><span class="s2">.</span><span class="s1">combinations</span><span class="s2">(</span><span class="s1">regressors</span><span class="s2">, </span><span class="s1">r</span><span class="s2">=</span><span class="s5">2</span><span class="s2">):</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span>
            <span class="s1">regressors</span><span class="s2">[</span><span class="s1">solver_1</span><span class="s2">].</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">regressors</span><span class="s2">[</span><span class="s1">solver_2</span><span class="s2">].</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s5">3</span>
        <span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_logistic_regression_solvers_multiclass</span><span class="s2">():</span>
    <span class="s6">&quot;&quot;&quot;Test solvers converge to the same result for multiclass problems.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s5">20</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s5">20</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">n_classes</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span>
    <span class="s2">)</span>
    <span class="s1">tol </span><span class="s2">= </span><span class="s5">1e-8</span>
    <span class="s1">params </span><span class="s2">= </span><span class="s1">dict</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s1">tol</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">)</span>

    <span class="s4"># Override max iteration count for specific solvers to allow for</span>
    <span class="s4"># proper convergence.</span>
    <span class="s1">solver_max_iter </span><span class="s2">= {</span><span class="s3">&quot;sag&quot;</span><span class="s2">: </span><span class="s5">10_000</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">: </span><span class="s5">10_000</span><span class="s2">}</span>

    <span class="s1">regressors </span><span class="s2">= {</span>
        <span class="s1">solver</span><span class="s2">: </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
            <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s1">solver_max_iter</span><span class="s2">.</span><span class="s1">get</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">, </span><span class="s5">100</span><span class="s2">), **</span><span class="s1">params</span>
        <span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s1">set</span><span class="s2">(</span><span class="s1">SOLVERS</span><span class="s2">) - </span><span class="s1">set</span><span class="s2">([</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">])</span>
    <span class="s2">}</span>

    <span class="s0">for </span><span class="s1">solver_1</span><span class="s2">, </span><span class="s1">solver_2 </span><span class="s0">in </span><span class="s1">itertools</span><span class="s2">.</span><span class="s1">combinations</span><span class="s2">(</span><span class="s1">regressors</span><span class="s2">, </span><span class="s1">r</span><span class="s2">=</span><span class="s5">2</span><span class="s2">):</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span>
            <span class="s1">regressors</span><span class="s2">[</span><span class="s1">solver_1</span><span class="s2">].</span><span class="s1">coef_</span><span class="s2">,</span>
            <span class="s1">regressors</span><span class="s2">[</span><span class="s1">solver_2</span><span class="s2">].</span><span class="s1">coef_</span><span class="s2">,</span>
            <span class="s1">rtol</span><span class="s2">=</span><span class="s5">5e-3 </span><span class="s0">if </span><span class="s1">solver_2 </span><span class="s2">== </span><span class="s3">&quot;saga&quot; </span><span class="s0">else </span><span class="s5">1e-3</span><span class="s2">,</span>
            <span class="s1">err_msg</span><span class="s2">=</span><span class="s3">f&quot;</span><span class="s0">{</span><span class="s1">solver_1</span><span class="s0">} </span><span class="s3">vs </span><span class="s0">{</span><span class="s1">solver_2</span><span class="s0">}</span><span class="s3">&quot;</span><span class="s2">,</span>
        <span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;weight&quot;</span><span class="s2">, [{</span><span class="s5">0</span><span class="s2">: </span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">: </span><span class="s5">0.2</span><span class="s2">}, {</span><span class="s5">0</span><span class="s2">: </span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">: </span><span class="s5">0.2</span><span class="s2">, </span><span class="s5">2</span><span class="s2">: </span><span class="s5">0.5</span><span class="s2">}])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;class_weight&quot;</span><span class="s2">, [</span><span class="s3">&quot;weight&quot;</span><span class="s2">, </span><span class="s3">&quot;balanced&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_logistic_regressioncv_class_weights</span><span class="s2">(</span><span class="s1">weight</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">, </span><span class="s1">global_random_seed</span><span class="s2">):</span>
    <span class="s6">&quot;&quot;&quot;Test class_weight for LogisticRegressionCV.&quot;&quot;&quot;</span>
    <span class="s1">n_classes </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">weight</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">class_weight </span><span class="s2">== </span><span class="s3">&quot;weight&quot;</span><span class="s2">:</span>
        <span class="s1">class_weight </span><span class="s2">= </span><span class="s1">weight</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s5">30</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s5">3</span><span class="s2">,</span>
        <span class="s1">n_repeated</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">n_informative</span><span class="s2">=</span><span class="s5">3</span><span class="s2">,</span>
        <span class="s1">n_redundant</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s1">n_classes</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">params </span><span class="s2">= </span><span class="s1">dict</span><span class="s2">(</span>
        <span class="s1">Cs</span><span class="s2">=</span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">class_weight</span><span class="s2">=</span><span class="s1">class_weight</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-8</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf_lbfgs </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">, **</span><span class="s1">params</span><span class="s2">)</span>

    <span class="s4"># XXX: lbfgs' line search can fail and cause a ConvergenceWarning for some</span>
    <span class="s4"># 10% of the random seeds, but only on specific platforms (in particular</span>
    <span class="s4"># when using Atlas BLAS/LAPACK implementation). Doubling the maxls internal</span>
    <span class="s4"># parameter of the solver does not help. However this lack of proper</span>
    <span class="s4"># convergence does not seem to prevent the assertion to pass, so we ignore</span>
    <span class="s4"># the warning for now.</span>
    <span class="s4"># See: https://github.com/scikit-learn/scikit-learn/pull/27649</span>
    <span class="s0">with </span><span class="s1">ignore_warnings</span><span class="s2">(</span><span class="s1">category</span><span class="s2">=</span><span class="s1">ConvergenceWarning</span><span class="s2">):</span>
        <span class="s1">clf_lbfgs</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s1">set</span><span class="s2">(</span><span class="s1">SOLVERS</span><span class="s2">) - </span><span class="s1">set</span><span class="s2">([</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">, </span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">]):</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, **</span><span class="s1">params</span><span class="s2">)</span>
        <span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">):</span>
            <span class="s1">clf</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(</span>
                <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-18</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s5">10000</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed </span><span class="s2">+ </span><span class="s5">1</span>
            <span class="s2">)</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

        <span class="s1">assert_allclose</span><span class="s2">(</span>
            <span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf_lbfgs</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">1e-3</span><span class="s2">, </span><span class="s1">err_msg</span><span class="s2">=</span><span class="s3">f&quot;</span><span class="s0">{</span><span class="s1">solver</span><span class="s0">} </span><span class="s3">vs lbfgs&quot;</span>
        <span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_logistic_regression_sample_weights</span><span class="s2">():</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s5">20</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s5">5</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">n_classes</span><span class="s2">=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span>
    <span class="s2">)</span>
    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s1">y </span><span class="s2">+ </span><span class="s5">1</span>

    <span class="s0">for </span><span class="s1">LR </span><span class="s0">in </span><span class="s2">[</span><span class="s1">LogisticRegression</span><span class="s2">, </span><span class="s1">LogisticRegressionCV</span><span class="s2">]:</span>
        <span class="s1">kw </span><span class="s2">= {</span><span class="s3">&quot;random_state&quot;</span><span class="s2">: </span><span class="s5">42</span><span class="s2">, </span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">: </span><span class="s0">False</span><span class="s2">}</span>
        <span class="s0">if </span><span class="s1">LR </span><span class="s0">is </span><span class="s1">LogisticRegressionCV</span><span class="s2">:</span>
            <span class="s1">kw</span><span class="s2">.</span><span class="s1">update</span><span class="s2">({</span><span class="s3">&quot;Cs&quot;</span><span class="s2">: </span><span class="s5">3</span><span class="s2">, </span><span class="s3">&quot;cv&quot;</span><span class="s2">: </span><span class="s5">3</span><span class="s2">})</span>

        <span class="s4"># Test that passing sample_weight as ones is the same as</span>
        <span class="s4"># not passing them at all (default None)</span>
        <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">, </span><span class="s3">&quot;liblinear&quot;</span><span class="s2">]:</span>
            <span class="s1">clf_sw_none </span><span class="s2">= </span><span class="s1">LR</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">)</span>
            <span class="s1">clf_sw_ones </span><span class="s2">= </span><span class="s1">LR</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">)</span>
            <span class="s1">clf_sw_none</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
            <span class="s1">clf_sw_ones</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">y</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">]))</span>
            <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf_sw_none</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf_sw_ones</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">1e-4</span><span class="s2">)</span>

        <span class="s4"># Test that sample weights work the same with the lbfgs,</span>
        <span class="s4"># newton-cg, newton-cholesky and 'sag' solvers</span>
        <span class="s1">clf_sw_lbfgs </span><span class="s2">= </span><span class="s1">LR</span><span class="s2">(**</span><span class="s1">kw</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-5</span><span class="s2">)</span>
        <span class="s1">clf_sw_lbfgs</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>
        <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s1">set</span><span class="s2">(</span><span class="s1">SOLVERS</span><span class="s2">) - </span><span class="s1">set</span><span class="s2">([</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">]):</span>
            <span class="s1">clf_sw </span><span class="s2">= </span><span class="s1">LR</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-10 </span><span class="s0">if </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;sag&quot; </span><span class="s0">else </span><span class="s5">1e-5</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">)</span>
            <span class="s4"># ignore convergence warning due to small dataset with sag</span>
            <span class="s0">with </span><span class="s1">ignore_warnings</span><span class="s2">():</span>
                <span class="s1">clf_sw</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>
            <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf_sw_lbfgs</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf_sw</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">1e-4</span><span class="s2">)</span>

        <span class="s4"># Test that passing class_weight as [1,2] is the same as</span>
        <span class="s4"># passing class weight = [1,1] but adjusting sample weights</span>
        <span class="s4"># to be 2 for all instances of class 2</span>
        <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">, </span><span class="s3">&quot;liblinear&quot;</span><span class="s2">]:</span>
            <span class="s1">clf_cw_12 </span><span class="s2">= </span><span class="s1">LR</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">={</span><span class="s5">0</span><span class="s2">: </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">: </span><span class="s5">2</span><span class="s2">}, **</span><span class="s1">kw</span><span class="s2">)</span>
            <span class="s1">clf_cw_12</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
            <span class="s1">clf_sw_12 </span><span class="s2">= </span><span class="s1">LR</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">)</span>
            <span class="s1">clf_sw_12</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>
            <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf_cw_12</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf_sw_12</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">1e-4</span><span class="s2">)</span>

    <span class="s4"># Test the above for l1 penalty and l2 penalty with dual=True.</span>
    <span class="s4"># since the patched liblinear code is different.</span>
    <span class="s1">clf_cw </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">class_weight</span><span class="s2">={</span><span class="s5">0</span><span class="s2">: </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">: </span><span class="s5">2</span><span class="s2">},</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-5</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf_cw</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">clf_sw </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-5</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf_sw</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf_cw</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf_sw</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s5">4</span><span class="s2">)</span>

    <span class="s1">clf_cw </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">class_weight</span><span class="s2">={</span><span class="s5">0</span><span class="s2">: </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">: </span><span class="s5">2</span><span class="s2">},</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l2&quot;</span><span class="s2">,</span>
        <span class="s1">dual</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf_cw</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">clf_sw </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l2&quot;</span><span class="s2">,</span>
        <span class="s1">dual</span><span class="s2">=</span><span class="s0">True</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">clf_sw</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf_cw</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf_sw</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s5">4</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">_compute_class_weight_dictionary</span><span class="s2">(</span><span class="s1">y</span><span class="s2">):</span>
    <span class="s4"># helper for returning a dictionary instead of an array</span>
    <span class="s1">classes </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">class_weight </span><span class="s2">= </span><span class="s1">compute_class_weight</span><span class="s2">(</span><span class="s3">&quot;balanced&quot;</span><span class="s2">, </span><span class="s1">classes</span><span class="s2">=</span><span class="s1">classes</span><span class="s2">, </span><span class="s1">y</span><span class="s2">=</span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">class_weight_dict </span><span class="s2">= </span><span class="s1">dict</span><span class="s2">(</span><span class="s1">zip</span><span class="s2">(</span><span class="s1">classes</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">))</span>
    <span class="s0">return </span><span class="s1">class_weight_dict</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, [</span><span class="s0">lambda </span><span class="s1">x</span><span class="s2">: </span><span class="s1">x</span><span class="s2">] + </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_logistic_regression_class_weights</span><span class="s2">(</span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s4"># Scale data to avoid convergence warnings with the lbfgs solver</span>
    <span class="s1">X_iris </span><span class="s2">= </span><span class="s1">scale</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">)</span>
    <span class="s4"># Multinomial case: remove 90% of class 0</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X_iris</span><span class="s2">[</span><span class="s5">45</span><span class="s2">:, :]</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">[</span><span class="s5">45</span><span class="s2">:]</span>
    <span class="s1">class_weight_dict </span><span class="s2">= </span><span class="s1">_compute_class_weight_dictionary</span><span class="s2">(</span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s1">set</span><span class="s2">(</span><span class="s1">SOLVERS</span><span class="s2">) - </span><span class="s1">set</span><span class="s2">([</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">]):</span>
        <span class="s1">params </span><span class="s2">= </span><span class="s1">dict</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s5">1000</span><span class="s2">)</span>
        <span class="s1">clf1 </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">=</span><span class="s3">&quot;balanced&quot;</span><span class="s2">, **</span><span class="s1">params</span><span class="s2">)</span>
        <span class="s1">clf2 </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">=</span><span class="s1">class_weight_dict</span><span class="s2">, **</span><span class="s1">params</span><span class="s2">)</span>
        <span class="s1">clf1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s1">clf2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">len</span><span class="s2">(</span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">) == </span><span class="s5">3</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">1e-4</span><span class="s2">)</span>
        <span class="s4"># Same as appropriate sample_weight.</span>
        <span class="s1">sw </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">])</span>
        <span class="s0">for </span><span class="s1">c </span><span class="s0">in </span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">classes_</span><span class="s2">:</span>
            <span class="s1">sw</span><span class="s2">[</span><span class="s1">y </span><span class="s2">== </span><span class="s1">c</span><span class="s2">] *= </span><span class="s1">class_weight_dict</span><span class="s2">[</span><span class="s1">c</span><span class="s2">]</span>
        <span class="s1">clf3 </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(**</span><span class="s1">params</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sw</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf3</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">1e-4</span><span class="s2">)</span>

    <span class="s4"># Binary case: remove 90% of class 0 and 100% of class 2</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X_iris</span><span class="s2">[</span><span class="s5">45</span><span class="s2">:</span><span class="s5">100</span><span class="s2">, :]</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">[</span><span class="s5">45</span><span class="s2">:</span><span class="s5">100</span><span class="s2">]</span>
    <span class="s1">class_weight_dict </span><span class="s2">= </span><span class="s1">_compute_class_weight_dictionary</span><span class="s2">(</span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s1">SOLVERS</span><span class="s2">:</span>
        <span class="s1">params </span><span class="s2">= </span><span class="s1">dict</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s5">1000</span><span class="s2">)</span>
        <span class="s1">clf1 </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">=</span><span class="s3">&quot;balanced&quot;</span><span class="s2">, **</span><span class="s1">params</span><span class="s2">)</span>
        <span class="s1">clf2 </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">class_weight</span><span class="s2">=</span><span class="s1">class_weight_dict</span><span class="s2">, **</span><span class="s1">params</span><span class="s2">)</span>
        <span class="s1">clf1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s1">clf2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">clf1</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf2</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s5">6</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_logistic_regression_multinomial</span><span class="s2">():</span>
    <span class="s4"># Tests for the multinomial option in logistic regression</span>

    <span class="s4"># Some basic attributes of Logistic Regression</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">, </span><span class="s1">n_classes </span><span class="s2">= </span><span class="s5">50</span><span class="s2">, </span><span class="s5">20</span><span class="s2">, </span><span class="s5">3</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">,</span>
        <span class="s1">n_informative</span><span class="s2">=</span><span class="s5">10</span><span class="s2">,</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s1">n_classes</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">X </span><span class="s2">= </span><span class="s1">StandardScaler</span><span class="s2">(</span><span class="s1">with_mean</span><span class="s2">=</span><span class="s0">False</span><span class="s2">).</span><span class="s1">fit_transform</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s4"># 'lbfgs' is used as a referenced</span>
    <span class="s1">solver </span><span class="s2">= </span><span class="s3">&quot;lbfgs&quot;</span>
    <span class="s1">ref_i </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-6</span><span class="s2">)</span>
    <span class="s1">ref_w </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-6</span><span class="s2">)</span>
    <span class="s1">ref_i</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">ref_w</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ref_i</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_classes</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">ref_w</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_classes</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cg&quot;</span><span class="s2">]:</span>
        <span class="s1">clf_i </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
            <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
            <span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">,</span>
            <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">2000</span><span class="s2">,</span>
            <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-7</span><span class="s2">,</span>
        <span class="s2">)</span>
        <span class="s1">clf_w </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
            <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
            <span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">,</span>
            <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">2000</span><span class="s2">,</span>
            <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-7</span><span class="s2">,</span>
            <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s2">)</span>
        <span class="s1">clf_i</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s1">clf_w</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">clf_i</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_classes</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
        <span class="s0">assert </span><span class="s1">clf_w</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_classes</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>

        <span class="s4"># Compare solutions between lbfgs and the other solvers</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">ref_i</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf_i</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">1e-3</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">ref_w</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">clf_w</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">ref_i</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">clf_i</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">1e-3</span><span class="s2">)</span>

    <span class="s4"># Test that the path give almost the same results. However since in this</span>
    <span class="s4"># case we take the average of the coefs after fitting across all the</span>
    <span class="s4"># folds, it need not be exactly the same.</span>
    <span class="s0">for </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cg&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">]:</span>
        <span class="s1">clf_path </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span>
            <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s5">2000</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-6</span><span class="s2">, </span><span class="s1">Cs</span><span class="s2">=[</span><span class="s5">1.0</span><span class="s2">]</span>
        <span class="s2">)</span>
        <span class="s1">clf_path</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf_path</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">ref_i</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf_path</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">ref_i</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_liblinear_decision_function_zero</span><span class="s2">():</span>
    <span class="s4"># Test negative prediction when decision_function values are zero.</span>
    <span class="s4"># Liblinear predicts the positive class when decision_function values</span>
    <span class="s4"># are zero. This is a test to verify that we do not do the same.</span>
    <span class="s4"># See Issue: https://github.com/scikit-learn/scikit-learn/issues/3600</span>
    <span class="s4"># and the PR https://github.com/scikit-learn/scikit-learn/pull/3623</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">5</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s5">5</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s4"># Dummy data such that the decision function becomes zero.</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">((</span><span class="s5">5</span><span class="s2">, </span><span class="s5">5</span><span class="s2">))</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s5">5</span><span class="s2">))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_liblinear_logregcv_sparse</span><span class="s2">(</span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s4"># Test LogRegCV with solver='liblinear' works for sparse matrices</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s5">5</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_saga_sparse</span><span class="s2">(</span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s4"># Test LogRegCV with solver='liblinear' works for sparse matrices</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s5">5</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">y</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_logreg_intercept_scaling_zero</span><span class="s2">():</span>
    <span class="s4"># Test that intercept_scaling is ignored when fit_intercept is False</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y1</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_ </span><span class="s2">== </span><span class="s5">0.0</span>


<span class="s0">def </span><span class="s1">test_logreg_l1</span><span class="s2">():</span>
    <span class="s4"># Because liblinear penalizes the intercept and saga does not, we do not</span>
    <span class="s4"># fit the intercept to make it possible to compare the coefficients of</span>
    <span class="s4"># the two models at convergence.</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s5">42</span><span class="s2">)</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s5">50</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s5">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">X_noise </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">size</span><span class="s2">=(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s5">3</span><span class="s2">))</span>
    <span class="s1">X_constant </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">=(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s5">2</span><span class="s2">))</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">((</span><span class="s1">X</span><span class="s2">, </span><span class="s1">X_noise</span><span class="s2">, </span><span class="s1">X_constant</span><span class="s2">), </span><span class="s1">axis</span><span class="s2">=</span><span class="s5">1</span><span class="s2">)</span>
    <span class="s1">lr_liblinear </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">,</span>
        <span class="s1">C</span><span class="s2">=</span><span class="s5">1.0</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-10</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lr_liblinear</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">lr_saga </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">,</span>
        <span class="s1">C</span><span class="s2">=</span><span class="s5">1.0</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">1000</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-10</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lr_saga</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr_saga</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">lr_liblinear</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>

    <span class="s4"># Noise and constant features should be regularized to zero by the l1</span>
    <span class="s4"># penalty</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr_liblinear</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">[</span><span class="s5">0</span><span class="s2">, -</span><span class="s5">5</span><span class="s2">:], </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s5">5</span><span class="s2">))</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr_saga</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">[</span><span class="s5">0</span><span class="s2">, -</span><span class="s5">5</span><span class="s2">:], </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s5">5</span><span class="s2">))</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_logreg_l1_sparse_data</span><span class="s2">(</span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s4"># Because liblinear penalizes the intercept and saga does not, we do not</span>
    <span class="s4"># fit the intercept to make it possible to compare the coefficients of</span>
    <span class="s4"># the two models at convergence.</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s5">42</span><span class="s2">)</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s5">50</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s5">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">X_noise </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">normal</span><span class="s2">(</span><span class="s1">scale</span><span class="s2">=</span><span class="s5">0.1</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s5">3</span><span class="s2">))</span>
    <span class="s1">X_constant </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">=(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s5">2</span><span class="s2">))</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">((</span><span class="s1">X</span><span class="s2">, </span><span class="s1">X_noise</span><span class="s2">, </span><span class="s1">X_constant</span><span class="s2">), </span><span class="s1">axis</span><span class="s2">=</span><span class="s5">1</span><span class="s2">)</span>
    <span class="s1">X</span><span class="s2">[</span><span class="s1">X </span><span class="s2">&lt; </span><span class="s5">1</span><span class="s2">] = </span><span class="s5">0</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">lr_liblinear </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">,</span>
        <span class="s1">C</span><span class="s2">=</span><span class="s5">1.0</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-10</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lr_liblinear</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">lr_saga </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">,</span>
        <span class="s1">C</span><span class="s2">=</span><span class="s5">1.0</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">1000</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-10</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lr_saga</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr_saga</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">lr_liblinear</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>
    <span class="s4"># Noise and constant features should be regularized to zero by the l1</span>
    <span class="s4"># penalty</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr_liblinear</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">[</span><span class="s5">0</span><span class="s2">, -</span><span class="s5">5</span><span class="s2">:], </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s5">5</span><span class="s2">))</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr_saga</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">[</span><span class="s5">0</span><span class="s2">, -</span><span class="s5">5</span><span class="s2">:], </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s5">5</span><span class="s2">))</span>

    <span class="s4"># Check that solving on the sparse and dense data yield the same results</span>
    <span class="s1">lr_saga_dense </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">,</span>
        <span class="s1">C</span><span class="s2">=</span><span class="s5">1.0</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">1000</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-10</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lr_saga_dense</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">toarray</span><span class="s2">(), </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr_saga</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">lr_saga_dense</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;random_seed&quot;</span><span class="s2">, [</span><span class="s5">42</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;penalty&quot;</span><span class="s2">, [</span><span class="s3">&quot;l1&quot;</span><span class="s2">, </span><span class="s3">&quot;l2&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_logistic_regression_cv_refit</span><span class="s2">(</span><span class="s1">random_seed</span><span class="s2">, </span><span class="s1">penalty</span><span class="s2">):</span>
    <span class="s4"># Test that when refit=True, logistic regression cv with the saga solver</span>
    <span class="s4"># converges to the same solution as logistic regression with a fixed</span>
    <span class="s4"># regularization parameter.</span>
    <span class="s4"># Internally the LogisticRegressionCV model uses a warm start to refit on</span>
    <span class="s4"># the full data model with the optimal C found by CV. As the penalized</span>
    <span class="s4"># logistic regression loss is convex, we should still recover exactly</span>
    <span class="s4"># the same solution as long as the stopping criterion is strict enough (and</span>
    <span class="s4"># that there are no exactly duplicated features when penalty='l1').</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">100</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s5">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">random_seed</span><span class="s2">)</span>
    <span class="s1">common_params </span><span class="s2">= </span><span class="s1">dict</span><span class="s2">(</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s1">penalty</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">random_seed</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">1000</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-12</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lr_cv </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">Cs</span><span class="s2">=[</span><span class="s5">1.0</span><span class="s2">], </span><span class="s1">refit</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, **</span><span class="s1">common_params</span><span class="s2">)</span>
    <span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">C</span><span class="s2">=</span><span class="s5">1.0</span><span class="s2">, **</span><span class="s1">common_params</span><span class="s2">)</span>
    <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_logreg_predict_proba_multinomial</span><span class="s2">():</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s5">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">n_classes</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s5">10</span>
    <span class="s2">)</span>

    <span class="s4"># Predicted probabilities using the true-entropy loss should give a</span>
    <span class="s4"># smaller loss than those using the ovr method.</span>
    <span class="s1">clf_multi </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">)</span>
    <span class="s1">clf_multi</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">clf_multi_loss </span><span class="s2">= </span><span class="s1">log_loss</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">clf_multi</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X</span><span class="s2">))</span>
    <span class="s1">clf_ovr </span><span class="s2">= </span><span class="s1">OneVsRestClassifier</span><span class="s2">(</span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">))</span>
    <span class="s1">clf_ovr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">clf_ovr_loss </span><span class="s2">= </span><span class="s1">log_loss</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">clf_ovr</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X</span><span class="s2">))</span>
    <span class="s0">assert </span><span class="s1">clf_ovr_loss </span><span class="s2">&gt; </span><span class="s1">clf_multi_loss</span>

    <span class="s4"># Predicted probabilities using the soft-max function should give a</span>
    <span class="s4"># smaller loss than those using the logistic function.</span>
    <span class="s1">clf_multi_loss </span><span class="s2">= </span><span class="s1">log_loss</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">clf_multi</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X</span><span class="s2">))</span>
    <span class="s1">clf_wrong_loss </span><span class="s2">= </span><span class="s1">log_loss</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">clf_multi</span><span class="s2">.</span><span class="s1">_predict_proba_lr</span><span class="s2">(</span><span class="s1">X</span><span class="s2">))</span>
    <span class="s0">assert </span><span class="s1">clf_wrong_loss </span><span class="s2">&gt; </span><span class="s1">clf_multi_loss</span>


<span class="s4"># TODO(1.7): remove filterwarnings after the deprecation of multi_class</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*'multi_class' was deprecated.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;max_iter&quot;</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">5</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;multi_class&quot;</span><span class="s2">, [</span><span class="s3">&quot;ovr&quot;</span><span class="s2">, </span><span class="s3">&quot;multinomial&quot;</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;solver, message&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">(</span>
            <span class="s3">&quot;newton-cg&quot;</span><span class="s2">,</span>
            <span class="s3">&quot;newton-cg failed to converge.* Increase the number of iterations.&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s2">(</span>
            <span class="s3">&quot;liblinear&quot;</span><span class="s2">,</span>
            <span class="s3">&quot;Liblinear failed to converge, increase the number of iterations.&quot;</span><span class="s2">,</span>
        <span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;The max_iter was reached which means the coef_ did not converge&quot;</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s3">&quot;The max_iter was reached which means the coef_ did not converge&quot;</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">, </span><span class="s3">&quot;lbfgs failed to converge&quot;</span><span class="s2">),</span>
        <span class="s2">(</span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;Newton solver did not converge after [0-9]* iterations&quot;</span><span class="s2">),</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_max_iter</span><span class="s2">(</span><span class="s1">max_iter</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">, </span><span class="s1">message</span><span class="s2">):</span>
    <span class="s4"># Test that the maximum number of iteration is reached</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y_bin </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">()</span>
    <span class="s1">y_bin</span><span class="s2">[</span><span class="s1">y_bin </span><span class="s2">== </span><span class="s5">2</span><span class="s2">] = </span><span class="s5">0</span>

    <span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">) </span><span class="s0">and </span><span class="s1">multi_class </span><span class="s2">== </span><span class="s3">&quot;multinomial&quot;</span><span class="s2">:</span>
        <span class="s1">pytest</span><span class="s2">.</span><span class="s1">skip</span><span class="s2">(</span><span class="s3">&quot;'multinomial' is not supported by liblinear and newton-cholesky&quot;</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;newton-cholesky&quot; </span><span class="s0">and </span><span class="s1">max_iter </span><span class="s2">&gt; </span><span class="s5">1</span><span class="s2">:</span>
        <span class="s1">pytest</span><span class="s2">.</span><span class="s1">skip</span><span class="s2">(</span><span class="s3">&quot;solver newton-cholesky might converge very fast&quot;</span><span class="s2">)</span>

    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s1">max_iter</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-15</span><span class="s2">,</span>
        <span class="s1">multi_class</span><span class="s2">=</span><span class="s1">multi_class</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">ConvergenceWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">message</span><span class="s2">):</span>
        <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_bin</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">n_iter_</span><span class="s2">[</span><span class="s5">0</span><span class="s2">] == </span><span class="s1">max_iter</span>


<span class="s4"># TODO(1.7): remove filterwarnings after the deprecation of multi_class</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*'multi_class' was deprecated.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">SOLVERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_n_iter</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">):</span>
    <span class="s4"># Test that self.n_iter_ has the correct format.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span>
    <span class="s0">if </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">:</span>
        <span class="s4"># lbfgs requires scaling to avoid convergence warnings</span>
        <span class="s1">X </span><span class="s2">= </span><span class="s1">scale</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">n_classes </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">unique</span><span class="s2">(</span><span class="s1">y</span><span class="s2">).</span><span class="s1">shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">]</span>
    <span class="s0">assert </span><span class="s1">n_classes </span><span class="s2">== </span><span class="s5">3</span>

    <span class="s4"># Also generate a binary classification sub-problem.</span>
    <span class="s1">y_bin </span><span class="s2">= </span><span class="s1">y</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">()</span>
    <span class="s1">y_bin</span><span class="s2">[</span><span class="s1">y_bin </span><span class="s2">== </span><span class="s5">2</span><span class="s2">] = </span><span class="s5">0</span>

    <span class="s1">n_Cs </span><span class="s2">= </span><span class="s5">4</span>
    <span class="s1">n_cv_fold </span><span class="s2">= </span><span class="s5">2</span>

    <span class="s4"># Binary classification case</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">, </span><span class="s1">C</span><span class="s2">=</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_bin</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">n_iter_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s5">1</span><span class="s2">,)</span>

    <span class="s1">clf_cv </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">Cs</span><span class="s2">=</span><span class="s1">n_Cs</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s1">n_cv_fold</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span>
    <span class="s2">)</span>
    <span class="s1">clf_cv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_bin</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf_cv</span><span class="s2">.</span><span class="s1">n_iter_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s5">1</span><span class="s2">, </span><span class="s1">n_cv_fold</span><span class="s2">, </span><span class="s1">n_Cs</span><span class="s2">)</span>

    <span class="s4"># OvR case</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(</span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">n_iter_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_classes</span><span class="s2">,)</span>

    <span class="s1">clf_cv</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(</span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf_cv</span><span class="s2">.</span><span class="s1">n_iter_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_classes</span><span class="s2">, </span><span class="s1">n_cv_fold</span><span class="s2">, </span><span class="s1">n_Cs</span><span class="s2">)</span>

    <span class="s4"># multinomial case</span>
    <span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">):</span>
        <span class="s4"># This solver only supports one-vs-rest multiclass classification.</span>
        <span class="s0">return</span>

    <span class="s4"># When using the multinomial objective function, there is a single</span>
    <span class="s4"># optimization problem to solve for all classes at once:</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(</span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;multinomial&quot;</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">n_iter_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s5">1</span><span class="s2">,)</span>

    <span class="s1">clf_cv</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(</span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;multinomial&quot;</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf_cv</span><span class="s2">.</span><span class="s1">n_iter_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s5">1</span><span class="s2">, </span><span class="s1">n_cv_fold</span><span class="s2">, </span><span class="s1">n_Cs</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">sorted</span><span class="s2">(</span><span class="s1">set</span><span class="s2">(</span><span class="s1">SOLVERS</span><span class="s2">) - </span><span class="s1">set</span><span class="s2">([</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">]))</span>
<span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;warm_start&quot;</span><span class="s2">, (</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, (</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">))</span>
<span class="s0">def </span><span class="s1">test_warm_start</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">warm_start</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">):</span>
    <span class="s4"># A 1-iteration second fit on same data should give almost same result</span>
    <span class="s4"># with warm starting, and quite different result without warm starting.</span>
    <span class="s4"># Warm starting does not work with liblinear solver.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-4</span><span class="s2">,</span>
        <span class="s1">warm_start</span><span class="s2">=</span><span class="s1">warm_start</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">ignore_warnings</span><span class="s2">(</span><span class="s1">category</span><span class="s2">=</span><span class="s1">ConvergenceWarning</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s1">coef_1 </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span>

        <span class="s1">clf</span><span class="s2">.</span><span class="s1">max_iter </span><span class="s2">= </span><span class="s5">1</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">cum_diff </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">abs</span><span class="s2">(</span><span class="s1">coef_1 </span><span class="s2">- </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">))</span>
    <span class="s1">msg </span><span class="s2">= (</span>
        <span class="s3">f&quot;Warm starting issue with solver </span><span class="s0">{</span><span class="s1">solver</span><span class="s0">}</span><span class="s3">&quot;</span>
        <span class="s3">f&quot;with </span><span class="s0">{</span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">} </span><span class="s3">and </span><span class="s0">{</span><span class="s1">warm_start</span><span class="s2">=</span><span class="s0">}</span><span class="s3">&quot;</span>
    <span class="s2">)</span>
    <span class="s0">if </span><span class="s1">warm_start</span><span class="s2">:</span>
        <span class="s0">assert </span><span class="s5">2.0 </span><span class="s2">&gt; </span><span class="s1">cum_diff</span><span class="s2">, </span><span class="s1">msg</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s0">assert </span><span class="s1">cum_diff </span><span class="s2">&gt; </span><span class="s5">2.0</span><span class="s2">, </span><span class="s1">msg</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_saga_vs_liblinear</span><span class="s2">(</span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s1">iris </span><span class="s2">= </span><span class="s1">load_iris</span><span class="s2">()</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">, </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">([</span><span class="s1">X</span><span class="s2">] * </span><span class="s5">3</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">([</span><span class="s1">y</span><span class="s2">] * </span><span class="s5">3</span><span class="s2">)</span>

    <span class="s1">X_bin </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[</span><span class="s1">y </span><span class="s2">&lt;= </span><span class="s5">1</span><span class="s2">]</span>
    <span class="s1">y_bin </span><span class="s2">= </span><span class="s1">y</span><span class="s2">[</span><span class="s1">y </span><span class="s2">&lt;= </span><span class="s5">1</span><span class="s2">] * </span><span class="s5">2 </span><span class="s2">- </span><span class="s5">1</span>

    <span class="s1">X_sparse</span><span class="s2">, </span><span class="s1">y_sparse </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s5">50</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s5">20</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span>
    <span class="s2">)</span>
    <span class="s1">X_sparse </span><span class="s2">= </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X_sparse</span><span class="s2">)</span>

    <span class="s0">for </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s0">in </span><span class="s2">((</span><span class="s1">X_bin</span><span class="s2">, </span><span class="s1">y_bin</span><span class="s2">), (</span><span class="s1">X_sparse</span><span class="s2">, </span><span class="s1">y_sparse</span><span class="s2">)):</span>
        <span class="s0">for </span><span class="s1">penalty </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;l1&quot;</span><span class="s2">, </span><span class="s3">&quot;l2&quot;</span><span class="s2">]:</span>
            <span class="s1">n_samples </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">]</span>
            <span class="s4"># alpha=1e-3 is time consuming</span>
            <span class="s0">for </span><span class="s1">alpha </span><span class="s0">in </span><span class="s1">np</span><span class="s2">.</span><span class="s1">logspace</span><span class="s2">(-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">3</span><span class="s2">):</span>
                <span class="s1">saga </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
                    <span class="s1">C</span><span class="s2">=</span><span class="s5">1.0 </span><span class="s2">/ (</span><span class="s1">n_samples </span><span class="s2">* </span><span class="s1">alpha</span><span class="s2">),</span>
                    <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
                    <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">200</span><span class="s2">,</span>
                    <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
                    <span class="s1">penalty</span><span class="s2">=</span><span class="s1">penalty</span><span class="s2">,</span>
                    <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
                    <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-6</span><span class="s2">,</span>
                <span class="s2">)</span>

                <span class="s1">liblinear </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
                    <span class="s1">C</span><span class="s2">=</span><span class="s5">1.0 </span><span class="s2">/ (</span><span class="s1">n_samples </span><span class="s2">* </span><span class="s1">alpha</span><span class="s2">),</span>
                    <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">,</span>
                    <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">200</span><span class="s2">,</span>
                    <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
                    <span class="s1">penalty</span><span class="s2">=</span><span class="s1">penalty</span><span class="s2">,</span>
                    <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
                    <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-6</span><span class="s2">,</span>
                <span class="s2">)</span>

                <span class="s1">saga</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
                <span class="s1">liblinear</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
                <span class="s4"># Convergence for alpha=1e-3 is very slow</span>
                <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">saga</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">liblinear</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s5">3</span><span class="s2">)</span>


<span class="s4"># TODO(1.7): remove filterwarnings after the deprecation of multi_class</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*'multi_class' was deprecated.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;multi_class&quot;</span><span class="s2">, [</span><span class="s3">&quot;ovr&quot;</span><span class="s2">, </span><span class="s3">&quot;multinomial&quot;</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;solver&quot;</span><span class="s2">, [</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cg&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, [</span><span class="s0">False</span><span class="s2">, </span><span class="s0">True</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_dtype_match</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">, </span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s4"># Test that np.float32 input data is not cast to np.float64 when possible</span>
    <span class="s4"># and that the output is approximately the same no matter the input format.</span>

    <span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">) </span><span class="s0">and </span><span class="s1">multi_class </span><span class="s2">== </span><span class="s3">&quot;multinomial&quot;</span><span class="s2">:</span>
        <span class="s1">pytest</span><span class="s2">.</span><span class="s1">skip</span><span class="s2">(</span><span class="s3">f&quot;Solver=</span><span class="s0">{</span><span class="s1">solver</span><span class="s0">} </span><span class="s3">does not support multinomial logistic.&quot;</span><span class="s2">)</span>

    <span class="s1">out32_type </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64 </span><span class="s0">if </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;liblinear&quot; </span><span class="s0">else </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span>

    <span class="s1">X_32 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">X</span><span class="s2">).</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">)</span>
    <span class="s1">y_32 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">Y1</span><span class="s2">).</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">)</span>
    <span class="s1">X_64 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">X</span><span class="s2">).</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
    <span class="s1">y_64 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span><span class="s1">Y1</span><span class="s2">).</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
    <span class="s1">X_sparse_32 </span><span class="s2">= </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">)</span>
    <span class="s1">X_sparse_64 </span><span class="s2">= </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span><span class="s2">)</span>
    <span class="s1">solver_tol </span><span class="s2">= </span><span class="s5">5e-4</span>

    <span class="s1">lr_templ </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">,</span>
        <span class="s1">multi_class</span><span class="s2">=</span><span class="s1">multi_class</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s1">solver_tol</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s4"># Check 32-bit type consistency</span>
    <span class="s1">lr_32 </span><span class="s2">= </span><span class="s1">clone</span><span class="s2">(</span><span class="s1">lr_templ</span><span class="s2">)</span>
    <span class="s1">lr_32</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_32</span><span class="s2">, </span><span class="s1">y_32</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">lr_32</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">out32_type</span>

    <span class="s4"># Check 32-bit type consistency with sparsity</span>
    <span class="s1">lr_32_sparse </span><span class="s2">= </span><span class="s1">clone</span><span class="s2">(</span><span class="s1">lr_templ</span><span class="s2">)</span>
    <span class="s1">lr_32_sparse</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_sparse_32</span><span class="s2">, </span><span class="s1">y_32</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">lr_32_sparse</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">out32_type</span>

    <span class="s4"># Check 64-bit type consistency</span>
    <span class="s1">lr_64 </span><span class="s2">= </span><span class="s1">clone</span><span class="s2">(</span><span class="s1">lr_templ</span><span class="s2">)</span>
    <span class="s1">lr_64</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_64</span><span class="s2">, </span><span class="s1">y_64</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">lr_64</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span>

    <span class="s4"># Check 64-bit type consistency with sparsity</span>
    <span class="s1">lr_64_sparse </span><span class="s2">= </span><span class="s1">clone</span><span class="s2">(</span><span class="s1">lr_templ</span><span class="s2">)</span>
    <span class="s1">lr_64_sparse</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_sparse_64</span><span class="s2">, </span><span class="s1">y_64</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">lr_64_sparse</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">dtype </span><span class="s2">== </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float64</span>

    <span class="s4"># solver_tol bounds the norm of the loss gradient</span>
    <span class="s4"># dw ~= inv(H)*grad ==&gt; |dw| ~= |inv(H)| * solver_tol, where H - hessian</span>
    <span class="s4">#</span>
    <span class="s4"># See https://github.com/scikit-learn/scikit-learn/pull/13645</span>
    <span class="s4">#</span>
    <span class="s4"># with  Z = np.hstack((np.ones((3,1)), np.array(X)))</span>
    <span class="s4"># In [8]: np.linalg.norm(np.diag([0,2,2]) + np.linalg.inv((Z.T @ Z)/4))</span>
    <span class="s4"># Out[8]: 1.7193336918135917</span>

    <span class="s4"># factor of 2 to get the ball diameter</span>
    <span class="s1">atol </span><span class="s2">= </span><span class="s5">2 </span><span class="s2">* </span><span class="s5">1.72 </span><span class="s2">* </span><span class="s1">solver_tol</span>
    <span class="s0">if </span><span class="s1">os</span><span class="s2">.</span><span class="s1">name </span><span class="s2">== </span><span class="s3">&quot;nt&quot; </span><span class="s0">and </span><span class="s1">_IS_32BIT</span><span class="s2">:</span>
        <span class="s4"># FIXME</span>
        <span class="s1">atol </span><span class="s2">= </span><span class="s5">1e-2</span>

    <span class="s4"># Check accuracy consistency</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">lr_32</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">lr_64</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">astype</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">), </span><span class="s1">atol</span><span class="s2">=</span><span class="s1">atol</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">solver </span><span class="s2">== </span><span class="s3">&quot;saga&quot; </span><span class="s0">and </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s4"># FIXME: SAGA on sparse data fits the intercept inaccurately with the</span>
        <span class="s4"># default tol and max_iter parameters.</span>
        <span class="s1">atol </span><span class="s2">= </span><span class="s5">1e-1</span>

    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">lr_32</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">lr_32_sparse</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s1">atol</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">lr_64</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">lr_64_sparse</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s1">atol</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_warm_start_converge_LR</span><span class="s2">():</span>
    <span class="s4"># Test to see that the logistic regression converges on warm start,</span>
    <span class="s4"># with multi_class='multinomial'. Non-regressive test for #10836</span>

    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">concatenate</span><span class="s2">((</span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s5">100</span><span class="s2">, </span><span class="s5">2</span><span class="s2">) + [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">], </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randn</span><span class="s2">(</span><span class="s5">100</span><span class="s2">, </span><span class="s5">2</span><span class="s2">)))</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s5">1</span><span class="s2">] * </span><span class="s5">100 </span><span class="s2">+ [-</span><span class="s5">1</span><span class="s2">] * </span><span class="s5">100</span><span class="s2">)</span>
    <span class="s1">lr_no_ws </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s1">warm_start</span><span class="s2">=</span><span class="s0">False</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">lr_ws </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s1">warm_start</span><span class="s2">=</span><span class="s0">True</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>

    <span class="s1">lr_no_ws_loss </span><span class="s2">= </span><span class="s1">log_loss</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">lr_no_ws</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">).</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X</span><span class="s2">))</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s5">5</span><span class="s2">):</span>
        <span class="s1">lr_ws</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">lr_ws_loss </span><span class="s2">= </span><span class="s1">log_loss</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">lr_ws</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X</span><span class="s2">))</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">lr_no_ws_loss</span><span class="s2">, </span><span class="s1">lr_ws_loss</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">1e-5</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_elastic_net_coeffs</span><span class="s2">():</span>
    <span class="s4"># make sure elasticnet penalty gives different coefficients from l1 and l2</span>
    <span class="s4"># with saga solver (l1_ratio different from 0 or 1)</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>

    <span class="s1">C </span><span class="s2">= </span><span class="s5">2.0</span>
    <span class="s1">l1_ratio </span><span class="s2">= </span><span class="s5">0.5</span>
    <span class="s1">coeffs </span><span class="s2">= </span><span class="s1">list</span><span class="s2">()</span>
    <span class="s0">for </span><span class="s1">penalty</span><span class="s2">, </span><span class="s1">ratio </span><span class="s0">in </span><span class="s2">((</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">, </span><span class="s1">l1_ratio</span><span class="s2">), (</span><span class="s3">&quot;l1&quot;</span><span class="s2">, </span><span class="s0">None</span><span class="s2">), (</span><span class="s3">&quot;l2&quot;</span><span class="s2">, </span><span class="s0">None</span><span class="s2">)):</span>
        <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
            <span class="s1">penalty</span><span class="s2">=</span><span class="s1">penalty</span><span class="s2">,</span>
            <span class="s1">C</span><span class="s2">=</span><span class="s1">C</span><span class="s2">,</span>
            <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
            <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
            <span class="s1">l1_ratio</span><span class="s2">=</span><span class="s1">ratio</span><span class="s2">,</span>
            <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-3</span><span class="s2">,</span>
            <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">200</span><span class="s2">,</span>
        <span class="s2">)</span>
        <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
        <span class="s1">coeffs</span><span class="s2">.</span><span class="s1">append</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>

    <span class="s1">elastic_net_coeffs</span><span class="s2">, </span><span class="s1">l1_coeffs</span><span class="s2">, </span><span class="s1">l2_coeffs </span><span class="s2">= </span><span class="s1">coeffs</span>
    <span class="s4"># make sure coeffs differ by at least .1</span>
    <span class="s0">assert not </span><span class="s1">np</span><span class="s2">.</span><span class="s1">allclose</span><span class="s2">(</span><span class="s1">elastic_net_coeffs</span><span class="s2">, </span><span class="s1">l1_coeffs</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s5">0.1</span><span class="s2">)</span>
    <span class="s0">assert not </span><span class="s1">np</span><span class="s2">.</span><span class="s1">allclose</span><span class="s2">(</span><span class="s1">elastic_net_coeffs</span><span class="s2">, </span><span class="s1">l2_coeffs</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s5">0.1</span><span class="s2">)</span>
    <span class="s0">assert not </span><span class="s1">np</span><span class="s2">.</span><span class="s1">allclose</span><span class="s2">(</span><span class="s1">l2_coeffs</span><span class="s2">, </span><span class="s1">l1_coeffs</span><span class="s2">, </span><span class="s1">rtol</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s5">0.1</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;C&quot;</span><span class="s2">, [</span><span class="s5">0.001</span><span class="s2">, </span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">10</span><span class="s2">, </span><span class="s5">100</span><span class="s2">, </span><span class="s5">1000</span><span class="s2">, </span><span class="s5">1e6</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;penalty, l1_ratio&quot;</span><span class="s2">, [(</span><span class="s3">&quot;l1&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s2">), (</span><span class="s3">&quot;l2&quot;</span><span class="s2">, </span><span class="s5">0</span><span class="s2">)])</span>
<span class="s0">def </span><span class="s1">test_elastic_net_l1_l2_equivalence</span><span class="s2">(</span><span class="s1">C</span><span class="s2">, </span><span class="s1">penalty</span><span class="s2">, </span><span class="s1">l1_ratio</span><span class="s2">):</span>
    <span class="s4"># Make sure elasticnet is equivalent to l1 when l1_ratio=1 and to l2 when</span>
    <span class="s4"># l1_ratio=0.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>

    <span class="s1">lr_enet </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
        <span class="s1">C</span><span class="s2">=</span><span class="s1">C</span><span class="s2">,</span>
        <span class="s1">l1_ratio</span><span class="s2">=</span><span class="s1">l1_ratio</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lr_expected </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s1">penalty</span><span class="s2">, </span><span class="s1">C</span><span class="s2">=</span><span class="s1">C</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span>
    <span class="s2">)</span>
    <span class="s1">lr_enet</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">lr_expected</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">lr_enet</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">lr_expected</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;C&quot;</span><span class="s2">, [</span><span class="s5">0.001</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">100</span><span class="s2">, </span><span class="s5">1e6</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_elastic_net_vs_l1_l2</span><span class="s2">(</span><span class="s1">C</span><span class="s2">):</span>
    <span class="s4"># Make sure that elasticnet with grid search on l1_ratio gives same or</span>
    <span class="s4"># better results than just l1 or just l2.</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s5">500</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>

    <span class="s1">param_grid </span><span class="s2">= {</span><span class="s3">&quot;l1_ratio&quot;</span><span class="s2">: </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">5</span><span class="s2">)}</span>

    <span class="s1">enet_clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">, </span><span class="s1">C</span><span class="s2">=</span><span class="s1">C</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span>
    <span class="s2">)</span>
    <span class="s1">gs </span><span class="s2">= </span><span class="s1">GridSearchCV</span><span class="s2">(</span><span class="s1">enet_clf</span><span class="s2">, </span><span class="s1">param_grid</span><span class="s2">, </span><span class="s1">refit</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>

    <span class="s1">l1_clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">, </span><span class="s1">C</span><span class="s2">=</span><span class="s1">C</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span>
    <span class="s2">)</span>
    <span class="s1">l2_clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l2&quot;</span><span class="s2">, </span><span class="s1">C</span><span class="s2">=</span><span class="s1">C</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span>
    <span class="s2">)</span>

    <span class="s0">for </span><span class="s1">clf </span><span class="s0">in </span><span class="s2">(</span><span class="s1">gs</span><span class="s2">, </span><span class="s1">l1_clf</span><span class="s2">, </span><span class="s1">l2_clf</span><span class="s2">):</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">gs</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">) &gt;= </span><span class="s1">l1_clf</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">gs</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">) &gt;= </span><span class="s1">l2_clf</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;C&quot;</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">logspace</span><span class="s2">(-</span><span class="s5">3</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">4</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;l1_ratio&quot;</span><span class="s2">, [</span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">0.9</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_LogisticRegression_elastic_net_objective</span><span class="s2">(</span><span class="s1">C</span><span class="s2">, </span><span class="s1">l1_ratio</span><span class="s2">):</span>
    <span class="s4"># Check that training with a penalty matching the objective leads</span>
    <span class="s4"># to a lower objective.</span>
    <span class="s4"># Here we train a logistic regression with l2 (a) and elasticnet (b)</span>
    <span class="s4"># penalties, and compute the elasticnet objective. That of a should be</span>
    <span class="s4"># greater than that of b (both objectives are convex).</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s5">1000</span><span class="s2">,</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s5">2</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s5">20</span><span class="s2">,</span>
        <span class="s1">n_informative</span><span class="s2">=</span><span class="s5">10</span><span class="s2">,</span>
        <span class="s1">n_redundant</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">n_repeated</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">scale</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">lr_enet </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">C</span><span class="s2">=</span><span class="s1">C</span><span class="s2">,</span>
        <span class="s1">l1_ratio</span><span class="s2">=</span><span class="s1">l1_ratio</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lr_l2 </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l2&quot;</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">C</span><span class="s2">=</span><span class="s1">C</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span>
    <span class="s2">)</span>
    <span class="s1">lr_enet</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">lr_l2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">def </span><span class="s1">enet_objective</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">):</span>
        <span class="s1">coef </span><span class="s2">= </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">()</span>
        <span class="s1">obj </span><span class="s2">= </span><span class="s1">C </span><span class="s2">* </span><span class="s1">log_loss</span><span class="s2">(</span><span class="s1">y</span><span class="s2">, </span><span class="s1">lr</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X</span><span class="s2">))</span>
        <span class="s1">obj </span><span class="s2">+= </span><span class="s1">l1_ratio </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">abs</span><span class="s2">(</span><span class="s1">coef</span><span class="s2">))</span>
        <span class="s1">obj </span><span class="s2">+= (</span><span class="s5">1.0 </span><span class="s2">- </span><span class="s1">l1_ratio</span><span class="s2">) * </span><span class="s5">0.5 </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">dot</span><span class="s2">(</span><span class="s1">coef</span><span class="s2">, </span><span class="s1">coef</span><span class="s2">)</span>
        <span class="s0">return </span><span class="s1">obj</span>

    <span class="s0">assert </span><span class="s1">enet_objective</span><span class="s2">(</span><span class="s1">lr_enet</span><span class="s2">) &lt; </span><span class="s1">enet_objective</span><span class="s2">(</span><span class="s1">lr_l2</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;n_classes&quot;</span><span class="s2">, (</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">))</span>
<span class="s0">def </span><span class="s1">test_LogisticRegressionCV_GridSearchCV_elastic_net</span><span class="s2">(</span><span class="s1">n_classes</span><span class="s2">):</span>
    <span class="s4"># make sure LogisticRegressionCV gives same best params (l1 and C) as</span>
    <span class="s4"># GridSearchCV when penalty is elasticnet</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s5">100</span><span class="s2">, </span><span class="s1">n_classes</span><span class="s2">=</span><span class="s1">n_classes</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span>
    <span class="s2">)</span>

    <span class="s1">cv </span><span class="s2">= </span><span class="s1">StratifiedKFold</span><span class="s2">(</span><span class="s5">5</span><span class="s2">)</span>

    <span class="s1">l1_ratios </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">3</span><span class="s2">)</span>
    <span class="s1">Cs </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">logspace</span><span class="s2">(-</span><span class="s5">4</span><span class="s2">, </span><span class="s5">4</span><span class="s2">, </span><span class="s5">3</span><span class="s2">)</span>

    <span class="s1">lrcv </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
        <span class="s1">Cs</span><span class="s2">=</span><span class="s1">Cs</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">,</span>
        <span class="s1">l1_ratios</span><span class="s2">=</span><span class="s1">l1_ratios</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lrcv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">param_grid </span><span class="s2">= {</span><span class="s3">&quot;C&quot;</span><span class="s2">: </span><span class="s1">Cs</span><span class="s2">, </span><span class="s3">&quot;l1_ratio&quot;</span><span class="s2">: </span><span class="s1">l1_ratios</span><span class="s2">}</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">gs </span><span class="s2">= </span><span class="s1">GridSearchCV</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">param_grid</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">)</span>
    <span class="s1">gs</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">gs</span><span class="s2">.</span><span class="s1">best_params_</span><span class="s2">[</span><span class="s3">&quot;l1_ratio&quot;</span><span class="s2">] == </span><span class="s1">lrcv</span><span class="s2">.</span><span class="s1">l1_ratio_</span><span class="s2">[</span><span class="s5">0</span><span class="s2">]</span>
    <span class="s0">assert </span><span class="s1">gs</span><span class="s2">.</span><span class="s1">best_params_</span><span class="s2">[</span><span class="s3">&quot;C&quot;</span><span class="s2">] == </span><span class="s1">lrcv</span><span class="s2">.</span><span class="s1">C_</span><span class="s2">[</span><span class="s5">0</span><span class="s2">]</span>


<span class="s4"># TODO(1.7): remove filterwarnings after the deprecation of multi_class</span>
<span class="s4"># Maybe remove whole test after removal of the deprecated multi_class.</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*'multi_class' was deprecated.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_LogisticRegressionCV_GridSearchCV_elastic_net_ovr</span><span class="s2">():</span>
    <span class="s4"># make sure LogisticRegressionCV gives same best params (l1 and C) as</span>
    <span class="s4"># GridSearchCV when penalty is elasticnet and multiclass is ovr. We can't</span>
    <span class="s4"># compare best_params like in the previous test because</span>
    <span class="s4"># LogisticRegressionCV with multi_class='ovr' will have one C and one</span>
    <span class="s4"># l1_param for each class, while LogisticRegression will share the</span>
    <span class="s4"># parameters over the *n_classes* classifiers.</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s5">100</span><span class="s2">, </span><span class="s1">n_classes</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span>
    <span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">X_test</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">, </span><span class="s1">y_test </span><span class="s2">= </span><span class="s1">train_test_split</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">cv </span><span class="s2">= </span><span class="s1">StratifiedKFold</span><span class="s2">(</span><span class="s5">5</span><span class="s2">)</span>

    <span class="s1">l1_ratios </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">3</span><span class="s2">)</span>
    <span class="s1">Cs </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">logspace</span><span class="s2">(-</span><span class="s5">4</span><span class="s2">, </span><span class="s5">4</span><span class="s2">, </span><span class="s5">3</span><span class="s2">)</span>

    <span class="s1">lrcv </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
        <span class="s1">Cs</span><span class="s2">=</span><span class="s1">Cs</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">,</span>
        <span class="s1">l1_ratios</span><span class="s2">=</span><span class="s1">l1_ratios</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lrcv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>

    <span class="s1">param_grid </span><span class="s2">= {</span><span class="s3">&quot;C&quot;</span><span class="s2">: </span><span class="s1">Cs</span><span class="s2">, </span><span class="s3">&quot;l1_ratio&quot;</span><span class="s2">: </span><span class="s1">l1_ratios</span><span class="s2">}</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">gs </span><span class="s2">= </span><span class="s1">GridSearchCV</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">param_grid</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">)</span>
    <span class="s1">gs</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>

    <span class="s4"># Check that predictions are 80% the same</span>
    <span class="s0">assert </span><span class="s2">(</span><span class="s1">lrcv</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">) == </span><span class="s1">gs</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">)).</span><span class="s1">mean</span><span class="s2">() &gt;= </span><span class="s5">0.8</span>
    <span class="s0">assert </span><span class="s2">(</span><span class="s1">lrcv</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">) == </span><span class="s1">gs</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)).</span><span class="s1">mean</span><span class="s2">() &gt;= </span><span class="s5">0.8</span>


<span class="s4"># TODO(1.7): remove filterwarnings after the deprecation of multi_class</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*'multi_class' was deprecated.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;penalty&quot;</span><span class="s2">, (</span><span class="s3">&quot;l2&quot;</span><span class="s2">, </span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;multi_class&quot;</span><span class="s2">, (</span><span class="s3">&quot;ovr&quot;</span><span class="s2">, </span><span class="s3">&quot;multinomial&quot;</span><span class="s2">, </span><span class="s3">&quot;auto&quot;</span><span class="s2">))</span>
<span class="s0">def </span><span class="s1">test_LogisticRegressionCV_no_refit</span><span class="s2">(</span><span class="s1">penalty</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">):</span>
    <span class="s4"># Test LogisticRegressionCV attribute shapes when refit is False</span>

    <span class="s1">n_classes </span><span class="s2">= </span><span class="s5">3</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s5">20</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s5">200</span><span class="s2">,</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s1">n_classes</span><span class="s2">,</span>
        <span class="s1">n_informative</span><span class="s2">=</span><span class="s1">n_classes</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">Cs </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">logspace</span><span class="s2">(-</span><span class="s5">4</span><span class="s2">, </span><span class="s5">4</span><span class="s2">, </span><span class="s5">3</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">penalty </span><span class="s2">== </span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">:</span>
        <span class="s1">l1_ratios </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">l1_ratios </span><span class="s2">= </span><span class="s0">None</span>

    <span class="s1">lrcv </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s1">penalty</span><span class="s2">,</span>
        <span class="s1">Cs</span><span class="s2">=</span><span class="s1">Cs</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">l1_ratios</span><span class="s2">=</span><span class="s1">l1_ratios</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">multi_class</span><span class="s2">=</span><span class="s1">multi_class</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">,</span>
        <span class="s1">refit</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lrcv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">lrcv</span><span class="s2">.</span><span class="s1">C_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_classes</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">lrcv</span><span class="s2">.</span><span class="s1">l1_ratio_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_classes</span><span class="s2">,)</span>
    <span class="s0">assert </span><span class="s1">lrcv</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_classes</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>


<span class="s4"># TODO(1.7): remove filterwarnings after the deprecation of multi_class</span>
<span class="s4"># Remove multi_class an change first element of the expected n_iter_.shape from</span>
<span class="s4"># n_classes to 1 (according to the docstring).</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*'multi_class' was deprecated.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_LogisticRegressionCV_elasticnet_attribute_shapes</span><span class="s2">():</span>
    <span class="s4"># Make sure the shapes of scores_ and coefs_paths_ attributes are correct</span>
    <span class="s4"># when using elasticnet (added one dimension for l1_ratios)</span>

    <span class="s1">n_classes </span><span class="s2">= </span><span class="s5">3</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s5">20</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s5">200</span><span class="s2">,</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s1">n_classes</span><span class="s2">,</span>
        <span class="s1">n_informative</span><span class="s2">=</span><span class="s1">n_classes</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s1">n_features</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">Cs </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">logspace</span><span class="s2">(-</span><span class="s5">4</span><span class="s2">, </span><span class="s5">4</span><span class="s2">, </span><span class="s5">3</span><span class="s2">)</span>
    <span class="s1">l1_ratios </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">)</span>

    <span class="s1">n_folds </span><span class="s2">= </span><span class="s5">2</span>
    <span class="s1">lrcv </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
        <span class="s1">Cs</span><span class="s2">=</span><span class="s1">Cs</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">cv</span><span class="s2">=</span><span class="s1">n_folds</span><span class="s2">,</span>
        <span class="s1">l1_ratios</span><span class="s2">=</span><span class="s1">l1_ratios</span><span class="s2">,</span>
        <span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-2</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lrcv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">coefs_paths </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">list</span><span class="s2">(</span><span class="s1">lrcv</span><span class="s2">.</span><span class="s1">coefs_paths_</span><span class="s2">.</span><span class="s1">values</span><span class="s2">()))</span>
    <span class="s0">assert </span><span class="s1">coefs_paths</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span>
        <span class="s1">n_classes</span><span class="s2">,</span>
        <span class="s1">n_folds</span><span class="s2">,</span>
        <span class="s1">Cs</span><span class="s2">.</span><span class="s1">size</span><span class="s2">,</span>
        <span class="s1">l1_ratios</span><span class="s2">.</span><span class="s1">size</span><span class="s2">,</span>
        <span class="s1">n_features </span><span class="s2">+ </span><span class="s5">1</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">scores </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">asarray</span><span class="s2">(</span><span class="s1">list</span><span class="s2">(</span><span class="s1">lrcv</span><span class="s2">.</span><span class="s1">scores_</span><span class="s2">.</span><span class="s1">values</span><span class="s2">()))</span>
    <span class="s0">assert </span><span class="s1">scores</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_classes</span><span class="s2">, </span><span class="s1">n_folds</span><span class="s2">, </span><span class="s1">Cs</span><span class="s2">.</span><span class="s1">size</span><span class="s2">, </span><span class="s1">l1_ratios</span><span class="s2">.</span><span class="s1">size</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">lrcv</span><span class="s2">.</span><span class="s1">n_iter_</span><span class="s2">.</span><span class="s1">shape </span><span class="s2">== (</span><span class="s1">n_classes</span><span class="s2">, </span><span class="s1">n_folds</span><span class="s2">, </span><span class="s1">Cs</span><span class="s2">.</span><span class="s1">size</span><span class="s2">, </span><span class="s1">l1_ratios</span><span class="s2">.</span><span class="s1">size</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_l1_ratio_non_elasticnet</span><span class="s2">():</span>
    <span class="s1">msg </span><span class="s2">= (</span>
        <span class="s3">r&quot;l1_ratio parameter is only used when penalty is&quot;</span>
        <span class="s3">r&quot; 'elasticnet'\. Got \(penalty=l1\)&quot;</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">UserWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s1">l1_ratio</span><span class="s2">=</span><span class="s5">0.5</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">Y1</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;C&quot;</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">logspace</span><span class="s2">(-</span><span class="s5">3</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">4</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;l1_ratio&quot;</span><span class="s2">, [</span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">0.9</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_elastic_net_versus_sgd</span><span class="s2">(</span><span class="s1">C</span><span class="s2">, </span><span class="s1">l1_ratio</span><span class="s2">):</span>
    <span class="s4"># Compare elasticnet penalty in LogisticRegression() and SGD(loss='log')</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s5">500</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">,</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s5">2</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s5">5</span><span class="s2">,</span>
        <span class="s1">n_informative</span><span class="s2">=</span><span class="s5">5</span><span class="s2">,</span>
        <span class="s1">n_redundant</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">n_repeated</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">1</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">scale</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">sgd </span><span class="s2">= </span><span class="s1">SGDClassifier</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">2000</span><span class="s2">,</span>
        <span class="s1">l1_ratio</span><span class="s2">=</span><span class="s1">l1_ratio</span><span class="s2">,</span>
        <span class="s1">alpha</span><span class="s2">=</span><span class="s5">1.0 </span><span class="s2">/ </span><span class="s1">C </span><span class="s2">/ </span><span class="s1">n_samples</span><span class="s2">,</span>
        <span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;log_loss&quot;</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">log </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">False</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-5</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">1000</span><span class="s2">,</span>
        <span class="s1">l1_ratio</span><span class="s2">=</span><span class="s1">l1_ratio</span><span class="s2">,</span>
        <span class="s1">C</span><span class="s2">=</span><span class="s1">C</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s1">sgd</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">log</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">sgd</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">log</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">decimal</span><span class="s2">=</span><span class="s5">1</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_logistic_regression_path_coefs_multinomial</span><span class="s2">():</span>
    <span class="s4"># Make sure that the returned coefs by logistic_regression_path when</span>
    <span class="s4"># multi_class='multinomial' don't override each other (used to be a</span>
    <span class="s4"># bug).</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s5">200</span><span class="s2">,</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s5">3</span><span class="s2">,</span>
        <span class="s1">n_informative</span><span class="s2">=</span><span class="s5">2</span><span class="s2">,</span>
        <span class="s1">n_redundant</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">n_clusters_per_class</span><span class="s2">=</span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s5">2</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">Cs </span><span class="s2">= [</span><span class="s5">0.00001</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">10000</span><span class="s2">]</span>
    <span class="s1">coefs</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">= </span><span class="s1">_logistic_regression_path</span><span class="s2">(</span>
        <span class="s1">X</span><span class="s2">,</span>
        <span class="s1">y</span><span class="s2">,</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">,</span>
        <span class="s1">Cs</span><span class="s2">=</span><span class="s1">Cs</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;multinomial&quot;</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">AssertionError</span><span class="s2">):</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">coefs</span><span class="s2">[</span><span class="s5">0</span><span class="s2">], </span><span class="s1">coefs</span><span class="s2">[</span><span class="s5">1</span><span class="s2">], </span><span class="s1">decimal</span><span class="s2">=</span><span class="s5">1</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">AssertionError</span><span class="s2">):</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">coefs</span><span class="s2">[</span><span class="s5">0</span><span class="s2">], </span><span class="s1">coefs</span><span class="s2">[</span><span class="s5">2</span><span class="s2">], </span><span class="s1">decimal</span><span class="s2">=</span><span class="s5">1</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">AssertionError</span><span class="s2">):</span>
        <span class="s1">assert_array_almost_equal</span><span class="s2">(</span><span class="s1">coefs</span><span class="s2">[</span><span class="s5">1</span><span class="s2">], </span><span class="s1">coefs</span><span class="s2">[</span><span class="s5">2</span><span class="s2">], </span><span class="s1">decimal</span><span class="s2">=</span><span class="s5">1</span><span class="s2">)</span>


<span class="s4"># TODO(1.7): remove filterwarnings after the deprecation of multi_class</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*'multi_class' was deprecated.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;est&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s5">500</span><span class="s2">),</span>
        <span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">Cs</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-3</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s5">500</span><span class="s2">),</span>
    <span class="s2">],</span>
    <span class="s1">ids</span><span class="s2">=</span><span class="s0">lambda </span><span class="s1">x</span><span class="s2">: </span><span class="s1">x</span><span class="s2">.</span><span class="s1">__class__</span><span class="s2">.</span><span class="s1">__name__</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">SOLVERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_logistic_regression_multi_class_auto</span><span class="s2">(</span><span class="s1">est</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">):</span>
    <span class="s4"># check multi_class='auto' =&gt; multi_class='ovr'</span>
    <span class="s4"># iff binary y or liblinear or newton-cholesky</span>

    <span class="s0">def </span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, **</span><span class="s1">kw</span><span class="s2">):</span>
        <span class="s0">return </span><span class="s1">clone</span><span class="s2">(</span><span class="s1">est</span><span class="s2">).</span><span class="s1">set_params</span><span class="s2">(**</span><span class="s1">kw</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">scaled_data </span><span class="s2">= </span><span class="s1">scale</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">)</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">scaled_data</span><span class="s2">[::</span><span class="s5">10</span><span class="s2">]</span>
    <span class="s1">X2 </span><span class="s2">= </span><span class="s1">scaled_data</span><span class="s2">[</span><span class="s5">1</span><span class="s2">::</span><span class="s5">10</span><span class="s2">]</span>
    <span class="s1">y_multi </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">[::</span><span class="s5">10</span><span class="s2">]</span>
    <span class="s1">y_bin </span><span class="s2">= </span><span class="s1">y_multi </span><span class="s2">== </span><span class="s5">0</span>
    <span class="s1">est_auto_bin </span><span class="s2">= </span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_bin</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;auto&quot;</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">)</span>
    <span class="s1">est_ovr_bin </span><span class="s2">= </span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_bin</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">est_auto_bin</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">est_ovr_bin</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">est_auto_bin</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">), </span><span class="s1">est_ovr_bin</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">))</span>

    <span class="s1">est_auto_multi </span><span class="s2">= </span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_multi</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;auto&quot;</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s3">&quot;newton-cholesky&quot;</span><span class="s2">):</span>
        <span class="s1">est_ovr_multi </span><span class="s2">= </span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_multi</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">est_auto_multi</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">est_ovr_multi</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span>
            <span class="s1">est_auto_multi</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">), </span><span class="s1">est_ovr_multi</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">)</span>
        <span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">est_multi_multi </span><span class="s2">= </span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_multi</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;multinomial&quot;</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">est_auto_multi</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">est_multi_multi</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span>
            <span class="s1">est_auto_multi</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">), </span><span class="s1">est_multi_multi</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">)</span>
        <span class="s2">)</span>

        <span class="s4"># Make sure multi_class='ovr' is distinct from ='multinomial'</span>
        <span class="s0">assert not </span><span class="s1">np</span><span class="s2">.</span><span class="s1">allclose</span><span class="s2">(</span>
            <span class="s1">est_auto_bin</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">,</span>
            <span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_bin</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;multinomial&quot;</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">).</span><span class="s1">coef_</span><span class="s2">,</span>
        <span class="s2">)</span>
        <span class="s0">assert not </span><span class="s1">np</span><span class="s2">.</span><span class="s1">allclose</span><span class="s2">(</span>
            <span class="s1">est_auto_bin</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">,</span>
            <span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y_multi</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;multinomial&quot;</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">).</span><span class="s1">coef_</span><span class="s2">,</span>
        <span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">sorted</span><span class="s2">(</span><span class="s1">set</span><span class="s2">(</span><span class="s1">SOLVERS</span><span class="s2">) - </span><span class="s1">set</span><span class="s2">([</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">])))</span>
<span class="s0">def </span><span class="s1">test_penalty_none</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">):</span>
    <span class="s4"># - Make sure warning is raised if penalty=None and C is set to a</span>
    <span class="s4">#   non-default value.</span>
    <span class="s4"># - Make sure setting penalty=None is equivalent to setting C=np.inf with</span>
    <span class="s4">#   l2 penalty.</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">1000</span><span class="s2">, </span><span class="s1">n_redundant</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>

    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Setting penalty=None will ignore the C&quot;</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">penalty</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">C</span><span class="s2">=</span><span class="s5">4</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">UserWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">lr_none </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">penalty</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">lr_l2_C_inf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l2&quot;</span><span class="s2">, </span><span class="s1">C</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">inf</span><span class="s2">, </span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span>
    <span class="s2">)</span>
    <span class="s1">pred_none </span><span class="s2">= </span><span class="s1">lr_none</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">).</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">pred_l2_C_inf </span><span class="s2">= </span><span class="s1">lr_l2_C_inf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">).</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">assert_array_equal</span><span class="s2">(</span><span class="s1">pred_none</span><span class="s2">, </span><span class="s1">pred_l2_C_inf</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;params&quot;</span><span class="s2">,</span>
    <span class="s2">[</span>
        <span class="s2">{</span><span class="s3">&quot;penalty&quot;</span><span class="s2">: </span><span class="s3">&quot;l1&quot;</span><span class="s2">, </span><span class="s3">&quot;dual&quot;</span><span class="s2">: </span><span class="s0">False</span><span class="s2">, </span><span class="s3">&quot;tol&quot;</span><span class="s2">: </span><span class="s5">1e-6</span><span class="s2">, </span><span class="s3">&quot;max_iter&quot;</span><span class="s2">: </span><span class="s5">1000</span><span class="s2">},</span>
        <span class="s2">{</span><span class="s3">&quot;penalty&quot;</span><span class="s2">: </span><span class="s3">&quot;l2&quot;</span><span class="s2">, </span><span class="s3">&quot;dual&quot;</span><span class="s2">: </span><span class="s0">True</span><span class="s2">, </span><span class="s3">&quot;tol&quot;</span><span class="s2">: </span><span class="s5">1e-12</span><span class="s2">, </span><span class="s3">&quot;max_iter&quot;</span><span class="s2">: </span><span class="s5">1000</span><span class="s2">},</span>
        <span class="s2">{</span><span class="s3">&quot;penalty&quot;</span><span class="s2">: </span><span class="s3">&quot;l2&quot;</span><span class="s2">, </span><span class="s3">&quot;dual&quot;</span><span class="s2">: </span><span class="s0">False</span><span class="s2">, </span><span class="s3">&quot;tol&quot;</span><span class="s2">: </span><span class="s5">1e-12</span><span class="s2">, </span><span class="s3">&quot;max_iter&quot;</span><span class="s2">: </span><span class="s5">1000</span><span class="s2">},</span>
    <span class="s2">],</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_logisticregression_liblinear_sample_weight</span><span class="s2">(</span><span class="s1">params</span><span class="s2">):</span>
    <span class="s4"># check that we support sample_weight with liblinear in all possible cases:</span>
    <span class="s4"># l1-primal, l2-primal, l2-dual</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span>
        <span class="s2">[</span>
            <span class="s2">[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">3</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">3</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">3</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">3</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">3</span><span class="s2">, </span><span class="s5">3</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">3</span><span class="s2">, </span><span class="s5">3</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">3</span><span class="s2">, </span><span class="s5">3</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">3</span><span class="s2">, </span><span class="s5">3</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">4</span><span class="s2">, </span><span class="s5">1</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">4</span><span class="s2">, </span><span class="s5">1</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">4</span><span class="s2">, </span><span class="s5">1</span><span class="s2">],</span>
            <span class="s2">[</span><span class="s5">4</span><span class="s2">, </span><span class="s5">1</span><span class="s2">],</span>
        <span class="s2">],</span>
        <span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">dtype</span><span class="s2">(</span><span class="s3">&quot;float&quot;</span><span class="s2">),</span>
    <span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">(</span>
        <span class="s2">[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">2</span><span class="s2">], </span><span class="s1">dtype</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">dtype</span><span class="s2">(</span><span class="s3">&quot;int&quot;</span><span class="s2">)</span>
    <span class="s2">)</span>

    <span class="s1">X2 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">vstack</span><span class="s2">([</span><span class="s1">X</span><span class="s2">, </span><span class="s1">X</span><span class="s2">])</span>
    <span class="s1">y2 </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">hstack</span><span class="s2">([</span><span class="s1">y</span><span class="s2">, </span><span class="s5">3 </span><span class="s2">- </span><span class="s1">y</span><span class="s2">])</span>
    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">=</span><span class="s1">len</span><span class="s2">(</span><span class="s1">y</span><span class="s2">) * </span><span class="s5">2</span><span class="s2">)</span>
    <span class="s1">sample_weight</span><span class="s2">[</span><span class="s1">len</span><span class="s2">(</span><span class="s1">y</span><span class="s2">) :] = </span><span class="s5">0</span>
    <span class="s1">X2</span><span class="s2">, </span><span class="s1">y2</span><span class="s2">, </span><span class="s1">sample_weight </span><span class="s2">= </span><span class="s1">shuffle</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">y2</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>

    <span class="s1">base_clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">42</span><span class="s2">)</span>
    <span class="s1">base_clf</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(**</span><span class="s1">params</span><span class="s2">)</span>
    <span class="s1">clf_no_weight </span><span class="s2">= </span><span class="s1">clone</span><span class="s2">(</span><span class="s1">base_clf</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">clf_with_weight </span><span class="s2">= </span><span class="s1">clone</span><span class="s2">(</span><span class="s1">base_clf</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X2</span><span class="s2">, </span><span class="s1">y2</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">sample_weight</span><span class="s2">)</span>

    <span class="s0">for </span><span class="s1">method </span><span class="s0">in </span><span class="s2">(</span><span class="s3">&quot;predict&quot;</span><span class="s2">, </span><span class="s3">&quot;predict_proba&quot;</span><span class="s2">, </span><span class="s3">&quot;decision_function&quot;</span><span class="s2">):</span>
        <span class="s1">X_clf_no_weight </span><span class="s2">= </span><span class="s1">getattr</span><span class="s2">(</span><span class="s1">clf_no_weight</span><span class="s2">, </span><span class="s1">method</span><span class="s2">)(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s1">X_clf_with_weight </span><span class="s2">= </span><span class="s1">getattr</span><span class="s2">(</span><span class="s1">clf_with_weight</span><span class="s2">, </span><span class="s1">method</span><span class="s2">)(</span><span class="s1">X</span><span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">X_clf_no_weight</span><span class="s2">, </span><span class="s1">X_clf_with_weight</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_scores_attribute_layout_elasticnet</span><span class="s2">():</span>
    <span class="s4"># Non regression test for issue #14955.</span>
    <span class="s4"># when penalty is elastic net the scores_ attribute has shape</span>
    <span class="s4"># (n_classes, n_Cs, n_l1_ratios)</span>
    <span class="s4"># We here make sure that the second dimension indeed corresponds to Cs and</span>
    <span class="s4"># the third dimension corresponds to l1_ratios.</span>

    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">1000</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">cv </span><span class="s2">= </span><span class="s1">StratifiedKFold</span><span class="s2">(</span><span class="s1">n_splits</span><span class="s2">=</span><span class="s5">5</span><span class="s2">)</span>

    <span class="s1">l1_ratios </span><span class="s2">= [</span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">0.9</span><span class="s2">]</span>
    <span class="s1">Cs </span><span class="s2">= [</span><span class="s5">0.1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">10</span><span class="s2">]</span>

    <span class="s1">lrcv </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
        <span class="s1">l1_ratios</span><span class="s2">=</span><span class="s1">l1_ratios</span><span class="s2">,</span>
        <span class="s1">Cs</span><span class="s2">=</span><span class="s1">Cs</span><span class="s2">,</span>
        <span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">250</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-3</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">lrcv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">avg_scores_lrcv </span><span class="s2">= </span><span class="s1">lrcv</span><span class="s2">.</span><span class="s1">scores_</span><span class="s2">[</span><span class="s5">1</span><span class="s2">].</span><span class="s1">mean</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)  </span><span class="s4"># average over folds</span>

    <span class="s0">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">C </span><span class="s0">in </span><span class="s1">enumerate</span><span class="s2">(</span><span class="s1">Cs</span><span class="s2">):</span>
        <span class="s0">for </span><span class="s1">j</span><span class="s2">, </span><span class="s1">l1_ratio </span><span class="s0">in </span><span class="s1">enumerate</span><span class="s2">(</span><span class="s1">l1_ratios</span><span class="s2">):</span>
            <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
                <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;elasticnet&quot;</span><span class="s2">,</span>
                <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;saga&quot;</span><span class="s2">,</span>
                <span class="s1">C</span><span class="s2">=</span><span class="s1">C</span><span class="s2">,</span>
                <span class="s1">l1_ratio</span><span class="s2">=</span><span class="s1">l1_ratio</span><span class="s2">,</span>
                <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
                <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">250</span><span class="s2">,</span>
                <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-3</span><span class="s2">,</span>
            <span class="s2">)</span>

            <span class="s1">avg_score_lr </span><span class="s2">= </span><span class="s1">cross_val_score</span><span class="s2">(</span><span class="s1">lr</span><span class="s2">, </span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">cv</span><span class="s2">=</span><span class="s1">cv</span><span class="s2">).</span><span class="s1">mean</span><span class="s2">()</span>
            <span class="s0">assert </span><span class="s1">avg_scores_lrcv</span><span class="s2">[</span><span class="s1">i</span><span class="s2">, </span><span class="s1">j</span><span class="s2">] == </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s1">avg_score_lr</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;fit_intercept&quot;</span><span class="s2">, [</span><span class="s0">False</span><span class="s2">, </span><span class="s0">True</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_multinomial_identifiability_on_iris</span><span class="s2">(</span><span class="s1">fit_intercept</span><span class="s2">):</span>
    <span class="s6">&quot;&quot;&quot;Test that the multinomial classification is identifiable. 
 
    A multinomial with c classes can be modeled with 
    probability_k = exp(X@coef_k) / sum(exp(X@coef_l), l=1..c) for k=1..c. 
    This is not identifiable, unless one chooses a further constraint. 
    According to [1], the maximum of the L2 penalized likelihood automatically 
    satisfies the symmetric constraint: 
    sum(coef_k, k=1..c) = 0 
 
    Further details can be found in [2]. 
 
    Reference 
    --------- 
    .. [1] :doi:`Zhu, Ji and Trevor J. Hastie. &quot;Classification of gene microarrays by 
           penalized logistic regression&quot;. Biostatistics 5 3 (2004): 427-43. 
           &lt;10.1093/biostatistics/kxg046&gt;` 
 
    .. [2] :arxiv:`Noah Simon and Jerome Friedman and Trevor Hastie. (2013) 
           &quot;A Blockwise Descent Algorithm for Group-penalized Multiresponse and 
           Multinomial Regression&quot;. &lt;1311.6529&gt;` 
    &quot;&quot;&quot;</span>
    <span class="s4"># Test logistic regression with the iris dataset</span>
    <span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">.</span><span class="s1">shape</span>
    <span class="s1">target </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target_names</span><span class="s2">[</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">]</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">C</span><span class="s2">=</span><span class="s1">len</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">),</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">,</span>
        <span class="s1">fit_intercept</span><span class="s2">=</span><span class="s1">fit_intercept</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s4"># Scaling X to ease convergence.</span>
    <span class="s1">X_scaled </span><span class="s2">= </span><span class="s1">scale</span><span class="s2">(</span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_scaled</span><span class="s2">, </span><span class="s1">target</span><span class="s2">)</span>

    <span class="s4"># axis=0 is sum over classes</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s5">0</span><span class="s2">), </span><span class="s5">0</span><span class="s2">, </span><span class="s1">atol</span><span class="s2">=</span><span class="s5">1e-10</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">fit_intercept</span><span class="s2">:</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s5">0</span><span class="s2">) == </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">approx</span><span class="s2">(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">abs</span><span class="s2">=</span><span class="s5">1e-15</span><span class="s2">)</span>


<span class="s4"># TODO(1.7): remove filterwarnings after the deprecation of multi_class</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore:.*'multi_class' was deprecated.*:FutureWarning&quot;</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;multi_class&quot;</span><span class="s2">, [</span><span class="s3">&quot;ovr&quot;</span><span class="s2">, </span><span class="s3">&quot;multinomial&quot;</span><span class="s2">, </span><span class="s3">&quot;auto&quot;</span><span class="s2">])</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;class_weight&quot;</span><span class="s2">, [{</span><span class="s5">0</span><span class="s2">: </span><span class="s5">1.0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">: </span><span class="s5">10.0</span><span class="s2">, </span><span class="s5">2</span><span class="s2">: </span><span class="s5">1.0</span><span class="s2">}, </span><span class="s3">&quot;balanced&quot;</span><span class="s2">])</span>
<span class="s0">def </span><span class="s1">test_sample_weight_not_modified</span><span class="s2">(</span><span class="s1">multi_class</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">):</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">load_iris</span><span class="s2">(</span><span class="s1">return_X_y</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s1">len</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>
    <span class="s1">W </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">W</span><span class="s2">[: </span><span class="s1">n_features </span><span class="s2">// </span><span class="s5">2</span><span class="s2">] = </span><span class="s5">2</span>

    <span class="s1">expected </span><span class="s2">= </span><span class="s1">W</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">()</span>

    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">class_weight</span><span class="s2">=</span><span class="s1">class_weight</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s5">200</span><span class="s2">, </span><span class="s1">multi_class</span><span class="s2">=</span><span class="s1">multi_class</span>
    <span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s1">W</span><span class="s2">)</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">expected</span><span class="s2">, </span><span class="s1">W</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">SOLVERS</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csr_container&quot;</span><span class="s2">, </span><span class="s1">CSR_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_large_sparse_matrix</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">global_random_seed</span><span class="s2">, </span><span class="s1">csr_container</span><span class="s2">):</span>
    <span class="s4"># Solvers either accept large sparse matrices, or raise helpful error.</span>
    <span class="s4"># Non-regression test for pull-request #21093.</span>

    <span class="s4"># generate sparse matrix with int64 indices</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">csr_container</span><span class="s2">(</span><span class="s1">sparse</span><span class="s2">.</span><span class="s1">rand</span><span class="s2">(</span><span class="s5">20</span><span class="s2">, </span><span class="s5">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">))</span>
    <span class="s0">for </span><span class="s1">attr </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;indices&quot;</span><span class="s2">, </span><span class="s3">&quot;indptr&quot;</span><span class="s2">]:</span>
        <span class="s1">setattr</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">attr</span><span class="s2">, </span><span class="s1">getattr</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">attr</span><span class="s2">).</span><span class="s1">astype</span><span class="s2">(</span><span class="s3">&quot;int64&quot;</span><span class="s2">))</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">global_random_seed</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">randint</span><span class="s2">(</span><span class="s5">2</span><span class="s2">, </span><span class="s1">size</span><span class="s2">=</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">])</span>

    <span class="s0">if </span><span class="s1">solver </span><span class="s0">in </span><span class="s2">[</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">, </span><span class="s3">&quot;saga&quot;</span><span class="s2">]:</span>
        <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Only sparse matrices with 32-bit integer indices&quot;</span>
        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
            <span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_single_feature_newton_cg</span><span class="s2">():</span>
    <span class="s4"># Test that Newton-CG works with a single feature and intercept.</span>
    <span class="s4"># Non-regression test for issue #23605.</span>

    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([[</span><span class="s5">0.5</span><span class="s2">, </span><span class="s5">0.65</span><span class="s2">, </span><span class="s5">1.1</span><span class="s2">, </span><span class="s5">1.25</span><span class="s2">, </span><span class="s5">0.8</span><span class="s2">, </span><span class="s5">0.54</span><span class="s2">, </span><span class="s5">0.95</span><span class="s2">, </span><span class="s5">0.7</span><span class="s2">]]).</span><span class="s1">T</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s5">1</span><span class="s2">] == </span><span class="s5">1</span>
    <span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;newton-cg&quot;</span><span class="s2">, </span><span class="s1">fit_intercept</span><span class="s2">=</span><span class="s0">True</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_liblinear_not_stuck</span><span class="s2">():</span>
    <span class="s4"># Non-regression https://github.com/scikit-learn/scikit-learn/issues/18264</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">data</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">()</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">iris</span><span class="s2">.</span><span class="s1">target</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">()</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[</span><span class="s1">y </span><span class="s2">!= </span><span class="s5">2</span><span class="s2">]</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">y</span><span class="s2">[</span><span class="s1">y </span><span class="s2">!= </span><span class="s5">2</span><span class="s2">]</span>
    <span class="s1">X_prep </span><span class="s2">= </span><span class="s1">StandardScaler</span><span class="s2">().</span><span class="s1">fit_transform</span><span class="s2">(</span><span class="s1">X</span><span class="s2">)</span>

    <span class="s1">C </span><span class="s2">= </span><span class="s1">l1_min_c</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">loss</span><span class="s2">=</span><span class="s3">&quot;log&quot;</span><span class="s2">) * </span><span class="s5">10 </span><span class="s2">** (</span><span class="s5">10 </span><span class="s2">/ </span><span class="s5">29</span><span class="s2">)</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span>
        <span class="s1">penalty</span><span class="s2">=</span><span class="s3">&quot;l1&quot;</span><span class="s2">,</span>
        <span class="s1">solver</span><span class="s2">=</span><span class="s3">&quot;liblinear&quot;</span><span class="s2">,</span>
        <span class="s1">tol</span><span class="s2">=</span><span class="s5">1e-6</span><span class="s2">,</span>
        <span class="s1">max_iter</span><span class="s2">=</span><span class="s5">100</span><span class="s2">,</span>
        <span class="s1">intercept_scaling</span><span class="s2">=</span><span class="s5">10000.0</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">C</span><span class="s2">=</span><span class="s1">C</span><span class="s2">,</span>
    <span class="s2">)</span>

    <span class="s4"># test that the fit does not raise a ConvergenceWarning</span>
    <span class="s0">with </span><span class="s1">warnings</span><span class="s2">.</span><span class="s1">catch_warnings</span><span class="s2">():</span>
        <span class="s1">warnings</span><span class="s2">.</span><span class="s1">simplefilter</span><span class="s2">(</span><span class="s3">&quot;error&quot;</span><span class="s2">, </span><span class="s1">ConvergenceWarning</span><span class="s2">)</span>
        <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_prep</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">usefixtures</span><span class="s2">(</span><span class="s3">&quot;enable_slep006&quot;</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_lr_cv_scores_differ_when_sample_weight_is_requested</span><span class="s2">():</span>
    <span class="s6">&quot;&quot;&quot;Test that `sample_weight` is correctly passed to the scorer in 
    `LogisticRegressionCV.fit` and `LogisticRegressionCV.score` by 
    checking the difference in scores with the case when `sample_weight` 
    is not requested. 
    &quot;&quot;&quot;</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s5">10</span><span class="s2">)</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">rng</span><span class="s2">)</span>
    <span class="s1">X_t</span><span class="s2">, </span><span class="s1">y_t </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">rng</span><span class="s2">)</span>
    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">len</span><span class="s2">(</span><span class="s1">y</span><span class="s2">))</span>
    <span class="s1">sample_weight</span><span class="s2">[: </span><span class="s1">len</span><span class="s2">(</span><span class="s1">y</span><span class="s2">) // </span><span class="s5">2</span><span class="s2">] = </span><span class="s5">2</span>
    <span class="s1">kwargs </span><span class="s2">= {</span><span class="s3">&quot;sample_weight&quot;</span><span class="s2">: </span><span class="s1">sample_weight</span><span class="s2">}</span>

    <span class="s1">scorer1 </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">)</span>
    <span class="s1">lr_cv1 </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scorer1</span><span class="s2">)</span>
    <span class="s1">lr_cv1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, **</span><span class="s1">kwargs</span><span class="s2">)</span>

    <span class="s1">scorer2 </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">)</span>
    <span class="s1">scorer2</span><span class="s2">.</span><span class="s1">set_score_request</span><span class="s2">(</span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s1">lr_cv2 </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scorer2</span><span class="s2">)</span>
    <span class="s1">lr_cv2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, **</span><span class="s1">kwargs</span><span class="s2">)</span>

    <span class="s0">assert not </span><span class="s1">np</span><span class="s2">.</span><span class="s1">allclose</span><span class="s2">(</span><span class="s1">lr_cv1</span><span class="s2">.</span><span class="s1">scores_</span><span class="s2">[</span><span class="s5">1</span><span class="s2">], </span><span class="s1">lr_cv2</span><span class="s2">.</span><span class="s1">scores_</span><span class="s2">[</span><span class="s5">1</span><span class="s2">])</span>

    <span class="s1">score_1 </span><span class="s2">= </span><span class="s1">lr_cv1</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X_t</span><span class="s2">, </span><span class="s1">y_t</span><span class="s2">, **</span><span class="s1">kwargs</span><span class="s2">)</span>
    <span class="s1">score_2 </span><span class="s2">= </span><span class="s1">lr_cv2</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X_t</span><span class="s2">, </span><span class="s1">y_t</span><span class="s2">, **</span><span class="s1">kwargs</span><span class="s2">)</span>

    <span class="s0">assert not </span><span class="s1">np</span><span class="s2">.</span><span class="s1">allclose</span><span class="s2">(</span><span class="s1">score_1</span><span class="s2">, </span><span class="s1">score_2</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_lr_cv_scores_without_enabling_metadata_routing</span><span class="s2">():</span>
    <span class="s6">&quot;&quot;&quot;Test that `sample_weight` is passed correctly to the scorer in 
    `LogisticRegressionCV.fit` and `LogisticRegressionCV.score` even 
    when `enable_metadata_routing=False` 
    &quot;&quot;&quot;</span>
    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s5">10</span><span class="s2">)</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">rng</span><span class="s2">)</span>
    <span class="s1">X_t</span><span class="s2">, </span><span class="s1">y_t </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">rng</span><span class="s2">)</span>
    <span class="s1">sample_weight </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">ones</span><span class="s2">(</span><span class="s1">len</span><span class="s2">(</span><span class="s1">y</span><span class="s2">))</span>
    <span class="s1">sample_weight</span><span class="s2">[: </span><span class="s1">len</span><span class="s2">(</span><span class="s1">y</span><span class="s2">) // </span><span class="s5">2</span><span class="s2">] = </span><span class="s5">2</span>
    <span class="s1">kwargs </span><span class="s2">= {</span><span class="s3">&quot;sample_weight&quot;</span><span class="s2">: </span><span class="s1">sample_weight</span><span class="s2">}</span>

    <span class="s0">with </span><span class="s1">config_context</span><span class="s2">(</span><span class="s1">enable_metadata_routing</span><span class="s2">=</span><span class="s0">False</span><span class="s2">):</span>
        <span class="s1">scorer1 </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">)</span>
        <span class="s1">lr_cv1 </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scorer1</span><span class="s2">)</span>
        <span class="s1">lr_cv1</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, **</span><span class="s1">kwargs</span><span class="s2">)</span>
        <span class="s1">score_1 </span><span class="s2">= </span><span class="s1">lr_cv1</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X_t</span><span class="s2">, </span><span class="s1">y_t</span><span class="s2">, **</span><span class="s1">kwargs</span><span class="s2">)</span>

    <span class="s0">with </span><span class="s1">config_context</span><span class="s2">(</span><span class="s1">enable_metadata_routing</span><span class="s2">=</span><span class="s0">True</span><span class="s2">):</span>
        <span class="s1">scorer2 </span><span class="s2">= </span><span class="s1">get_scorer</span><span class="s2">(</span><span class="s3">&quot;accuracy&quot;</span><span class="s2">)</span>
        <span class="s1">scorer2</span><span class="s2">.</span><span class="s1">set_score_request</span><span class="s2">(</span><span class="s1">sample_weight</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
        <span class="s1">lr_cv2 </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">scoring</span><span class="s2">=</span><span class="s1">scorer2</span><span class="s2">)</span>
        <span class="s1">lr_cv2</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, **</span><span class="s1">kwargs</span><span class="s2">)</span>
        <span class="s1">score_2 </span><span class="s2">= </span><span class="s1">lr_cv2</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X_t</span><span class="s2">, </span><span class="s1">y_t</span><span class="s2">, **</span><span class="s1">kwargs</span><span class="s2">)</span>

    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">lr_cv1</span><span class="s2">.</span><span class="s1">scores_</span><span class="s2">[</span><span class="s5">1</span><span class="s2">], </span><span class="s1">lr_cv2</span><span class="s2">.</span><span class="s1">scores_</span><span class="s2">[</span><span class="s5">1</span><span class="s2">])</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">score_1</span><span class="s2">, </span><span class="s1">score_2</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;solver&quot;</span><span class="s2">, </span><span class="s1">SOLVERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_zero_max_iter</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">):</span>
    <span class="s4"># Make sure we can inspect the state of LogisticRegression right after</span>
    <span class="s4"># initialization (before the first weight update).</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">load_iris</span><span class="s2">(</span><span class="s1">return_X_y</span><span class="s2">=</span><span class="s0">True</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">y </span><span class="s2">== </span><span class="s5">2</span>
    <span class="s0">with </span><span class="s1">ignore_warnings</span><span class="s2">(</span><span class="s1">category</span><span class="s2">=</span><span class="s1">ConvergenceWarning</span><span class="s2">):</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">solver</span><span class="s2">=</span><span class="s1">solver</span><span class="s2">, </span><span class="s1">max_iter</span><span class="s2">=</span><span class="s5">0</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">solver </span><span class="s0">not in </span><span class="s2">[</span><span class="s3">&quot;saga&quot;</span><span class="s2">, </span><span class="s3">&quot;sag&quot;</span><span class="s2">]:</span>
        <span class="s4"># XXX: sag and saga have n_iter_ = [1]...</span>
        <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">n_iter_ </span><span class="s2">== </span><span class="s5">0</span>

    <span class="s0">if </span><span class="s1">solver </span><span class="s2">!= </span><span class="s3">&quot;lbfgs&quot;</span><span class="s2">:</span>
        <span class="s4"># XXX: lbfgs has already started to update the coefficients...</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros_like</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">coef_</span><span class="s2">))</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span>
            <span class="s1">clf</span><span class="s2">.</span><span class="s1">decision_function</span><span class="s2">(</span><span class="s1">X</span><span class="s2">),</span>
            <span class="s1">np</span><span class="s2">.</span><span class="s1">full</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">=</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">], </span><span class="s1">fill_value</span><span class="s2">=</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">intercept_</span><span class="s2">),</span>
        <span class="s2">)</span>
        <span class="s1">assert_allclose</span><span class="s2">(</span>
            <span class="s1">clf</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X</span><span class="s2">),</span>
            <span class="s1">np</span><span class="s2">.</span><span class="s1">full</span><span class="s2">(</span><span class="s1">shape</span><span class="s2">=(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s5">0</span><span class="s2">], </span><span class="s5">2</span><span class="s2">), </span><span class="s1">fill_value</span><span class="s2">=</span><span class="s5">0.5</span><span class="s2">),</span>
        <span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">) &lt; </span><span class="s5">0.7</span>


<span class="s0">def </span><span class="s1">test_passing_params_without_enabling_metadata_routing</span><span class="s2">():</span>
    <span class="s6">&quot;&quot;&quot;Test that the right error message is raised when metadata params 
    are passed while not supported when `enable_metadata_routing=False`.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s5">0</span><span class="s2">)</span>
    <span class="s1">lr_cv </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">()</span>
    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;is only supported if enable_metadata_routing=True&quot;</span>

    <span class="s0">with </span><span class="s1">config_context</span><span class="s2">(</span><span class="s1">enable_metadata_routing</span><span class="s2">=</span><span class="s0">False</span><span class="s2">):</span>
        <span class="s1">params </span><span class="s2">= {</span><span class="s3">&quot;extra_param&quot;</span><span class="s2">: </span><span class="s5">1.0</span><span class="s2">}</span>

        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
            <span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, **</span><span class="s1">params</span><span class="s2">)</span>

        <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
            <span class="s1">lr_cv</span><span class="s2">.</span><span class="s1">score</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, **</span><span class="s1">params</span><span class="s2">)</span>


<span class="s4"># TODO(1.7): remove</span>
<span class="s0">def </span><span class="s1">test_multi_class_deprecated</span><span class="s2">():</span>
    <span class="s6">&quot;&quot;&quot;Check `multi_class` parameter deprecated.&quot;&quot;&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_classes</span><span class="s2">=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">50</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s5">6</span><span class="s2">)</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">)</span>
    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;'multi_class' was deprecated&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">FutureWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">lrCV </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;ovr&quot;</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">FutureWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">lrCV</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s4"># Special warning for &quot;binary multinomial&quot;</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span><span class="s1">n_classes</span><span class="s2">=</span><span class="s5">2</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">=</span><span class="s5">50</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s5">6</span><span class="s2">)</span>
    <span class="s1">lr </span><span class="s2">= </span><span class="s1">LogisticRegression</span><span class="s2">(</span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;multinomial&quot;</span><span class="s2">)</span>
    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;'multi_class' was deprecated.*binary problems&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">FutureWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">lr</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">lrCV </span><span class="s2">= </span><span class="s1">LogisticRegressionCV</span><span class="s2">(</span><span class="s1">multi_class</span><span class="s2">=</span><span class="s3">&quot;multinomial&quot;</span><span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">warns</span><span class="s2">(</span><span class="s1">FutureWarning</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">lrCV</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
</pre>
</body>
</html>