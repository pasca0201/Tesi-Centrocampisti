<html>
<head>
<title>test_mlp.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_mlp.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Testing for Multi-layer Perceptron module (sklearn.neural_network) 
&quot;&quot;&quot;</span>

<span class="s2"># Author: Issam H. Laradji</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">re</span>
<span class="s3">import </span><span class="s1">sys</span>
<span class="s3">import </span><span class="s1">warnings</span>
<span class="s3">from </span><span class="s1">io </span><span class="s3">import </span><span class="s1">StringIO</span>

<span class="s3">import </span><span class="s1">joblib</span>
<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">import </span><span class="s1">pytest</span>
<span class="s3">from </span><span class="s1">numpy</span><span class="s4">.</span><span class="s1">testing </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">assert_allclose</span><span class="s4">,</span>
    <span class="s1">assert_almost_equal</span><span class="s4">,</span>
    <span class="s1">assert_array_equal</span><span class="s4">,</span>
<span class="s4">)</span>

<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">datasets </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">load_digits</span><span class="s4">,</span>
    <span class="s1">load_iris</span><span class="s4">,</span>
    <span class="s1">make_multilabel_classification</span><span class="s4">,</span>
    <span class="s1">make_regression</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">exceptions </span><span class="s3">import </span><span class="s1">ConvergenceWarning</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">metrics </span><span class="s3">import </span><span class="s1">roc_auc_score</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">neural_network </span><span class="s3">import </span><span class="s1">MLPClassifier</span><span class="s4">, </span><span class="s1">MLPRegressor</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">preprocessing </span><span class="s3">import </span><span class="s1">LabelBinarizer</span><span class="s4">, </span><span class="s1">MinMaxScaler</span><span class="s4">, </span><span class="s1">scale</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_testing </span><span class="s3">import </span><span class="s1">ignore_warnings</span>
<span class="s3">from </span><span class="s1">sklearn</span><span class="s4">.</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">fixes </span><span class="s3">import </span><span class="s1">CSR_CONTAINERS</span>

<span class="s1">ACTIVATION_TYPES </span><span class="s4">= [</span><span class="s5">&quot;identity&quot;</span><span class="s4">, </span><span class="s5">&quot;logistic&quot;</span><span class="s4">, </span><span class="s5">&quot;tanh&quot;</span><span class="s4">, </span><span class="s5">&quot;relu&quot;</span><span class="s4">]</span>

<span class="s1">X_digits</span><span class="s4">, </span><span class="s1">y_digits </span><span class="s4">= </span><span class="s1">load_digits</span><span class="s4">(</span><span class="s1">n_class</span><span class="s4">=</span><span class="s6">3</span><span class="s4">, </span><span class="s1">return_X_y</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>

<span class="s1">X_digits_multi </span><span class="s4">= </span><span class="s1">MinMaxScaler</span><span class="s4">().</span><span class="s1">fit_transform</span><span class="s4">(</span><span class="s1">X_digits</span><span class="s4">[:</span><span class="s6">200</span><span class="s4">])</span>
<span class="s1">y_digits_multi </span><span class="s4">= </span><span class="s1">y_digits</span><span class="s4">[:</span><span class="s6">200</span><span class="s4">]</span>

<span class="s1">X_digits</span><span class="s4">, </span><span class="s1">y_digits </span><span class="s4">= </span><span class="s1">load_digits</span><span class="s4">(</span><span class="s1">n_class</span><span class="s4">=</span><span class="s6">2</span><span class="s4">, </span><span class="s1">return_X_y</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>

<span class="s1">X_digits_binary </span><span class="s4">= </span><span class="s1">MinMaxScaler</span><span class="s4">().</span><span class="s1">fit_transform</span><span class="s4">(</span><span class="s1">X_digits</span><span class="s4">[:</span><span class="s6">200</span><span class="s4">])</span>
<span class="s1">y_digits_binary </span><span class="s4">= </span><span class="s1">y_digits</span><span class="s4">[:</span><span class="s6">200</span><span class="s4">]</span>

<span class="s1">classification_datasets </span><span class="s4">= [</span>
    <span class="s4">(</span><span class="s1">X_digits_multi</span><span class="s4">, </span><span class="s1">y_digits_multi</span><span class="s4">),</span>
    <span class="s4">(</span><span class="s1">X_digits_binary</span><span class="s4">, </span><span class="s1">y_digits_binary</span><span class="s4">),</span>
<span class="s4">]</span>

<span class="s1">X_reg</span><span class="s4">, </span><span class="s1">y_reg </span><span class="s4">= </span><span class="s1">make_regression</span><span class="s4">(</span>
    <span class="s1">n_samples</span><span class="s4">=</span><span class="s6">200</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">=</span><span class="s6">10</span><span class="s4">, </span><span class="s1">bias</span><span class="s4">=</span><span class="s6">20.0</span><span class="s4">, </span><span class="s1">noise</span><span class="s4">=</span><span class="s6">100.0</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">7</span>
<span class="s4">)</span>
<span class="s1">y_reg </span><span class="s4">= </span><span class="s1">scale</span><span class="s4">(</span><span class="s1">y_reg</span><span class="s4">)</span>
<span class="s1">regression_datasets </span><span class="s4">= [(</span><span class="s1">X_reg</span><span class="s4">, </span><span class="s1">y_reg</span><span class="s4">)]</span>

<span class="s1">iris </span><span class="s4">= </span><span class="s1">load_iris</span><span class="s4">()</span>

<span class="s1">X_iris </span><span class="s4">= </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">data</span>
<span class="s1">y_iris </span><span class="s4">= </span><span class="s1">iris</span><span class="s4">.</span><span class="s1">target</span>


<span class="s3">def </span><span class="s1">test_alpha</span><span class="s4">():</span>
    <span class="s2"># Test that larger alpha yields weights closer to zero</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">X_digits_binary</span><span class="s4">[:</span><span class="s6">100</span><span class="s4">]</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">y_digits_binary</span><span class="s4">[:</span><span class="s6">100</span><span class="s4">]</span>

    <span class="s1">alpha_vectors </span><span class="s4">= []</span>
    <span class="s1">alpha_values </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">arange</span><span class="s4">(</span><span class="s6">2</span><span class="s4">)</span>
    <span class="s1">absolute_sum </span><span class="s4">= </span><span class="s3">lambda </span><span class="s1">x</span><span class="s4">: </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">abs</span><span class="s4">(</span><span class="s1">x</span><span class="s4">))</span>

    <span class="s3">for </span><span class="s1">alpha </span><span class="s3">in </span><span class="s1">alpha_values</span><span class="s4">:</span>
        <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">10</span><span class="s4">, </span><span class="s1">alpha</span><span class="s4">=</span><span class="s1">alpha</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">)</span>
        <span class="s3">with </span><span class="s1">ignore_warnings</span><span class="s4">(</span><span class="s1">category</span><span class="s4">=</span><span class="s1">ConvergenceWarning</span><span class="s4">):</span>
            <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
        <span class="s1">alpha_vectors</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span>
            <span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s1">absolute_sum</span><span class="s4">(</span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">coefs_</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]), </span><span class="s1">absolute_sum</span><span class="s4">(</span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">coefs_</span><span class="s4">[</span><span class="s6">1</span><span class="s4">])])</span>
        <span class="s4">)</span>

    <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">len</span><span class="s4">(</span><span class="s1">alpha_values</span><span class="s4">) - </span><span class="s6">1</span><span class="s4">):</span>
        <span class="s3">assert </span><span class="s4">(</span><span class="s1">alpha_vectors</span><span class="s4">[</span><span class="s1">i</span><span class="s4">] &gt; </span><span class="s1">alpha_vectors</span><span class="s4">[</span><span class="s1">i </span><span class="s4">+ </span><span class="s6">1</span><span class="s4">]).</span><span class="s1">all</span><span class="s4">()</span>


<span class="s3">def </span><span class="s1">test_fit</span><span class="s4">():</span>
    <span class="s2"># Test that the algorithm solution is equal to a worked out example.</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([[</span><span class="s6">0.6</span><span class="s4">, </span><span class="s6">0.8</span><span class="s4">, </span><span class="s6">0.7</span><span class="s4">]])</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s6">0</span><span class="s4">])</span>
    <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span>
        <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">,</span>
        <span class="s1">learning_rate_init</span><span class="s4">=</span><span class="s6">0.1</span><span class="s4">,</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s6">0.1</span><span class="s4">,</span>
        <span class="s1">activation</span><span class="s4">=</span><span class="s5">&quot;logistic&quot;</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
        <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">2</span><span class="s4">,</span>
        <span class="s1">momentum</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
    <span class="s4">)</span>
    <span class="s2"># set weights</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">coefs_ </span><span class="s4">= [</span><span class="s6">0</span><span class="s4">] * </span><span class="s6">2</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">intercepts_ </span><span class="s4">= [</span><span class="s6">0</span><span class="s4">] * </span><span class="s6">2</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">n_outputs_ </span><span class="s4">= </span><span class="s6">1</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">coefs_</span><span class="s4">[</span><span class="s6">0</span><span class="s4">] = </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([[</span><span class="s6">0.1</span><span class="s4">, </span><span class="s6">0.2</span><span class="s4">], [</span><span class="s6">0.3</span><span class="s4">, </span><span class="s6">0.1</span><span class="s4">], [</span><span class="s6">0.5</span><span class="s4">, </span><span class="s6">0</span><span class="s4">]])</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">coefs_</span><span class="s4">[</span><span class="s6">1</span><span class="s4">] = </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([[</span><span class="s6">0.1</span><span class="s4">], [</span><span class="s6">0.2</span><span class="s4">]])</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">intercepts_</span><span class="s4">[</span><span class="s6">0</span><span class="s4">] = </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s6">0.1</span><span class="s4">, </span><span class="s6">0.1</span><span class="s4">])</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">intercepts_</span><span class="s4">[</span><span class="s6">1</span><span class="s4">] = </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s6">1.0</span><span class="s4">])</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">_coef_grads </span><span class="s4">= [] * </span><span class="s6">2</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">_intercept_grads </span><span class="s4">= [] * </span><span class="s6">2</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">n_features_in_ </span><span class="s4">= </span><span class="s6">3</span>

    <span class="s2"># Initialize parameters</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">n_iter_ </span><span class="s4">= </span><span class="s6">0</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">learning_rate_ </span><span class="s4">= </span><span class="s6">0.1</span>

    <span class="s2"># Compute the number of layers</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">n_layers_ </span><span class="s4">= </span><span class="s6">3</span>

    <span class="s2"># Pre-allocate gradient matrices</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">_coef_grads </span><span class="s4">= [</span><span class="s6">0</span><span class="s4">] * (</span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">n_layers_ </span><span class="s4">- </span><span class="s6">1</span><span class="s4">)</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">_intercept_grads </span><span class="s4">= [</span><span class="s6">0</span><span class="s4">] * (</span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">n_layers_ </span><span class="s4">- </span><span class="s6">1</span><span class="s4">)</span>

    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">out_activation_ </span><span class="s4">= </span><span class="s5">&quot;logistic&quot;</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">t_ </span><span class="s4">= </span><span class="s6">0</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">best_loss_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">loss_curve_ </span><span class="s4">= []</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">_no_improvement_count </span><span class="s4">= </span><span class="s6">0</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">_intercept_velocity </span><span class="s4">= [</span>
        <span class="s1">np</span><span class="s4">.</span><span class="s1">zeros_like</span><span class="s4">(</span><span class="s1">intercepts</span><span class="s4">) </span><span class="s3">for </span><span class="s1">intercepts </span><span class="s3">in </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">intercepts_</span>
    <span class="s4">]</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">_coef_velocity </span><span class="s4">= [</span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros_like</span><span class="s4">(</span><span class="s1">coefs</span><span class="s4">) </span><span class="s3">for </span><span class="s1">coefs </span><span class="s3">in </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">coefs_</span><span class="s4">]</span>

    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">partial_fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">classes</span><span class="s4">=[</span><span class="s6">0</span><span class="s4">, </span><span class="s6">1</span><span class="s4">])</span>
    <span class="s2"># Manually worked out example</span>
    <span class="s2"># h1 = g(X1 * W_i1 + b11) = g(0.6 * 0.1 + 0.8 * 0.3 + 0.7 * 0.5 + 0.1)</span>
    <span class="s2">#       =  0.679178699175393</span>
    <span class="s2"># h2 = g(X2 * W_i2 + b12) = g(0.6 * 0.2 + 0.8 * 0.1 + 0.7 * 0 + 0.1)</span>
    <span class="s2">#         = 0.574442516811659</span>
    <span class="s2"># o1 = g(h * W2 + b21) = g(0.679 * 0.1 + 0.574 * 0.2 + 1)</span>
    <span class="s2">#       = 0.7654329236196236</span>
    <span class="s2"># d21 = -(0 - 0.765) = 0.765</span>
    <span class="s2"># d11 = (1 - 0.679) * 0.679 * 0.765 * 0.1 = 0.01667</span>
    <span class="s2"># d12 = (1 - 0.574) * 0.574 * 0.765 * 0.2 = 0.0374</span>
    <span class="s2"># W1grad11 = X1 * d11 + alpha * W11 = 0.6 * 0.01667 + 0.1 * 0.1 = 0.0200</span>
    <span class="s2"># W1grad11 = X1 * d12 + alpha * W12 = 0.6 * 0.0374 + 0.1 * 0.2 = 0.04244</span>
    <span class="s2"># W1grad21 = X2 * d11 + alpha * W13 = 0.8 * 0.01667 + 0.1 * 0.3 = 0.043336</span>
    <span class="s2"># W1grad22 = X2 * d12 + alpha * W14 = 0.8 * 0.0374 + 0.1 * 0.1 = 0.03992</span>
    <span class="s2"># W1grad31 = X3 * d11 + alpha * W15 = 0.6 * 0.01667 + 0.1 * 0.5 = 0.060002</span>
    <span class="s2"># W1grad32 = X3 * d12 + alpha * W16 = 0.6 * 0.0374 + 0.1 * 0 = 0.02244</span>
    <span class="s2"># W2grad1 = h1 * d21 + alpha * W21 = 0.679 * 0.765 + 0.1 * 0.1 = 0.5294</span>
    <span class="s2"># W2grad2 = h2 * d21 + alpha * W22 = 0.574 * 0.765 + 0.1 * 0.2 = 0.45911</span>
    <span class="s2"># b1grad1 = d11 = 0.01667</span>
    <span class="s2"># b1grad2 = d12 = 0.0374</span>
    <span class="s2"># b2grad = d21 = 0.765</span>
    <span class="s2"># W1 = W1 - eta * [W1grad11, .., W1grad32] = [[0.1, 0.2], [0.3, 0.1],</span>
    <span class="s2">#          [0.5, 0]] - 0.1 * [[0.0200, 0.04244], [0.043336, 0.03992],</span>
    <span class="s2">#          [0.060002, 0.02244]] = [[0.098, 0.195756], [0.2956664,</span>
    <span class="s2">#          0.096008], [0.4939998, -0.002244]]</span>
    <span class="s2"># W2 = W2 - eta * [W2grad1, W2grad2] = [[0.1], [0.2]] - 0.1 *</span>
    <span class="s2">#        [[0.5294], [0.45911]] = [[0.04706], [0.154089]]</span>
    <span class="s2"># b1 = b1 - eta * [b1grad1, b1grad2] = 0.1 - 0.1 * [0.01667, 0.0374]</span>
    <span class="s2">#         = [0.098333, 0.09626]</span>
    <span class="s2"># b2 = b2 - eta * b2grad = 1.0 - 0.1 * 0.765 = 0.9235</span>
    <span class="s1">assert_almost_equal</span><span class="s4">(</span>
        <span class="s1">mlp</span><span class="s4">.</span><span class="s1">coefs_</span><span class="s4">[</span><span class="s6">0</span><span class="s4">],</span>
        <span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([[</span><span class="s6">0.098</span><span class="s4">, </span><span class="s6">0.195756</span><span class="s4">], [</span><span class="s6">0.2956664</span><span class="s4">, </span><span class="s6">0.096008</span><span class="s4">], [</span><span class="s6">0.4939998</span><span class="s4">, -</span><span class="s6">0.002244</span><span class="s4">]]),</span>
        <span class="s1">decimal</span><span class="s4">=</span><span class="s6">3</span><span class="s4">,</span>
    <span class="s4">)</span>
    <span class="s1">assert_almost_equal</span><span class="s4">(</span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">coefs_</span><span class="s4">[</span><span class="s6">1</span><span class="s4">], </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([[</span><span class="s6">0.04706</span><span class="s4">], [</span><span class="s6">0.154089</span><span class="s4">]]), </span><span class="s1">decimal</span><span class="s4">=</span><span class="s6">3</span><span class="s4">)</span>
    <span class="s1">assert_almost_equal</span><span class="s4">(</span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">intercepts_</span><span class="s4">[</span><span class="s6">0</span><span class="s4">], </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s6">0.098333</span><span class="s4">, </span><span class="s6">0.09626</span><span class="s4">]), </span><span class="s1">decimal</span><span class="s4">=</span><span class="s6">3</span><span class="s4">)</span>
    <span class="s1">assert_almost_equal</span><span class="s4">(</span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">intercepts_</span><span class="s4">[</span><span class="s6">1</span><span class="s4">], </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span><span class="s6">0.9235</span><span class="s4">), </span><span class="s1">decimal</span><span class="s4">=</span><span class="s6">3</span><span class="s4">)</span>
    <span class="s2"># Testing output</span>
    <span class="s2">#  h1 = g(X1 * W_i1 + b11) = g(0.6 * 0.098 + 0.8 * 0.2956664 +</span>
    <span class="s2">#               0.7 * 0.4939998 + 0.098333) = 0.677</span>
    <span class="s2">#  h2 = g(X2 * W_i2 + b12) = g(0.6 * 0.195756 + 0.8 * 0.096008 +</span>
    <span class="s2">#            0.7 * -0.002244 + 0.09626) = 0.572</span>
    <span class="s2">#  o1 = h * W2 + b21 = 0.677 * 0.04706 +</span>
    <span class="s2">#             0.572 * 0.154089 + 0.9235 = 1.043</span>
    <span class="s2">#  prob = sigmoid(o1) = 0.739</span>
    <span class="s1">assert_almost_equal</span><span class="s4">(</span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)[</span><span class="s6">0</span><span class="s4">, </span><span class="s6">1</span><span class="s4">], </span><span class="s6">0.739</span><span class="s4">, </span><span class="s1">decimal</span><span class="s4">=</span><span class="s6">3</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_gradient</span><span class="s4">():</span>
    <span class="s2"># Test gradient.</span>

    <span class="s2"># This makes sure that the activation functions and their derivatives</span>
    <span class="s2"># are correct. The numerical and analytical computation of the gradient</span>
    <span class="s2"># should be close.</span>
    <span class="s3">for </span><span class="s1">n_labels </span><span class="s3">in </span><span class="s4">[</span><span class="s6">2</span><span class="s4">, </span><span class="s6">3</span><span class="s4">]:</span>
        <span class="s1">n_samples </span><span class="s4">= </span><span class="s6">5</span>
        <span class="s1">n_features </span><span class="s4">= </span><span class="s6">10</span>
        <span class="s1">random_state </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">random</span><span class="s4">.</span><span class="s1">RandomState</span><span class="s4">(</span><span class="s1">seed</span><span class="s4">=</span><span class="s6">42</span><span class="s4">)</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">random_state</span><span class="s4">.</span><span class="s1">rand</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">)</span>
        <span class="s1">y </span><span class="s4">= </span><span class="s6">1 </span><span class="s4">+ </span><span class="s1">np</span><span class="s4">.</span><span class="s1">mod</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">arange</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">) + </span><span class="s6">1</span><span class="s4">, </span><span class="s1">n_labels</span><span class="s4">)</span>
        <span class="s1">Y </span><span class="s4">= </span><span class="s1">LabelBinarizer</span><span class="s4">().</span><span class="s1">fit_transform</span><span class="s4">(</span><span class="s1">y</span><span class="s4">)</span>

        <span class="s3">for </span><span class="s1">activation </span><span class="s3">in </span><span class="s1">ACTIVATION_TYPES</span><span class="s4">:</span>
            <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span>
                <span class="s1">activation</span><span class="s4">=</span><span class="s1">activation</span><span class="s4">,</span>
                <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">10</span><span class="s4">,</span>
                <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;lbfgs&quot;</span><span class="s4">,</span>
                <span class="s1">alpha</span><span class="s4">=</span><span class="s6">1e-5</span><span class="s4">,</span>
                <span class="s1">learning_rate_init</span><span class="s4">=</span><span class="s6">0.2</span><span class="s4">,</span>
                <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
                <span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s4">)</span>
            <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

            <span class="s1">theta </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">hstack</span><span class="s4">([</span><span class="s1">l</span><span class="s4">.</span><span class="s1">ravel</span><span class="s4">() </span><span class="s3">for </span><span class="s1">l </span><span class="s3">in </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">coefs_ </span><span class="s4">+ </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">intercepts_</span><span class="s4">])</span>

            <span class="s1">layer_units </span><span class="s4">= [</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]] + [</span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">hidden_layer_sizes</span><span class="s4">] + [</span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">n_outputs_</span><span class="s4">]</span>

            <span class="s1">activations </span><span class="s4">= []</span>
            <span class="s1">deltas </span><span class="s4">= []</span>
            <span class="s1">coef_grads </span><span class="s4">= []</span>
            <span class="s1">intercept_grads </span><span class="s4">= []</span>

            <span class="s1">activations</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">n_layers_ </span><span class="s4">- </span><span class="s6">1</span><span class="s4">):</span>
                <span class="s1">activations</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">empty</span><span class="s4">((</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">], </span><span class="s1">layer_units</span><span class="s4">[</span><span class="s1">i </span><span class="s4">+ </span><span class="s6">1</span><span class="s4">])))</span>
                <span class="s1">deltas</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">empty</span><span class="s4">((</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">], </span><span class="s1">layer_units</span><span class="s4">[</span><span class="s1">i </span><span class="s4">+ </span><span class="s6">1</span><span class="s4">])))</span>

                <span class="s1">fan_in </span><span class="s4">= </span><span class="s1">layer_units</span><span class="s4">[</span><span class="s1">i</span><span class="s4">]</span>
                <span class="s1">fan_out </span><span class="s4">= </span><span class="s1">layer_units</span><span class="s4">[</span><span class="s1">i </span><span class="s4">+ </span><span class="s6">1</span><span class="s4">]</span>
                <span class="s1">coef_grads</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">empty</span><span class="s4">((</span><span class="s1">fan_in</span><span class="s4">, </span><span class="s1">fan_out</span><span class="s4">)))</span>
                <span class="s1">intercept_grads</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">empty</span><span class="s4">(</span><span class="s1">fan_out</span><span class="s4">))</span>

            <span class="s2"># analytically compute the gradients</span>
            <span class="s3">def </span><span class="s1">loss_grad_fun</span><span class="s4">(</span><span class="s1">t</span><span class="s4">):</span>
                <span class="s3">return </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">_loss_grad_lbfgs</span><span class="s4">(</span>
                    <span class="s1">t</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">Y</span><span class="s4">, </span><span class="s1">activations</span><span class="s4">, </span><span class="s1">deltas</span><span class="s4">, </span><span class="s1">coef_grads</span><span class="s4">, </span><span class="s1">intercept_grads</span>
                <span class="s4">)</span>

            <span class="s4">[</span><span class="s1">value</span><span class="s4">, </span><span class="s1">grad</span><span class="s4">] = </span><span class="s1">loss_grad_fun</span><span class="s4">(</span><span class="s1">theta</span><span class="s4">)</span>
            <span class="s1">numgrad </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">size</span><span class="s4">(</span><span class="s1">theta</span><span class="s4">))</span>
            <span class="s1">n </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">size</span><span class="s4">(</span><span class="s1">theta</span><span class="s4">, </span><span class="s6">0</span><span class="s4">)</span>
            <span class="s1">E </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">eye</span><span class="s4">(</span><span class="s1">n</span><span class="s4">)</span>
            <span class="s1">epsilon </span><span class="s4">= </span><span class="s6">1e-5</span>
            <span class="s2"># numerically compute the gradients</span>
            <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">n</span><span class="s4">):</span>
                <span class="s1">dtheta </span><span class="s4">= </span><span class="s1">E</span><span class="s4">[:, </span><span class="s1">i</span><span class="s4">] * </span><span class="s1">epsilon</span>
                <span class="s1">numgrad</span><span class="s4">[</span><span class="s1">i</span><span class="s4">] = (</span>
                    <span class="s1">loss_grad_fun</span><span class="s4">(</span><span class="s1">theta </span><span class="s4">+ </span><span class="s1">dtheta</span><span class="s4">)[</span><span class="s6">0</span><span class="s4">] - </span><span class="s1">loss_grad_fun</span><span class="s4">(</span><span class="s1">theta </span><span class="s4">- </span><span class="s1">dtheta</span><span class="s4">)[</span><span class="s6">0</span><span class="s4">]</span>
                <span class="s4">) / (</span><span class="s1">epsilon </span><span class="s4">* </span><span class="s6">2.0</span><span class="s4">)</span>
            <span class="s1">assert_almost_equal</span><span class="s4">(</span><span class="s1">numgrad</span><span class="s4">, </span><span class="s1">grad</span><span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;X,y&quot;</span><span class="s4">, </span><span class="s1">classification_datasets</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_lbfgs_classification</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">):</span>
    <span class="s2"># Test lbfgs on classification.</span>
    <span class="s2"># It should achieve a score higher than 0.95 for the binary and multi-class</span>
    <span class="s2"># versions of the digits dataset.</span>
    <span class="s1">X_train </span><span class="s4">= </span><span class="s1">X</span><span class="s4">[:</span><span class="s6">150</span><span class="s4">]</span>
    <span class="s1">y_train </span><span class="s4">= </span><span class="s1">y</span><span class="s4">[:</span><span class="s6">150</span><span class="s4">]</span>
    <span class="s1">X_test </span><span class="s4">= </span><span class="s1">X</span><span class="s4">[</span><span class="s6">150</span><span class="s4">:]</span>
    <span class="s1">expected_shape_dtype </span><span class="s4">= (</span><span class="s1">X_test</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">], </span><span class="s1">y_train</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">.</span><span class="s1">kind</span><span class="s4">)</span>

    <span class="s3">for </span><span class="s1">activation </span><span class="s3">in </span><span class="s1">ACTIVATION_TYPES</span><span class="s4">:</span>
        <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span>
            <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;lbfgs&quot;</span><span class="s4">,</span>
            <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">50</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">150</span><span class="s4">,</span>
            <span class="s1">shuffle</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">activation</span><span class="s4">=</span><span class="s1">activation</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">)</span>
        <span class="s1">y_predict </span><span class="s4">= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>
        <span class="s3">assert </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">, </span><span class="s1">y_train</span><span class="s4">) &gt; </span><span class="s6">0.95</span>
        <span class="s3">assert </span><span class="s4">(</span><span class="s1">y_predict</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">], </span><span class="s1">y_predict</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">.</span><span class="s1">kind</span><span class="s4">) == </span><span class="s1">expected_shape_dtype</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;X,y&quot;</span><span class="s4">, </span><span class="s1">regression_datasets</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_lbfgs_regression</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">):</span>
    <span class="s2"># Test lbfgs on the regression dataset.</span>
    <span class="s3">for </span><span class="s1">activation </span><span class="s3">in </span><span class="s1">ACTIVATION_TYPES</span><span class="s4">:</span>
        <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPRegressor</span><span class="s4">(</span>
            <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;lbfgs&quot;</span><span class="s4">,</span>
            <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">50</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">150</span><span class="s4">,</span>
            <span class="s1">shuffle</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">activation</span><span class="s4">=</span><span class="s1">activation</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
        <span class="s3">if </span><span class="s1">activation </span><span class="s4">== </span><span class="s5">&quot;identity&quot;</span><span class="s4">:</span>
            <span class="s3">assert </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">) &gt; </span><span class="s6">0.80</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s2"># Non linear models perform much better than linear bottleneck:</span>
            <span class="s3">assert </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">) &gt; </span><span class="s6">0.98</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;X,y&quot;</span><span class="s4">, </span><span class="s1">classification_datasets</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_lbfgs_classification_maxfun</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">):</span>
    <span class="s2"># Test lbfgs parameter max_fun.</span>
    <span class="s2"># It should independently limit the number of iterations for lbfgs.</span>
    <span class="s1">max_fun </span><span class="s4">= </span><span class="s6">10</span>
    <span class="s2"># classification tests</span>
    <span class="s3">for </span><span class="s1">activation </span><span class="s3">in </span><span class="s1">ACTIVATION_TYPES</span><span class="s4">:</span>
        <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span>
            <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;lbfgs&quot;</span><span class="s4">,</span>
            <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">50</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">150</span><span class="s4">,</span>
            <span class="s1">max_fun</span><span class="s4">=</span><span class="s1">max_fun</span><span class="s4">,</span>
            <span class="s1">shuffle</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">activation</span><span class="s4">=</span><span class="s1">activation</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">warns</span><span class="s4">(</span><span class="s1">ConvergenceWarning</span><span class="s4">):</span>
            <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
            <span class="s3">assert </span><span class="s1">max_fun </span><span class="s4">&gt;= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">n_iter_</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;X,y&quot;</span><span class="s4">, </span><span class="s1">regression_datasets</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_lbfgs_regression_maxfun</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">):</span>
    <span class="s2"># Test lbfgs parameter max_fun.</span>
    <span class="s2"># It should independently limit the number of iterations for lbfgs.</span>
    <span class="s1">max_fun </span><span class="s4">= </span><span class="s6">10</span>
    <span class="s2"># regression tests</span>
    <span class="s3">for </span><span class="s1">activation </span><span class="s3">in </span><span class="s1">ACTIVATION_TYPES</span><span class="s4">:</span>
        <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPRegressor</span><span class="s4">(</span>
            <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;lbfgs&quot;</span><span class="s4">,</span>
            <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">50</span><span class="s4">,</span>
            <span class="s1">tol</span><span class="s4">=</span><span class="s6">0.0</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">150</span><span class="s4">,</span>
            <span class="s1">max_fun</span><span class="s4">=</span><span class="s1">max_fun</span><span class="s4">,</span>
            <span class="s1">shuffle</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">activation</span><span class="s4">=</span><span class="s1">activation</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">warns</span><span class="s4">(</span><span class="s1">ConvergenceWarning</span><span class="s4">):</span>
            <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
            <span class="s3">assert </span><span class="s1">max_fun </span><span class="s4">&gt;= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">n_iter_</span>


<span class="s3">def </span><span class="s1">test_learning_rate_warmstart</span><span class="s4">():</span>
    <span class="s2"># Tests that warm_start reuse past solutions.</span>
    <span class="s1">X </span><span class="s4">= [[</span><span class="s6">3</span><span class="s4">, </span><span class="s6">2</span><span class="s4">], [</span><span class="s6">1</span><span class="s4">, </span><span class="s6">6</span><span class="s4">], [</span><span class="s6">5</span><span class="s4">, </span><span class="s6">6</span><span class="s4">], [-</span><span class="s6">2</span><span class="s4">, -</span><span class="s6">4</span><span class="s4">]]</span>
    <span class="s1">y </span><span class="s4">= [</span><span class="s6">1</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s6">0</span><span class="s4">]</span>
    <span class="s3">for </span><span class="s1">learning_rate </span><span class="s3">in </span><span class="s4">[</span><span class="s5">&quot;invscaling&quot;</span><span class="s4">, </span><span class="s5">&quot;constant&quot;</span><span class="s4">]:</span>
        <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span>
            <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">,</span>
            <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">4</span><span class="s4">,</span>
            <span class="s1">learning_rate</span><span class="s4">=</span><span class="s1">learning_rate</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">power_t</span><span class="s4">=</span><span class="s6">0.25</span><span class="s4">,</span>
            <span class="s1">warm_start</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s3">with </span><span class="s1">ignore_warnings</span><span class="s4">(</span><span class="s1">category</span><span class="s4">=</span><span class="s1">ConvergenceWarning</span><span class="s4">):</span>
            <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
            <span class="s1">prev_eta </span><span class="s4">= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">_optimizer</span><span class="s4">.</span><span class="s1">learning_rate</span>
            <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
            <span class="s1">post_eta </span><span class="s4">= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">_optimizer</span><span class="s4">.</span><span class="s1">learning_rate</span>

        <span class="s3">if </span><span class="s1">learning_rate </span><span class="s4">== </span><span class="s5">&quot;constant&quot;</span><span class="s4">:</span>
            <span class="s3">assert </span><span class="s1">prev_eta </span><span class="s4">== </span><span class="s1">post_eta</span>
        <span class="s3">elif </span><span class="s1">learning_rate </span><span class="s4">== </span><span class="s5">&quot;invscaling&quot;</span><span class="s4">:</span>
            <span class="s3">assert </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">learning_rate_init </span><span class="s4">/ </span><span class="s1">pow</span><span class="s4">(</span><span class="s6">8 </span><span class="s4">+ </span><span class="s6">1</span><span class="s4">, </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">power_t</span><span class="s4">) == </span><span class="s1">post_eta</span>


<span class="s3">def </span><span class="s1">test_multilabel_classification</span><span class="s4">():</span>
    <span class="s2"># Test that multi-label classification works as expected.</span>
    <span class="s2"># test fit method</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">make_multilabel_classification</span><span class="s4">(</span>
        <span class="s1">n_samples</span><span class="s4">=</span><span class="s6">50</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">, </span><span class="s1">return_indicator</span><span class="s4">=</span><span class="s3">True</span>
    <span class="s4">)</span>
    <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span>
        <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;lbfgs&quot;</span><span class="s4">,</span>
        <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">50</span><span class="s4">,</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s6">1e-5</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">150</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
        <span class="s1">activation</span><span class="s4">=</span><span class="s5">&quot;logistic&quot;</span><span class="s4">,</span>
        <span class="s1">learning_rate_init</span><span class="s4">=</span><span class="s6">0.2</span><span class="s4">,</span>
    <span class="s4">)</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">) &gt; </span><span class="s6">0.97</span>

    <span class="s2"># test partial fit method</span>
    <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span>
        <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">,</span>
        <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">50</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">150</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
        <span class="s1">activation</span><span class="s4">=</span><span class="s5">&quot;logistic&quot;</span><span class="s4">,</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s6">1e-5</span><span class="s4">,</span>
        <span class="s1">learning_rate_init</span><span class="s4">=</span><span class="s6">0.2</span><span class="s4">,</span>
    <span class="s4">)</span>
    <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s6">100</span><span class="s4">):</span>
        <span class="s1">mlp</span><span class="s4">.</span><span class="s1">partial_fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">classes</span><span class="s4">=[</span><span class="s6">0</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s6">2</span><span class="s4">, </span><span class="s6">3</span><span class="s4">, </span><span class="s6">4</span><span class="s4">])</span>
    <span class="s3">assert </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">) &gt; </span><span class="s6">0.9</span>

    <span class="s2"># Make sure early stopping still work now that splitting is stratified by</span>
    <span class="s2"># default (it is disabled for multilabel classification)</span>
    <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">early_stopping</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">).</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_multioutput_regression</span><span class="s4">():</span>
    <span class="s2"># Test that multi-output regression works as expected</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">make_regression</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">=</span><span class="s6">200</span><span class="s4">, </span><span class="s1">n_targets</span><span class="s4">=</span><span class="s6">5</span><span class="s4">)</span>
    <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPRegressor</span><span class="s4">(</span>
        <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;lbfgs&quot;</span><span class="s4">, </span><span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">50</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">200</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span>
    <span class="s4">)</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">) &gt; </span><span class="s6">0.9</span>


<span class="s3">def </span><span class="s1">test_partial_fit_classes_error</span><span class="s4">():</span>
    <span class="s2"># Tests that passing different classes to partial_fit raises an error</span>
    <span class="s1">X </span><span class="s4">= [[</span><span class="s6">3</span><span class="s4">, </span><span class="s6">2</span><span class="s4">]]</span>
    <span class="s1">y </span><span class="s4">= [</span><span class="s6">0</span><span class="s4">]</span>
    <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">partial_fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">classes</span><span class="s4">=[</span><span class="s6">0</span><span class="s4">, </span><span class="s6">1</span><span class="s4">])</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">ValueError</span><span class="s4">):</span>
        <span class="s1">clf</span><span class="s4">.</span><span class="s1">partial_fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">classes</span><span class="s4">=[</span><span class="s6">1</span><span class="s4">, </span><span class="s6">2</span><span class="s4">])</span>


<span class="s3">def </span><span class="s1">test_partial_fit_classification</span><span class="s4">():</span>
    <span class="s2"># Test partial_fit on classification.</span>
    <span class="s2"># `partial_fit` should yield the same results as 'fit' for binary and</span>
    <span class="s2"># multi-class classification.</span>
    <span class="s3">for </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s3">in </span><span class="s1">classification_datasets</span><span class="s4">:</span>
        <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span>
            <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">100</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">tol</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
            <span class="s1">alpha</span><span class="s4">=</span><span class="s6">1e-5</span><span class="s4">,</span>
            <span class="s1">learning_rate_init</span><span class="s4">=</span><span class="s6">0.2</span><span class="s4">,</span>
        <span class="s4">)</span>

        <span class="s3">with </span><span class="s1">ignore_warnings</span><span class="s4">(</span><span class="s1">category</span><span class="s4">=</span><span class="s1">ConvergenceWarning</span><span class="s4">):</span>
            <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
        <span class="s1">pred1 </span><span class="s4">= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span>
            <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">alpha</span><span class="s4">=</span><span class="s6">1e-5</span><span class="s4">, </span><span class="s1">learning_rate_init</span><span class="s4">=</span><span class="s6">0.2</span>
        <span class="s4">)</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s6">100</span><span class="s4">):</span>
            <span class="s1">mlp</span><span class="s4">.</span><span class="s1">partial_fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">classes</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">unique</span><span class="s4">(</span><span class="s1">y</span><span class="s4">))</span>
        <span class="s1">pred2 </span><span class="s4">= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s1">assert_array_equal</span><span class="s4">(</span><span class="s1">pred1</span><span class="s4">, </span><span class="s1">pred2</span><span class="s4">)</span>
        <span class="s3">assert </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">) &gt; </span><span class="s6">0.95</span>


<span class="s3">def </span><span class="s1">test_partial_fit_unseen_classes</span><span class="s4">():</span>
    <span class="s2"># Non regression test for bug 6994</span>
    <span class="s2"># Tests for labeling errors in partial fit</span>

    <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">partial_fit</span><span class="s4">([[</span><span class="s6">1</span><span class="s4">], [</span><span class="s6">2</span><span class="s4">], [</span><span class="s6">3</span><span class="s4">]], [</span><span class="s5">&quot;a&quot;</span><span class="s4">, </span><span class="s5">&quot;b&quot;</span><span class="s4">, </span><span class="s5">&quot;c&quot;</span><span class="s4">], </span><span class="s1">classes</span><span class="s4">=[</span><span class="s5">&quot;a&quot;</span><span class="s4">, </span><span class="s5">&quot;b&quot;</span><span class="s4">, </span><span class="s5">&quot;c&quot;</span><span class="s4">, </span><span class="s5">&quot;d&quot;</span><span class="s4">])</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">partial_fit</span><span class="s4">([[</span><span class="s6">4</span><span class="s4">]], [</span><span class="s5">&quot;d&quot;</span><span class="s4">])</span>
    <span class="s3">assert </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">score</span><span class="s4">([[</span><span class="s6">1</span><span class="s4">], [</span><span class="s6">2</span><span class="s4">], [</span><span class="s6">3</span><span class="s4">], [</span><span class="s6">4</span><span class="s4">]], [</span><span class="s5">&quot;a&quot;</span><span class="s4">, </span><span class="s5">&quot;b&quot;</span><span class="s4">, </span><span class="s5">&quot;c&quot;</span><span class="s4">, </span><span class="s5">&quot;d&quot;</span><span class="s4">]) &gt; </span><span class="s6">0</span>


<span class="s3">def </span><span class="s1">test_partial_fit_regression</span><span class="s4">():</span>
    <span class="s2"># Test partial_fit on regression.</span>
    <span class="s2"># `partial_fit` should yield the same results as 'fit' for regression.</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">X_reg</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">y_reg</span>

    <span class="s3">for </span><span class="s1">momentum </span><span class="s3">in </span><span class="s4">[</span><span class="s6">0</span><span class="s4">, </span><span class="s6">0.9</span><span class="s4">]:</span>
        <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPRegressor</span><span class="s4">(</span>
            <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">100</span><span class="s4">,</span>
            <span class="s1">activation</span><span class="s4">=</span><span class="s5">&quot;relu&quot;</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">learning_rate_init</span><span class="s4">=</span><span class="s6">0.01</span><span class="s4">,</span>
            <span class="s1">batch_size</span><span class="s4">=</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">],</span>
            <span class="s1">momentum</span><span class="s4">=</span><span class="s1">momentum</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s3">with </span><span class="s1">warnings</span><span class="s4">.</span><span class="s1">catch_warnings</span><span class="s4">(</span><span class="s1">record</span><span class="s4">=</span><span class="s3">True</span><span class="s4">):</span>
            <span class="s2"># catch convergence warning</span>
            <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
        <span class="s1">pred1 </span><span class="s4">= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPRegressor</span><span class="s4">(</span>
            <span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">,</span>
            <span class="s1">activation</span><span class="s4">=</span><span class="s5">&quot;relu&quot;</span><span class="s4">,</span>
            <span class="s1">learning_rate_init</span><span class="s4">=</span><span class="s6">0.01</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">batch_size</span><span class="s4">=</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">],</span>
            <span class="s1">momentum</span><span class="s4">=</span><span class="s1">momentum</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s6">100</span><span class="s4">):</span>
            <span class="s1">mlp</span><span class="s4">.</span><span class="s1">partial_fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

        <span class="s1">pred2 </span><span class="s4">= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s1">assert_allclose</span><span class="s4">(</span><span class="s1">pred1</span><span class="s4">, </span><span class="s1">pred2</span><span class="s4">)</span>
        <span class="s1">score </span><span class="s4">= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">score</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
        <span class="s3">assert </span><span class="s1">score </span><span class="s4">&gt; </span><span class="s6">0.65</span>


<span class="s3">def </span><span class="s1">test_partial_fit_errors</span><span class="s4">():</span>
    <span class="s2"># Test partial_fit error handling.</span>
    <span class="s1">X </span><span class="s4">= [[</span><span class="s6">3</span><span class="s4">, </span><span class="s6">2</span><span class="s4">], [</span><span class="s6">1</span><span class="s4">, </span><span class="s6">6</span><span class="s4">]]</span>
    <span class="s1">y </span><span class="s4">= [</span><span class="s6">1</span><span class="s4">, </span><span class="s6">0</span><span class="s4">]</span>

    <span class="s2"># no classes passed</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">ValueError</span><span class="s4">):</span>
        <span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">).</span><span class="s1">partial_fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">classes</span><span class="s4">=[</span><span class="s6">2</span><span class="s4">])</span>

    <span class="s2"># lbfgs doesn't support partial_fit</span>
    <span class="s3">assert not </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;lbfgs&quot;</span><span class="s4">), </span><span class="s5">&quot;partial_fit&quot;</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_nonfinite_params</span><span class="s4">():</span>
    <span class="s2"># Check that MLPRegressor throws ValueError when dealing with non-finite</span>
    <span class="s2"># parameter values</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">random</span><span class="s4">.</span><span class="s1">RandomState</span><span class="s4">(</span><span class="s6">0</span><span class="s4">)</span>
    <span class="s1">n_samples </span><span class="s4">= </span><span class="s6">10</span>
    <span class="s1">fmax </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">finfo</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">).</span><span class="s1">max</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">fmax </span><span class="s4">* </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">uniform</span><span class="s4">(</span><span class="s1">size</span><span class="s4">=(</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s6">2</span><span class="s4">))</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">rng</span><span class="s4">.</span><span class="s1">standard_normal</span><span class="s4">(</span><span class="s1">size</span><span class="s4">=</span><span class="s1">n_samples</span><span class="s4">)</span>

    <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPRegressor</span><span class="s4">()</span>
    <span class="s1">msg </span><span class="s4">= (</span>
        <span class="s5">&quot;Solver produced non-finite parameter weights. The input data may contain large&quot;</span>
        <span class="s5">&quot; values and need to be preprocessed.&quot;</span>
    <span class="s4">)</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">ValueError</span><span class="s4">, </span><span class="s1">match</span><span class="s4">=</span><span class="s1">msg</span><span class="s4">):</span>
        <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_predict_proba_binary</span><span class="s4">():</span>
    <span class="s2"># Test that predict_proba works as expected for binary class.</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">X_digits_binary</span><span class="s4">[:</span><span class="s6">50</span><span class="s4">]</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">y_digits_binary</span><span class="s4">[:</span><span class="s6">50</span><span class="s4">]</span>

    <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">5</span><span class="s4">, </span><span class="s1">activation</span><span class="s4">=</span><span class="s5">&quot;logistic&quot;</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">)</span>
    <span class="s3">with </span><span class="s1">ignore_warnings</span><span class="s4">(</span><span class="s1">category</span><span class="s4">=</span><span class="s1">ConvergenceWarning</span><span class="s4">):</span>
        <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">y_proba </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
    <span class="s1">y_log_proba </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">predict_log_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s4">(</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_classes</span><span class="s4">) = </span><span class="s1">y</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">], </span><span class="s6">2</span>

    <span class="s1">proba_max </span><span class="s4">= </span><span class="s1">y_proba</span><span class="s4">.</span><span class="s1">argmax</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">1</span><span class="s4">)</span>
    <span class="s1">proba_log_max </span><span class="s4">= </span><span class="s1">y_log_proba</span><span class="s4">.</span><span class="s1">argmax</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">1</span><span class="s4">)</span>

    <span class="s3">assert </span><span class="s1">y_proba</span><span class="s4">.</span><span class="s1">shape </span><span class="s4">== (</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_classes</span><span class="s4">)</span>
    <span class="s1">assert_array_equal</span><span class="s4">(</span><span class="s1">proba_max</span><span class="s4">, </span><span class="s1">proba_log_max</span><span class="s4">)</span>
    <span class="s1">assert_allclose</span><span class="s4">(</span><span class="s1">y_log_proba</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">log</span><span class="s4">(</span><span class="s1">y_proba</span><span class="s4">))</span>

    <span class="s3">assert </span><span class="s1">roc_auc_score</span><span class="s4">(</span><span class="s1">y</span><span class="s4">, </span><span class="s1">y_proba</span><span class="s4">[:, </span><span class="s6">1</span><span class="s4">]) == </span><span class="s6">1.0</span>


<span class="s3">def </span><span class="s1">test_predict_proba_multiclass</span><span class="s4">():</span>
    <span class="s2"># Test that predict_proba works as expected for multi class.</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">X_digits_multi</span><span class="s4">[:</span><span class="s6">10</span><span class="s4">]</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">y_digits_multi</span><span class="s4">[:</span><span class="s6">10</span><span class="s4">]</span>

    <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">5</span><span class="s4">)</span>
    <span class="s3">with </span><span class="s1">ignore_warnings</span><span class="s4">(</span><span class="s1">category</span><span class="s4">=</span><span class="s1">ConvergenceWarning</span><span class="s4">):</span>
        <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">y_proba </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
    <span class="s1">y_log_proba </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">predict_log_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s4">(</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_classes</span><span class="s4">) = </span><span class="s1">y</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">], </span><span class="s1">np</span><span class="s4">.</span><span class="s1">unique</span><span class="s4">(</span><span class="s1">y</span><span class="s4">).</span><span class="s1">size</span>

    <span class="s1">proba_max </span><span class="s4">= </span><span class="s1">y_proba</span><span class="s4">.</span><span class="s1">argmax</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">1</span><span class="s4">)</span>
    <span class="s1">proba_log_max </span><span class="s4">= </span><span class="s1">y_log_proba</span><span class="s4">.</span><span class="s1">argmax</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">1</span><span class="s4">)</span>

    <span class="s3">assert </span><span class="s1">y_proba</span><span class="s4">.</span><span class="s1">shape </span><span class="s4">== (</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_classes</span><span class="s4">)</span>
    <span class="s1">assert_array_equal</span><span class="s4">(</span><span class="s1">proba_max</span><span class="s4">, </span><span class="s1">proba_log_max</span><span class="s4">)</span>
    <span class="s1">assert_allclose</span><span class="s4">(</span><span class="s1">y_log_proba</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">log</span><span class="s4">(</span><span class="s1">y_proba</span><span class="s4">))</span>


<span class="s3">def </span><span class="s1">test_predict_proba_multilabel</span><span class="s4">():</span>
    <span class="s2"># Test that predict_proba works as expected for multilabel.</span>
    <span class="s2"># Multilabel should not use softmax which makes probabilities sum to 1</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">Y </span><span class="s4">= </span><span class="s1">make_multilabel_classification</span><span class="s4">(</span>
        <span class="s1">n_samples</span><span class="s4">=</span><span class="s6">50</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">, </span><span class="s1">return_indicator</span><span class="s4">=</span><span class="s3">True</span>
    <span class="s4">)</span>
    <span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_classes </span><span class="s4">= </span><span class="s1">Y</span><span class="s4">.</span><span class="s1">shape</span>

    <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;lbfgs&quot;</span><span class="s4">, </span><span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">30</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">Y</span><span class="s4">)</span>
    <span class="s1">y_proba </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s3">assert </span><span class="s1">y_proba</span><span class="s4">.</span><span class="s1">shape </span><span class="s4">== (</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_classes</span><span class="s4">)</span>
    <span class="s1">assert_array_equal</span><span class="s4">(</span><span class="s1">y_proba </span><span class="s4">&gt; </span><span class="s6">0.5</span><span class="s4">, </span><span class="s1">Y</span><span class="s4">)</span>

    <span class="s1">y_log_proba </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">predict_log_proba</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
    <span class="s1">proba_max </span><span class="s4">= </span><span class="s1">y_proba</span><span class="s4">.</span><span class="s1">argmax</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">1</span><span class="s4">)</span>
    <span class="s1">proba_log_max </span><span class="s4">= </span><span class="s1">y_log_proba</span><span class="s4">.</span><span class="s1">argmax</span><span class="s4">(</span><span class="s1">axis</span><span class="s4">=</span><span class="s6">1</span><span class="s4">)</span>

    <span class="s3">assert </span><span class="s4">(</span><span class="s1">y_proba</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s6">1</span><span class="s4">) - </span><span class="s6">1</span><span class="s4">).</span><span class="s1">dot</span><span class="s4">(</span><span class="s1">y_proba</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s6">1</span><span class="s4">) - </span><span class="s6">1</span><span class="s4">) &gt; </span><span class="s6">1e-10</span>
    <span class="s1">assert_array_equal</span><span class="s4">(</span><span class="s1">proba_max</span><span class="s4">, </span><span class="s1">proba_log_max</span><span class="s4">)</span>
    <span class="s1">assert_allclose</span><span class="s4">(</span><span class="s1">y_log_proba</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">log</span><span class="s4">(</span><span class="s1">y_proba</span><span class="s4">))</span>


<span class="s3">def </span><span class="s1">test_shuffle</span><span class="s4">():</span>
    <span class="s2"># Test that the shuffle parameter affects the training process (it should)</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">make_regression</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">=</span><span class="s6">50</span><span class="s4">, </span><span class="s1">n_features</span><span class="s4">=</span><span class="s6">5</span><span class="s4">, </span><span class="s1">n_targets</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">)</span>

    <span class="s2"># The coefficients will be identical if both do or do not shuffle</span>
    <span class="s3">for </span><span class="s1">shuffle </span><span class="s3">in </span><span class="s4">[</span><span class="s3">True</span><span class="s4">, </span><span class="s3">False</span><span class="s4">]:</span>
        <span class="s1">mlp1 </span><span class="s4">= </span><span class="s1">MLPRegressor</span><span class="s4">(</span>
            <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">batch_size</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
            <span class="s1">shuffle</span><span class="s4">=</span><span class="s1">shuffle</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">mlp2 </span><span class="s4">= </span><span class="s1">MLPRegressor</span><span class="s4">(</span>
            <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">batch_size</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
            <span class="s1">shuffle</span><span class="s4">=</span><span class="s1">shuffle</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">mlp1</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
        <span class="s1">mlp2</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

        <span class="s3">assert </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array_equal</span><span class="s4">(</span><span class="s1">mlp1</span><span class="s4">.</span><span class="s1">coefs_</span><span class="s4">[</span><span class="s6">0</span><span class="s4">], </span><span class="s1">mlp2</span><span class="s4">.</span><span class="s1">coefs_</span><span class="s4">[</span><span class="s6">0</span><span class="s4">])</span>

    <span class="s2"># The coefficients will be slightly different if shuffle=True</span>
    <span class="s1">mlp1 </span><span class="s4">= </span><span class="s1">MLPRegressor</span><span class="s4">(</span>
        <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">batch_size</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">, </span><span class="s1">shuffle</span><span class="s4">=</span><span class="s3">True</span>
    <span class="s4">)</span>
    <span class="s1">mlp2 </span><span class="s4">= </span><span class="s1">MLPRegressor</span><span class="s4">(</span>
        <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">batch_size</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">, </span><span class="s1">shuffle</span><span class="s4">=</span><span class="s3">False</span>
    <span class="s4">)</span>
    <span class="s1">mlp1</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">mlp2</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

    <span class="s3">assert not </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array_equal</span><span class="s4">(</span><span class="s1">mlp1</span><span class="s4">.</span><span class="s1">coefs_</span><span class="s4">[</span><span class="s6">0</span><span class="s4">], </span><span class="s1">mlp2</span><span class="s4">.</span><span class="s1">coefs_</span><span class="s4">[</span><span class="s6">0</span><span class="s4">])</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;csr_container&quot;</span><span class="s4">, </span><span class="s1">CSR_CONTAINERS</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_sparse_matrices</span><span class="s4">(</span><span class="s1">csr_container</span><span class="s4">):</span>
    <span class="s2"># Test that sparse and dense input matrices output the same results.</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">X_digits_binary</span><span class="s4">[:</span><span class="s6">50</span><span class="s4">]</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">y_digits_binary</span><span class="s4">[:</span><span class="s6">50</span><span class="s4">]</span>
    <span class="s1">X_sparse </span><span class="s4">= </span><span class="s1">csr_container</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
    <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;lbfgs&quot;</span><span class="s4">, </span><span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">15</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">)</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">pred1 </span><span class="s4">= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_sparse</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">pred2 </span><span class="s4">= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_sparse</span><span class="s4">)</span>
    <span class="s1">assert_almost_equal</span><span class="s4">(</span><span class="s1">pred1</span><span class="s4">, </span><span class="s1">pred2</span><span class="s4">)</span>
    <span class="s1">pred1 </span><span class="s4">= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
    <span class="s1">pred2 </span><span class="s4">= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_sparse</span><span class="s4">)</span>
    <span class="s1">assert_array_equal</span><span class="s4">(</span><span class="s1">pred1</span><span class="s4">, </span><span class="s1">pred2</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_tolerance</span><span class="s4">():</span>
    <span class="s2"># Test tolerance.</span>
    <span class="s2"># It should force the solver to exit the loop when it converges.</span>
    <span class="s1">X </span><span class="s4">= [[</span><span class="s6">3</span><span class="s4">, </span><span class="s6">2</span><span class="s4">], [</span><span class="s6">1</span><span class="s4">, </span><span class="s6">6</span><span class="s4">]]</span>
    <span class="s1">y </span><span class="s4">= [</span><span class="s6">1</span><span class="s4">, </span><span class="s6">0</span><span class="s4">]</span>
    <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">tol</span><span class="s4">=</span><span class="s6">0.5</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">3000</span><span class="s4">, </span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">max_iter </span><span class="s4">&gt; </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">n_iter_</span>


<span class="s3">def </span><span class="s1">test_verbose_sgd</span><span class="s4">():</span>
    <span class="s2"># Test verbose.</span>
    <span class="s1">X </span><span class="s4">= [[</span><span class="s6">3</span><span class="s4">, </span><span class="s6">2</span><span class="s4">], [</span><span class="s6">1</span><span class="s4">, </span><span class="s6">6</span><span class="s4">]]</span>
    <span class="s1">y </span><span class="s4">= [</span><span class="s6">1</span><span class="s4">, </span><span class="s6">0</span><span class="s4">]</span>
    <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">2</span><span class="s4">, </span><span class="s1">verbose</span><span class="s4">=</span><span class="s6">10</span><span class="s4">, </span><span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">2</span><span class="s4">)</span>
    <span class="s1">old_stdout </span><span class="s4">= </span><span class="s1">sys</span><span class="s4">.</span><span class="s1">stdout</span>
    <span class="s1">sys</span><span class="s4">.</span><span class="s1">stdout </span><span class="s4">= </span><span class="s1">output </span><span class="s4">= </span><span class="s1">StringIO</span><span class="s4">()</span>

    <span class="s3">with </span><span class="s1">ignore_warnings</span><span class="s4">(</span><span class="s1">category</span><span class="s4">=</span><span class="s1">ConvergenceWarning</span><span class="s4">):</span>
        <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">partial_fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

    <span class="s1">sys</span><span class="s4">.</span><span class="s1">stdout </span><span class="s4">= </span><span class="s1">old_stdout</span>
    <span class="s3">assert </span><span class="s5">&quot;Iteration&quot; </span><span class="s3">in </span><span class="s1">output</span><span class="s4">.</span><span class="s1">getvalue</span><span class="s4">()</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;MLPEstimator&quot;</span><span class="s4">, [</span><span class="s1">MLPClassifier</span><span class="s4">, </span><span class="s1">MLPRegressor</span><span class="s4">])</span>
<span class="s3">def </span><span class="s1">test_early_stopping</span><span class="s4">(</span><span class="s1">MLPEstimator</span><span class="s4">):</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">X_digits_binary</span><span class="s4">[:</span><span class="s6">100</span><span class="s4">]</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">y_digits_binary</span><span class="s4">[:</span><span class="s6">100</span><span class="s4">]</span>
    <span class="s1">tol </span><span class="s4">= </span><span class="s6">0.2</span>
    <span class="s1">mlp_estimator </span><span class="s4">= </span><span class="s1">MLPEstimator</span><span class="s4">(</span>
        <span class="s1">tol</span><span class="s4">=</span><span class="s1">tol</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">3000</span><span class="s4">, </span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">, </span><span class="s1">early_stopping</span><span class="s4">=</span><span class="s3">True</span>
    <span class="s4">)</span>
    <span class="s1">mlp_estimator</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">mlp_estimator</span><span class="s4">.</span><span class="s1">max_iter </span><span class="s4">&gt; </span><span class="s1">mlp_estimator</span><span class="s4">.</span><span class="s1">n_iter_</span>

    <span class="s3">assert </span><span class="s1">mlp_estimator</span><span class="s4">.</span><span class="s1">best_loss_ </span><span class="s3">is None</span>
    <span class="s3">assert </span><span class="s1">isinstance</span><span class="s4">(</span><span class="s1">mlp_estimator</span><span class="s4">.</span><span class="s1">validation_scores_</span><span class="s4">, </span><span class="s1">list</span><span class="s4">)</span>

    <span class="s1">valid_scores </span><span class="s4">= </span><span class="s1">mlp_estimator</span><span class="s4">.</span><span class="s1">validation_scores_</span>
    <span class="s1">best_valid_score </span><span class="s4">= </span><span class="s1">mlp_estimator</span><span class="s4">.</span><span class="s1">best_validation_score_</span>
    <span class="s3">assert </span><span class="s1">max</span><span class="s4">(</span><span class="s1">valid_scores</span><span class="s4">) == </span><span class="s1">best_valid_score</span>
    <span class="s3">assert </span><span class="s1">best_valid_score </span><span class="s4">+ </span><span class="s1">tol </span><span class="s4">&gt; </span><span class="s1">valid_scores</span><span class="s4">[-</span><span class="s6">2</span><span class="s4">]</span>
    <span class="s3">assert </span><span class="s1">best_valid_score </span><span class="s4">+ </span><span class="s1">tol </span><span class="s4">&gt; </span><span class="s1">valid_scores</span><span class="s4">[-</span><span class="s6">1</span><span class="s4">]</span>

    <span class="s2"># check that the attributes `validation_scores_` and `best_validation_score_`</span>
    <span class="s2"># are set to None when `early_stopping=False`</span>
    <span class="s1">mlp_estimator </span><span class="s4">= </span><span class="s1">MLPEstimator</span><span class="s4">(</span>
        <span class="s1">tol</span><span class="s4">=</span><span class="s1">tol</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">3000</span><span class="s4">, </span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">, </span><span class="s1">early_stopping</span><span class="s4">=</span><span class="s3">False</span>
    <span class="s4">)</span>
    <span class="s1">mlp_estimator</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">mlp_estimator</span><span class="s4">.</span><span class="s1">validation_scores_ </span><span class="s3">is None</span>
    <span class="s3">assert </span><span class="s1">mlp_estimator</span><span class="s4">.</span><span class="s1">best_validation_score_ </span><span class="s3">is None</span>
    <span class="s3">assert </span><span class="s1">mlp_estimator</span><span class="s4">.</span><span class="s1">best_loss_ </span><span class="s3">is not None</span>


<span class="s3">def </span><span class="s1">test_adaptive_learning_rate</span><span class="s4">():</span>
    <span class="s1">X </span><span class="s4">= [[</span><span class="s6">3</span><span class="s4">, </span><span class="s6">2</span><span class="s4">], [</span><span class="s6">1</span><span class="s4">, </span><span class="s6">6</span><span class="s4">]]</span>
    <span class="s1">y </span><span class="s4">= [</span><span class="s6">1</span><span class="s4">, </span><span class="s6">0</span><span class="s4">]</span>
    <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">tol</span><span class="s4">=</span><span class="s6">0.5</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">3000</span><span class="s4">, </span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">, </span><span class="s1">learning_rate</span><span class="s4">=</span><span class="s5">&quot;adaptive&quot;</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">max_iter </span><span class="s4">&gt; </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">n_iter_</span>
    <span class="s3">assert </span><span class="s6">1e-6 </span><span class="s4">&gt; </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">_optimizer</span><span class="s4">.</span><span class="s1">learning_rate</span>


<span class="s4">@</span><span class="s1">ignore_warnings</span><span class="s4">(</span><span class="s1">category</span><span class="s4">=</span><span class="s1">RuntimeWarning</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_warm_start</span><span class="s4">():</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">X_iris</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">y_iris</span>

    <span class="s1">y_2classes </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s6">0</span><span class="s4">] * </span><span class="s6">75 </span><span class="s4">+ [</span><span class="s6">1</span><span class="s4">] * </span><span class="s6">75</span><span class="s4">)</span>
    <span class="s1">y_3classes </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s6">0</span><span class="s4">] * </span><span class="s6">40 </span><span class="s4">+ [</span><span class="s6">1</span><span class="s4">] * </span><span class="s6">40 </span><span class="s4">+ [</span><span class="s6">2</span><span class="s4">] * </span><span class="s6">70</span><span class="s4">)</span>
    <span class="s1">y_3classes_alt </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s6">0</span><span class="s4">] * </span><span class="s6">50 </span><span class="s4">+ [</span><span class="s6">1</span><span class="s4">] * </span><span class="s6">50 </span><span class="s4">+ [</span><span class="s6">3</span><span class="s4">] * </span><span class="s6">50</span><span class="s4">)</span>
    <span class="s1">y_4classes </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s6">0</span><span class="s4">] * </span><span class="s6">37 </span><span class="s4">+ [</span><span class="s6">1</span><span class="s4">] * </span><span class="s6">37 </span><span class="s4">+ [</span><span class="s6">2</span><span class="s4">] * </span><span class="s6">38 </span><span class="s4">+ [</span><span class="s6">3</span><span class="s4">] * </span><span class="s6">38</span><span class="s4">)</span>
    <span class="s1">y_5classes </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">([</span><span class="s6">0</span><span class="s4">] * </span><span class="s6">30 </span><span class="s4">+ [</span><span class="s6">1</span><span class="s4">] * </span><span class="s6">30 </span><span class="s4">+ [</span><span class="s6">2</span><span class="s4">] * </span><span class="s6">30 </span><span class="s4">+ [</span><span class="s6">3</span><span class="s4">] * </span><span class="s6">30 </span><span class="s4">+ [</span><span class="s6">4</span><span class="s4">] * </span><span class="s6">30</span><span class="s4">)</span>

    <span class="s2"># No error raised</span>
    <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">2</span><span class="s4">, </span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;lbfgs&quot;</span><span class="s4">, </span><span class="s1">warm_start</span><span class="s4">=</span><span class="s3">True</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y_3classes</span><span class="s4">)</span>

    <span class="s3">for </span><span class="s1">y_i </span><span class="s3">in </span><span class="s4">(</span><span class="s1">y_2classes</span><span class="s4">, </span><span class="s1">y_3classes_alt</span><span class="s4">, </span><span class="s1">y_4classes</span><span class="s4">, </span><span class="s1">y_5classes</span><span class="s4">):</span>
        <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">2</span><span class="s4">, </span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;lbfgs&quot;</span><span class="s4">, </span><span class="s1">warm_start</span><span class="s4">=</span><span class="s3">True</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">, </span><span class="s1">y</span>
        <span class="s4">)</span>
        <span class="s1">message </span><span class="s4">= (</span>
            <span class="s5">&quot;warm_start can only be used where `y` has the same &quot;</span>
            <span class="s5">&quot;classes as in the previous call to fit.&quot;</span>
            <span class="s5">&quot; Previously got [0 1 2], `y` has %s&quot; </span><span class="s4">% </span><span class="s1">np</span><span class="s4">.</span><span class="s1">unique</span><span class="s4">(</span><span class="s1">y_i</span><span class="s4">)</span>
        <span class="s4">)</span>
        <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">ValueError</span><span class="s4">, </span><span class="s1">match</span><span class="s4">=</span><span class="s1">re</span><span class="s4">.</span><span class="s1">escape</span><span class="s4">(</span><span class="s1">message</span><span class="s4">)):</span>
            <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y_i</span><span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;MLPEstimator&quot;</span><span class="s4">, [</span><span class="s1">MLPClassifier</span><span class="s4">, </span><span class="s1">MLPRegressor</span><span class="s4">])</span>
<span class="s3">def </span><span class="s1">test_warm_start_full_iteration</span><span class="s4">(</span><span class="s1">MLPEstimator</span><span class="s4">):</span>
    <span class="s2"># Non-regression test for:</span>
    <span class="s2"># https://github.com/scikit-learn/scikit-learn/issues/16812</span>
    <span class="s2"># Check that the MLP estimator accomplish `max_iter` with a</span>
    <span class="s2"># warm started estimator.</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">X_iris</span><span class="s4">, </span><span class="s1">y_iris</span>
    <span class="s1">max_iter </span><span class="s4">= </span><span class="s6">3</span>
    <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPEstimator</span><span class="s4">(</span>
        <span class="s1">hidden_layer_sizes</span><span class="s4">=</span><span class="s6">2</span><span class="s4">, </span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">, </span><span class="s1">warm_start</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span>
    <span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">max_iter </span><span class="s4">== </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">n_iter_</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">max_iter </span><span class="s4">== </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">n_iter_</span>


<span class="s3">def </span><span class="s1">test_n_iter_no_change</span><span class="s4">():</span>
    <span class="s2"># test n_iter_no_change using binary data set</span>
    <span class="s2"># the classifying fitting process is not prone to loss curve fluctuations</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">X_digits_binary</span><span class="s4">[:</span><span class="s6">100</span><span class="s4">]</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">y_digits_binary</span><span class="s4">[:</span><span class="s6">100</span><span class="s4">]</span>
    <span class="s1">tol </span><span class="s4">= </span><span class="s6">0.01</span>
    <span class="s1">max_iter </span><span class="s4">= </span><span class="s6">3000</span>

    <span class="s2"># test multiple n_iter_no_change</span>
    <span class="s3">for </span><span class="s1">n_iter_no_change </span><span class="s3">in </span><span class="s4">[</span><span class="s6">2</span><span class="s4">, </span><span class="s6">5</span><span class="s4">, </span><span class="s6">10</span><span class="s4">, </span><span class="s6">50</span><span class="s4">, </span><span class="s6">100</span><span class="s4">]:</span>
        <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span>
            <span class="s1">tol</span><span class="s4">=</span><span class="s1">tol</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span><span class="s4">, </span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">, </span><span class="s1">n_iter_no_change</span><span class="s4">=</span><span class="s1">n_iter_no_change</span>
        <span class="s4">)</span>
        <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

        <span class="s2"># validate n_iter_no_change</span>
        <span class="s3">assert </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">_no_improvement_count </span><span class="s4">== </span><span class="s1">n_iter_no_change </span><span class="s4">+ </span><span class="s6">1</span>
        <span class="s3">assert </span><span class="s1">max_iter </span><span class="s4">&gt; </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">n_iter_</span>


<span class="s4">@</span><span class="s1">ignore_warnings</span><span class="s4">(</span><span class="s1">category</span><span class="s4">=</span><span class="s1">ConvergenceWarning</span><span class="s4">)</span>
<span class="s3">def </span><span class="s1">test_n_iter_no_change_inf</span><span class="s4">():</span>
    <span class="s2"># test n_iter_no_change using binary data set</span>
    <span class="s2"># the fitting process should go to max_iter iterations</span>
    <span class="s1">X </span><span class="s4">= </span><span class="s1">X_digits_binary</span><span class="s4">[:</span><span class="s6">100</span><span class="s4">]</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">y_digits_binary</span><span class="s4">[:</span><span class="s6">100</span><span class="s4">]</span>

    <span class="s2"># set a ridiculous tolerance</span>
    <span class="s2"># this should always trigger _update_no_improvement_count()</span>
    <span class="s1">tol </span><span class="s4">= </span><span class="s6">1e9</span>

    <span class="s2"># fit</span>
    <span class="s1">n_iter_no_change </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span>
    <span class="s1">max_iter </span><span class="s4">= </span><span class="s6">3000</span>
    <span class="s1">clf </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span>
        <span class="s1">tol</span><span class="s4">=</span><span class="s1">tol</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span><span class="s4">, </span><span class="s1">solver</span><span class="s4">=</span><span class="s5">&quot;sgd&quot;</span><span class="s4">, </span><span class="s1">n_iter_no_change</span><span class="s4">=</span><span class="s1">n_iter_no_change</span>
    <span class="s4">)</span>
    <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>

    <span class="s2"># validate n_iter_no_change doesn't cause early stopping</span>
    <span class="s3">assert </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">n_iter_ </span><span class="s4">== </span><span class="s1">max_iter</span>

    <span class="s2"># validate _update_no_improvement_count() was always triggered</span>
    <span class="s3">assert </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">_no_improvement_count </span><span class="s4">== </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">n_iter_ </span><span class="s4">- </span><span class="s6">1</span>


<span class="s3">def </span><span class="s1">test_early_stopping_stratified</span><span class="s4">():</span>
    <span class="s2"># Make sure data splitting for early stopping is stratified</span>
    <span class="s1">X </span><span class="s4">= [[</span><span class="s6">1</span><span class="s4">, </span><span class="s6">2</span><span class="s4">], [</span><span class="s6">2</span><span class="s4">, </span><span class="s6">3</span><span class="s4">], [</span><span class="s6">3</span><span class="s4">, </span><span class="s6">4</span><span class="s4">], [</span><span class="s6">4</span><span class="s4">, </span><span class="s6">5</span><span class="s4">]]</span>
    <span class="s1">y </span><span class="s4">= [</span><span class="s6">0</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s6">1</span><span class="s4">]</span>

    <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span><span class="s1">early_stopping</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span>
        <span class="s1">ValueError</span><span class="s4">, </span><span class="s1">match</span><span class="s4">=</span><span class="s5">&quot;The least populated class in y has only 1 member&quot;</span>
    <span class="s4">):</span>
        <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_mlp_classifier_dtypes_casting</span><span class="s4">():</span>
    <span class="s2"># Compare predictions for different dtypes</span>
    <span class="s1">mlp_64 </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s6">1e-5</span><span class="s4">, </span><span class="s1">hidden_layer_sizes</span><span class="s4">=(</span><span class="s6">5</span><span class="s4">, </span><span class="s6">3</span><span class="s4">), </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">50</span>
    <span class="s4">)</span>
    <span class="s1">mlp_64</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_digits</span><span class="s4">[:</span><span class="s6">300</span><span class="s4">], </span><span class="s1">y_digits</span><span class="s4">[:</span><span class="s6">300</span><span class="s4">])</span>
    <span class="s1">pred_64 </span><span class="s4">= </span><span class="s1">mlp_64</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_digits</span><span class="s4">[</span><span class="s6">300</span><span class="s4">:])</span>
    <span class="s1">proba_64 </span><span class="s4">= </span><span class="s1">mlp_64</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X_digits</span><span class="s4">[</span><span class="s6">300</span><span class="s4">:])</span>

    <span class="s1">mlp_32 </span><span class="s4">= </span><span class="s1">MLPClassifier</span><span class="s4">(</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s6">1e-5</span><span class="s4">, </span><span class="s1">hidden_layer_sizes</span><span class="s4">=(</span><span class="s6">5</span><span class="s4">, </span><span class="s6">3</span><span class="s4">), </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">50</span>
    <span class="s4">)</span>
    <span class="s1">mlp_32</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_digits</span><span class="s4">[:</span><span class="s6">300</span><span class="s4">].</span><span class="s1">astype</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">), </span><span class="s1">y_digits</span><span class="s4">[:</span><span class="s6">300</span><span class="s4">])</span>
    <span class="s1">pred_32 </span><span class="s4">= </span><span class="s1">mlp_32</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_digits</span><span class="s4">[</span><span class="s6">300</span><span class="s4">:].</span><span class="s1">astype</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">))</span>
    <span class="s1">proba_32 </span><span class="s4">= </span><span class="s1">mlp_32</span><span class="s4">.</span><span class="s1">predict_proba</span><span class="s4">(</span><span class="s1">X_digits</span><span class="s4">[</span><span class="s6">300</span><span class="s4">:].</span><span class="s1">astype</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">))</span>

    <span class="s1">assert_array_equal</span><span class="s4">(</span><span class="s1">pred_64</span><span class="s4">, </span><span class="s1">pred_32</span><span class="s4">)</span>
    <span class="s1">assert_allclose</span><span class="s4">(</span><span class="s1">proba_64</span><span class="s4">, </span><span class="s1">proba_32</span><span class="s4">, </span><span class="s1">rtol</span><span class="s4">=</span><span class="s6">1e-02</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">test_mlp_regressor_dtypes_casting</span><span class="s4">():</span>
    <span class="s1">mlp_64 </span><span class="s4">= </span><span class="s1">MLPRegressor</span><span class="s4">(</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s6">1e-5</span><span class="s4">, </span><span class="s1">hidden_layer_sizes</span><span class="s4">=(</span><span class="s6">5</span><span class="s4">, </span><span class="s6">3</span><span class="s4">), </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">50</span>
    <span class="s4">)</span>
    <span class="s1">mlp_64</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_digits</span><span class="s4">[:</span><span class="s6">300</span><span class="s4">], </span><span class="s1">y_digits</span><span class="s4">[:</span><span class="s6">300</span><span class="s4">])</span>
    <span class="s1">pred_64 </span><span class="s4">= </span><span class="s1">mlp_64</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_digits</span><span class="s4">[</span><span class="s6">300</span><span class="s4">:])</span>

    <span class="s1">mlp_32 </span><span class="s4">= </span><span class="s1">MLPRegressor</span><span class="s4">(</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s6">1e-5</span><span class="s4">, </span><span class="s1">hidden_layer_sizes</span><span class="s4">=(</span><span class="s6">5</span><span class="s4">, </span><span class="s6">3</span><span class="s4">), </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">50</span>
    <span class="s4">)</span>
    <span class="s1">mlp_32</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_digits</span><span class="s4">[:</span><span class="s6">300</span><span class="s4">].</span><span class="s1">astype</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">), </span><span class="s1">y_digits</span><span class="s4">[:</span><span class="s6">300</span><span class="s4">])</span>
    <span class="s1">pred_32 </span><span class="s4">= </span><span class="s1">mlp_32</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X_digits</span><span class="s4">[</span><span class="s6">300</span><span class="s4">:].</span><span class="s1">astype</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">))</span>

    <span class="s1">assert_allclose</span><span class="s4">(</span><span class="s1">pred_64</span><span class="s4">, </span><span class="s1">pred_32</span><span class="s4">, </span><span class="s1">rtol</span><span class="s4">=</span><span class="s6">1e-04</span><span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;dtype&quot;</span><span class="s4">, [</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">])</span>
<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;Estimator&quot;</span><span class="s4">, [</span><span class="s1">MLPClassifier</span><span class="s4">, </span><span class="s1">MLPRegressor</span><span class="s4">])</span>
<span class="s3">def </span><span class="s1">test_mlp_param_dtypes</span><span class="s4">(</span><span class="s1">dtype</span><span class="s4">, </span><span class="s1">Estimator</span><span class="s4">):</span>
    <span class="s2"># Checks if input dtype is used for network parameters</span>
    <span class="s2"># and predictions</span>
    <span class="s1">X</span><span class="s4">, </span><span class="s1">y </span><span class="s4">= </span><span class="s1">X_digits</span><span class="s4">.</span><span class="s1">astype</span><span class="s4">(</span><span class="s1">dtype</span><span class="s4">), </span><span class="s1">y_digits</span>
    <span class="s1">mlp </span><span class="s4">= </span><span class="s1">Estimator</span><span class="s4">(</span><span class="s1">alpha</span><span class="s4">=</span><span class="s6">1e-5</span><span class="s4">, </span><span class="s1">hidden_layer_sizes</span><span class="s4">=(</span><span class="s6">5</span><span class="s4">, </span><span class="s6">3</span><span class="s4">), </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">1</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">50</span><span class="s4">)</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">[:</span><span class="s6">300</span><span class="s4">], </span><span class="s1">y</span><span class="s4">[:</span><span class="s6">300</span><span class="s4">])</span>
    <span class="s1">pred </span><span class="s4">= </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">[</span><span class="s6">300</span><span class="s4">:])</span>

    <span class="s3">assert </span><span class="s1">all</span><span class="s4">([</span><span class="s1">intercept</span><span class="s4">.</span><span class="s1">dtype </span><span class="s4">== </span><span class="s1">dtype </span><span class="s3">for </span><span class="s1">intercept </span><span class="s3">in </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">intercepts_</span><span class="s4">])</span>

    <span class="s3">assert </span><span class="s1">all</span><span class="s4">([</span><span class="s1">coef</span><span class="s4">.</span><span class="s1">dtype </span><span class="s4">== </span><span class="s1">dtype </span><span class="s3">for </span><span class="s1">coef </span><span class="s3">in </span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">coefs_</span><span class="s4">])</span>

    <span class="s3">if </span><span class="s1">Estimator </span><span class="s4">== </span><span class="s1">MLPRegressor</span><span class="s4">:</span>
        <span class="s3">assert </span><span class="s1">pred</span><span class="s4">.</span><span class="s1">dtype </span><span class="s4">== </span><span class="s1">dtype</span>


<span class="s3">def </span><span class="s1">test_mlp_loading_from_joblib_partial_fit</span><span class="s4">(</span><span class="s1">tmp_path</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Loading from MLP and partial fitting updates weights. Non-regression 
    test for #19626.&quot;&quot;&quot;</span>
    <span class="s1">pre_trained_estimator </span><span class="s4">= </span><span class="s1">MLPRegressor</span><span class="s4">(</span>
        <span class="s1">hidden_layer_sizes</span><span class="s4">=(</span><span class="s6">42</span><span class="s4">,), </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">42</span><span class="s4">, </span><span class="s1">learning_rate_init</span><span class="s4">=</span><span class="s6">0.01</span><span class="s4">, </span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">200</span>
    <span class="s4">)</span>
    <span class="s1">features</span><span class="s4">, </span><span class="s1">target </span><span class="s4">= [[</span><span class="s6">2</span><span class="s4">]], [</span><span class="s6">4</span><span class="s4">]</span>

    <span class="s2"># Fit on x=2, y=4</span>
    <span class="s1">pre_trained_estimator</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">features</span><span class="s4">, </span><span class="s1">target</span><span class="s4">)</span>

    <span class="s2"># dump and load model</span>
    <span class="s1">pickled_file </span><span class="s4">= </span><span class="s1">tmp_path </span><span class="s4">/ </span><span class="s5">&quot;mlp.pkl&quot;</span>
    <span class="s1">joblib</span><span class="s4">.</span><span class="s1">dump</span><span class="s4">(</span><span class="s1">pre_trained_estimator</span><span class="s4">, </span><span class="s1">pickled_file</span><span class="s4">)</span>
    <span class="s1">load_estimator </span><span class="s4">= </span><span class="s1">joblib</span><span class="s4">.</span><span class="s1">load</span><span class="s4">(</span><span class="s1">pickled_file</span><span class="s4">)</span>

    <span class="s2"># Train for a more epochs on point x=2, y=1</span>
    <span class="s1">fine_tune_features</span><span class="s4">, </span><span class="s1">fine_tune_target </span><span class="s4">= [[</span><span class="s6">2</span><span class="s4">]], [</span><span class="s6">1</span><span class="s4">]</span>

    <span class="s3">for </span><span class="s1">_ </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s6">200</span><span class="s4">):</span>
        <span class="s1">load_estimator</span><span class="s4">.</span><span class="s1">partial_fit</span><span class="s4">(</span><span class="s1">fine_tune_features</span><span class="s4">, </span><span class="s1">fine_tune_target</span><span class="s4">)</span>

    <span class="s2"># finetuned model learned the new target</span>
    <span class="s1">predicted_value </span><span class="s4">= </span><span class="s1">load_estimator</span><span class="s4">.</span><span class="s1">predict</span><span class="s4">(</span><span class="s1">fine_tune_features</span><span class="s4">)</span>
    <span class="s1">assert_allclose</span><span class="s4">(</span><span class="s1">predicted_value</span><span class="s4">, </span><span class="s1">fine_tune_target</span><span class="s4">, </span><span class="s1">rtol</span><span class="s4">=</span><span class="s6">1e-4</span><span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;Estimator&quot;</span><span class="s4">, [</span><span class="s1">MLPClassifier</span><span class="s4">, </span><span class="s1">MLPRegressor</span><span class="s4">])</span>
<span class="s3">def </span><span class="s1">test_preserve_feature_names</span><span class="s4">(</span><span class="s1">Estimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Check that feature names are preserved when early stopping is enabled. 
 
    Feature names are required for consistency checks during scoring. 
 
    Non-regression test for gh-24846 
    &quot;&quot;&quot;</span>
    <span class="s1">pd </span><span class="s4">= </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">importorskip</span><span class="s4">(</span><span class="s5">&quot;pandas&quot;</span><span class="s4">)</span>
    <span class="s1">rng </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">random</span><span class="s4">.</span><span class="s1">RandomState</span><span class="s4">(</span><span class="s6">0</span><span class="s4">)</span>

    <span class="s1">X </span><span class="s4">= </span><span class="s1">pd</span><span class="s4">.</span><span class="s1">DataFrame</span><span class="s4">(</span><span class="s1">data</span><span class="s4">=</span><span class="s1">rng</span><span class="s4">.</span><span class="s1">randn</span><span class="s4">(</span><span class="s6">10</span><span class="s4">, </span><span class="s6">2</span><span class="s4">), </span><span class="s1">columns</span><span class="s4">=[</span><span class="s5">&quot;colname_a&quot;</span><span class="s4">, </span><span class="s5">&quot;colname_b&quot;</span><span class="s4">])</span>
    <span class="s1">y </span><span class="s4">= </span><span class="s1">pd</span><span class="s4">.</span><span class="s1">Series</span><span class="s4">(</span><span class="s1">data</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">full</span><span class="s4">(</span><span class="s6">10</span><span class="s4">, </span><span class="s6">1</span><span class="s4">), </span><span class="s1">name</span><span class="s4">=</span><span class="s5">&quot;colname_y&quot;</span><span class="s4">)</span>

    <span class="s1">model </span><span class="s4">= </span><span class="s1">Estimator</span><span class="s4">(</span><span class="s1">early_stopping</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">validation_fraction</span><span class="s4">=</span><span class="s6">0.2</span><span class="s4">)</span>

    <span class="s3">with </span><span class="s1">warnings</span><span class="s4">.</span><span class="s1">catch_warnings</span><span class="s4">():</span>
        <span class="s1">warnings</span><span class="s4">.</span><span class="s1">simplefilter</span><span class="s4">(</span><span class="s5">&quot;error&quot;</span><span class="s4">, </span><span class="s1">UserWarning</span><span class="s4">)</span>
        <span class="s1">model</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">)</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;MLPEstimator&quot;</span><span class="s4">, [</span><span class="s1">MLPClassifier</span><span class="s4">, </span><span class="s1">MLPRegressor</span><span class="s4">])</span>
<span class="s3">def </span><span class="s1">test_mlp_warm_start_with_early_stopping</span><span class="s4">(</span><span class="s1">MLPEstimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Check that early stopping works with warm start.&quot;&quot;&quot;</span>
    <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPEstimator</span><span class="s4">(</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">10</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">, </span><span class="s1">warm_start</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">early_stopping</span><span class="s4">=</span><span class="s3">True</span>
    <span class="s4">)</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_iris</span><span class="s4">, </span><span class="s1">y_iris</span><span class="s4">)</span>
    <span class="s1">n_validation_scores </span><span class="s4">= </span><span class="s1">len</span><span class="s4">(</span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">validation_scores_</span><span class="s4">)</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">set_params</span><span class="s4">(</span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">20</span><span class="s4">)</span>
    <span class="s1">mlp</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_iris</span><span class="s4">, </span><span class="s1">y_iris</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">len</span><span class="s4">(</span><span class="s1">mlp</span><span class="s4">.</span><span class="s1">validation_scores_</span><span class="s4">) &gt; </span><span class="s1">n_validation_scores</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;MLPEstimator&quot;</span><span class="s4">, [</span><span class="s1">MLPClassifier</span><span class="s4">, </span><span class="s1">MLPRegressor</span><span class="s4">])</span>
<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;solver&quot;</span><span class="s4">, [</span><span class="s5">&quot;sgd&quot;</span><span class="s4">, </span><span class="s5">&quot;adam&quot;</span><span class="s4">, </span><span class="s5">&quot;lbfgs&quot;</span><span class="s4">])</span>
<span class="s3">def </span><span class="s1">test_mlp_warm_start_no_convergence</span><span class="s4">(</span><span class="s1">MLPEstimator</span><span class="s4">, </span><span class="s1">solver</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Check that we stop the number of iteration at `max_iter` when warm starting. 
 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/24764 
    &quot;&quot;&quot;</span>
    <span class="s1">model </span><span class="s4">= </span><span class="s1">MLPEstimator</span><span class="s4">(</span>
        <span class="s1">solver</span><span class="s4">=</span><span class="s1">solver</span><span class="s4">,</span>
        <span class="s1">warm_start</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
        <span class="s1">early_stopping</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">10</span><span class="s4">,</span>
        <span class="s1">n_iter_no_change</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
    <span class="s4">)</span>

    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">warns</span><span class="s4">(</span><span class="s1">ConvergenceWarning</span><span class="s4">):</span>
        <span class="s1">model</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_iris</span><span class="s4">, </span><span class="s1">y_iris</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">model</span><span class="s4">.</span><span class="s1">n_iter_ </span><span class="s4">== </span><span class="s6">10</span>

    <span class="s1">model</span><span class="s4">.</span><span class="s1">set_params</span><span class="s4">(</span><span class="s1">max_iter</span><span class="s4">=</span><span class="s6">20</span><span class="s4">)</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">warns</span><span class="s4">(</span><span class="s1">ConvergenceWarning</span><span class="s4">):</span>
        <span class="s1">model</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_iris</span><span class="s4">, </span><span class="s1">y_iris</span><span class="s4">)</span>
    <span class="s3">assert </span><span class="s1">model</span><span class="s4">.</span><span class="s1">n_iter_ </span><span class="s4">== </span><span class="s6">20</span>


<span class="s4">@</span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">mark</span><span class="s4">.</span><span class="s1">parametrize</span><span class="s4">(</span><span class="s5">&quot;MLPEstimator&quot;</span><span class="s4">, [</span><span class="s1">MLPClassifier</span><span class="s4">, </span><span class="s1">MLPRegressor</span><span class="s4">])</span>
<span class="s3">def </span><span class="s1">test_mlp_partial_fit_after_fit</span><span class="s4">(</span><span class="s1">MLPEstimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Check partial fit does not fail after fit when early_stopping=True. 
 
    Non-regression test for gh-25693. 
    &quot;&quot;&quot;</span>
    <span class="s1">mlp </span><span class="s4">= </span><span class="s1">MLPEstimator</span><span class="s4">(</span><span class="s1">early_stopping</span><span class="s4">=</span><span class="s3">True</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s6">0</span><span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X_iris</span><span class="s4">, </span><span class="s1">y_iris</span><span class="s4">)</span>

    <span class="s1">msg </span><span class="s4">= </span><span class="s5">&quot;partial_fit does not support early_stopping=True&quot;</span>
    <span class="s3">with </span><span class="s1">pytest</span><span class="s4">.</span><span class="s1">raises</span><span class="s4">(</span><span class="s1">ValueError</span><span class="s4">, </span><span class="s1">match</span><span class="s4">=</span><span class="s1">msg</span><span class="s4">):</span>
        <span class="s1">mlp</span><span class="s4">.</span><span class="s1">partial_fit</span><span class="s4">(</span><span class="s1">X_iris</span><span class="s4">, </span><span class="s1">y_iris</span><span class="s4">)</span>
</pre>
</body>
</html>