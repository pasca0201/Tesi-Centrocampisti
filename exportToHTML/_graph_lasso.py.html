<html>
<head>
<title>_graph_lasso.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #2aacb8;}
.s6 { color: #6aab73;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_graph_lasso.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;GraphicalLasso: sparse inverse covariance estimation with an l1-penalized 
estimator. 
&quot;&quot;&quot;</span>

<span class="s2"># Author: Gael Varoquaux &lt;gael.varoquaux@normalesup.org&gt;</span>
<span class="s2"># License: BSD 3 clause</span>
<span class="s2"># Copyright: INRIA</span>
<span class="s3">import </span><span class="s1">operator</span>
<span class="s3">import </span><span class="s1">sys</span>
<span class="s3">import </span><span class="s1">time</span>
<span class="s3">import </span><span class="s1">warnings</span>
<span class="s3">from </span><span class="s1">numbers </span><span class="s3">import </span><span class="s1">Integral</span><span class="s4">, </span><span class="s1">Real</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">linalg</span>

<span class="s3">from </span><span class="s4">..</span><span class="s1">base </span><span class="s3">import </span><span class="s1">_fit_context</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">exceptions </span><span class="s3">import </span><span class="s1">ConvergenceWarning</span>

<span class="s2"># mypy error: Module 'sklearn.linear_model' has no attribute '_cd_fast'</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">linear_model </span><span class="s3">import </span><span class="s1">_cd_fast </span><span class="s3">as </span><span class="s1">cd_fast  </span><span class="s2"># type: ignore</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">linear_model </span><span class="s3">import </span><span class="s1">lars_path_gram</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">model_selection </span><span class="s3">import </span><span class="s1">check_cv</span><span class="s4">, </span><span class="s1">cross_val_score</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils </span><span class="s3">import </span><span class="s1">Bunch</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_param_validation </span><span class="s3">import </span><span class="s1">Interval</span><span class="s4">, </span><span class="s1">StrOptions</span><span class="s4">, </span><span class="s1">validate_params</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">metadata_routing </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">MetadataRouter</span><span class="s4">,</span>
    <span class="s1">MethodMapping</span><span class="s4">,</span>
    <span class="s1">_raise_for_params</span><span class="s4">,</span>
    <span class="s1">_routing_enabled</span><span class="s4">,</span>
    <span class="s1">process_routing</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">parallel </span><span class="s3">import </span><span class="s1">Parallel</span><span class="s4">, </span><span class="s1">delayed</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">validation </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">_is_arraylike_not_scalar</span><span class="s4">,</span>
    <span class="s1">check_random_state</span><span class="s4">,</span>
    <span class="s1">check_scalar</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s4">. </span><span class="s3">import </span><span class="s1">EmpiricalCovariance</span><span class="s4">, </span><span class="s1">empirical_covariance</span><span class="s4">, </span><span class="s1">log_likelihood</span>


<span class="s2"># Helper functions to compute the objective and dual objective functions</span>
<span class="s2"># of the l1-penalized estimator</span>
<span class="s3">def </span><span class="s1">_objective</span><span class="s4">(</span><span class="s1">mle</span><span class="s4">, </span><span class="s1">precision_</span><span class="s4">, </span><span class="s1">alpha</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Evaluation of the graphical-lasso objective function 
 
    the objective function is made of a shifted scaled version of the 
    normalized log-likelihood (i.e. its empirical mean over the samples) and a 
    penalisation term to promote sparsity 
    &quot;&quot;&quot;</span>
    <span class="s1">p </span><span class="s4">= </span><span class="s1">precision_</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">]</span>
    <span class="s1">cost </span><span class="s4">= -</span><span class="s5">2.0 </span><span class="s4">* </span><span class="s1">log_likelihood</span><span class="s4">(</span><span class="s1">mle</span><span class="s4">, </span><span class="s1">precision_</span><span class="s4">) + </span><span class="s1">p </span><span class="s4">* </span><span class="s1">np</span><span class="s4">.</span><span class="s1">log</span><span class="s4">(</span><span class="s5">2 </span><span class="s4">* </span><span class="s1">np</span><span class="s4">.</span><span class="s1">pi</span><span class="s4">)</span>
    <span class="s1">cost </span><span class="s4">+= </span><span class="s1">alpha </span><span class="s4">* (</span><span class="s1">np</span><span class="s4">.</span><span class="s1">abs</span><span class="s4">(</span><span class="s1">precision_</span><span class="s4">).</span><span class="s1">sum</span><span class="s4">() - </span><span class="s1">np</span><span class="s4">.</span><span class="s1">abs</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">diag</span><span class="s4">(</span><span class="s1">precision_</span><span class="s4">)).</span><span class="s1">sum</span><span class="s4">())</span>
    <span class="s3">return </span><span class="s1">cost</span>


<span class="s3">def </span><span class="s1">_dual_gap</span><span class="s4">(</span><span class="s1">emp_cov</span><span class="s4">, </span><span class="s1">precision_</span><span class="s4">, </span><span class="s1">alpha</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Expression of the dual gap convergence criterion 
 
    The specific definition is given in Duchi &quot;Projected Subgradient Methods 
    for Learning Sparse Gaussians&quot;. 
    &quot;&quot;&quot;</span>
    <span class="s1">gap </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">emp_cov </span><span class="s4">* </span><span class="s1">precision_</span><span class="s4">)</span>
    <span class="s1">gap </span><span class="s4">-= </span><span class="s1">precision_</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">]</span>
    <span class="s1">gap </span><span class="s4">+= </span><span class="s1">alpha </span><span class="s4">* (</span><span class="s1">np</span><span class="s4">.</span><span class="s1">abs</span><span class="s4">(</span><span class="s1">precision_</span><span class="s4">).</span><span class="s1">sum</span><span class="s4">() - </span><span class="s1">np</span><span class="s4">.</span><span class="s1">abs</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">diag</span><span class="s4">(</span><span class="s1">precision_</span><span class="s4">)).</span><span class="s1">sum</span><span class="s4">())</span>
    <span class="s3">return </span><span class="s1">gap</span>


<span class="s2"># The g-lasso algorithm</span>
<span class="s3">def </span><span class="s1">_graphical_lasso</span><span class="s4">(</span>
    <span class="s1">emp_cov</span><span class="s4">,</span>
    <span class="s1">alpha</span><span class="s4">,</span>
    <span class="s4">*,</span>
    <span class="s1">cov_init</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">mode</span><span class="s4">=</span><span class="s6">&quot;cd&quot;</span><span class="s4">,</span>
    <span class="s1">tol</span><span class="s4">=</span><span class="s5">1e-4</span><span class="s4">,</span>
    <span class="s1">enet_tol</span><span class="s4">=</span><span class="s5">1e-4</span><span class="s4">,</span>
    <span class="s1">max_iter</span><span class="s4">=</span><span class="s5">100</span><span class="s4">,</span>
    <span class="s1">verbose</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s1">eps</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">finfo</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">).</span><span class="s1">eps</span><span class="s4">,</span>
<span class="s4">):</span>
    <span class="s1">_</span><span class="s4">, </span><span class="s1">n_features </span><span class="s4">= </span><span class="s1">emp_cov</span><span class="s4">.</span><span class="s1">shape</span>
    <span class="s3">if </span><span class="s1">alpha </span><span class="s4">== </span><span class="s5">0</span><span class="s4">:</span>
        <span class="s2"># Early return without regularization</span>
        <span class="s1">precision_ </span><span class="s4">= </span><span class="s1">linalg</span><span class="s4">.</span><span class="s1">inv</span><span class="s4">(</span><span class="s1">emp_cov</span><span class="s4">)</span>
        <span class="s1">cost </span><span class="s4">= -</span><span class="s5">2.0 </span><span class="s4">* </span><span class="s1">log_likelihood</span><span class="s4">(</span><span class="s1">emp_cov</span><span class="s4">, </span><span class="s1">precision_</span><span class="s4">)</span>
        <span class="s1">cost </span><span class="s4">+= </span><span class="s1">n_features </span><span class="s4">* </span><span class="s1">np</span><span class="s4">.</span><span class="s1">log</span><span class="s4">(</span><span class="s5">2 </span><span class="s4">* </span><span class="s1">np</span><span class="s4">.</span><span class="s1">pi</span><span class="s4">)</span>
        <span class="s1">d_gap </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">emp_cov </span><span class="s4">* </span><span class="s1">precision_</span><span class="s4">) - </span><span class="s1">n_features</span>
        <span class="s3">return </span><span class="s1">emp_cov</span><span class="s4">, </span><span class="s1">precision_</span><span class="s4">, (</span><span class="s1">cost</span><span class="s4">, </span><span class="s1">d_gap</span><span class="s4">), </span><span class="s5">0</span>

    <span class="s3">if </span><span class="s1">cov_init </span><span class="s3">is None</span><span class="s4">:</span>
        <span class="s1">covariance_ </span><span class="s4">= </span><span class="s1">emp_cov</span><span class="s4">.</span><span class="s1">copy</span><span class="s4">()</span>
    <span class="s3">else</span><span class="s4">:</span>
        <span class="s1">covariance_ </span><span class="s4">= </span><span class="s1">cov_init</span><span class="s4">.</span><span class="s1">copy</span><span class="s4">()</span>
    <span class="s2"># As a trivial regularization (Tikhonov like), we scale down the</span>
    <span class="s2"># off-diagonal coefficients of our starting point: This is needed, as</span>
    <span class="s2"># in the cross-validation the cov_init can easily be</span>
    <span class="s2"># ill-conditioned, and the CV loop blows. Beside, this takes</span>
    <span class="s2"># conservative stand-point on the initial conditions, and it tends to</span>
    <span class="s2"># make the convergence go faster.</span>
    <span class="s1">covariance_ </span><span class="s4">*= </span><span class="s5">0.95</span>
    <span class="s1">diagonal </span><span class="s4">= </span><span class="s1">emp_cov</span><span class="s4">.</span><span class="s1">flat</span><span class="s4">[:: </span><span class="s1">n_features </span><span class="s4">+ </span><span class="s5">1</span><span class="s4">]</span>
    <span class="s1">covariance_</span><span class="s4">.</span><span class="s1">flat</span><span class="s4">[:: </span><span class="s1">n_features </span><span class="s4">+ </span><span class="s5">1</span><span class="s4">] = </span><span class="s1">diagonal</span>
    <span class="s1">precision_ </span><span class="s4">= </span><span class="s1">linalg</span><span class="s4">.</span><span class="s1">pinvh</span><span class="s4">(</span><span class="s1">covariance_</span><span class="s4">)</span>

    <span class="s1">indices </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">arange</span><span class="s4">(</span><span class="s1">n_features</span><span class="s4">)</span>
    <span class="s1">i </span><span class="s4">= </span><span class="s5">0  </span><span class="s2"># initialize the counter to be robust to `max_iter=0`</span>
    <span class="s1">costs </span><span class="s4">= </span><span class="s1">list</span><span class="s4">()</span>
    <span class="s2"># The different l1 regression solver have different numerical errors</span>
    <span class="s3">if </span><span class="s1">mode </span><span class="s4">== </span><span class="s6">&quot;cd&quot;</span><span class="s4">:</span>
        <span class="s1">errors </span><span class="s4">= </span><span class="s1">dict</span><span class="s4">(</span><span class="s1">over</span><span class="s4">=</span><span class="s6">&quot;raise&quot;</span><span class="s4">, </span><span class="s1">invalid</span><span class="s4">=</span><span class="s6">&quot;ignore&quot;</span><span class="s4">)</span>
    <span class="s3">else</span><span class="s4">:</span>
        <span class="s1">errors </span><span class="s4">= </span><span class="s1">dict</span><span class="s4">(</span><span class="s1">invalid</span><span class="s4">=</span><span class="s6">&quot;raise&quot;</span><span class="s4">)</span>
    <span class="s3">try</span><span class="s4">:</span>
        <span class="s2"># be robust to the max_iter=0 edge case, see:</span>
        <span class="s2"># https://github.com/scikit-learn/scikit-learn/issues/4134</span>
        <span class="s1">d_gap </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span>
        <span class="s2"># set a sub_covariance buffer</span>
        <span class="s1">sub_covariance </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">copy</span><span class="s4">(</span><span class="s1">covariance_</span><span class="s4">[</span><span class="s5">1</span><span class="s4">:, </span><span class="s5">1</span><span class="s4">:], </span><span class="s1">order</span><span class="s4">=</span><span class="s6">&quot;C&quot;</span><span class="s4">)</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">max_iter</span><span class="s4">):</span>
            <span class="s3">for </span><span class="s1">idx </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">n_features</span><span class="s4">):</span>
                <span class="s2"># To keep the contiguous matrix `sub_covariance` equal to</span>
                <span class="s2"># covariance_[indices != idx].T[indices != idx]</span>
                <span class="s2"># we only need to update 1 column and 1 line when idx changes</span>
                <span class="s3">if </span><span class="s1">idx </span><span class="s4">&gt; </span><span class="s5">0</span><span class="s4">:</span>
                    <span class="s1">di </span><span class="s4">= </span><span class="s1">idx </span><span class="s4">- </span><span class="s5">1</span>
                    <span class="s1">sub_covariance</span><span class="s4">[</span><span class="s1">di</span><span class="s4">] = </span><span class="s1">covariance_</span><span class="s4">[</span><span class="s1">di</span><span class="s4">][</span><span class="s1">indices </span><span class="s4">!= </span><span class="s1">idx</span><span class="s4">]</span>
                    <span class="s1">sub_covariance</span><span class="s4">[:, </span><span class="s1">di</span><span class="s4">] = </span><span class="s1">covariance_</span><span class="s4">[:, </span><span class="s1">di</span><span class="s4">][</span><span class="s1">indices </span><span class="s4">!= </span><span class="s1">idx</span><span class="s4">]</span>
                <span class="s3">else</span><span class="s4">:</span>
                    <span class="s1">sub_covariance</span><span class="s4">[:] = </span><span class="s1">covariance_</span><span class="s4">[</span><span class="s5">1</span><span class="s4">:, </span><span class="s5">1</span><span class="s4">:]</span>
                <span class="s1">row </span><span class="s4">= </span><span class="s1">emp_cov</span><span class="s4">[</span><span class="s1">idx</span><span class="s4">, </span><span class="s1">indices </span><span class="s4">!= </span><span class="s1">idx</span><span class="s4">]</span>
                <span class="s3">with </span><span class="s1">np</span><span class="s4">.</span><span class="s1">errstate</span><span class="s4">(**</span><span class="s1">errors</span><span class="s4">):</span>
                    <span class="s3">if </span><span class="s1">mode </span><span class="s4">== </span><span class="s6">&quot;cd&quot;</span><span class="s4">:</span>
                        <span class="s2"># Use coordinate descent</span>
                        <span class="s1">coefs </span><span class="s4">= -(</span>
                            <span class="s1">precision_</span><span class="s4">[</span><span class="s1">indices </span><span class="s4">!= </span><span class="s1">idx</span><span class="s4">, </span><span class="s1">idx</span><span class="s4">]</span>
                            <span class="s4">/ (</span><span class="s1">precision_</span><span class="s4">[</span><span class="s1">idx</span><span class="s4">, </span><span class="s1">idx</span><span class="s4">] + </span><span class="s5">1000 </span><span class="s4">* </span><span class="s1">eps</span><span class="s4">)</span>
                        <span class="s4">)</span>
                        <span class="s1">coefs</span><span class="s4">, </span><span class="s1">_</span><span class="s4">, </span><span class="s1">_</span><span class="s4">, </span><span class="s1">_ </span><span class="s4">= </span><span class="s1">cd_fast</span><span class="s4">.</span><span class="s1">enet_coordinate_descent_gram</span><span class="s4">(</span>
                            <span class="s1">coefs</span><span class="s4">,</span>
                            <span class="s1">alpha</span><span class="s4">,</span>
                            <span class="s5">0</span><span class="s4">,</span>
                            <span class="s1">sub_covariance</span><span class="s4">,</span>
                            <span class="s1">row</span><span class="s4">,</span>
                            <span class="s1">row</span><span class="s4">,</span>
                            <span class="s1">max_iter</span><span class="s4">,</span>
                            <span class="s1">enet_tol</span><span class="s4">,</span>
                            <span class="s1">check_random_state</span><span class="s4">(</span><span class="s3">None</span><span class="s4">),</span>
                            <span class="s3">False</span><span class="s4">,</span>
                        <span class="s4">)</span>
                    <span class="s3">else</span><span class="s4">:  </span><span class="s2"># mode == &quot;lars&quot;</span>
                        <span class="s1">_</span><span class="s4">, </span><span class="s1">_</span><span class="s4">, </span><span class="s1">coefs </span><span class="s4">= </span><span class="s1">lars_path_gram</span><span class="s4">(</span>
                            <span class="s1">Xy</span><span class="s4">=</span><span class="s1">row</span><span class="s4">,</span>
                            <span class="s1">Gram</span><span class="s4">=</span><span class="s1">sub_covariance</span><span class="s4">,</span>
                            <span class="s1">n_samples</span><span class="s4">=</span><span class="s1">row</span><span class="s4">.</span><span class="s1">size</span><span class="s4">,</span>
                            <span class="s1">alpha_min</span><span class="s4">=</span><span class="s1">alpha </span><span class="s4">/ (</span><span class="s1">n_features </span><span class="s4">- </span><span class="s5">1</span><span class="s4">),</span>
                            <span class="s1">copy_Gram</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
                            <span class="s1">eps</span><span class="s4">=</span><span class="s1">eps</span><span class="s4">,</span>
                            <span class="s1">method</span><span class="s4">=</span><span class="s6">&quot;lars&quot;</span><span class="s4">,</span>
                            <span class="s1">return_path</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
                        <span class="s4">)</span>
                <span class="s2"># Update the precision matrix</span>
                <span class="s1">precision_</span><span class="s4">[</span><span class="s1">idx</span><span class="s4">, </span><span class="s1">idx</span><span class="s4">] = </span><span class="s5">1.0 </span><span class="s4">/ (</span>
                    <span class="s1">covariance_</span><span class="s4">[</span><span class="s1">idx</span><span class="s4">, </span><span class="s1">idx</span><span class="s4">]</span>
                    <span class="s4">- </span><span class="s1">np</span><span class="s4">.</span><span class="s1">dot</span><span class="s4">(</span><span class="s1">covariance_</span><span class="s4">[</span><span class="s1">indices </span><span class="s4">!= </span><span class="s1">idx</span><span class="s4">, </span><span class="s1">idx</span><span class="s4">], </span><span class="s1">coefs</span><span class="s4">)</span>
                <span class="s4">)</span>
                <span class="s1">precision_</span><span class="s4">[</span><span class="s1">indices </span><span class="s4">!= </span><span class="s1">idx</span><span class="s4">, </span><span class="s1">idx</span><span class="s4">] = -</span><span class="s1">precision_</span><span class="s4">[</span><span class="s1">idx</span><span class="s4">, </span><span class="s1">idx</span><span class="s4">] * </span><span class="s1">coefs</span>
                <span class="s1">precision_</span><span class="s4">[</span><span class="s1">idx</span><span class="s4">, </span><span class="s1">indices </span><span class="s4">!= </span><span class="s1">idx</span><span class="s4">] = -</span><span class="s1">precision_</span><span class="s4">[</span><span class="s1">idx</span><span class="s4">, </span><span class="s1">idx</span><span class="s4">] * </span><span class="s1">coefs</span>
                <span class="s1">coefs </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">dot</span><span class="s4">(</span><span class="s1">sub_covariance</span><span class="s4">, </span><span class="s1">coefs</span><span class="s4">)</span>
                <span class="s1">covariance_</span><span class="s4">[</span><span class="s1">idx</span><span class="s4">, </span><span class="s1">indices </span><span class="s4">!= </span><span class="s1">idx</span><span class="s4">] = </span><span class="s1">coefs</span>
                <span class="s1">covariance_</span><span class="s4">[</span><span class="s1">indices </span><span class="s4">!= </span><span class="s1">idx</span><span class="s4">, </span><span class="s1">idx</span><span class="s4">] = </span><span class="s1">coefs</span>
            <span class="s3">if not </span><span class="s1">np</span><span class="s4">.</span><span class="s1">isfinite</span><span class="s4">(</span><span class="s1">precision_</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">()):</span>
                <span class="s3">raise </span><span class="s1">FloatingPointError</span><span class="s4">(</span>
                    <span class="s6">&quot;The system is too ill-conditioned for this solver&quot;</span>
                <span class="s4">)</span>
            <span class="s1">d_gap </span><span class="s4">= </span><span class="s1">_dual_gap</span><span class="s4">(</span><span class="s1">emp_cov</span><span class="s4">, </span><span class="s1">precision_</span><span class="s4">, </span><span class="s1">alpha</span><span class="s4">)</span>
            <span class="s1">cost </span><span class="s4">= </span><span class="s1">_objective</span><span class="s4">(</span><span class="s1">emp_cov</span><span class="s4">, </span><span class="s1">precision_</span><span class="s4">, </span><span class="s1">alpha</span><span class="s4">)</span>
            <span class="s3">if </span><span class="s1">verbose</span><span class="s4">:</span>
                <span class="s1">print</span><span class="s4">(</span>
                    <span class="s6">&quot;[graphical_lasso] Iteration % 3i, cost % 3.2e, dual gap %.3e&quot;</span>
                    <span class="s4">% (</span><span class="s1">i</span><span class="s4">, </span><span class="s1">cost</span><span class="s4">, </span><span class="s1">d_gap</span><span class="s4">)</span>
                <span class="s4">)</span>
            <span class="s1">costs</span><span class="s4">.</span><span class="s1">append</span><span class="s4">((</span><span class="s1">cost</span><span class="s4">, </span><span class="s1">d_gap</span><span class="s4">))</span>
            <span class="s3">if </span><span class="s1">np</span><span class="s4">.</span><span class="s1">abs</span><span class="s4">(</span><span class="s1">d_gap</span><span class="s4">) &lt; </span><span class="s1">tol</span><span class="s4">:</span>
                <span class="s3">break</span>
            <span class="s3">if not </span><span class="s1">np</span><span class="s4">.</span><span class="s1">isfinite</span><span class="s4">(</span><span class="s1">cost</span><span class="s4">) </span><span class="s3">and </span><span class="s1">i </span><span class="s4">&gt; </span><span class="s5">0</span><span class="s4">:</span>
                <span class="s3">raise </span><span class="s1">FloatingPointError</span><span class="s4">(</span>
                    <span class="s6">&quot;Non SPD result: the system is too ill-conditioned for this solver&quot;</span>
                <span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">warnings</span><span class="s4">.</span><span class="s1">warn</span><span class="s4">(</span>
                <span class="s6">&quot;graphical_lasso: did not converge after %i iteration: dual gap: %.3e&quot;</span>
                <span class="s4">% (</span><span class="s1">max_iter</span><span class="s4">, </span><span class="s1">d_gap</span><span class="s4">),</span>
                <span class="s1">ConvergenceWarning</span><span class="s4">,</span>
            <span class="s4">)</span>
    <span class="s3">except </span><span class="s1">FloatingPointError </span><span class="s3">as </span><span class="s1">e</span><span class="s4">:</span>
        <span class="s1">e</span><span class="s4">.</span><span class="s1">args </span><span class="s4">= (</span><span class="s1">e</span><span class="s4">.</span><span class="s1">args</span><span class="s4">[</span><span class="s5">0</span><span class="s4">] + </span><span class="s6">&quot;. The system is too ill-conditioned for this solver&quot;</span><span class="s4">,)</span>
        <span class="s3">raise </span><span class="s1">e</span>

    <span class="s3">return </span><span class="s1">covariance_</span><span class="s4">, </span><span class="s1">precision_</span><span class="s4">, </span><span class="s1">costs</span><span class="s4">, </span><span class="s1">i </span><span class="s4">+ </span><span class="s5">1</span>


<span class="s3">def </span><span class="s1">alpha_max</span><span class="s4">(</span><span class="s1">emp_cov</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Find the maximum alpha for which there are some non-zeros off-diagonal. 
 
    Parameters 
    ---------- 
    emp_cov : ndarray of shape (n_features, n_features) 
        The sample covariance matrix. 
 
    Notes 
    ----- 
    This results from the bound for the all the Lasso that are solved 
    in GraphicalLasso: each time, the row of cov corresponds to Xy. As the 
    bound for alpha is given by `max(abs(Xy))`, the result follows. 
    &quot;&quot;&quot;</span>
    <span class="s1">A </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">copy</span><span class="s4">(</span><span class="s1">emp_cov</span><span class="s4">)</span>
    <span class="s1">A</span><span class="s4">.</span><span class="s1">flat</span><span class="s4">[:: </span><span class="s1">A</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">0</span><span class="s4">] + </span><span class="s5">1</span><span class="s4">] = </span><span class="s5">0</span>
    <span class="s3">return </span><span class="s1">np</span><span class="s4">.</span><span class="s1">max</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">abs</span><span class="s4">(</span><span class="s1">A</span><span class="s4">))</span>


<span class="s4">@</span><span class="s1">validate_params</span><span class="s4">(</span>
    <span class="s4">{</span>
        <span class="s6">&quot;emp_cov&quot;</span><span class="s4">: [</span><span class="s6">&quot;array-like&quot;</span><span class="s4">],</span>
        <span class="s6">&quot;return_costs&quot;</span><span class="s4">: [</span><span class="s6">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s6">&quot;return_n_iter&quot;</span><span class="s4">: [</span><span class="s6">&quot;boolean&quot;</span><span class="s4">],</span>
    <span class="s4">},</span>
    <span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">def </span><span class="s1">graphical_lasso</span><span class="s4">(</span>
    <span class="s1">emp_cov</span><span class="s4">,</span>
    <span class="s1">alpha</span><span class="s4">,</span>
    <span class="s4">*,</span>
    <span class="s1">mode</span><span class="s4">=</span><span class="s6">&quot;cd&quot;</span><span class="s4">,</span>
    <span class="s1">tol</span><span class="s4">=</span><span class="s5">1e-4</span><span class="s4">,</span>
    <span class="s1">enet_tol</span><span class="s4">=</span><span class="s5">1e-4</span><span class="s4">,</span>
    <span class="s1">max_iter</span><span class="s4">=</span><span class="s5">100</span><span class="s4">,</span>
    <span class="s1">verbose</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s1">return_costs</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s1">eps</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">finfo</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">).</span><span class="s1">eps</span><span class="s4">,</span>
    <span class="s1">return_n_iter</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
<span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;L1-penalized covariance estimator. 
 
    Read more in the :ref:`User Guide &lt;sparse_inverse_covariance&gt;`. 
 
    .. versionchanged:: v0.20 
        graph_lasso has been renamed to graphical_lasso 
 
    Parameters 
    ---------- 
    emp_cov : array-like of shape (n_features, n_features) 
        Empirical covariance from which to compute the covariance estimate. 
 
    alpha : float 
        The regularization parameter: the higher alpha, the more 
        regularization, the sparser the inverse covariance. 
        Range is (0, inf]. 
 
    mode : {'cd', 'lars'}, default='cd' 
        The Lasso solver to use: coordinate descent or LARS. Use LARS for 
        very sparse underlying graphs, where p &gt; n. Elsewhere prefer cd 
        which is more numerically stable. 
 
    tol : float, default=1e-4 
        The tolerance to declare convergence: if the dual gap goes below 
        this value, iterations are stopped. Range is (0, inf]. 
 
    enet_tol : float, default=1e-4 
        The tolerance for the elastic net solver used to calculate the descent 
        direction. This parameter controls the accuracy of the search direction 
        for a given column update, not of the overall parameter estimate. Only 
        used for mode='cd'. Range is (0, inf]. 
 
    max_iter : int, default=100 
        The maximum number of iterations. 
 
    verbose : bool, default=False 
        If verbose is True, the objective function and dual gap are 
        printed at each iteration. 
 
    return_costs : bool, default=False 
        If return_costs is True, the objective function and dual gap 
        at each iteration are returned. 
 
    eps : float, default=eps 
        The machine-precision regularization in the computation of the 
        Cholesky diagonal factors. Increase this for very ill-conditioned 
        systems. Default is `np.finfo(np.float64).eps`. 
 
    return_n_iter : bool, default=False 
        Whether or not to return the number of iterations. 
 
    Returns 
    ------- 
    covariance : ndarray of shape (n_features, n_features) 
        The estimated covariance matrix. 
 
    precision : ndarray of shape (n_features, n_features) 
        The estimated (sparse) precision matrix. 
 
    costs : list of (objective, dual_gap) pairs 
        The list of values of the objective function and the dual gap at 
        each iteration. Returned only if return_costs is True. 
 
    n_iter : int 
        Number of iterations. Returned only if `return_n_iter` is set to True. 
 
    See Also 
    -------- 
    GraphicalLasso : Sparse inverse covariance estimation 
        with an l1-penalized estimator. 
    GraphicalLassoCV : Sparse inverse covariance with 
        cross-validated choice of the l1 penalty. 
 
    Notes 
    ----- 
    The algorithm employed to solve this problem is the GLasso algorithm, 
    from the Friedman 2008 Biostatistics paper. It is the same algorithm 
    as in the R `glasso` package. 
 
    One possible difference with the `glasso` R package is that the 
    diagonal coefficients are not penalized. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.datasets import make_sparse_spd_matrix 
    &gt;&gt;&gt; from sklearn.covariance import empirical_covariance, graphical_lasso 
    &gt;&gt;&gt; true_cov = make_sparse_spd_matrix(n_dim=3,random_state=42) 
    &gt;&gt;&gt; rng = np.random.RandomState(42) 
    &gt;&gt;&gt; X = rng.multivariate_normal(mean=np.zeros(3), cov=true_cov, size=3) 
    &gt;&gt;&gt; emp_cov = empirical_covariance(X, assume_centered=True) 
    &gt;&gt;&gt; emp_cov, _ = graphical_lasso(emp_cov, alpha=0.05) 
    &gt;&gt;&gt; emp_cov 
    array([[ 1.68...,  0.21..., -0.20...], 
           [ 0.21...,  0.22..., -0.08...], 
           [-0.20..., -0.08...,  0.23...]]) 
    &quot;&quot;&quot;</span>
    <span class="s1">model </span><span class="s4">= </span><span class="s1">GraphicalLasso</span><span class="s4">(</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s1">alpha</span><span class="s4">,</span>
        <span class="s1">mode</span><span class="s4">=</span><span class="s1">mode</span><span class="s4">,</span>
        <span class="s1">covariance</span><span class="s4">=</span><span class="s6">&quot;precomputed&quot;</span><span class="s4">,</span>
        <span class="s1">tol</span><span class="s4">=</span><span class="s1">tol</span><span class="s4">,</span>
        <span class="s1">enet_tol</span><span class="s4">=</span><span class="s1">enet_tol</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
        <span class="s1">eps</span><span class="s4">=</span><span class="s1">eps</span><span class="s4">,</span>
        <span class="s1">assume_centered</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">emp_cov</span><span class="s4">)</span>

    <span class="s1">output </span><span class="s4">= [</span><span class="s1">model</span><span class="s4">.</span><span class="s1">covariance_</span><span class="s4">, </span><span class="s1">model</span><span class="s4">.</span><span class="s1">precision_</span><span class="s4">]</span>
    <span class="s3">if </span><span class="s1">return_costs</span><span class="s4">:</span>
        <span class="s1">output</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">model</span><span class="s4">.</span><span class="s1">costs_</span><span class="s4">)</span>
    <span class="s3">if </span><span class="s1">return_n_iter</span><span class="s4">:</span>
        <span class="s1">output</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">model</span><span class="s4">.</span><span class="s1">n_iter_</span><span class="s4">)</span>
    <span class="s3">return </span><span class="s1">tuple</span><span class="s4">(</span><span class="s1">output</span><span class="s4">)</span>


<span class="s3">class </span><span class="s1">BaseGraphicalLasso</span><span class="s4">(</span><span class="s1">EmpiricalCovariance</span><span class="s4">):</span>
    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s4">**</span><span class="s1">EmpiricalCovariance</span><span class="s4">.</span><span class="s1">_parameter_constraints</span><span class="s4">,</span>
        <span class="s6">&quot;tol&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s5">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s6">&quot;right&quot;</span><span class="s4">)],</span>
        <span class="s6">&quot;enet_tol&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s5">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s6">&quot;right&quot;</span><span class="s4">)],</span>
        <span class="s6">&quot;max_iter&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s5">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s6">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s6">&quot;mode&quot;</span><span class="s4">: [</span><span class="s1">StrOptions</span><span class="s4">({</span><span class="s6">&quot;cd&quot;</span><span class="s4">, </span><span class="s6">&quot;lars&quot;</span><span class="s4">})],</span>
        <span class="s6">&quot;verbose&quot;</span><span class="s4">: [</span><span class="s6">&quot;verbose&quot;</span><span class="s4">],</span>
        <span class="s6">&quot;eps&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s5">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s6">&quot;both&quot;</span><span class="s4">)],</span>
    <span class="s4">}</span>
    <span class="s1">_parameter_constraints</span><span class="s4">.</span><span class="s1">pop</span><span class="s4">(</span><span class="s6">&quot;store_precision&quot;</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">tol</span><span class="s4">=</span><span class="s5">1e-4</span><span class="s4">,</span>
        <span class="s1">enet_tol</span><span class="s4">=</span><span class="s5">1e-4</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s5">100</span><span class="s4">,</span>
        <span class="s1">mode</span><span class="s4">=</span><span class="s6">&quot;cd&quot;</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">eps</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">finfo</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">).</span><span class="s1">eps</span><span class="s4">,</span>
        <span class="s1">assume_centered</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">super</span><span class="s4">().</span><span class="s1">__init__</span><span class="s4">(</span><span class="s1">assume_centered</span><span class="s4">=</span><span class="s1">assume_centered</span><span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">tol </span><span class="s4">= </span><span class="s1">tol</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">enet_tol </span><span class="s4">= </span><span class="s1">enet_tol</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">max_iter </span><span class="s4">= </span><span class="s1">max_iter</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">mode </span><span class="s4">= </span><span class="s1">mode</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">verbose </span><span class="s4">= </span><span class="s1">verbose</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">eps </span><span class="s4">= </span><span class="s1">eps</span>


<span class="s3">class </span><span class="s1">GraphicalLasso</span><span class="s4">(</span><span class="s1">BaseGraphicalLasso</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Sparse inverse covariance estimation with an l1-penalized estimator. 
 
    For a usage example see 
    :ref:`sphx_glr_auto_examples_applications_plot_stock_market.py`. 
 
    Read more in the :ref:`User Guide &lt;sparse_inverse_covariance&gt;`. 
 
    .. versionchanged:: v0.20 
        GraphLasso has been renamed to GraphicalLasso 
 
    Parameters 
    ---------- 
    alpha : float, default=0.01 
        The regularization parameter: the higher alpha, the more 
        regularization, the sparser the inverse covariance. 
        Range is (0, inf]. 
 
    mode : {'cd', 'lars'}, default='cd' 
        The Lasso solver to use: coordinate descent or LARS. Use LARS for 
        very sparse underlying graphs, where p &gt; n. Elsewhere prefer cd 
        which is more numerically stable. 
 
    covariance : &quot;precomputed&quot;, default=None 
        If covariance is &quot;precomputed&quot;, the input data in `fit` is assumed 
        to be the covariance matrix. If `None`, the empirical covariance 
        is estimated from the data `X`. 
 
        .. versionadded:: 1.3 
 
    tol : float, default=1e-4 
        The tolerance to declare convergence: if the dual gap goes below 
        this value, iterations are stopped. Range is (0, inf]. 
 
    enet_tol : float, default=1e-4 
        The tolerance for the elastic net solver used to calculate the descent 
        direction. This parameter controls the accuracy of the search direction 
        for a given column update, not of the overall parameter estimate. Only 
        used for mode='cd'. Range is (0, inf]. 
 
    max_iter : int, default=100 
        The maximum number of iterations. 
 
    verbose : bool, default=False 
        If verbose is True, the objective function and dual gap are 
        plotted at each iteration. 
 
    eps : float, default=eps 
        The machine-precision regularization in the computation of the 
        Cholesky diagonal factors. Increase this for very ill-conditioned 
        systems. Default is `np.finfo(np.float64).eps`. 
 
        .. versionadded:: 1.3 
 
    assume_centered : bool, default=False 
        If True, data are not centered before computation. 
        Useful when working with data whose mean is almost, but not exactly 
        zero. 
        If False, data are centered before computation. 
 
    Attributes 
    ---------- 
    location_ : ndarray of shape (n_features,) 
        Estimated location, i.e. the estimated mean. 
 
    covariance_ : ndarray of shape (n_features, n_features) 
        Estimated covariance matrix 
 
    precision_ : ndarray of shape (n_features, n_features) 
        Estimated pseudo inverse matrix. 
 
    n_iter_ : int 
        Number of iterations run. 
 
    costs_ : list of (objective, dual_gap) pairs 
        The list of values of the objective function and the dual gap at 
        each iteration. Returned only if return_costs is True. 
 
        .. versionadded:: 1.3 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    See Also 
    -------- 
    graphical_lasso : L1-penalized covariance estimator. 
    GraphicalLassoCV : Sparse inverse covariance with 
        cross-validated choice of the l1 penalty. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.covariance import GraphicalLasso 
    &gt;&gt;&gt; true_cov = np.array([[0.8, 0.0, 0.2, 0.0], 
    ...                      [0.0, 0.4, 0.0, 0.0], 
    ...                      [0.2, 0.0, 0.3, 0.1], 
    ...                      [0.0, 0.0, 0.1, 0.7]]) 
    &gt;&gt;&gt; np.random.seed(0) 
    &gt;&gt;&gt; X = np.random.multivariate_normal(mean=[0, 0, 0, 0], 
    ...                                   cov=true_cov, 
    ...                                   size=200) 
    &gt;&gt;&gt; cov = GraphicalLasso().fit(X) 
    &gt;&gt;&gt; np.around(cov.covariance_, decimals=3) 
    array([[0.816, 0.049, 0.218, 0.019], 
           [0.049, 0.364, 0.017, 0.034], 
           [0.218, 0.017, 0.322, 0.093], 
           [0.019, 0.034, 0.093, 0.69 ]]) 
    &gt;&gt;&gt; np.around(cov.location_, decimals=3) 
    array([0.073, 0.04 , 0.038, 0.143]) 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s4">**</span><span class="s1">BaseGraphicalLasso</span><span class="s4">.</span><span class="s1">_parameter_constraints</span><span class="s4">,</span>
        <span class="s6">&quot;alpha&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s5">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s6">&quot;both&quot;</span><span class="s4">)],</span>
        <span class="s6">&quot;covariance&quot;</span><span class="s4">: [</span><span class="s1">StrOptions</span><span class="s4">({</span><span class="s6">&quot;precomputed&quot;</span><span class="s4">}), </span><span class="s3">None</span><span class="s4">],</span>
    <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s5">0.01</span><span class="s4">,</span>
        <span class="s4">*,</span>
        <span class="s1">mode</span><span class="s4">=</span><span class="s6">&quot;cd&quot;</span><span class="s4">,</span>
        <span class="s1">covariance</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">tol</span><span class="s4">=</span><span class="s5">1e-4</span><span class="s4">,</span>
        <span class="s1">enet_tol</span><span class="s4">=</span><span class="s5">1e-4</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s5">100</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">eps</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">finfo</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">).</span><span class="s1">eps</span><span class="s4">,</span>
        <span class="s1">assume_centered</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">super</span><span class="s4">().</span><span class="s1">__init__</span><span class="s4">(</span>
            <span class="s1">tol</span><span class="s4">=</span><span class="s1">tol</span><span class="s4">,</span>
            <span class="s1">enet_tol</span><span class="s4">=</span><span class="s1">enet_tol</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span><span class="s4">,</span>
            <span class="s1">mode</span><span class="s4">=</span><span class="s1">mode</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
            <span class="s1">eps</span><span class="s4">=</span><span class="s1">eps</span><span class="s4">,</span>
            <span class="s1">assume_centered</span><span class="s4">=</span><span class="s1">assume_centered</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">alpha </span><span class="s4">= </span><span class="s1">alpha</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">covariance </span><span class="s4">= </span><span class="s1">covariance</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Fit the GraphicalLasso model to X. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Data from which to compute the covariance estimate. 
 
        y : Ignored 
            Not used, present for API consistency by convention. 
 
        Returns 
        ------- 
        self : object 
            Returns the instance itself. 
        &quot;&quot;&quot;</span>
        <span class="s2"># Covariance does not make sense for a single feature</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">ensure_min_features</span><span class="s4">=</span><span class="s5">2</span><span class="s4">, </span><span class="s1">ensure_min_samples</span><span class="s4">=</span><span class="s5">2</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">covariance </span><span class="s4">== </span><span class="s6">&quot;precomputed&quot;</span><span class="s4">:</span>
            <span class="s1">emp_cov </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">copy</span><span class="s4">()</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">location_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">1</span><span class="s4">])</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">emp_cov </span><span class="s4">= </span><span class="s1">empirical_covariance</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">assume_centered</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">assume_centered</span><span class="s4">)</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">assume_centered</span><span class="s4">:</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">location_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">1</span><span class="s4">])</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">location_ </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">mean</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">covariance_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">precision_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">costs_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter_ </span><span class="s4">= </span><span class="s1">_graphical_lasso</span><span class="s4">(</span>
            <span class="s1">emp_cov</span><span class="s4">,</span>
            <span class="s1">alpha</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">alpha</span><span class="s4">,</span>
            <span class="s1">cov_init</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
            <span class="s1">mode</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">mode</span><span class="s4">,</span>
            <span class="s1">tol</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">tol</span><span class="s4">,</span>
            <span class="s1">enet_tol</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">enet_tol</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">max_iter</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">,</span>
            <span class="s1">eps</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">eps</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span>


<span class="s2"># Cross-validation with GraphicalLasso</span>
<span class="s3">def </span><span class="s1">graphical_lasso_path</span><span class="s4">(</span>
    <span class="s1">X</span><span class="s4">,</span>
    <span class="s1">alphas</span><span class="s4">,</span>
    <span class="s1">cov_init</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">X_test</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">mode</span><span class="s4">=</span><span class="s6">&quot;cd&quot;</span><span class="s4">,</span>
    <span class="s1">tol</span><span class="s4">=</span><span class="s5">1e-4</span><span class="s4">,</span>
    <span class="s1">enet_tol</span><span class="s4">=</span><span class="s5">1e-4</span><span class="s4">,</span>
    <span class="s1">max_iter</span><span class="s4">=</span><span class="s5">100</span><span class="s4">,</span>
    <span class="s1">verbose</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s1">eps</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">finfo</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">).</span><span class="s1">eps</span><span class="s4">,</span>
<span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;l1-penalized covariance estimator along a path of decreasing alphas 
 
    Read more in the :ref:`User Guide &lt;sparse_inverse_covariance&gt;`. 
 
    Parameters 
    ---------- 
    X : ndarray of shape (n_samples, n_features) 
        Data from which to compute the covariance estimate. 
 
    alphas : array-like of shape (n_alphas,) 
        The list of regularization parameters, decreasing order. 
 
    cov_init : array of shape (n_features, n_features), default=None 
        The initial guess for the covariance. 
 
    X_test : array of shape (n_test_samples, n_features), default=None 
        Optional test matrix to measure generalisation error. 
 
    mode : {'cd', 'lars'}, default='cd' 
        The Lasso solver to use: coordinate descent or LARS. Use LARS for 
        very sparse underlying graphs, where p &gt; n. Elsewhere prefer cd 
        which is more numerically stable. 
 
    tol : float, default=1e-4 
        The tolerance to declare convergence: if the dual gap goes below 
        this value, iterations are stopped. The tolerance must be a positive 
        number. 
 
    enet_tol : float, default=1e-4 
        The tolerance for the elastic net solver used to calculate the descent 
        direction. This parameter controls the accuracy of the search direction 
        for a given column update, not of the overall parameter estimate. Only 
        used for mode='cd'. The tolerance must be a positive number. 
 
    max_iter : int, default=100 
        The maximum number of iterations. This parameter should be a strictly 
        positive integer. 
 
    verbose : int or bool, default=False 
        The higher the verbosity flag, the more information is printed 
        during the fitting. 
 
    eps : float, default=eps 
        The machine-precision regularization in the computation of the 
        Cholesky diagonal factors. Increase this for very ill-conditioned 
        systems. Default is `np.finfo(np.float64).eps`. 
 
        .. versionadded:: 1.3 
 
    Returns 
    ------- 
    covariances_ : list of shape (n_alphas,) of ndarray of shape \ 
            (n_features, n_features) 
        The estimated covariance matrices. 
 
    precisions_ : list of shape (n_alphas,) of ndarray of shape \ 
            (n_features, n_features) 
        The estimated (sparse) precision matrices. 
 
    scores_ : list of shape (n_alphas,), dtype=float 
        The generalisation error (log-likelihood) on the test data. 
        Returned only if test data is passed. 
    &quot;&quot;&quot;</span>
    <span class="s1">inner_verbose </span><span class="s4">= </span><span class="s1">max</span><span class="s4">(</span><span class="s5">0</span><span class="s4">, </span><span class="s1">verbose </span><span class="s4">- </span><span class="s5">1</span><span class="s4">)</span>
    <span class="s1">emp_cov </span><span class="s4">= </span><span class="s1">empirical_covariance</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
    <span class="s3">if </span><span class="s1">cov_init </span><span class="s3">is None</span><span class="s4">:</span>
        <span class="s1">covariance_ </span><span class="s4">= </span><span class="s1">emp_cov</span><span class="s4">.</span><span class="s1">copy</span><span class="s4">()</span>
    <span class="s3">else</span><span class="s4">:</span>
        <span class="s1">covariance_ </span><span class="s4">= </span><span class="s1">cov_init</span>
    <span class="s1">covariances_ </span><span class="s4">= </span><span class="s1">list</span><span class="s4">()</span>
    <span class="s1">precisions_ </span><span class="s4">= </span><span class="s1">list</span><span class="s4">()</span>
    <span class="s1">scores_ </span><span class="s4">= </span><span class="s1">list</span><span class="s4">()</span>
    <span class="s3">if </span><span class="s1">X_test </span><span class="s3">is not None</span><span class="s4">:</span>
        <span class="s1">test_emp_cov </span><span class="s4">= </span><span class="s1">empirical_covariance</span><span class="s4">(</span><span class="s1">X_test</span><span class="s4">)</span>

    <span class="s3">for </span><span class="s1">alpha </span><span class="s3">in </span><span class="s1">alphas</span><span class="s4">:</span>
        <span class="s3">try</span><span class="s4">:</span>
            <span class="s2"># Capture the errors, and move on</span>
            <span class="s1">covariance_</span><span class="s4">, </span><span class="s1">precision_</span><span class="s4">, </span><span class="s1">_</span><span class="s4">, </span><span class="s1">_ </span><span class="s4">= </span><span class="s1">_graphical_lasso</span><span class="s4">(</span>
                <span class="s1">emp_cov</span><span class="s4">,</span>
                <span class="s1">alpha</span><span class="s4">=</span><span class="s1">alpha</span><span class="s4">,</span>
                <span class="s1">cov_init</span><span class="s4">=</span><span class="s1">covariance_</span><span class="s4">,</span>
                <span class="s1">mode</span><span class="s4">=</span><span class="s1">mode</span><span class="s4">,</span>
                <span class="s1">tol</span><span class="s4">=</span><span class="s1">tol</span><span class="s4">,</span>
                <span class="s1">enet_tol</span><span class="s4">=</span><span class="s1">enet_tol</span><span class="s4">,</span>
                <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span><span class="s4">,</span>
                <span class="s1">verbose</span><span class="s4">=</span><span class="s1">inner_verbose</span><span class="s4">,</span>
                <span class="s1">eps</span><span class="s4">=</span><span class="s1">eps</span><span class="s4">,</span>
            <span class="s4">)</span>
            <span class="s1">covariances_</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">covariance_</span><span class="s4">)</span>
            <span class="s1">precisions_</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">precision_</span><span class="s4">)</span>
            <span class="s3">if </span><span class="s1">X_test </span><span class="s3">is not None</span><span class="s4">:</span>
                <span class="s1">this_score </span><span class="s4">= </span><span class="s1">log_likelihood</span><span class="s4">(</span><span class="s1">test_emp_cov</span><span class="s4">, </span><span class="s1">precision_</span><span class="s4">)</span>
        <span class="s3">except </span><span class="s1">FloatingPointError</span><span class="s4">:</span>
            <span class="s1">this_score </span><span class="s4">= -</span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span>
            <span class="s1">covariances_</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">nan</span><span class="s4">)</span>
            <span class="s1">precisions_</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">nan</span><span class="s4">)</span>
        <span class="s3">if </span><span class="s1">X_test </span><span class="s3">is not None</span><span class="s4">:</span>
            <span class="s3">if not </span><span class="s1">np</span><span class="s4">.</span><span class="s1">isfinite</span><span class="s4">(</span><span class="s1">this_score</span><span class="s4">):</span>
                <span class="s1">this_score </span><span class="s4">= -</span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span>
            <span class="s1">scores_</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">this_score</span><span class="s4">)</span>
        <span class="s3">if </span><span class="s1">verbose </span><span class="s4">== </span><span class="s5">1</span><span class="s4">:</span>
            <span class="s1">sys</span><span class="s4">.</span><span class="s1">stderr</span><span class="s4">.</span><span class="s1">write</span><span class="s4">(</span><span class="s6">&quot;.&quot;</span><span class="s4">)</span>
        <span class="s3">elif </span><span class="s1">verbose </span><span class="s4">&gt; </span><span class="s5">1</span><span class="s4">:</span>
            <span class="s3">if </span><span class="s1">X_test </span><span class="s3">is not None</span><span class="s4">:</span>
                <span class="s1">print</span><span class="s4">(</span>
                    <span class="s6">&quot;[graphical_lasso_path] alpha: %.2e, score: %.2e&quot;</span>
                    <span class="s4">% (</span><span class="s1">alpha</span><span class="s4">, </span><span class="s1">this_score</span><span class="s4">)</span>
                <span class="s4">)</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s1">print</span><span class="s4">(</span><span class="s6">&quot;[graphical_lasso_path] alpha: %.2e&quot; </span><span class="s4">% </span><span class="s1">alpha</span><span class="s4">)</span>
    <span class="s3">if </span><span class="s1">X_test </span><span class="s3">is not None</span><span class="s4">:</span>
        <span class="s3">return </span><span class="s1">covariances_</span><span class="s4">, </span><span class="s1">precisions_</span><span class="s4">, </span><span class="s1">scores_</span>
    <span class="s3">return </span><span class="s1">covariances_</span><span class="s4">, </span><span class="s1">precisions_</span>


<span class="s3">class </span><span class="s1">GraphicalLassoCV</span><span class="s4">(</span><span class="s1">BaseGraphicalLasso</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Sparse inverse covariance w/ cross-validated choice of the l1 penalty. 
 
    See glossary entry for :term:`cross-validation estimator`. 
 
    Read more in the :ref:`User Guide &lt;sparse_inverse_covariance&gt;`. 
 
    .. versionchanged:: v0.20 
        GraphLassoCV has been renamed to GraphicalLassoCV 
 
    Parameters 
    ---------- 
    alphas : int or array-like of shape (n_alphas,), dtype=float, default=4 
        If an integer is given, it fixes the number of points on the 
        grids of alpha to be used. If a list is given, it gives the 
        grid to be used. See the notes in the class docstring for 
        more details. Range is [1, inf) for an integer. 
        Range is (0, inf] for an array-like of floats. 
 
    n_refinements : int, default=4 
        The number of times the grid is refined. Not used if explicit 
        values of alphas are passed. Range is [1, inf). 
 
    cv : int, cross-validation generator or iterable, default=None 
        Determines the cross-validation splitting strategy. 
        Possible inputs for cv are: 
 
        - None, to use the default 5-fold cross-validation, 
        - integer, to specify the number of folds. 
        - :term:`CV splitter`, 
        - An iterable yielding (train, test) splits as arrays of indices. 
 
        For integer/None inputs :class:`~sklearn.model_selection.KFold` is used. 
 
        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various 
        cross-validation strategies that can be used here. 
 
        .. versionchanged:: 0.20 
            ``cv`` default value if None changed from 3-fold to 5-fold. 
 
    tol : float, default=1e-4 
        The tolerance to declare convergence: if the dual gap goes below 
        this value, iterations are stopped. Range is (0, inf]. 
 
    enet_tol : float, default=1e-4 
        The tolerance for the elastic net solver used to calculate the descent 
        direction. This parameter controls the accuracy of the search direction 
        for a given column update, not of the overall parameter estimate. Only 
        used for mode='cd'. Range is (0, inf]. 
 
    max_iter : int, default=100 
        Maximum number of iterations. 
 
    mode : {'cd', 'lars'}, default='cd' 
        The Lasso solver to use: coordinate descent or LARS. Use LARS for 
        very sparse underlying graphs, where number of features is greater 
        than number of samples. Elsewhere prefer cd which is more numerically 
        stable. 
 
    n_jobs : int, default=None 
        Number of jobs to run in parallel. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
        .. versionchanged:: v0.20 
           `n_jobs` default changed from 1 to None 
 
    verbose : bool, default=False 
        If verbose is True, the objective function and duality gap are 
        printed at each iteration. 
 
    eps : float, default=eps 
        The machine-precision regularization in the computation of the 
        Cholesky diagonal factors. Increase this for very ill-conditioned 
        systems. Default is `np.finfo(np.float64).eps`. 
 
        .. versionadded:: 1.3 
 
    assume_centered : bool, default=False 
        If True, data are not centered before computation. 
        Useful when working with data whose mean is almost, but not exactly 
        zero. 
        If False, data are centered before computation. 
 
    Attributes 
    ---------- 
    location_ : ndarray of shape (n_features,) 
        Estimated location, i.e. the estimated mean. 
 
    covariance_ : ndarray of shape (n_features, n_features) 
        Estimated covariance matrix. 
 
    precision_ : ndarray of shape (n_features, n_features) 
        Estimated precision matrix (inverse covariance). 
 
    costs_ : list of (objective, dual_gap) pairs 
        The list of values of the objective function and the dual gap at 
        each iteration. Returned only if return_costs is True. 
 
        .. versionadded:: 1.3 
 
    alpha_ : float 
        Penalization parameter selected. 
 
    cv_results_ : dict of ndarrays 
        A dict with keys: 
 
        alphas : ndarray of shape (n_alphas,) 
            All penalization parameters explored. 
 
        split(k)_test_score : ndarray of shape (n_alphas,) 
            Log-likelihood score on left-out data across (k)th fold. 
 
            .. versionadded:: 1.0 
 
        mean_test_score : ndarray of shape (n_alphas,) 
            Mean of scores over the folds. 
 
            .. versionadded:: 1.0 
 
        std_test_score : ndarray of shape (n_alphas,) 
            Standard deviation of scores over the folds. 
 
            .. versionadded:: 1.0 
 
    n_iter_ : int 
        Number of iterations run for the optimal alpha. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    See Also 
    -------- 
    graphical_lasso : L1-penalized covariance estimator. 
    GraphicalLasso : Sparse inverse covariance estimation 
        with an l1-penalized estimator. 
 
    Notes 
    ----- 
    The search for the optimal penalization parameter (`alpha`) is done on an 
    iteratively refined grid: first the cross-validated scores on a grid are 
    computed, then a new refined grid is centered around the maximum, and so 
    on. 
 
    One of the challenges which is faced here is that the solvers can 
    fail to converge to a well-conditioned estimate. The corresponding 
    values of `alpha` then come out as missing values, but the optimum may 
    be close to these missing values. 
 
    In `fit`, once the best parameter `alpha` is found through 
    cross-validation, the model is fit again using the entire training set. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.covariance import GraphicalLassoCV 
    &gt;&gt;&gt; true_cov = np.array([[0.8, 0.0, 0.2, 0.0], 
    ...                      [0.0, 0.4, 0.0, 0.0], 
    ...                      [0.2, 0.0, 0.3, 0.1], 
    ...                      [0.0, 0.0, 0.1, 0.7]]) 
    &gt;&gt;&gt; np.random.seed(0) 
    &gt;&gt;&gt; X = np.random.multivariate_normal(mean=[0, 0, 0, 0], 
    ...                                   cov=true_cov, 
    ...                                   size=200) 
    &gt;&gt;&gt; cov = GraphicalLassoCV().fit(X) 
    &gt;&gt;&gt; np.around(cov.covariance_, decimals=3) 
    array([[0.816, 0.051, 0.22 , 0.017], 
           [0.051, 0.364, 0.018, 0.036], 
           [0.22 , 0.018, 0.322, 0.094], 
           [0.017, 0.036, 0.094, 0.69 ]]) 
    &gt;&gt;&gt; np.around(cov.location_, decimals=3) 
    array([0.073, 0.04 , 0.038, 0.143]) 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s4">**</span><span class="s1">BaseGraphicalLasso</span><span class="s4">.</span><span class="s1">_parameter_constraints</span><span class="s4">,</span>
        <span class="s6">&quot;alphas&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s5">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s6">&quot;left&quot;</span><span class="s4">), </span><span class="s6">&quot;array-like&quot;</span><span class="s4">],</span>
        <span class="s6">&quot;n_refinements&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s5">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s6">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s6">&quot;cv&quot;</span><span class="s4">: [</span><span class="s6">&quot;cv_object&quot;</span><span class="s4">],</span>
        <span class="s6">&quot;n_jobs&quot;</span><span class="s4">: [</span><span class="s1">Integral</span><span class="s4">, </span><span class="s3">None</span><span class="s4">],</span>
    <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s4">*,</span>
        <span class="s1">alphas</span><span class="s4">=</span><span class="s5">4</span><span class="s4">,</span>
        <span class="s1">n_refinements</span><span class="s4">=</span><span class="s5">4</span><span class="s4">,</span>
        <span class="s1">cv</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">tol</span><span class="s4">=</span><span class="s5">1e-4</span><span class="s4">,</span>
        <span class="s1">enet_tol</span><span class="s4">=</span><span class="s5">1e-4</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s5">100</span><span class="s4">,</span>
        <span class="s1">mode</span><span class="s4">=</span><span class="s6">&quot;cd&quot;</span><span class="s4">,</span>
        <span class="s1">n_jobs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">eps</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">finfo</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">).</span><span class="s1">eps</span><span class="s4">,</span>
        <span class="s1">assume_centered</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">super</span><span class="s4">().</span><span class="s1">__init__</span><span class="s4">(</span>
            <span class="s1">tol</span><span class="s4">=</span><span class="s1">tol</span><span class="s4">,</span>
            <span class="s1">enet_tol</span><span class="s4">=</span><span class="s1">enet_tol</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span><span class="s4">,</span>
            <span class="s1">mode</span><span class="s4">=</span><span class="s1">mode</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
            <span class="s1">eps</span><span class="s4">=</span><span class="s1">eps</span><span class="s4">,</span>
            <span class="s1">assume_centered</span><span class="s4">=</span><span class="s1">assume_centered</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">alphas </span><span class="s4">= </span><span class="s1">alphas</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_refinements </span><span class="s4">= </span><span class="s1">n_refinements</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">cv </span><span class="s4">= </span><span class="s1">cv</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_jobs </span><span class="s4">= </span><span class="s1">n_jobs</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">, **</span><span class="s1">params</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Fit the GraphicalLasso covariance model to X. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Data from which to compute the covariance estimate. 
 
        y : Ignored 
            Not used, present for API consistency by convention. 
 
        **params : dict, default=None 
            Parameters to be passed to the CV splitter and the 
            cross_val_score function. 
 
            .. versionadded:: 1.5 
                Only available if `enable_metadata_routing=True`, 
                which can be set by using 
                ``sklearn.set_config(enable_metadata_routing=True)``. 
                See :ref:`Metadata Routing User Guide &lt;metadata_routing&gt;` for 
                more details. 
 
        Returns 
        ------- 
        self : object 
            Returns the instance itself. 
        &quot;&quot;&quot;</span>
        <span class="s2"># Covariance does not make sense for a single feature</span>
        <span class="s1">_raise_for_params</span><span class="s4">(</span><span class="s1">params</span><span class="s4">, </span><span class="s1">self</span><span class="s4">, </span><span class="s6">&quot;fit&quot;</span><span class="s4">)</span>

        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">ensure_min_features</span><span class="s4">=</span><span class="s5">2</span><span class="s4">)</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">assume_centered</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">location_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">1</span><span class="s4">])</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">location_ </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">mean</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>
        <span class="s1">emp_cov </span><span class="s4">= </span><span class="s1">empirical_covariance</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">assume_centered</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">assume_centered</span><span class="s4">)</span>

        <span class="s1">cv </span><span class="s4">= </span><span class="s1">check_cv</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">cv</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, </span><span class="s1">classifier</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>

        <span class="s2"># List of (alpha, scores, covs)</span>
        <span class="s1">path </span><span class="s4">= </span><span class="s1">list</span><span class="s4">()</span>
        <span class="s1">n_alphas </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">alphas</span>
        <span class="s1">inner_verbose </span><span class="s4">= </span><span class="s1">max</span><span class="s4">(</span><span class="s5">0</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose </span><span class="s4">- </span><span class="s5">1</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">_is_arraylike_not_scalar</span><span class="s4">(</span><span class="s1">n_alphas</span><span class="s4">):</span>
            <span class="s3">for </span><span class="s1">alpha </span><span class="s3">in </span><span class="s1">self</span><span class="s4">.</span><span class="s1">alphas</span><span class="s4">:</span>
                <span class="s1">check_scalar</span><span class="s4">(</span>
                    <span class="s1">alpha</span><span class="s4">,</span>
                    <span class="s6">&quot;alpha&quot;</span><span class="s4">,</span>
                    <span class="s1">Real</span><span class="s4">,</span>
                    <span class="s1">min_val</span><span class="s4">=</span><span class="s5">0</span><span class="s4">,</span>
                    <span class="s1">max_val</span><span class="s4">=</span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span><span class="s4">,</span>
                    <span class="s1">include_boundaries</span><span class="s4">=</span><span class="s6">&quot;right&quot;</span><span class="s4">,</span>
                <span class="s4">)</span>
            <span class="s1">alphas </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">alphas</span>
            <span class="s1">n_refinements </span><span class="s4">= </span><span class="s5">1</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">n_refinements </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_refinements</span>
            <span class="s1">alpha_1 </span><span class="s4">= </span><span class="s1">alpha_max</span><span class="s4">(</span><span class="s1">emp_cov</span><span class="s4">)</span>
            <span class="s1">alpha_0 </span><span class="s4">= </span><span class="s5">1e-2 </span><span class="s4">* </span><span class="s1">alpha_1</span>
            <span class="s1">alphas </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">logspace</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">log10</span><span class="s4">(</span><span class="s1">alpha_0</span><span class="s4">), </span><span class="s1">np</span><span class="s4">.</span><span class="s1">log10</span><span class="s4">(</span><span class="s1">alpha_1</span><span class="s4">), </span><span class="s1">n_alphas</span><span class="s4">)[::-</span><span class="s5">1</span><span class="s4">]</span>

        <span class="s3">if </span><span class="s1">_routing_enabled</span><span class="s4">():</span>
            <span class="s1">routed_params </span><span class="s4">= </span><span class="s1">process_routing</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s6">&quot;fit&quot;</span><span class="s4">, **</span><span class="s1">params</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">routed_params </span><span class="s4">= </span><span class="s1">Bunch</span><span class="s4">(</span><span class="s1">splitter</span><span class="s4">=</span><span class="s1">Bunch</span><span class="s4">(</span><span class="s1">split</span><span class="s4">={}))</span>

        <span class="s1">t0 </span><span class="s4">= </span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">()</span>
        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">n_refinements</span><span class="s4">):</span>
            <span class="s3">with </span><span class="s1">warnings</span><span class="s4">.</span><span class="s1">catch_warnings</span><span class="s4">():</span>
                <span class="s2"># No need to see the convergence warnings on this grid:</span>
                <span class="s2"># they will always be points that will not converge</span>
                <span class="s2"># during the cross-validation</span>
                <span class="s1">warnings</span><span class="s4">.</span><span class="s1">simplefilter</span><span class="s4">(</span><span class="s6">&quot;ignore&quot;</span><span class="s4">, </span><span class="s1">ConvergenceWarning</span><span class="s4">)</span>
                <span class="s2"># Compute the cross-validated loss on the current grid</span>

                <span class="s2"># NOTE: Warm-restarting graphical_lasso_path has been tried,</span>
                <span class="s2"># and this did not allow to gain anything</span>
                <span class="s2"># (same execution time with or without).</span>
                <span class="s1">this_path </span><span class="s4">= </span><span class="s1">Parallel</span><span class="s4">(</span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_jobs</span><span class="s4">, </span><span class="s1">verbose</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">)(</span>
                    <span class="s1">delayed</span><span class="s4">(</span><span class="s1">graphical_lasso_path</span><span class="s4">)(</span>
                        <span class="s1">X</span><span class="s4">[</span><span class="s1">train</span><span class="s4">],</span>
                        <span class="s1">alphas</span><span class="s4">=</span><span class="s1">alphas</span><span class="s4">,</span>
                        <span class="s1">X_test</span><span class="s4">=</span><span class="s1">X</span><span class="s4">[</span><span class="s1">test</span><span class="s4">],</span>
                        <span class="s1">mode</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">mode</span><span class="s4">,</span>
                        <span class="s1">tol</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">tol</span><span class="s4">,</span>
                        <span class="s1">enet_tol</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">enet_tol</span><span class="s4">,</span>
                        <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">int</span><span class="s4">(</span><span class="s5">0.1 </span><span class="s4">* </span><span class="s1">self</span><span class="s4">.</span><span class="s1">max_iter</span><span class="s4">),</span>
                        <span class="s1">verbose</span><span class="s4">=</span><span class="s1">inner_verbose</span><span class="s4">,</span>
                        <span class="s1">eps</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">eps</span><span class="s4">,</span>
                    <span class="s4">)</span>
                    <span class="s3">for </span><span class="s1">train</span><span class="s4">, </span><span class="s1">test </span><span class="s3">in </span><span class="s1">cv</span><span class="s4">.</span><span class="s1">split</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">, **</span><span class="s1">routed_params</span><span class="s4">.</span><span class="s1">splitter</span><span class="s4">.</span><span class="s1">split</span><span class="s4">)</span>
                <span class="s4">)</span>

            <span class="s2"># Little danse to transform the list in what we need</span>
            <span class="s1">covs</span><span class="s4">, </span><span class="s1">_</span><span class="s4">, </span><span class="s1">scores </span><span class="s4">= </span><span class="s1">zip</span><span class="s4">(*</span><span class="s1">this_path</span><span class="s4">)</span>
            <span class="s1">covs </span><span class="s4">= </span><span class="s1">zip</span><span class="s4">(*</span><span class="s1">covs</span><span class="s4">)</span>
            <span class="s1">scores </span><span class="s4">= </span><span class="s1">zip</span><span class="s4">(*</span><span class="s1">scores</span><span class="s4">)</span>
            <span class="s1">path</span><span class="s4">.</span><span class="s1">extend</span><span class="s4">(</span><span class="s1">zip</span><span class="s4">(</span><span class="s1">alphas</span><span class="s4">, </span><span class="s1">scores</span><span class="s4">, </span><span class="s1">covs</span><span class="s4">))</span>
            <span class="s1">path </span><span class="s4">= </span><span class="s1">sorted</span><span class="s4">(</span><span class="s1">path</span><span class="s4">, </span><span class="s1">key</span><span class="s4">=</span><span class="s1">operator</span><span class="s4">.</span><span class="s1">itemgetter</span><span class="s4">(</span><span class="s5">0</span><span class="s4">), </span><span class="s1">reverse</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>

            <span class="s2"># Find the maximum (avoid using built in 'max' function to</span>
            <span class="s2"># have a fully-reproducible selection of the smallest alpha</span>
            <span class="s2"># in case of equality)</span>
            <span class="s1">best_score </span><span class="s4">= -</span><span class="s1">np</span><span class="s4">.</span><span class="s1">inf</span>
            <span class="s1">last_finite_idx </span><span class="s4">= </span><span class="s5">0</span>
            <span class="s3">for </span><span class="s1">index</span><span class="s4">, (</span><span class="s1">alpha</span><span class="s4">, </span><span class="s1">scores</span><span class="s4">, </span><span class="s1">_</span><span class="s4">) </span><span class="s3">in </span><span class="s1">enumerate</span><span class="s4">(</span><span class="s1">path</span><span class="s4">):</span>
                <span class="s1">this_score </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">mean</span><span class="s4">(</span><span class="s1">scores</span><span class="s4">)</span>
                <span class="s3">if </span><span class="s1">this_score </span><span class="s4">&gt;= </span><span class="s5">0.1 </span><span class="s4">/ </span><span class="s1">np</span><span class="s4">.</span><span class="s1">finfo</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">).</span><span class="s1">eps</span><span class="s4">:</span>
                    <span class="s1">this_score </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">nan</span>
                <span class="s3">if </span><span class="s1">np</span><span class="s4">.</span><span class="s1">isfinite</span><span class="s4">(</span><span class="s1">this_score</span><span class="s4">):</span>
                    <span class="s1">last_finite_idx </span><span class="s4">= </span><span class="s1">index</span>
                <span class="s3">if </span><span class="s1">this_score </span><span class="s4">&gt;= </span><span class="s1">best_score</span><span class="s4">:</span>
                    <span class="s1">best_score </span><span class="s4">= </span><span class="s1">this_score</span>
                    <span class="s1">best_index </span><span class="s4">= </span><span class="s1">index</span>

            <span class="s2"># Refine the grid</span>
            <span class="s3">if </span><span class="s1">best_index </span><span class="s4">== </span><span class="s5">0</span><span class="s4">:</span>
                <span class="s2"># We do not need to go back: we have chosen</span>
                <span class="s2"># the highest value of alpha for which there are</span>
                <span class="s2"># non-zero coefficients</span>
                <span class="s1">alpha_1 </span><span class="s4">= </span><span class="s1">path</span><span class="s4">[</span><span class="s5">0</span><span class="s4">][</span><span class="s5">0</span><span class="s4">]</span>
                <span class="s1">alpha_0 </span><span class="s4">= </span><span class="s1">path</span><span class="s4">[</span><span class="s5">1</span><span class="s4">][</span><span class="s5">0</span><span class="s4">]</span>
            <span class="s3">elif </span><span class="s1">best_index </span><span class="s4">== </span><span class="s1">last_finite_idx </span><span class="s3">and not </span><span class="s1">best_index </span><span class="s4">== </span><span class="s1">len</span><span class="s4">(</span><span class="s1">path</span><span class="s4">) - </span><span class="s5">1</span><span class="s4">:</span>
                <span class="s2"># We have non-converged models on the upper bound of the</span>
                <span class="s2"># grid, we need to refine the grid there</span>
                <span class="s1">alpha_1 </span><span class="s4">= </span><span class="s1">path</span><span class="s4">[</span><span class="s1">best_index</span><span class="s4">][</span><span class="s5">0</span><span class="s4">]</span>
                <span class="s1">alpha_0 </span><span class="s4">= </span><span class="s1">path</span><span class="s4">[</span><span class="s1">best_index </span><span class="s4">+ </span><span class="s5">1</span><span class="s4">][</span><span class="s5">0</span><span class="s4">]</span>
            <span class="s3">elif </span><span class="s1">best_index </span><span class="s4">== </span><span class="s1">len</span><span class="s4">(</span><span class="s1">path</span><span class="s4">) - </span><span class="s5">1</span><span class="s4">:</span>
                <span class="s1">alpha_1 </span><span class="s4">= </span><span class="s1">path</span><span class="s4">[</span><span class="s1">best_index</span><span class="s4">][</span><span class="s5">0</span><span class="s4">]</span>
                <span class="s1">alpha_0 </span><span class="s4">= </span><span class="s5">0.01 </span><span class="s4">* </span><span class="s1">path</span><span class="s4">[</span><span class="s1">best_index</span><span class="s4">][</span><span class="s5">0</span><span class="s4">]</span>
            <span class="s3">else</span><span class="s4">:</span>
                <span class="s1">alpha_1 </span><span class="s4">= </span><span class="s1">path</span><span class="s4">[</span><span class="s1">best_index </span><span class="s4">- </span><span class="s5">1</span><span class="s4">][</span><span class="s5">0</span><span class="s4">]</span>
                <span class="s1">alpha_0 </span><span class="s4">= </span><span class="s1">path</span><span class="s4">[</span><span class="s1">best_index </span><span class="s4">+ </span><span class="s5">1</span><span class="s4">][</span><span class="s5">0</span><span class="s4">]</span>

            <span class="s3">if not </span><span class="s1">_is_arraylike_not_scalar</span><span class="s4">(</span><span class="s1">n_alphas</span><span class="s4">):</span>
                <span class="s1">alphas </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">logspace</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">log10</span><span class="s4">(</span><span class="s1">alpha_1</span><span class="s4">), </span><span class="s1">np</span><span class="s4">.</span><span class="s1">log10</span><span class="s4">(</span><span class="s1">alpha_0</span><span class="s4">), </span><span class="s1">n_alphas </span><span class="s4">+ </span><span class="s5">2</span><span class="s4">)</span>
                <span class="s1">alphas </span><span class="s4">= </span><span class="s1">alphas</span><span class="s4">[</span><span class="s5">1</span><span class="s4">:-</span><span class="s5">1</span><span class="s4">]</span>

            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose </span><span class="s3">and </span><span class="s1">n_refinements </span><span class="s4">&gt; </span><span class="s5">1</span><span class="s4">:</span>
                <span class="s1">print</span><span class="s4">(</span>
                    <span class="s6">&quot;[GraphicalLassoCV] Done refinement % 2i out of %i: % 3is&quot;</span>
                    <span class="s4">% (</span><span class="s1">i </span><span class="s4">+ </span><span class="s5">1</span><span class="s4">, </span><span class="s1">n_refinements</span><span class="s4">, </span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">() - </span><span class="s1">t0</span><span class="s4">)</span>
                <span class="s4">)</span>

        <span class="s1">path </span><span class="s4">= </span><span class="s1">list</span><span class="s4">(</span><span class="s1">zip</span><span class="s4">(*</span><span class="s1">path</span><span class="s4">))</span>
        <span class="s1">grid_scores </span><span class="s4">= </span><span class="s1">list</span><span class="s4">(</span><span class="s1">path</span><span class="s4">[</span><span class="s5">1</span><span class="s4">])</span>
        <span class="s1">alphas </span><span class="s4">= </span><span class="s1">list</span><span class="s4">(</span><span class="s1">path</span><span class="s4">[</span><span class="s5">0</span><span class="s4">])</span>
        <span class="s2"># Finally, compute the score with alpha = 0</span>
        <span class="s1">alphas</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s5">0</span><span class="s4">)</span>
        <span class="s1">grid_scores</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span>
            <span class="s1">cross_val_score</span><span class="s4">(</span>
                <span class="s1">EmpiricalCovariance</span><span class="s4">(),</span>
                <span class="s1">X</span><span class="s4">,</span>
                <span class="s1">cv</span><span class="s4">=</span><span class="s1">cv</span><span class="s4">,</span>
                <span class="s1">n_jobs</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_jobs</span><span class="s4">,</span>
                <span class="s1">verbose</span><span class="s4">=</span><span class="s1">inner_verbose</span><span class="s4">,</span>
                <span class="s1">params</span><span class="s4">=</span><span class="s1">params</span><span class="s4">,</span>
            <span class="s4">)</span>
        <span class="s4">)</span>
        <span class="s1">grid_scores </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span><span class="s1">grid_scores</span><span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">cv_results_ </span><span class="s4">= {</span><span class="s6">&quot;alphas&quot;</span><span class="s4">: </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span><span class="s1">alphas</span><span class="s4">)}</span>

        <span class="s3">for </span><span class="s1">i </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">grid_scores</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s5">1</span><span class="s4">]):</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">cv_results_</span><span class="s4">[</span><span class="s6">f&quot;split</span><span class="s3">{</span><span class="s1">i</span><span class="s3">}</span><span class="s6">_test_score&quot;</span><span class="s4">] = </span><span class="s1">grid_scores</span><span class="s4">[:, </span><span class="s1">i</span><span class="s4">]</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">cv_results_</span><span class="s4">[</span><span class="s6">&quot;mean_test_score&quot;</span><span class="s4">] = </span><span class="s1">np</span><span class="s4">.</span><span class="s1">mean</span><span class="s4">(</span><span class="s1">grid_scores</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">cv_results_</span><span class="s4">[</span><span class="s6">&quot;std_test_score&quot;</span><span class="s4">] = </span><span class="s1">np</span><span class="s4">.</span><span class="s1">std</span><span class="s4">(</span><span class="s1">grid_scores</span><span class="s4">, </span><span class="s1">axis</span><span class="s4">=</span><span class="s5">1</span><span class="s4">)</span>

        <span class="s1">best_alpha </span><span class="s4">= </span><span class="s1">alphas</span><span class="s4">[</span><span class="s1">best_index</span><span class="s4">]</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">alpha_ </span><span class="s4">= </span><span class="s1">best_alpha</span>

        <span class="s2"># Finally fit the model with the selected alpha</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">covariance_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">precision_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">costs_</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter_ </span><span class="s4">= </span><span class="s1">_graphical_lasso</span><span class="s4">(</span>
            <span class="s1">emp_cov</span><span class="s4">,</span>
            <span class="s1">alpha</span><span class="s4">=</span><span class="s1">best_alpha</span><span class="s4">,</span>
            <span class="s1">mode</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">mode</span><span class="s4">,</span>
            <span class="s1">tol</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">tol</span><span class="s4">,</span>
            <span class="s1">enet_tol</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">enet_tol</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">max_iter</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">inner_verbose</span><span class="s4">,</span>
            <span class="s1">eps</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">eps</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span>

    <span class="s3">def </span><span class="s1">get_metadata_routing</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Get metadata routing of this object. 
 
        Please check :ref:`User Guide &lt;metadata_routing&gt;` on how the routing 
        mechanism works. 
 
        .. versionadded:: 1.5 
 
        Returns 
        ------- 
        routing : MetadataRouter 
            A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating 
            routing information. 
        &quot;&quot;&quot;</span>
        <span class="s1">router </span><span class="s4">= </span><span class="s1">MetadataRouter</span><span class="s4">(</span><span class="s1">owner</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">__class__</span><span class="s4">.</span><span class="s1">__name__</span><span class="s4">).</span><span class="s1">add</span><span class="s4">(</span>
            <span class="s1">splitter</span><span class="s4">=</span><span class="s1">check_cv</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">cv</span><span class="s4">),</span>
            <span class="s1">method_mapping</span><span class="s4">=</span><span class="s1">MethodMapping</span><span class="s4">().</span><span class="s1">add</span><span class="s4">(</span><span class="s1">callee</span><span class="s4">=</span><span class="s6">&quot;split&quot;</span><span class="s4">, </span><span class="s1">caller</span><span class="s4">=</span><span class="s6">&quot;fit&quot;</span><span class="s4">),</span>
        <span class="s4">)</span>
        <span class="s3">return </span><span class="s1">router</span>
</pre>
</body>
</html>