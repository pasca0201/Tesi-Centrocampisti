<html>
<head>
<title>test_monotonic_tree.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cf8e6d;}
.s1 { color: #bcbec4;}
.s2 { color: #bcbec4;}
.s3 { color: #6aab73;}
.s4 { color: #2aacb8;}
.s5 { color: #7a7e85;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_monotonic_tree.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">import </span><span class="s1">pytest</span>

<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">datasets </span><span class="s0">import </span><span class="s1">make_classification</span><span class="s2">, </span><span class="s1">make_regression</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">ensemble </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">ExtraTreesClassifier</span><span class="s2">,</span>
    <span class="s1">ExtraTreesRegressor</span><span class="s2">,</span>
    <span class="s1">RandomForestClassifier</span><span class="s2">,</span>
    <span class="s1">RandomForestRegressor</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">tree </span><span class="s0">import </span><span class="s2">(</span>
    <span class="s1">DecisionTreeClassifier</span><span class="s2">,</span>
    <span class="s1">DecisionTreeRegressor</span><span class="s2">,</span>
    <span class="s1">ExtraTreeClassifier</span><span class="s2">,</span>
    <span class="s1">ExtraTreeRegressor</span><span class="s2">,</span>
<span class="s2">)</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">_testing </span><span class="s0">import </span><span class="s1">assert_allclose</span>
<span class="s0">from </span><span class="s1">sklearn</span><span class="s2">.</span><span class="s1">utils</span><span class="s2">.</span><span class="s1">fixes </span><span class="s0">import </span><span class="s1">CSC_CONTAINERS</span>

<span class="s1">TREE_CLASSIFIER_CLASSES </span><span class="s2">= [</span><span class="s1">DecisionTreeClassifier</span><span class="s2">, </span><span class="s1">ExtraTreeClassifier</span><span class="s2">]</span>
<span class="s1">TREE_REGRESSOR_CLASSES </span><span class="s2">= [</span><span class="s1">DecisionTreeRegressor</span><span class="s2">, </span><span class="s1">ExtraTreeRegressor</span><span class="s2">]</span>
<span class="s1">TREE_BASED_CLASSIFIER_CLASSES </span><span class="s2">= </span><span class="s1">TREE_CLASSIFIER_CLASSES </span><span class="s2">+ [</span>
    <span class="s1">RandomForestClassifier</span><span class="s2">,</span>
    <span class="s1">ExtraTreesClassifier</span><span class="s2">,</span>
<span class="s2">]</span>
<span class="s1">TREE_BASED_REGRESSOR_CLASSES </span><span class="s2">= </span><span class="s1">TREE_REGRESSOR_CLASSES </span><span class="s2">+ [</span>
    <span class="s1">RandomForestRegressor</span><span class="s2">,</span>
    <span class="s1">ExtraTreesRegressor</span><span class="s2">,</span>
<span class="s2">]</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;TreeClassifier&quot;</span><span class="s2">, </span><span class="s1">TREE_BASED_CLASSIFIER_CLASSES</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;depth_first_builder&quot;</span><span class="s2">, (</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;sparse_splitter&quot;</span><span class="s2">, (</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csc_container&quot;</span><span class="s2">, </span><span class="s1">CSC_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_monotonic_constraints_classifications</span><span class="s2">(</span>
    <span class="s1">TreeClassifier</span><span class="s2">,</span>
    <span class="s1">depth_first_builder</span><span class="s2">,</span>
    <span class="s1">sparse_splitter</span><span class="s2">,</span>
    <span class="s1">global_random_seed</span><span class="s2">,</span>
    <span class="s1">csc_container</span><span class="s2">,</span>
<span class="s2">):</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">1000</span>
    <span class="s1">n_samples_train </span><span class="s2">= </span><span class="s4">900</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">,</span>
        <span class="s1">n_classes</span><span class="s2">=</span><span class="s4">2</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s4">5</span><span class="s2">,</span>
        <span class="s1">n_informative</span><span class="s2">=</span><span class="s4">5</span><span class="s2">,</span>
        <span class="s1">n_redundant</span><span class="s2">=</span><span class="s4">0</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[:</span><span class="s1">n_samples_train</span><span class="s2">], </span><span class="s1">y</span><span class="s2">[:</span><span class="s1">n_samples_train</span><span class="s2">]</span>
    <span class="s1">X_test</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[</span><span class="s1">n_samples_train</span><span class="s2">:], </span><span class="s1">y</span><span class="s2">[</span><span class="s1">n_samples_train</span><span class="s2">:]</span>

    <span class="s1">X_test_0incr</span><span class="s2">, </span><span class="s1">X_test_0decr </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>
    <span class="s1">X_test_1incr</span><span class="s2">, </span><span class="s1">X_test_1decr </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>
    <span class="s1">X_test_0incr</span><span class="s2">[:, </span><span class="s4">0</span><span class="s2">] += </span><span class="s4">10</span>
    <span class="s1">X_test_0decr</span><span class="s2">[:, </span><span class="s4">0</span><span class="s2">] -= </span><span class="s4">10</span>
    <span class="s1">X_test_1incr</span><span class="s2">[:, </span><span class="s4">1</span><span class="s2">] += </span><span class="s4">10</span>
    <span class="s1">X_test_1decr</span><span class="s2">[:, </span><span class="s4">1</span><span class="s2">] -= </span><span class="s4">10</span>
    <span class="s1">monotonic_cst </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s1">monotonic_cst</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] = </span><span class="s4">1</span>
    <span class="s1">monotonic_cst</span><span class="s2">[</span><span class="s4">1</span><span class="s2">] = -</span><span class="s4">1</span>

    <span class="s0">if </span><span class="s1">depth_first_builder</span><span class="s2">:</span>
        <span class="s1">est </span><span class="s2">= </span><span class="s1">TreeClassifier</span><span class="s2">(</span><span class="s1">max_depth</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">est </span><span class="s2">= </span><span class="s1">TreeClassifier</span><span class="s2">(</span>
            <span class="s1">max_depth</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
            <span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">,</span>
            <span class="s1">max_leaf_nodes</span><span class="s2">=</span><span class="s1">n_samples_train</span><span class="s2">,</span>
        <span class="s2">)</span>
    <span class="s0">if </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">est</span><span class="s2">, </span><span class="s3">&quot;random_state&quot;</span><span class="s2">):</span>
        <span class="s1">est</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(**{</span><span class="s3">&quot;random_state&quot;</span><span class="s2">: </span><span class="s1">global_random_seed</span><span class="s2">})</span>
    <span class="s0">if </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">est</span><span class="s2">, </span><span class="s3">&quot;n_estimators&quot;</span><span class="s2">):</span>
        <span class="s1">est</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(**{</span><span class="s3">&quot;n_estimators&quot;</span><span class="s2">: </span><span class="s4">5</span><span class="s2">})</span>
    <span class="s0">if </span><span class="s1">sparse_splitter</span><span class="s2">:</span>
        <span class="s1">X_train </span><span class="s2">= </span><span class="s1">csc_container</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">)</span>
    <span class="s1">est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>
    <span class="s1">proba_test </span><span class="s2">= </span><span class="s1">est</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>

    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">logical_and</span><span class="s2">(</span>
        <span class="s1">proba_test </span><span class="s2">&gt;= </span><span class="s4">0.0</span><span class="s2">, </span><span class="s1">proba_test </span><span class="s2">&lt;= </span><span class="s4">1.0</span>
    <span class="s2">).</span><span class="s1">all</span><span class="s2">(), </span><span class="s3">&quot;Probability should always be in [0, 1] range.&quot;</span>
    <span class="s1">assert_allclose</span><span class="s2">(</span><span class="s1">proba_test</span><span class="s2">.</span><span class="s1">sum</span><span class="s2">(</span><span class="s1">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">), </span><span class="s4">1.0</span><span class="s2">)</span>

    <span class="s5"># Monotonic increase constraint, it applies to the positive class</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">est</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X_test_0incr</span><span class="s2">)[:, </span><span class="s4">1</span><span class="s2">] &gt;= </span><span class="s1">proba_test</span><span class="s2">[:, </span><span class="s4">1</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">est</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X_test_0decr</span><span class="s2">)[:, </span><span class="s4">1</span><span class="s2">] &lt;= </span><span class="s1">proba_test</span><span class="s2">[:, </span><span class="s4">1</span><span class="s2">])</span>

    <span class="s5"># Monotonic decrease constraint, it applies to the positive class</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">est</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X_test_1incr</span><span class="s2">)[:, </span><span class="s4">1</span><span class="s2">] &lt;= </span><span class="s1">proba_test</span><span class="s2">[:, </span><span class="s4">1</span><span class="s2">])</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">est</span><span class="s2">.</span><span class="s1">predict_proba</span><span class="s2">(</span><span class="s1">X_test_1decr</span><span class="s2">)[:, </span><span class="s4">1</span><span class="s2">] &gt;= </span><span class="s1">proba_test</span><span class="s2">[:, </span><span class="s4">1</span><span class="s2">])</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;TreeRegressor&quot;</span><span class="s2">, </span><span class="s1">TREE_BASED_REGRESSOR_CLASSES</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;depth_first_builder&quot;</span><span class="s2">, (</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;sparse_splitter&quot;</span><span class="s2">, (</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;criterion&quot;</span><span class="s2">, (</span><span class="s3">&quot;absolute_error&quot;</span><span class="s2">, </span><span class="s3">&quot;squared_error&quot;</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;csc_container&quot;</span><span class="s2">, </span><span class="s1">CSC_CONTAINERS</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_monotonic_constraints_regressions</span><span class="s2">(</span>
    <span class="s1">TreeRegressor</span><span class="s2">,</span>
    <span class="s1">depth_first_builder</span><span class="s2">,</span>
    <span class="s1">sparse_splitter</span><span class="s2">,</span>
    <span class="s1">criterion</span><span class="s2">,</span>
    <span class="s1">global_random_seed</span><span class="s2">,</span>
    <span class="s1">csc_container</span><span class="s2">,</span>
<span class="s2">):</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">1000</span>
    <span class="s1">n_samples_train </span><span class="s2">= </span><span class="s4">900</span>
    <span class="s5"># Build a regression task using 5 informative features</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_regression</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">,</span>
        <span class="s1">n_features</span><span class="s2">=</span><span class="s4">5</span><span class="s2">,</span>
        <span class="s1">n_informative</span><span class="s2">=</span><span class="s4">5</span><span class="s2">,</span>
        <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
    <span class="s2">)</span>
    <span class="s1">train </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">n_samples_train</span><span class="s2">)</span>
    <span class="s1">test </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">arange</span><span class="s2">(</span><span class="s1">n_samples_train</span><span class="s2">, </span><span class="s1">n_samples</span><span class="s2">)</span>
    <span class="s1">X_train </span><span class="s2">= </span><span class="s1">X</span><span class="s2">[</span><span class="s1">train</span><span class="s2">]</span>
    <span class="s1">y_train </span><span class="s2">= </span><span class="s1">y</span><span class="s2">[</span><span class="s1">train</span><span class="s2">]</span>
    <span class="s1">X_test </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">(</span><span class="s1">X</span><span class="s2">[</span><span class="s1">test</span><span class="s2">])</span>
    <span class="s1">X_test_incr </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>
    <span class="s1">X_test_decr </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">copy</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>
    <span class="s1">X_test_incr</span><span class="s2">[:, </span><span class="s4">0</span><span class="s2">] += </span><span class="s4">10</span>
    <span class="s1">X_test_decr</span><span class="s2">[:, </span><span class="s4">1</span><span class="s2">] += </span><span class="s4">10</span>
    <span class="s1">monotonic_cst </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s1">monotonic_cst</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] = </span><span class="s4">1</span>
    <span class="s1">monotonic_cst</span><span class="s2">[</span><span class="s4">1</span><span class="s2">] = -</span><span class="s4">1</span>

    <span class="s0">if </span><span class="s1">depth_first_builder</span><span class="s2">:</span>
        <span class="s1">est </span><span class="s2">= </span><span class="s1">TreeRegressor</span><span class="s2">(</span>
            <span class="s1">max_depth</span><span class="s2">=</span><span class="s0">None</span><span class="s2">,</span>
            <span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">,</span>
            <span class="s1">criterion</span><span class="s2">=</span><span class="s1">criterion</span><span class="s2">,</span>
        <span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s1">est </span><span class="s2">= </span><span class="s1">TreeRegressor</span><span class="s2">(</span>
            <span class="s1">max_depth</span><span class="s2">=</span><span class="s4">8</span><span class="s2">,</span>
            <span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">,</span>
            <span class="s1">criterion</span><span class="s2">=</span><span class="s1">criterion</span><span class="s2">,</span>
            <span class="s1">max_leaf_nodes</span><span class="s2">=</span><span class="s1">n_samples_train</span><span class="s2">,</span>
        <span class="s2">)</span>
    <span class="s0">if </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">est</span><span class="s2">, </span><span class="s3">&quot;random_state&quot;</span><span class="s2">):</span>
        <span class="s1">est</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(</span><span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">hasattr</span><span class="s2">(</span><span class="s1">est</span><span class="s2">, </span><span class="s3">&quot;n_estimators&quot;</span><span class="s2">):</span>
        <span class="s1">est</span><span class="s2">.</span><span class="s1">set_params</span><span class="s2">(**{</span><span class="s3">&quot;n_estimators&quot;</span><span class="s2">: </span><span class="s4">5</span><span class="s2">})</span>
    <span class="s0">if </span><span class="s1">sparse_splitter</span><span class="s2">:</span>
        <span class="s1">X_train </span><span class="s2">= </span><span class="s1">csc_container</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">)</span>
    <span class="s1">est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X_train</span><span class="s2">, </span><span class="s1">y_train</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">est</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test</span><span class="s2">)</span>
    <span class="s5"># Monotonic increase constraint</span>
    <span class="s1">y_incr </span><span class="s2">= </span><span class="s1">est</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test_incr</span><span class="s2">)</span>
    <span class="s5"># y_incr should always be greater than y</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">y_incr </span><span class="s2">&gt;= </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s5"># Monotonic decrease constraint</span>
    <span class="s1">y_decr </span><span class="s2">= </span><span class="s1">est</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_test_decr</span><span class="s2">)</span>
    <span class="s5"># y_decr should always be lower than y</span>
    <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">all</span><span class="s2">(</span><span class="s1">y_decr </span><span class="s2">&lt;= </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;TreeClassifier&quot;</span><span class="s2">, </span><span class="s1">TREE_BASED_CLASSIFIER_CLASSES</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_multiclass_raises</span><span class="s2">(</span><span class="s1">TreeClassifier</span><span class="s2">):</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s4">100</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">n_classes</span><span class="s2">=</span><span class="s4">3</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s4">3</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span>
    <span class="s2">)</span>
    <span class="s1">y</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] = </span><span class="s4">0</span>
    <span class="s1">monotonic_cst </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s1">monotonic_cst</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] = -</span><span class="s4">1</span>
    <span class="s1">monotonic_cst</span><span class="s2">[</span><span class="s4">1</span><span class="s2">] = </span><span class="s4">1</span>
    <span class="s1">est </span><span class="s2">= </span><span class="s1">TreeClassifier</span><span class="s2">(</span><span class="s1">max_depth</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">)</span>

    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Monotonicity constraints are not supported with multiclass classification&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;TreeClassifier&quot;</span><span class="s2">, </span><span class="s1">TREE_BASED_CLASSIFIER_CLASSES</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_multiple_output_raises</span><span class="s2">(</span><span class="s1">TreeClassifier</span><span class="s2">):</span>
    <span class="s1">X </span><span class="s2">= [[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">3</span><span class="s2">, </span><span class="s4">4</span><span class="s2">, </span><span class="s4">5</span><span class="s2">], [</span><span class="s4">6</span><span class="s2">, </span><span class="s4">7</span><span class="s2">, </span><span class="s4">8</span><span class="s2">, </span><span class="s4">9</span><span class="s2">, </span><span class="s4">10</span><span class="s2">]]</span>
    <span class="s1">y </span><span class="s2">= [[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">], [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]]</span>

    <span class="s1">est </span><span class="s2">= </span><span class="s1">TreeClassifier</span><span class="s2">(</span>
        <span class="s1">max_depth</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]), </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span>
    <span class="s2">)</span>
    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Monotonicity constraints are not supported with multiple output&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span>
    <span class="s3">&quot;DecisionTreeEstimator&quot;</span><span class="s2">, [</span><span class="s1">DecisionTreeClassifier</span><span class="s2">, </span><span class="s1">DecisionTreeRegressor</span><span class="s2">]</span>
<span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_missing_values_raises</span><span class="s2">(</span><span class="s1">DecisionTreeEstimator</span><span class="s2">):</span>
    <span class="s1">X</span><span class="s2">, </span><span class="s1">y </span><span class="s2">= </span><span class="s1">make_classification</span><span class="s2">(</span>
        <span class="s1">n_samples</span><span class="s2">=</span><span class="s4">100</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">n_classes</span><span class="s2">=</span><span class="s4">2</span><span class="s2">, </span><span class="s1">n_informative</span><span class="s2">=</span><span class="s4">3</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span>
    <span class="s2">)</span>
    <span class="s1">X</span><span class="s2">[</span><span class="s4">0</span><span class="s2">, </span><span class="s4">0</span><span class="s2">] = </span><span class="s1">np</span><span class="s2">.</span><span class="s1">nan</span>
    <span class="s1">monotonic_cst </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">zeros</span><span class="s2">(</span><span class="s1">X</span><span class="s2">.</span><span class="s1">shape</span><span class="s2">[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s1">monotonic_cst</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] = </span><span class="s4">1</span>
    <span class="s1">est </span><span class="s2">= </span><span class="s1">DecisionTreeEstimator</span><span class="s2">(</span>
        <span class="s1">max_depth</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span>
    <span class="s2">)</span>

    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;Input X contains NaN&quot;</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;TreeClassifier&quot;</span><span class="s2">, </span><span class="s1">TREE_BASED_CLASSIFIER_CLASSES</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_bad_monotonic_cst_raises</span><span class="s2">(</span><span class="s1">TreeClassifier</span><span class="s2">):</span>
    <span class="s1">X </span><span class="s2">= [[</span><span class="s4">1</span><span class="s2">, </span><span class="s4">2</span><span class="s2">], [</span><span class="s4">3</span><span class="s2">, </span><span class="s4">4</span><span class="s2">], [</span><span class="s4">5</span><span class="s2">, </span><span class="s4">6</span><span class="s2">], [</span><span class="s4">7</span><span class="s2">, </span><span class="s4">8</span><span class="s2">], [</span><span class="s4">9</span><span class="s2">, </span><span class="s4">10</span><span class="s2">]]</span>
    <span class="s1">y </span><span class="s2">= [</span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s4">1</span><span class="s2">]</span>

    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;monotonic_cst has shape 3 but the input data X has 2 features.&quot;</span>
    <span class="s1">est </span><span class="s2">= </span><span class="s1">TreeClassifier</span><span class="s2">(</span>
        <span class="s1">max_depth</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">0</span><span class="s2">]), </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">msg </span><span class="s2">= </span><span class="s3">&quot;monotonic_cst must be None or an array-like of -1, 0 or 1.&quot;</span>
    <span class="s1">est </span><span class="s2">= </span><span class="s1">TreeClassifier</span><span class="s2">(</span>
        <span class="s1">max_depth</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([-</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">]), </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg</span><span class="s2">):</span>
        <span class="s1">est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">est </span><span class="s2">= </span><span class="s1">TreeClassifier</span><span class="s2">(</span>
        <span class="s1">max_depth</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">np</span><span class="s2">.</span><span class="s1">array</span><span class="s2">([-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">0.8</span><span class="s2">]), </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span>
    <span class="s2">)</span>
    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">match</span><span class="s2">=</span><span class="s1">msg </span><span class="s2">+ </span><span class="s3">&quot;(.*)0.8]&quot;</span><span class="s2">):</span>
        <span class="s1">est</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">assert_1d_reg_tree_children_monotonic_bounded</span><span class="s2">(</span><span class="s1">tree_</span><span class="s2">, </span><span class="s1">monotonic_sign</span><span class="s2">):</span>
    <span class="s1">values </span><span class="s2">= </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">value</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">node_count</span><span class="s2">):</span>
        <span class="s0">if </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">children_left</span><span class="s2">[</span><span class="s1">i</span><span class="s2">] &gt; </span><span class="s1">i </span><span class="s0">and </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">children_right</span><span class="s2">[</span><span class="s1">i</span><span class="s2">] &gt; </span><span class="s1">i</span><span class="s2">:</span>
            <span class="s5"># Check monotonicity on children</span>
            <span class="s1">i_left </span><span class="s2">= </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">children_left</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>
            <span class="s1">i_right </span><span class="s2">= </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">children_right</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>
            <span class="s0">if </span><span class="s1">monotonic_sign </span><span class="s2">== </span><span class="s4">1</span><span class="s2">:</span>
                <span class="s0">assert </span><span class="s1">values</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">] &lt;= </span><span class="s1">values</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">]</span>
            <span class="s0">elif </span><span class="s1">monotonic_sign </span><span class="s2">== -</span><span class="s4">1</span><span class="s2">:</span>
                <span class="s0">assert </span><span class="s1">values</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">] &gt;= </span><span class="s1">values</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">]</span>
            <span class="s1">val_middle </span><span class="s2">= (</span><span class="s1">values</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">] + </span><span class="s1">values</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">]) / </span><span class="s4">2</span>
            <span class="s5"># Check bounds on grand-children, filtering out leaf nodes</span>
            <span class="s0">if </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">feature</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">] &gt;= </span><span class="s4">0</span><span class="s2">:</span>
                <span class="s1">i_left_right </span><span class="s2">= </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">children_right</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">]</span>
                <span class="s0">if </span><span class="s1">monotonic_sign </span><span class="s2">== </span><span class="s4">1</span><span class="s2">:</span>
                    <span class="s0">assert </span><span class="s1">values</span><span class="s2">[</span><span class="s1">i_left_right</span><span class="s2">] &lt;= </span><span class="s1">val_middle</span>
                <span class="s0">elif </span><span class="s1">monotonic_sign </span><span class="s2">== -</span><span class="s4">1</span><span class="s2">:</span>
                    <span class="s0">assert </span><span class="s1">values</span><span class="s2">[</span><span class="s1">i_left_right</span><span class="s2">] &gt;= </span><span class="s1">val_middle</span>
            <span class="s0">if </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">feature</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">] &gt;= </span><span class="s4">0</span><span class="s2">:</span>
                <span class="s1">i_right_left </span><span class="s2">= </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">children_left</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">]</span>
                <span class="s0">if </span><span class="s1">monotonic_sign </span><span class="s2">== </span><span class="s4">1</span><span class="s2">:</span>
                    <span class="s0">assert </span><span class="s1">val_middle </span><span class="s2">&lt;= </span><span class="s1">values</span><span class="s2">[</span><span class="s1">i_right_left</span><span class="s2">]</span>
                <span class="s0">elif </span><span class="s1">monotonic_sign </span><span class="s2">== -</span><span class="s4">1</span><span class="s2">:</span>
                    <span class="s0">assert </span><span class="s1">val_middle </span><span class="s2">&gt;= </span><span class="s1">values</span><span class="s2">[</span><span class="s1">i_right_left</span><span class="s2">]</span>


<span class="s0">def </span><span class="s1">test_assert_1d_reg_tree_children_monotonic_bounded</span><span class="s2">():</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s4">7</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sin</span><span class="s2">(</span><span class="s4">2 </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">pi </span><span class="s2">* </span><span class="s1">X</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">())</span>

    <span class="s1">reg </span><span class="s2">= </span><span class="s1">DecisionTreeRegressor</span><span class="s2">(</span><span class="s1">max_depth</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">AssertionError</span><span class="s2">):</span>
        <span class="s1">assert_1d_reg_tree_children_monotonic_bounded</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">tree_</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">AssertionError</span><span class="s2">):</span>
        <span class="s1">assert_1d_reg_tree_children_monotonic_bounded</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">tree_</span><span class="s2">, -</span><span class="s4">1</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">assert_1d_reg_monotonic</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">monotonic_sign</span><span class="s2">, </span><span class="s1">min_x</span><span class="s2">, </span><span class="s1">max_x</span><span class="s2">, </span><span class="s1">n_steps</span><span class="s2">):</span>
    <span class="s1">X_grid </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(</span><span class="s1">min_x</span><span class="s2">, </span><span class="s1">max_x</span><span class="s2">, </span><span class="s1">n_steps</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">y_pred_grid </span><span class="s2">= </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">predict</span><span class="s2">(</span><span class="s1">X_grid</span><span class="s2">)</span>
    <span class="s0">if </span><span class="s1">monotonic_sign </span><span class="s2">== </span><span class="s4">1</span><span class="s2">:</span>
        <span class="s0">assert </span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">diff</span><span class="s2">(</span><span class="s1">y_pred_grid</span><span class="s2">) &gt;= </span><span class="s4">0.0</span><span class="s2">).</span><span class="s1">all</span><span class="s2">()</span>
    <span class="s0">elif </span><span class="s1">monotonic_sign </span><span class="s2">== -</span><span class="s4">1</span><span class="s2">:</span>
        <span class="s0">assert </span><span class="s2">(</span><span class="s1">np</span><span class="s2">.</span><span class="s1">diff</span><span class="s2">(</span><span class="s1">y_pred_grid</span><span class="s2">) &lt;= </span><span class="s4">0.0</span><span class="s2">).</span><span class="s1">all</span><span class="s2">()</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;TreeRegressor&quot;</span><span class="s2">, </span><span class="s1">TREE_REGRESSOR_CLASSES</span><span class="s2">)</span>
<span class="s0">def </span><span class="s1">test_1d_opposite_monotonicity_cst_data</span><span class="s2">(</span><span class="s1">TreeRegressor</span><span class="s2">):</span>
    <span class="s5"># Check that positive monotonic data with negative monotonic constraint</span>
    <span class="s5"># yield constant predictions, equal to the average of target values</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(-</span><span class="s4">2</span><span class="s2">, </span><span class="s4">2</span><span class="s2">, </span><span class="s4">10</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">()</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">TreeRegressor</span><span class="s2">(</span><span class="s1">monotonic_cst</span><span class="s2">=[-</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">node_count </span><span class="s2">== </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">value</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] == </span><span class="s4">0.0</span>

    <span class="s5"># Swap monotonicity</span>
    <span class="s1">clf </span><span class="s2">= </span><span class="s1">TreeRegressor</span><span class="s2">(</span><span class="s1">monotonic_cst</span><span class="s2">=[</span><span class="s4">1</span><span class="s2">])</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, -</span><span class="s1">y</span><span class="s2">)</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">node_count </span><span class="s2">== </span><span class="s4">1</span>
    <span class="s0">assert </span><span class="s1">clf</span><span class="s2">.</span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">value</span><span class="s2">[</span><span class="s4">0</span><span class="s2">] == </span><span class="s4">0.0</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;TreeRegressor&quot;</span><span class="s2">, </span><span class="s1">TREE_REGRESSOR_CLASSES</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;monotonic_sign&quot;</span><span class="s2">, (-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;depth_first_builder&quot;</span><span class="s2">, (</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;criterion&quot;</span><span class="s2">, (</span><span class="s3">&quot;absolute_error&quot;</span><span class="s2">, </span><span class="s3">&quot;squared_error&quot;</span><span class="s2">))</span>
<span class="s0">def </span><span class="s1">test_1d_tree_nodes_values</span><span class="s2">(</span>
    <span class="s1">TreeRegressor</span><span class="s2">, </span><span class="s1">monotonic_sign</span><span class="s2">, </span><span class="s1">depth_first_builder</span><span class="s2">, </span><span class="s1">criterion</span><span class="s2">, </span><span class="s1">global_random_seed</span>
<span class="s2">):</span>
    <span class="s5"># Adaptation from test_nodes_values in test_monotonic_constraints.py</span>
    <span class="s5"># in sklearn.ensemble._hist_gradient_boosting</span>
    <span class="s5"># Build a single tree with only one feature, and make sure the node</span>
    <span class="s5"># values respect the monotonicity constraints.</span>

    <span class="s5"># Considering the following tree with a monotonic +1 constraint, we</span>
    <span class="s5"># should have:</span>
    <span class="s5">#</span>
    <span class="s5">#       root</span>
    <span class="s5">#      /    \</span>
    <span class="s5">#     a      b</span>
    <span class="s5">#    / \    / \</span>
    <span class="s5">#   c   d  e   f</span>
    <span class="s5">#</span>
    <span class="s5">#        a &lt;=  root  &lt;= b</span>
    <span class="s5"># c &lt;= d &lt;= (a + b) / 2 &lt;= e &lt;= f</span>

    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">global_random_seed</span><span class="s2">)</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">1000</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s4">1</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">rand</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">rand</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">depth_first_builder</span><span class="s2">:</span>
        <span class="s5"># No max_leaf_nodes, default depth first tree builder</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">TreeRegressor</span><span class="s2">(</span>
            <span class="s1">monotonic_cst</span><span class="s2">=[</span><span class="s1">monotonic_sign</span><span class="s2">],</span>
            <span class="s1">criterion</span><span class="s2">=</span><span class="s1">criterion</span><span class="s2">,</span>
            <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
        <span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s5"># max_leaf_nodes triggers best first tree builder</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">TreeRegressor</span><span class="s2">(</span>
            <span class="s1">monotonic_cst</span><span class="s2">=[</span><span class="s1">monotonic_sign</span><span class="s2">],</span>
            <span class="s1">max_leaf_nodes</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">,</span>
            <span class="s1">criterion</span><span class="s2">=</span><span class="s1">criterion</span><span class="s2">,</span>
            <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
        <span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s1">assert_1d_reg_tree_children_monotonic_bounded</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">tree_</span><span class="s2">, </span><span class="s1">monotonic_sign</span><span class="s2">)</span>
    <span class="s1">assert_1d_reg_monotonic</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">, </span><span class="s1">monotonic_sign</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">min</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s1">np</span><span class="s2">.</span><span class="s1">max</span><span class="s2">(</span><span class="s1">X</span><span class="s2">), </span><span class="s4">100</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">assert_nd_reg_tree_children_monotonic_bounded</span><span class="s2">(</span><span class="s1">tree_</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">):</span>
    <span class="s1">upper_bound </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">full</span><span class="s2">(</span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">node_count</span><span class="s2">, </span><span class="s1">np</span><span class="s2">.</span><span class="s1">inf</span><span class="s2">)</span>
    <span class="s1">lower_bound </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">full</span><span class="s2">(</span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">node_count</span><span class="s2">, -</span><span class="s1">np</span><span class="s2">.</span><span class="s1">inf</span><span class="s2">)</span>
    <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range</span><span class="s2">(</span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">node_count</span><span class="s2">):</span>
        <span class="s1">feature </span><span class="s2">= </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">feature</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>
        <span class="s1">node_value </span><span class="s2">= </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">value</span><span class="s2">[</span><span class="s1">i</span><span class="s2">][</span><span class="s4">0</span><span class="s2">][</span><span class="s4">0</span><span class="s2">]  </span><span class="s5"># unpack value from nx1x1 array</span>
        <span class="s5"># While building the tree, the computed middle value is slightly</span>
        <span class="s5"># different from the average of the siblings values, because</span>
        <span class="s5"># sum_right / weighted_n_right</span>
        <span class="s5"># is slightly different from the value of the right sibling.</span>
        <span class="s5"># This can cause a discrepancy up to numerical noise when clipping,</span>
        <span class="s5"># which is resolved by comparing with some loss of precision.</span>
        <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">(</span><span class="s1">node_value</span><span class="s2">) &lt;= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">(</span><span class="s1">upper_bound</span><span class="s2">[</span><span class="s1">i</span><span class="s2">])</span>
        <span class="s0">assert </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">(</span><span class="s1">node_value</span><span class="s2">) &gt;= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">float32</span><span class="s2">(</span><span class="s1">lower_bound</span><span class="s2">[</span><span class="s1">i</span><span class="s2">])</span>

        <span class="s0">if </span><span class="s1">feature </span><span class="s2">&lt; </span><span class="s4">0</span><span class="s2">:</span>
            <span class="s5"># Leaf: nothing to do</span>
            <span class="s0">continue</span>

        <span class="s5"># Split node: check and update bounds for the children.</span>
        <span class="s1">i_left </span><span class="s2">= </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">children_left</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>
        <span class="s1">i_right </span><span class="s2">= </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">children_right</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>
        <span class="s5"># unpack value from nx1x1 array</span>
        <span class="s1">middle_value </span><span class="s2">= (</span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">value</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">][</span><span class="s4">0</span><span class="s2">][</span><span class="s4">0</span><span class="s2">] + </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">value</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">][</span><span class="s4">0</span><span class="s2">][</span><span class="s4">0</span><span class="s2">]) / </span><span class="s4">2</span>

        <span class="s0">if </span><span class="s1">monotonic_cst</span><span class="s2">[</span><span class="s1">feature</span><span class="s2">] == </span><span class="s4">0</span><span class="s2">:</span>
            <span class="s5"># Feature without monotonicity constraint: propagate bounds</span>
            <span class="s5"># down the tree to both children.</span>
            <span class="s5"># Otherwise, with 2 features and a monotonic increase constraint</span>
            <span class="s5"># (encoded by +1) on feature 0, the following tree can be accepted,</span>
            <span class="s5"># although it does not respect the monotonic increase constraint:</span>
            <span class="s5">#</span>
            <span class="s5">#                      X[0] &lt;= 0</span>
            <span class="s5">#                      value = 100</span>
            <span class="s5">#                     /            \</span>
            <span class="s5">#          X[0] &lt;= -1                X[1] &lt;= 0</span>
            <span class="s5">#          value = 50                value = 150</span>
            <span class="s5">#        /            \             /            \</span>
            <span class="s5">#    leaf           leaf           leaf          leaf</span>
            <span class="s5">#    value = 25     value = 75     value = 50    value = 250</span>

            <span class="s1">lower_bound</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">] = </span><span class="s1">lower_bound</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>
            <span class="s1">upper_bound</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">] = </span><span class="s1">upper_bound</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>
            <span class="s1">lower_bound</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">] = </span><span class="s1">lower_bound</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>
            <span class="s1">upper_bound</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">] = </span><span class="s1">upper_bound</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>

        <span class="s0">elif </span><span class="s1">monotonic_cst</span><span class="s2">[</span><span class="s1">feature</span><span class="s2">] == </span><span class="s4">1</span><span class="s2">:</span>
            <span class="s5"># Feature with constraint: check monotonicity</span>
            <span class="s0">assert </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">value</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">] &lt;= </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">value</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">]</span>

            <span class="s5"># Propagate bounds down the tree to both children.</span>
            <span class="s1">lower_bound</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">] = </span><span class="s1">lower_bound</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>
            <span class="s1">upper_bound</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">] = </span><span class="s1">middle_value</span>
            <span class="s1">lower_bound</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">] = </span><span class="s1">middle_value</span>
            <span class="s1">upper_bound</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">] = </span><span class="s1">upper_bound</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>

        <span class="s0">elif </span><span class="s1">monotonic_cst</span><span class="s2">[</span><span class="s1">feature</span><span class="s2">] == -</span><span class="s4">1</span><span class="s2">:</span>
            <span class="s5"># Feature with constraint: check monotonicity</span>
            <span class="s0">assert </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">value</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">] &gt;= </span><span class="s1">tree_</span><span class="s2">.</span><span class="s1">value</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">]</span>

            <span class="s5"># Update and propagate bounds down the tree to both children.</span>
            <span class="s1">lower_bound</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">] = </span><span class="s1">middle_value</span>
            <span class="s1">upper_bound</span><span class="s2">[</span><span class="s1">i_left</span><span class="s2">] = </span><span class="s1">upper_bound</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>
            <span class="s1">lower_bound</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">] = </span><span class="s1">lower_bound</span><span class="s2">[</span><span class="s1">i</span><span class="s2">]</span>
            <span class="s1">upper_bound</span><span class="s2">[</span><span class="s1">i_right</span><span class="s2">] = </span><span class="s1">middle_value</span>

        <span class="s0">else</span><span class="s2">:  </span><span class="s5"># pragma: no cover</span>
            <span class="s0">raise </span><span class="s1">ValueError</span><span class="s2">(</span><span class="s3">f&quot;monotonic_cst[</span><span class="s0">{</span><span class="s1">feature</span><span class="s0">}</span><span class="s3">]=</span><span class="s0">{</span><span class="s1">monotonic_cst</span><span class="s2">[</span><span class="s1">feature</span><span class="s2">]</span><span class="s0">}</span><span class="s3">&quot;</span><span class="s2">)</span>


<span class="s0">def </span><span class="s1">test_assert_nd_reg_tree_children_monotonic_bounded</span><span class="s2">():</span>
    <span class="s5"># Check that assert_nd_reg_tree_children_monotonic_bounded can detect</span>
    <span class="s5"># non-monotonic tree predictions.</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(</span><span class="s4">0</span><span class="s2">, </span><span class="s4">2 </span><span class="s2">* </span><span class="s1">np</span><span class="s2">.</span><span class="s1">pi</span><span class="s2">, </span><span class="s4">30</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">sin</span><span class="s2">(</span><span class="s1">X</span><span class="s2">).</span><span class="s1">ravel</span><span class="s2">()</span>
    <span class="s1">reg </span><span class="s2">= </span><span class="s1">DecisionTreeRegressor</span><span class="s2">(</span><span class="s1">max_depth</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">AssertionError</span><span class="s2">):</span>
        <span class="s1">assert_nd_reg_tree_children_monotonic_bounded</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">tree_</span><span class="s2">, [</span><span class="s4">1</span><span class="s2">])</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">AssertionError</span><span class="s2">):</span>
        <span class="s1">assert_nd_reg_tree_children_monotonic_bounded</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">tree_</span><span class="s2">, [-</span><span class="s4">1</span><span class="s2">])</span>

    <span class="s1">assert_nd_reg_tree_children_monotonic_bounded</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">tree_</span><span class="s2">, [</span><span class="s4">0</span><span class="s2">])</span>

    <span class="s5"># Check that assert_nd_reg_tree_children_monotonic_bounded raises</span>
    <span class="s5"># when the data (and therefore the model) is naturally monotonic in the</span>
    <span class="s5"># opposite direction.</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">linspace</span><span class="s2">(-</span><span class="s4">5</span><span class="s2">, </span><span class="s4">5</span><span class="s2">, </span><span class="s4">5</span><span class="s2">).</span><span class="s1">reshape</span><span class="s2">(-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">X</span><span class="s2">.</span><span class="s1">ravel</span><span class="s2">() ** </span><span class="s4">3</span>
    <span class="s1">reg </span><span class="s2">= </span><span class="s1">DecisionTreeRegressor</span><span class="s2">(</span><span class="s1">max_depth</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">AssertionError</span><span class="s2">):</span>
        <span class="s1">assert_nd_reg_tree_children_monotonic_bounded</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">tree_</span><span class="s2">, [-</span><span class="s4">1</span><span class="s2">])</span>

    <span class="s5"># For completeness, check that the converse holds when swapping the sign.</span>
    <span class="s1">reg </span><span class="s2">= </span><span class="s1">DecisionTreeRegressor</span><span class="s2">(</span><span class="s1">max_depth</span><span class="s2">=</span><span class="s0">None</span><span class="s2">, </span><span class="s1">random_state</span><span class="s2">=</span><span class="s4">0</span><span class="s2">).</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, -</span><span class="s1">y</span><span class="s2">)</span>

    <span class="s0">with </span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">raises</span><span class="s2">(</span><span class="s1">AssertionError</span><span class="s2">):</span>
        <span class="s1">assert_nd_reg_tree_children_monotonic_bounded</span><span class="s2">(</span><span class="s1">reg</span><span class="s2">.</span><span class="s1">tree_</span><span class="s2">, [</span><span class="s4">1</span><span class="s2">])</span>


<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;TreeRegressor&quot;</span><span class="s2">, </span><span class="s1">TREE_REGRESSOR_CLASSES</span><span class="s2">)</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;monotonic_sign&quot;</span><span class="s2">, (-</span><span class="s4">1</span><span class="s2">, </span><span class="s4">1</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;depth_first_builder&quot;</span><span class="s2">, (</span><span class="s0">True</span><span class="s2">, </span><span class="s0">False</span><span class="s2">))</span>
<span class="s2">@</span><span class="s1">pytest</span><span class="s2">.</span><span class="s1">mark</span><span class="s2">.</span><span class="s1">parametrize</span><span class="s2">(</span><span class="s3">&quot;criterion&quot;</span><span class="s2">, (</span><span class="s3">&quot;absolute_error&quot;</span><span class="s2">, </span><span class="s3">&quot;squared_error&quot;</span><span class="s2">))</span>
<span class="s0">def </span><span class="s1">test_nd_tree_nodes_values</span><span class="s2">(</span>
    <span class="s1">TreeRegressor</span><span class="s2">, </span><span class="s1">monotonic_sign</span><span class="s2">, </span><span class="s1">depth_first_builder</span><span class="s2">, </span><span class="s1">criterion</span><span class="s2">, </span><span class="s1">global_random_seed</span>
<span class="s2">):</span>
    <span class="s5"># Build tree with several features, and make sure the nodes</span>
    <span class="s5"># values respect the monotonicity constraints.</span>

    <span class="s5"># Considering the following tree with a monotonic increase constraint on X[0],</span>
    <span class="s5"># we should have:</span>
    <span class="s5">#</span>
    <span class="s5">#            root</span>
    <span class="s5">#           X[0]&lt;=t</span>
    <span class="s5">#          /       \</span>
    <span class="s5">#         a         b</span>
    <span class="s5">#     X[0]&lt;=u   X[1]&lt;=v</span>
    <span class="s5">#    /       \   /     \</span>
    <span class="s5">#   c        d  e       f</span>
    <span class="s5">#</span>
    <span class="s5"># i)   a &lt;= root &lt;= b</span>
    <span class="s5"># ii)  c &lt;= a &lt;= d &lt;= (a+b)/2</span>
    <span class="s5"># iii) (a+b)/2 &lt;= min(e,f)</span>
    <span class="s5"># For iii) we check that each node value is within the proper lower and</span>
    <span class="s5"># upper bounds.</span>

    <span class="s1">rng </span><span class="s2">= </span><span class="s1">np</span><span class="s2">.</span><span class="s1">random</span><span class="s2">.</span><span class="s1">RandomState</span><span class="s2">(</span><span class="s1">global_random_seed</span><span class="s2">)</span>
    <span class="s1">n_samples </span><span class="s2">= </span><span class="s4">1000</span>
    <span class="s1">n_features </span><span class="s2">= </span><span class="s4">2</span>
    <span class="s1">monotonic_cst </span><span class="s2">= [</span><span class="s1">monotonic_sign</span><span class="s2">, </span><span class="s4">0</span><span class="s2">]</span>
    <span class="s1">X </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">rand</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">, </span><span class="s1">n_features</span><span class="s2">)</span>
    <span class="s1">y </span><span class="s2">= </span><span class="s1">rng</span><span class="s2">.</span><span class="s1">rand</span><span class="s2">(</span><span class="s1">n_samples</span><span class="s2">)</span>

    <span class="s0">if </span><span class="s1">depth_first_builder</span><span class="s2">:</span>
        <span class="s5"># No max_leaf_nodes, default depth first tree builder</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">TreeRegressor</span><span class="s2">(</span>
            <span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">,</span>
            <span class="s1">criterion</span><span class="s2">=</span><span class="s1">criterion</span><span class="s2">,</span>
            <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
        <span class="s2">)</span>
    <span class="s0">else</span><span class="s2">:</span>
        <span class="s5"># max_leaf_nodes triggers best first tree builder</span>
        <span class="s1">clf </span><span class="s2">= </span><span class="s1">TreeRegressor</span><span class="s2">(</span>
            <span class="s1">monotonic_cst</span><span class="s2">=</span><span class="s1">monotonic_cst</span><span class="s2">,</span>
            <span class="s1">max_leaf_nodes</span><span class="s2">=</span><span class="s1">n_samples</span><span class="s2">,</span>
            <span class="s1">criterion</span><span class="s2">=</span><span class="s1">criterion</span><span class="s2">,</span>
            <span class="s1">random_state</span><span class="s2">=</span><span class="s1">global_random_seed</span><span class="s2">,</span>
        <span class="s2">)</span>
    <span class="s1">clf</span><span class="s2">.</span><span class="s1">fit</span><span class="s2">(</span><span class="s1">X</span><span class="s2">, </span><span class="s1">y</span><span class="s2">)</span>
    <span class="s1">assert_nd_reg_tree_children_monotonic_bounded</span><span class="s2">(</span><span class="s1">clf</span><span class="s2">.</span><span class="s1">tree_</span><span class="s2">, </span><span class="s1">monotonic_cst</span><span class="s2">)</span>
</pre>
</body>
</html>