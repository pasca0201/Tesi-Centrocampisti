<html>
<head>
<title>test_weight_boosting.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #cf8e6d;}
.s3 { color: #bcbec4;}
.s4 { color: #7a7e85;}
.s5 { color: #2aacb8;}
.s6 { color: #6aab73;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_weight_boosting.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Testing for the boost module (sklearn.ensemble.boost).&quot;&quot;&quot;</span>

<span class="s2">import </span><span class="s1">re</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pytest</span>

<span class="s2">from </span><span class="s1">sklearn </span><span class="s2">import </span><span class="s1">datasets</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">base </span><span class="s2">import </span><span class="s1">BaseEstimator</span><span class="s3">, </span><span class="s1">clone</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">dummy </span><span class="s2">import </span><span class="s1">DummyClassifier</span><span class="s3">, </span><span class="s1">DummyRegressor</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">ensemble </span><span class="s2">import </span><span class="s1">AdaBoostClassifier</span><span class="s3">, </span><span class="s1">AdaBoostRegressor</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">ensemble</span><span class="s3">.</span><span class="s1">_weight_boosting </span><span class="s2">import </span><span class="s1">_samme_proba</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">linear_model </span><span class="s2">import </span><span class="s1">LinearRegression</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">model_selection </span><span class="s2">import </span><span class="s1">GridSearchCV</span><span class="s3">, </span><span class="s1">train_test_split</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">svm </span><span class="s2">import </span><span class="s1">SVC</span><span class="s3">, </span><span class="s1">SVR</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">tree </span><span class="s2">import </span><span class="s1">DecisionTreeClassifier</span><span class="s3">, </span><span class="s1">DecisionTreeRegressor</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils </span><span class="s2">import </span><span class="s1">shuffle</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">_mocking </span><span class="s2">import </span><span class="s1">NoSampleWeightWrapper</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">_testing </span><span class="s2">import </span><span class="s3">(</span>
    <span class="s1">assert_allclose</span><span class="s3">,</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">,</span>
    <span class="s1">assert_array_equal</span><span class="s3">,</span>
    <span class="s1">assert_array_less</span><span class="s3">,</span>
<span class="s3">)</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">utils</span><span class="s3">.</span><span class="s1">fixes </span><span class="s2">import </span><span class="s3">(</span>
    <span class="s1">COO_CONTAINERS</span><span class="s3">,</span>
    <span class="s1">CSC_CONTAINERS</span><span class="s3">,</span>
    <span class="s1">CSR_CONTAINERS</span><span class="s3">,</span>
    <span class="s1">DOK_CONTAINERS</span><span class="s3">,</span>
    <span class="s1">LIL_CONTAINERS</span><span class="s3">,</span>
<span class="s3">)</span>

<span class="s4"># Common random state</span>
<span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s5">0</span><span class="s3">)</span>

<span class="s4"># Toy sample</span>
<span class="s1">X </span><span class="s3">= [[-</span><span class="s5">2</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">], [-</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">], [-</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">2</span><span class="s3">], [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">], [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], [</span><span class="s5">2</span><span class="s3">, </span><span class="s5">1</span><span class="s3">]]</span>
<span class="s1">y_class </span><span class="s3">= [</span><span class="s6">&quot;foo&quot;</span><span class="s3">, </span><span class="s6">&quot;foo&quot;</span><span class="s3">, </span><span class="s6">&quot;foo&quot;</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">]  </span><span class="s4"># test string class labels</span>
<span class="s1">y_regr </span><span class="s3">= [-</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">]</span>
<span class="s1">T </span><span class="s3">= [[-</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">1</span><span class="s3">], [</span><span class="s5">2</span><span class="s3">, </span><span class="s5">2</span><span class="s3">], [</span><span class="s5">3</span><span class="s3">, </span><span class="s5">2</span><span class="s3">]]</span>
<span class="s1">y_t_class </span><span class="s3">= [</span><span class="s6">&quot;foo&quot;</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">]</span>
<span class="s1">y_t_regr </span><span class="s3">= [-</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">]</span>

<span class="s4"># Load the iris dataset and randomly permute it</span>
<span class="s1">iris </span><span class="s3">= </span><span class="s1">datasets</span><span class="s3">.</span><span class="s1">load_iris</span><span class="s3">()</span>
<span class="s1">perm </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">permutation</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">.</span><span class="s1">size</span><span class="s3">)</span>
<span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target </span><span class="s3">= </span><span class="s1">shuffle</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s1">rng</span><span class="s3">)</span>

<span class="s4"># Load the diabetes dataset and randomly permute it</span>
<span class="s1">diabetes </span><span class="s3">= </span><span class="s1">datasets</span><span class="s3">.</span><span class="s1">load_diabetes</span><span class="s3">()</span>
<span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">target </span><span class="s3">= </span><span class="s1">shuffle</span><span class="s3">(</span>
    <span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">target</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s1">rng</span>
<span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_samme_proba</span><span class="s3">():</span>
    <span class="s4"># Test the `_samme_proba` helper function.</span>

    <span class="s4"># Define some example (bad) `predict_proba` output.</span>
    <span class="s1">probs </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">(</span>
        <span class="s3">[[</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1e-6</span><span class="s3">, </span><span class="s5">0</span><span class="s3">], [</span><span class="s5">0.19</span><span class="s3">, </span><span class="s5">0.6</span><span class="s3">, </span><span class="s5">0.2</span><span class="s3">], [-</span><span class="s5">999</span><span class="s3">, </span><span class="s5">0.51</span><span class="s3">, </span><span class="s5">0.5</span><span class="s3">], [</span><span class="s5">1e-6</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">1e-9</span><span class="s3">]]</span>
    <span class="s3">)</span>
    <span class="s1">probs </span><span class="s3">/= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">abs</span><span class="s3">(</span><span class="s1">probs</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">axis</span><span class="s3">=</span><span class="s5">1</span><span class="s3">))[:, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">newaxis</span><span class="s3">]</span>

    <span class="s4"># _samme_proba calls estimator.predict_proba.</span>
    <span class="s4"># Make a mock object so I can control what gets returned.</span>
    <span class="s2">class </span><span class="s1">MockEstimator</span><span class="s3">:</span>
        <span class="s2">def </span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">):</span>
            <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">, </span><span class="s1">probs</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">)</span>
            <span class="s2">return </span><span class="s1">probs</span>

    <span class="s1">mock </span><span class="s3">= </span><span class="s1">MockEstimator</span><span class="s3">()</span>

    <span class="s1">samme_proba </span><span class="s3">= </span><span class="s1">_samme_proba</span><span class="s3">(</span><span class="s1">mock</span><span class="s3">, </span><span class="s5">3</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones_like</span><span class="s3">(</span><span class="s1">probs</span><span class="s3">))</span>

    <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">samme_proba</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">, </span><span class="s1">probs</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">isfinite</span><span class="s3">(</span><span class="s1">samme_proba</span><span class="s3">).</span><span class="s1">all</span><span class="s3">()</span>

    <span class="s4"># Make sure that the correct elements come out as smallest --</span>
    <span class="s4"># `_samme_proba` should preserve the ordering in each example.</span>
    <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">argmin</span><span class="s3">(</span><span class="s1">samme_proba</span><span class="s3">, </span><span class="s1">axis</span><span class="s3">=</span><span class="s5">1</span><span class="s3">), [</span><span class="s5">2</span><span class="s3">, </span><span class="s5">0</span><span class="s3">, </span><span class="s5">0</span><span class="s3">, </span><span class="s5">2</span><span class="s3">])</span>
    <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">argmax</span><span class="s3">(</span><span class="s1">samme_proba</span><span class="s3">, </span><span class="s1">axis</span><span class="s3">=</span><span class="s5">1</span><span class="s3">), [</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">])</span>


<span class="s2">def </span><span class="s1">test_oneclass_adaboost_proba</span><span class="s3">():</span>
    <span class="s4"># Test predict_proba robustness for one class label input.</span>
    <span class="s4"># In response to issue #7501</span>
    <span class="s4"># https://github.com/scikit-learn/scikit-learn/issues/7501</span>
    <span class="s1">y_t </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">(</span><span class="s1">len</span><span class="s3">(</span><span class="s1">X</span><span class="s3">))</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">algorithm</span><span class="s3">=</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y_t</span><span class="s3">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">), </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones</span><span class="s3">((</span><span class="s1">len</span><span class="s3">(</span><span class="s1">X</span><span class="s3">), </span><span class="s5">1</span><span class="s3">)))</span>


<span class="s4"># TODO(1.6): remove &quot;@pytest.mark.filterwarnings&quot; as SAMME.R will be removed</span>
<span class="s4"># and substituted with the SAMME algorithm as a default; also re-write test to</span>
<span class="s4"># only consider &quot;SAMME&quot;</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s6">&quot;ignore:The SAMME.R algorithm&quot;</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;algorithm&quot;</span><span class="s3">, [</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">, </span><span class="s6">&quot;SAMME.R&quot;</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_classification_toy</span><span class="s3">(</span><span class="s1">algorithm</span><span class="s3">):</span>
    <span class="s4"># Check classification on a toy dataset.</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">algorithm</span><span class="s3">=</span><span class="s1">algorithm</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y_class</span><span class="s3">)</span>
    <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">T</span><span class="s3">), </span><span class="s1">y_t_class</span><span class="s3">)</span>
    <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">unique</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">asarray</span><span class="s3">(</span><span class="s1">y_t_class</span><span class="s3">)), </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">classes_</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">T</span><span class="s3">).</span><span class="s1">shape </span><span class="s3">== (</span><span class="s1">len</span><span class="s3">(</span><span class="s1">T</span><span class="s3">), </span><span class="s5">2</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">decision_function</span><span class="s3">(</span><span class="s1">T</span><span class="s3">).</span><span class="s1">shape </span><span class="s3">== (</span><span class="s1">len</span><span class="s3">(</span><span class="s1">T</span><span class="s3">),)</span>


<span class="s2">def </span><span class="s1">test_regression_toy</span><span class="s3">():</span>
    <span class="s4"># Check classification on a toy dataset.</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostRegressor</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y_regr</span><span class="s3">)</span>
    <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">T</span><span class="s3">), </span><span class="s1">y_t_regr</span><span class="s3">)</span>


<span class="s4"># TODO(1.6): remove &quot;@pytest.mark.filterwarnings&quot; as SAMME.R will be removed</span>
<span class="s4"># and substituted with the SAMME algorithm as a default; also re-write test to</span>
<span class="s4"># only consider &quot;SAMME&quot;</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s6">&quot;ignore:The SAMME.R algorithm&quot;</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_iris</span><span class="s3">():</span>
    <span class="s4"># Check consistency on dataset iris.</span>
    <span class="s1">classes </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">unique</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
    <span class="s1">clf_samme </span><span class="s3">= </span><span class="s1">prob_samme </span><span class="s3">= </span><span class="s2">None</span>

    <span class="s2">for </span><span class="s1">alg </span><span class="s2">in </span><span class="s3">[</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">, </span><span class="s6">&quot;SAMME.R&quot;</span><span class="s3">]:</span>
        <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">algorithm</span><span class="s3">=</span><span class="s1">alg</span><span class="s3">)</span>
        <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>

        <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">classes</span><span class="s3">, </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">classes_</span><span class="s3">)</span>
        <span class="s1">proba </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">)</span>
        <span class="s2">if </span><span class="s1">alg </span><span class="s3">== </span><span class="s6">&quot;SAMME&quot;</span><span class="s3">:</span>
            <span class="s1">clf_samme </span><span class="s3">= </span><span class="s1">clf</span>
            <span class="s1">prob_samme </span><span class="s3">= </span><span class="s1">proba</span>
        <span class="s2">assert </span><span class="s1">proba</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">1</span><span class="s3">] == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">classes</span><span class="s3">)</span>
        <span class="s2">assert </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">decision_function</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">).</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">1</span><span class="s3">] == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">classes</span><span class="s3">)</span>

        <span class="s1">score </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
        <span class="s2">assert </span><span class="s1">score </span><span class="s3">&gt; </span><span class="s5">0.9</span><span class="s3">, </span><span class="s6">&quot;Failed with algorithm %s and score = %f&quot; </span><span class="s3">% (</span><span class="s1">alg</span><span class="s3">, </span><span class="s1">score</span><span class="s3">)</span>

        <span class="s4"># Check we used multiple estimators</span>
        <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">clf</span><span class="s3">.</span><span class="s1">estimators_</span><span class="s3">) &gt; </span><span class="s5">1</span>
        <span class="s4"># Check for distinct random states (see issue #7408)</span>
        <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">set</span><span class="s3">(</span><span class="s1">est</span><span class="s3">.</span><span class="s1">random_state </span><span class="s2">for </span><span class="s1">est </span><span class="s2">in </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">estimators_</span><span class="s3">)) == </span><span class="s1">len</span><span class="s3">(</span>
            <span class="s1">clf</span><span class="s3">.</span><span class="s1">estimators_</span>
        <span class="s3">)</span>

    <span class="s4"># Somewhat hacky regression test: prior to</span>
    <span class="s4"># ae7adc880d624615a34bafdb1d75ef67051b8200,</span>
    <span class="s4"># predict_proba returned SAMME.R values for SAMME.</span>
    <span class="s1">clf_samme</span><span class="s3">.</span><span class="s1">algorithm </span><span class="s3">= </span><span class="s6">&quot;SAMME.R&quot;</span>
    <span class="s1">assert_array_less</span><span class="s3">(</span><span class="s5">0</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">abs</span><span class="s3">(</span><span class="s1">clf_samme</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">) - </span><span class="s1">prob_samme</span><span class="s3">))</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;loss&quot;</span><span class="s3">, [</span><span class="s6">&quot;linear&quot;</span><span class="s3">, </span><span class="s6">&quot;square&quot;</span><span class="s3">, </span><span class="s6">&quot;exponential&quot;</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_diabetes</span><span class="s3">(</span><span class="s1">loss</span><span class="s3">):</span>
    <span class="s4"># Check consistency on dataset diabetes.</span>
    <span class="s1">reg </span><span class="s3">= </span><span class="s1">AdaBoostRegressor</span><span class="s3">(</span><span class="s1">loss</span><span class="s3">=</span><span class="s1">loss</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">reg</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
    <span class="s1">score </span><span class="s3">= </span><span class="s1">reg</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">score </span><span class="s3">&gt; </span><span class="s5">0.55</span>

    <span class="s4"># Check we used multiple estimators</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">reg</span><span class="s3">.</span><span class="s1">estimators_</span><span class="s3">) &gt; </span><span class="s5">1</span>
    <span class="s4"># Check for distinct random states (see issue #7408)</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">set</span><span class="s3">(</span><span class="s1">est</span><span class="s3">.</span><span class="s1">random_state </span><span class="s2">for </span><span class="s1">est </span><span class="s2">in </span><span class="s1">reg</span><span class="s3">.</span><span class="s1">estimators_</span><span class="s3">)) == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">reg</span><span class="s3">.</span><span class="s1">estimators_</span><span class="s3">)</span>


<span class="s4"># TODO(1.6): remove &quot;@pytest.mark.filterwarnings&quot; as SAMME.R will be removed</span>
<span class="s4"># and substituted with the SAMME algorithm as a default; also re-write test to</span>
<span class="s4"># only consider &quot;SAMME&quot;</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s6">&quot;ignore:The SAMME.R algorithm&quot;</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;algorithm&quot;</span><span class="s3">, [</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">, </span><span class="s6">&quot;SAMME.R&quot;</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_staged_predict</span><span class="s3">(</span><span class="s1">algorithm</span><span class="s3">):</span>
    <span class="s4"># Check staged predictions.</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">iris_weights </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randint</span><span class="s3">(</span><span class="s5">10</span><span class="s3">, </span><span class="s1">size</span><span class="s3">=</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">)</span>
    <span class="s1">diabetes_weights </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randint</span><span class="s3">(</span><span class="s5">10</span><span class="s3">, </span><span class="s1">size</span><span class="s3">=</span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">target</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">)</span>

    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">algorithm</span><span class="s3">=</span><span class="s1">algorithm</span><span class="s3">, </span><span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">10</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">iris_weights</span><span class="s3">)</span>

    <span class="s1">predictions </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">)</span>
    <span class="s1">staged_predictions </span><span class="s3">= [</span><span class="s1">p </span><span class="s2">for </span><span class="s1">p </span><span class="s2">in </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">staged_predict</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">)]</span>
    <span class="s1">proba </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">)</span>
    <span class="s1">staged_probas </span><span class="s3">= [</span><span class="s1">p </span><span class="s2">for </span><span class="s1">p </span><span class="s2">in </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">staged_predict_proba</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">)]</span>
    <span class="s1">score </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">iris_weights</span><span class="s3">)</span>
    <span class="s1">staged_scores </span><span class="s3">= [</span>
        <span class="s1">s </span><span class="s2">for </span><span class="s1">s </span><span class="s2">in </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">staged_score</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">iris_weights</span><span class="s3">)</span>
    <span class="s3">]</span>

    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">staged_predictions</span><span class="s3">) == </span><span class="s5">10</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">predictions</span><span class="s3">, </span><span class="s1">staged_predictions</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">])</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">staged_probas</span><span class="s3">) == </span><span class="s5">10</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">proba</span><span class="s3">, </span><span class="s1">staged_probas</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">])</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">staged_scores</span><span class="s3">) == </span><span class="s5">10</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">score</span><span class="s3">, </span><span class="s1">staged_scores</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">])</span>

    <span class="s4"># AdaBoost regression</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostRegressor</span><span class="s3">(</span><span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">10</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">target</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">diabetes_weights</span><span class="s3">)</span>

    <span class="s1">predictions </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">)</span>
    <span class="s1">staged_predictions </span><span class="s3">= [</span><span class="s1">p </span><span class="s2">for </span><span class="s1">p </span><span class="s2">in </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">staged_predict</span><span class="s3">(</span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">)]</span>
    <span class="s1">score </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">target</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">diabetes_weights</span><span class="s3">)</span>
    <span class="s1">staged_scores </span><span class="s3">= [</span>
        <span class="s1">s</span>
        <span class="s2">for </span><span class="s1">s </span><span class="s2">in </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">staged_score</span><span class="s3">(</span>
            <span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">target</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">diabetes_weights</span>
        <span class="s3">)</span>
    <span class="s3">]</span>

    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">staged_predictions</span><span class="s3">) == </span><span class="s5">10</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">predictions</span><span class="s3">, </span><span class="s1">staged_predictions</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">])</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">staged_scores</span><span class="s3">) == </span><span class="s5">10</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">score</span><span class="s3">, </span><span class="s1">staged_scores</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">])</span>


<span class="s2">def </span><span class="s1">test_gridsearch</span><span class="s3">():</span>
    <span class="s4"># Check that base trees can be grid-searched.</span>
    <span class="s4"># AdaBoost classification</span>
    <span class="s1">boost </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">=</span><span class="s1">DecisionTreeClassifier</span><span class="s3">())</span>
    <span class="s1">parameters </span><span class="s3">= {</span>
        <span class="s6">&quot;n_estimators&quot;</span><span class="s3">: (</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">),</span>
        <span class="s6">&quot;estimator__max_depth&quot;</span><span class="s3">: (</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">),</span>
        <span class="s6">&quot;algorithm&quot;</span><span class="s3">: (</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">, </span><span class="s6">&quot;SAMME.R&quot;</span><span class="s3">),</span>
    <span class="s3">}</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">GridSearchCV</span><span class="s3">(</span><span class="s1">boost</span><span class="s3">, </span><span class="s1">parameters</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>

    <span class="s4"># AdaBoost regression</span>
    <span class="s1">boost </span><span class="s3">= </span><span class="s1">AdaBoostRegressor</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">=</span><span class="s1">DecisionTreeRegressor</span><span class="s3">(), </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">parameters </span><span class="s3">= {</span><span class="s6">&quot;n_estimators&quot;</span><span class="s3">: (</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">), </span><span class="s6">&quot;estimator__max_depth&quot;</span><span class="s3">: (</span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">)}</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">GridSearchCV</span><span class="s3">(</span><span class="s1">boost</span><span class="s3">, </span><span class="s1">parameters</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>


<span class="s4"># TODO(1.6): remove &quot;@pytest.mark.filterwarnings&quot; as SAMME.R will be removed</span>
<span class="s4"># and substituted with the SAMME algorithm as a default; also re-write test to</span>
<span class="s4"># only consider &quot;SAMME&quot;</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s6">&quot;ignore:The SAMME.R algorithm&quot;</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_pickle</span><span class="s3">():</span>
    <span class="s4"># Check pickability.</span>
    <span class="s2">import </span><span class="s1">pickle</span>

    <span class="s4"># Adaboost classifier</span>
    <span class="s2">for </span><span class="s1">alg </span><span class="s2">in </span><span class="s3">[</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">, </span><span class="s6">&quot;SAMME.R&quot;</span><span class="s3">]:</span>
        <span class="s1">obj </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">algorithm</span><span class="s3">=</span><span class="s1">alg</span><span class="s3">)</span>
        <span class="s1">obj</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
        <span class="s1">score </span><span class="s3">= </span><span class="s1">obj</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
        <span class="s1">s </span><span class="s3">= </span><span class="s1">pickle</span><span class="s3">.</span><span class="s1">dumps</span><span class="s3">(</span><span class="s1">obj</span><span class="s3">)</span>

        <span class="s1">obj2 </span><span class="s3">= </span><span class="s1">pickle</span><span class="s3">.</span><span class="s1">loads</span><span class="s3">(</span><span class="s1">s</span><span class="s3">)</span>
        <span class="s2">assert </span><span class="s1">type</span><span class="s3">(</span><span class="s1">obj2</span><span class="s3">) == </span><span class="s1">obj</span><span class="s3">.</span><span class="s1">__class__</span>
        <span class="s1">score2 </span><span class="s3">= </span><span class="s1">obj2</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
        <span class="s2">assert </span><span class="s1">score </span><span class="s3">== </span><span class="s1">score2</span>

    <span class="s4"># Adaboost regressor</span>
    <span class="s1">obj </span><span class="s3">= </span><span class="s1">AdaBoostRegressor</span><span class="s3">(</span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">obj</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
    <span class="s1">score </span><span class="s3">= </span><span class="s1">obj</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
    <span class="s1">s </span><span class="s3">= </span><span class="s1">pickle</span><span class="s3">.</span><span class="s1">dumps</span><span class="s3">(</span><span class="s1">obj</span><span class="s3">)</span>

    <span class="s1">obj2 </span><span class="s3">= </span><span class="s1">pickle</span><span class="s3">.</span><span class="s1">loads</span><span class="s3">(</span><span class="s1">s</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">type</span><span class="s3">(</span><span class="s1">obj2</span><span class="s3">) == </span><span class="s1">obj</span><span class="s3">.</span><span class="s1">__class__</span>
    <span class="s1">score2 </span><span class="s3">= </span><span class="s1">obj2</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">score </span><span class="s3">== </span><span class="s1">score2</span>


<span class="s4"># TODO(1.6): remove &quot;@pytest.mark.filterwarnings&quot; as SAMME.R will be removed</span>
<span class="s4"># and substituted with the SAMME algorithm as a default; also re-write test to</span>
<span class="s4"># only consider &quot;SAMME&quot;</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s6">&quot;ignore:The SAMME.R algorithm&quot;</span><span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_importances</span><span class="s3">():</span>
    <span class="s4"># Check variable importances.</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">datasets</span><span class="s3">.</span><span class="s1">make_classification</span><span class="s3">(</span>
        <span class="s1">n_samples</span><span class="s3">=</span><span class="s5">2000</span><span class="s3">,</span>
        <span class="s1">n_features</span><span class="s3">=</span><span class="s5">10</span><span class="s3">,</span>
        <span class="s1">n_informative</span><span class="s3">=</span><span class="s5">3</span><span class="s3">,</span>
        <span class="s1">n_redundant</span><span class="s3">=</span><span class="s5">0</span><span class="s3">,</span>
        <span class="s1">n_repeated</span><span class="s3">=</span><span class="s5">0</span><span class="s3">,</span>
        <span class="s1">shuffle</span><span class="s3">=</span><span class="s2">False</span><span class="s3">,</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s5">1</span><span class="s3">,</span>
    <span class="s3">)</span>

    <span class="s2">for </span><span class="s1">alg </span><span class="s2">in </span><span class="s3">[</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">, </span><span class="s6">&quot;SAMME.R&quot;</span><span class="s3">]:</span>
        <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">algorithm</span><span class="s3">=</span><span class="s1">alg</span><span class="s3">)</span>

        <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
        <span class="s1">importances </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">feature_importances_</span>

        <span class="s2">assert </span><span class="s1">importances</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">] == </span><span class="s5">10</span>
        <span class="s2">assert </span><span class="s3">(</span><span class="s1">importances</span><span class="s3">[:</span><span class="s5">3</span><span class="s3">, </span><span class="s1">np</span><span class="s3">.</span><span class="s1">newaxis</span><span class="s3">] &gt;= </span><span class="s1">importances</span><span class="s3">[</span><span class="s5">3</span><span class="s3">:]).</span><span class="s1">all</span><span class="s3">()</span>


<span class="s2">def </span><span class="s1">test_adaboost_classifier_sample_weight_error</span><span class="s3">():</span>
    <span class="s4"># Test that it gives proper exception on incorrect sample weight.</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">()</span>
    <span class="s1">msg </span><span class="s3">= </span><span class="s1">re</span><span class="s3">.</span><span class="s1">escape</span><span class="s3">(</span><span class="s6">&quot;sample_weight.shape == (1,), expected (6,)&quot;</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">msg</span><span class="s3">):</span>
        <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y_class</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">np</span><span class="s3">.</span><span class="s1">asarray</span><span class="s3">([-</span><span class="s5">1</span><span class="s3">]))</span>


<span class="s2">def </span><span class="s1">test_estimator</span><span class="s3">():</span>
    <span class="s4"># Test different estimators.</span>
    <span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">ensemble </span><span class="s2">import </span><span class="s1">RandomForestClassifier</span>

    <span class="s4"># XXX doesn't work with y_class because RF doesn't support classes_</span>
    <span class="s4"># Shouldn't AdaBoost run a LabelBinarizer?</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">RandomForestClassifier</span><span class="s3">(), </span><span class="s1">algorithm</span><span class="s3">=</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y_regr</span><span class="s3">)</span>

    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">SVC</span><span class="s3">(), </span><span class="s1">algorithm</span><span class="s3">=</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y_class</span><span class="s3">)</span>

    <span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">ensemble </span><span class="s2">import </span><span class="s1">RandomForestRegressor</span>

    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostRegressor</span><span class="s3">(</span><span class="s1">RandomForestRegressor</span><span class="s3">(), </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y_regr</span><span class="s3">)</span>

    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostRegressor</span><span class="s3">(</span><span class="s1">SVR</span><span class="s3">(), </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>
    <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y_regr</span><span class="s3">)</span>

    <span class="s4"># Check that an empty discrete ensemble fails in fit, not predict.</span>
    <span class="s1">X_fail </span><span class="s3">= [[</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">], [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">], [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">], [</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">]]</span>
    <span class="s1">y_fail </span><span class="s3">= [</span><span class="s6">&quot;foo&quot;</span><span class="s3">, </span><span class="s6">&quot;bar&quot;</span><span class="s3">, </span><span class="s5">1</span><span class="s3">, </span><span class="s5">2</span><span class="s3">]</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">SVC</span><span class="s3">(), </span><span class="s1">algorithm</span><span class="s3">=</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s6">&quot;worse than random&quot;</span><span class="s3">):</span>
        <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_fail</span><span class="s3">, </span><span class="s1">y_fail</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_sample_weights_infinite</span><span class="s3">():</span>
    <span class="s1">msg </span><span class="s3">= </span><span class="s6">&quot;Sample weights have reached infinite values&quot;</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">30</span><span class="s3">, </span><span class="s1">learning_rate</span><span class="s3">=</span><span class="s5">23.0</span><span class="s3">, </span><span class="s1">algorithm</span><span class="s3">=</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">warns</span><span class="s3">(</span><span class="s1">UserWarning</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">msg</span><span class="s3">):</span>
        <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;sparse_container, expected_internal_type&quot;</span><span class="s3">,</span>
    <span class="s1">zip</span><span class="s3">(</span>
        <span class="s3">[</span>
            <span class="s3">*</span><span class="s1">CSC_CONTAINERS</span><span class="s3">,</span>
            <span class="s3">*</span><span class="s1">CSR_CONTAINERS</span><span class="s3">,</span>
            <span class="s3">*</span><span class="s1">LIL_CONTAINERS</span><span class="s3">,</span>
            <span class="s3">*</span><span class="s1">COO_CONTAINERS</span><span class="s3">,</span>
            <span class="s3">*</span><span class="s1">DOK_CONTAINERS</span><span class="s3">,</span>
        <span class="s3">],</span>
        <span class="s1">CSC_CONTAINERS </span><span class="s3">+ </span><span class="s5">4 </span><span class="s3">* </span><span class="s1">CSR_CONTAINERS</span><span class="s3">,</span>
    <span class="s3">),</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_sparse_classification</span><span class="s3">(</span><span class="s1">sparse_container</span><span class="s3">, </span><span class="s1">expected_internal_type</span><span class="s3">):</span>
    <span class="s4"># Check classification with sparse input.</span>

    <span class="s2">class </span><span class="s1">CustomSVC</span><span class="s3">(</span><span class="s1">SVC</span><span class="s3">):</span>
        <span class="s0">&quot;&quot;&quot;SVC variant that records the nature of the training set.&quot;&quot;&quot;</span>

        <span class="s2">def </span><span class="s1">fit</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s2">None</span><span class="s3">):</span>
            <span class="s0">&quot;&quot;&quot;Modification on fit caries data type for later verification.&quot;&quot;&quot;</span>
            <span class="s1">super</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>
            <span class="s1">self</span><span class="s3">.</span><span class="s1">data_type_ </span><span class="s3">= </span><span class="s1">type</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
            <span class="s2">return </span><span class="s1">self</span>

    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">datasets</span><span class="s3">.</span><span class="s1">make_multilabel_classification</span><span class="s3">(</span>
        <span class="s1">n_classes</span><span class="s3">=</span><span class="s5">1</span><span class="s3">, </span><span class="s1">n_samples</span><span class="s3">=</span><span class="s5">15</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s5">5</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">42</span>
    <span class="s3">)</span>
    <span class="s4"># Flatten y to a 1d array</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ravel</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">y_test </span><span class="s3">= </span><span class="s1">train_test_split</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>

    <span class="s1">X_train_sparse </span><span class="s3">= </span><span class="s1">sparse_container</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">)</span>
    <span class="s1">X_test_sparse </span><span class="s3">= </span><span class="s1">sparse_container</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>

    <span class="s4"># Trained on sparse format</span>
    <span class="s1">sparse_classifier </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span>
        <span class="s1">estimator</span><span class="s3">=</span><span class="s1">CustomSVC</span><span class="s3">(</span><span class="s1">probability</span><span class="s3">=</span><span class="s2">True</span><span class="s3">),</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s5">1</span><span class="s3">,</span>
        <span class="s1">algorithm</span><span class="s3">=</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">,</span>
    <span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train_sparse</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">)</span>

    <span class="s4"># Trained on dense format</span>
    <span class="s1">dense_classifier </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span>
        <span class="s1">estimator</span><span class="s3">=</span><span class="s1">CustomSVC</span><span class="s3">(</span><span class="s1">probability</span><span class="s3">=</span><span class="s2">True</span><span class="s3">),</span>
        <span class="s1">random_state</span><span class="s3">=</span><span class="s5">1</span><span class="s3">,</span>
        <span class="s1">algorithm</span><span class="s3">=</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">,</span>
    <span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">)</span>

    <span class="s4"># predict</span>
    <span class="s1">sparse_clf_results </span><span class="s3">= </span><span class="s1">sparse_classifier</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X_test_sparse</span><span class="s3">)</span>
    <span class="s1">dense_clf_results </span><span class="s3">= </span><span class="s1">dense_classifier</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
    <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">sparse_clf_results</span><span class="s3">, </span><span class="s1">dense_clf_results</span><span class="s3">)</span>

    <span class="s4"># decision_function</span>
    <span class="s1">sparse_clf_results </span><span class="s3">= </span><span class="s1">sparse_classifier</span><span class="s3">.</span><span class="s1">decision_function</span><span class="s3">(</span><span class="s1">X_test_sparse</span><span class="s3">)</span>
    <span class="s1">dense_clf_results </span><span class="s3">= </span><span class="s1">dense_classifier</span><span class="s3">.</span><span class="s1">decision_function</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">sparse_clf_results</span><span class="s3">, </span><span class="s1">dense_clf_results</span><span class="s3">)</span>

    <span class="s4"># predict_log_proba</span>
    <span class="s1">sparse_clf_results </span><span class="s3">= </span><span class="s1">sparse_classifier</span><span class="s3">.</span><span class="s1">predict_log_proba</span><span class="s3">(</span><span class="s1">X_test_sparse</span><span class="s3">)</span>
    <span class="s1">dense_clf_results </span><span class="s3">= </span><span class="s1">dense_classifier</span><span class="s3">.</span><span class="s1">predict_log_proba</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">sparse_clf_results</span><span class="s3">, </span><span class="s1">dense_clf_results</span><span class="s3">)</span>

    <span class="s4"># predict_proba</span>
    <span class="s1">sparse_clf_results </span><span class="s3">= </span><span class="s1">sparse_classifier</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X_test_sparse</span><span class="s3">)</span>
    <span class="s1">dense_clf_results </span><span class="s3">= </span><span class="s1">dense_classifier</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">sparse_clf_results</span><span class="s3">, </span><span class="s1">dense_clf_results</span><span class="s3">)</span>

    <span class="s4"># score</span>
    <span class="s1">sparse_clf_results </span><span class="s3">= </span><span class="s1">sparse_classifier</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">X_test_sparse</span><span class="s3">, </span><span class="s1">y_test</span><span class="s3">)</span>
    <span class="s1">dense_clf_results </span><span class="s3">= </span><span class="s1">dense_classifier</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_test</span><span class="s3">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">sparse_clf_results</span><span class="s3">, </span><span class="s1">dense_clf_results</span><span class="s3">)</span>

    <span class="s4"># staged_decision_function</span>
    <span class="s1">sparse_clf_results </span><span class="s3">= </span><span class="s1">sparse_classifier</span><span class="s3">.</span><span class="s1">staged_decision_function</span><span class="s3">(</span><span class="s1">X_test_sparse</span><span class="s3">)</span>
    <span class="s1">dense_clf_results </span><span class="s3">= </span><span class="s1">dense_classifier</span><span class="s3">.</span><span class="s1">staged_decision_function</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">sparse_clf_res</span><span class="s3">, </span><span class="s1">dense_clf_res </span><span class="s2">in </span><span class="s1">zip</span><span class="s3">(</span><span class="s1">sparse_clf_results</span><span class="s3">, </span><span class="s1">dense_clf_results</span><span class="s3">):</span>
        <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">sparse_clf_res</span><span class="s3">, </span><span class="s1">dense_clf_res</span><span class="s3">)</span>

    <span class="s4"># staged_predict</span>
    <span class="s1">sparse_clf_results </span><span class="s3">= </span><span class="s1">sparse_classifier</span><span class="s3">.</span><span class="s1">staged_predict</span><span class="s3">(</span><span class="s1">X_test_sparse</span><span class="s3">)</span>
    <span class="s1">dense_clf_results </span><span class="s3">= </span><span class="s1">dense_classifier</span><span class="s3">.</span><span class="s1">staged_predict</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">sparse_clf_res</span><span class="s3">, </span><span class="s1">dense_clf_res </span><span class="s2">in </span><span class="s1">zip</span><span class="s3">(</span><span class="s1">sparse_clf_results</span><span class="s3">, </span><span class="s1">dense_clf_results</span><span class="s3">):</span>
        <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">sparse_clf_res</span><span class="s3">, </span><span class="s1">dense_clf_res</span><span class="s3">)</span>

    <span class="s4"># staged_predict_proba</span>
    <span class="s1">sparse_clf_results </span><span class="s3">= </span><span class="s1">sparse_classifier</span><span class="s3">.</span><span class="s1">staged_predict_proba</span><span class="s3">(</span><span class="s1">X_test_sparse</span><span class="s3">)</span>
    <span class="s1">dense_clf_results </span><span class="s3">= </span><span class="s1">dense_classifier</span><span class="s3">.</span><span class="s1">staged_predict_proba</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">sparse_clf_res</span><span class="s3">, </span><span class="s1">dense_clf_res </span><span class="s2">in </span><span class="s1">zip</span><span class="s3">(</span><span class="s1">sparse_clf_results</span><span class="s3">, </span><span class="s1">dense_clf_results</span><span class="s3">):</span>
        <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">sparse_clf_res</span><span class="s3">, </span><span class="s1">dense_clf_res</span><span class="s3">)</span>

    <span class="s4"># staged_score</span>
    <span class="s1">sparse_clf_results </span><span class="s3">= </span><span class="s1">sparse_classifier</span><span class="s3">.</span><span class="s1">staged_score</span><span class="s3">(</span><span class="s1">X_test_sparse</span><span class="s3">, </span><span class="s1">y_test</span><span class="s3">)</span>
    <span class="s1">dense_clf_results </span><span class="s3">= </span><span class="s1">dense_classifier</span><span class="s3">.</span><span class="s1">staged_score</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_test</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">sparse_clf_res</span><span class="s3">, </span><span class="s1">dense_clf_res </span><span class="s2">in </span><span class="s1">zip</span><span class="s3">(</span><span class="s1">sparse_clf_results</span><span class="s3">, </span><span class="s1">dense_clf_results</span><span class="s3">):</span>
        <span class="s1">assert_array_equal</span><span class="s3">(</span><span class="s1">sparse_clf_res</span><span class="s3">, </span><span class="s1">dense_clf_res</span><span class="s3">)</span>

    <span class="s4"># Verify sparsity of data is maintained during training</span>
    <span class="s1">types </span><span class="s3">= [</span><span class="s1">i</span><span class="s3">.</span><span class="s1">data_type_ </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">sparse_classifier</span><span class="s3">.</span><span class="s1">estimators_</span><span class="s3">]</span>

    <span class="s2">assert </span><span class="s1">all</span><span class="s3">([</span><span class="s1">t </span><span class="s3">== </span><span class="s1">expected_internal_type </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">types</span><span class="s3">])</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;sparse_container, expected_internal_type&quot;</span><span class="s3">,</span>
    <span class="s1">zip</span><span class="s3">(</span>
        <span class="s3">[</span>
            <span class="s3">*</span><span class="s1">CSC_CONTAINERS</span><span class="s3">,</span>
            <span class="s3">*</span><span class="s1">CSR_CONTAINERS</span><span class="s3">,</span>
            <span class="s3">*</span><span class="s1">LIL_CONTAINERS</span><span class="s3">,</span>
            <span class="s3">*</span><span class="s1">COO_CONTAINERS</span><span class="s3">,</span>
            <span class="s3">*</span><span class="s1">DOK_CONTAINERS</span><span class="s3">,</span>
        <span class="s3">],</span>
        <span class="s1">CSC_CONTAINERS </span><span class="s3">+ </span><span class="s5">4 </span><span class="s3">* </span><span class="s1">CSR_CONTAINERS</span><span class="s3">,</span>
    <span class="s3">),</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_sparse_regression</span><span class="s3">(</span><span class="s1">sparse_container</span><span class="s3">, </span><span class="s1">expected_internal_type</span><span class="s3">):</span>
    <span class="s4"># Check regression with sparse input.</span>

    <span class="s2">class </span><span class="s1">CustomSVR</span><span class="s3">(</span><span class="s1">SVR</span><span class="s3">):</span>
        <span class="s0">&quot;&quot;&quot;SVR variant that records the nature of the training set.&quot;&quot;&quot;</span>

        <span class="s2">def </span><span class="s1">fit</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s2">None</span><span class="s3">):</span>
            <span class="s0">&quot;&quot;&quot;Modification on fit caries data type for later verification.&quot;&quot;&quot;</span>
            <span class="s1">super</span><span class="s3">().</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>
            <span class="s1">self</span><span class="s3">.</span><span class="s1">data_type_ </span><span class="s3">= </span><span class="s1">type</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
            <span class="s2">return </span><span class="s1">self</span>

    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">datasets</span><span class="s3">.</span><span class="s1">make_regression</span><span class="s3">(</span>
        <span class="s1">n_samples</span><span class="s3">=</span><span class="s5">15</span><span class="s3">, </span><span class="s1">n_features</span><span class="s3">=</span><span class="s5">50</span><span class="s3">, </span><span class="s1">n_targets</span><span class="s3">=</span><span class="s5">1</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">42</span>
    <span class="s3">)</span>

    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">y_test </span><span class="s3">= </span><span class="s1">train_test_split</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span><span class="s3">)</span>

    <span class="s1">X_train_sparse </span><span class="s3">= </span><span class="s1">sparse_container</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">)</span>
    <span class="s1">X_test_sparse </span><span class="s3">= </span><span class="s1">sparse_container</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>

    <span class="s4"># Trained on sparse format</span>
    <span class="s1">sparse_regressor </span><span class="s3">= </span><span class="s1">AdaBoostRegressor</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">=</span><span class="s1">CustomSVR</span><span class="s3">(), </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">1</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span>
        <span class="s1">X_train_sparse</span><span class="s3">, </span><span class="s1">y_train</span>
    <span class="s3">)</span>

    <span class="s4"># Trained on dense format</span>
    <span class="s1">dense_regressor </span><span class="s3">= </span><span class="s1">AdaBoostRegressor</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">=</span><span class="s1">CustomSVR</span><span class="s3">(), </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">1</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span>
        <span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span>
    <span class="s3">)</span>

    <span class="s4"># predict</span>
    <span class="s1">sparse_regr_results </span><span class="s3">= </span><span class="s1">sparse_regressor</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X_test_sparse</span><span class="s3">)</span>
    <span class="s1">dense_regr_results </span><span class="s3">= </span><span class="s1">dense_regressor</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
    <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">sparse_regr_results</span><span class="s3">, </span><span class="s1">dense_regr_results</span><span class="s3">)</span>

    <span class="s4"># staged_predict</span>
    <span class="s1">sparse_regr_results </span><span class="s3">= </span><span class="s1">sparse_regressor</span><span class="s3">.</span><span class="s1">staged_predict</span><span class="s3">(</span><span class="s1">X_test_sparse</span><span class="s3">)</span>
    <span class="s1">dense_regr_results </span><span class="s3">= </span><span class="s1">dense_regressor</span><span class="s3">.</span><span class="s1">staged_predict</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
    <span class="s2">for </span><span class="s1">sparse_regr_res</span><span class="s3">, </span><span class="s1">dense_regr_res </span><span class="s2">in </span><span class="s1">zip</span><span class="s3">(</span><span class="s1">sparse_regr_results</span><span class="s3">, </span><span class="s1">dense_regr_results</span><span class="s3">):</span>
        <span class="s1">assert_array_almost_equal</span><span class="s3">(</span><span class="s1">sparse_regr_res</span><span class="s3">, </span><span class="s1">dense_regr_res</span><span class="s3">)</span>

    <span class="s1">types </span><span class="s3">= [</span><span class="s1">i</span><span class="s3">.</span><span class="s1">data_type_ </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">sparse_regressor</span><span class="s3">.</span><span class="s1">estimators_</span><span class="s3">]</span>

    <span class="s2">assert </span><span class="s1">all</span><span class="s3">([</span><span class="s1">t </span><span class="s3">== </span><span class="s1">expected_internal_type </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">types</span><span class="s3">])</span>


<span class="s2">def </span><span class="s1">test_sample_weight_adaboost_regressor</span><span class="s3">():</span>
    <span class="s0">&quot;&quot;&quot; 
    AdaBoostRegressor should work without sample_weights in the base estimator 
    The random weighted sampling is done internally in the _boost method in 
    AdaBoostRegressor. 
    &quot;&quot;&quot;</span>

    <span class="s2">class </span><span class="s1">DummyEstimator</span><span class="s3">(</span><span class="s1">BaseEstimator</span><span class="s3">):</span>
        <span class="s2">def </span><span class="s1">fit</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">):</span>
            <span class="s2">pass</span>

        <span class="s2">def </span><span class="s1">predict</span><span class="s3">(</span><span class="s1">self</span><span class="s3">, </span><span class="s1">X</span><span class="s3">):</span>
            <span class="s2">return </span><span class="s1">np</span><span class="s3">.</span><span class="s1">zeros</span><span class="s3">(</span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">])</span>

    <span class="s1">boost </span><span class="s3">= </span><span class="s1">AdaBoostRegressor</span><span class="s3">(</span><span class="s1">DummyEstimator</span><span class="s3">(), </span><span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">3</span><span class="s3">)</span>
    <span class="s1">boost</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y_regr</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">len</span><span class="s3">(</span><span class="s1">boost</span><span class="s3">.</span><span class="s1">estimator_weights_</span><span class="s3">) == </span><span class="s1">len</span><span class="s3">(</span><span class="s1">boost</span><span class="s3">.</span><span class="s1">estimator_errors_</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_multidimensional_X</span><span class="s3">():</span>
    <span class="s0">&quot;&quot;&quot; 
    Check that the AdaBoost estimators can work with n-dimensional 
    data matrix 
    &quot;&quot;&quot;</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s5">0</span><span class="s3">)</span>

    <span class="s1">X </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s5">51</span><span class="s3">, </span><span class="s5">3</span><span class="s3">, </span><span class="s5">3</span><span class="s3">)</span>
    <span class="s1">yc </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">choice</span><span class="s3">([</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">], </span><span class="s5">51</span><span class="s3">)</span>
    <span class="s1">yr </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s5">51</span><span class="s3">)</span>

    <span class="s1">boost </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span>
        <span class="s1">DummyClassifier</span><span class="s3">(</span><span class="s1">strategy</span><span class="s3">=</span><span class="s6">&quot;most_frequent&quot;</span><span class="s3">), </span><span class="s1">algorithm</span><span class="s3">=</span><span class="s6">&quot;SAMME&quot;</span>
    <span class="s3">)</span>
    <span class="s1">boost</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">yc</span><span class="s3">)</span>
    <span class="s1">boost</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">boost</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>

    <span class="s1">boost </span><span class="s3">= </span><span class="s1">AdaBoostRegressor</span><span class="s3">(</span><span class="s1">DummyRegressor</span><span class="s3">())</span>
    <span class="s1">boost</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">yr</span><span class="s3">)</span>
    <span class="s1">boost</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>


<span class="s4"># TODO(1.6): remove &quot;@pytest.mark.filterwarnings&quot; as SAMME.R will be removed</span>
<span class="s4"># and substituted with the SAMME algorithm as a default; also re-write test to</span>
<span class="s4"># only consider &quot;SAMME&quot;</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s6">&quot;ignore:The SAMME.R algorithm&quot;</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;algorithm&quot;</span><span class="s3">, [</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">, </span><span class="s6">&quot;SAMME.R&quot;</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_adaboostclassifier_without_sample_weight</span><span class="s3">(</span><span class="s1">algorithm</span><span class="s3">):</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span>
    <span class="s1">estimator </span><span class="s3">= </span><span class="s1">NoSampleWeightWrapper</span><span class="s3">(</span><span class="s1">DummyClassifier</span><span class="s3">())</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">=</span><span class="s1">estimator</span><span class="s3">, </span><span class="s1">algorithm</span><span class="s3">=</span><span class="s1">algorithm</span><span class="s3">)</span>
    <span class="s1">err_msg </span><span class="s3">= </span><span class="s6">&quot;{} doesn't support sample_weight&quot;</span><span class="s3">.</span><span class="s1">format</span><span class="s3">(</span><span class="s1">estimator</span><span class="s3">.</span><span class="s1">__class__</span><span class="s3">.</span><span class="s1">__name__</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">err_msg</span><span class="s3">):</span>
        <span class="s1">clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_adaboostregressor_sample_weight</span><span class="s3">():</span>
    <span class="s4"># check that giving weight will have an influence on the error computed</span>
    <span class="s4"># for a weak learner</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s5">42</span><span class="s3">)</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">linspace</span><span class="s3">(</span><span class="s5">0</span><span class="s3">, </span><span class="s5">100</span><span class="s3">, </span><span class="s1">num</span><span class="s3">=</span><span class="s5">1000</span><span class="s3">)</span>
    <span class="s1">y </span><span class="s3">= (</span><span class="s5">0.8 </span><span class="s3">* </span><span class="s1">X </span><span class="s3">+ </span><span class="s5">0.2</span><span class="s3">) + (</span><span class="s1">rng</span><span class="s3">.</span><span class="s1">rand</span><span class="s3">(</span><span class="s1">X</span><span class="s3">.</span><span class="s1">shape</span><span class="s3">[</span><span class="s5">0</span><span class="s3">]) * </span><span class="s5">0.0001</span><span class="s3">)</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">X</span><span class="s3">.</span><span class="s1">reshape</span><span class="s3">(-</span><span class="s5">1</span><span class="s3">, </span><span class="s5">1</span><span class="s3">)</span>

    <span class="s4"># add an arbitrary outlier</span>
    <span class="s1">X</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">] *= </span><span class="s5">10</span>
    <span class="s1">y</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">] = </span><span class="s5">10000</span>

    <span class="s4"># random_state=0 ensure that the underlying bootstrap will use the outlier</span>
    <span class="s1">regr_no_outlier </span><span class="s3">= </span><span class="s1">AdaBoostRegressor</span><span class="s3">(</span>
        <span class="s1">estimator</span><span class="s3">=</span><span class="s1">LinearRegression</span><span class="s3">(), </span><span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">1</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">0</span>
    <span class="s3">)</span>
    <span class="s1">regr_with_weight </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">regr_no_outlier</span><span class="s3">)</span>
    <span class="s1">regr_with_outlier </span><span class="s3">= </span><span class="s1">clone</span><span class="s3">(</span><span class="s1">regr_no_outlier</span><span class="s3">)</span>

    <span class="s4"># fit 3 models:</span>
    <span class="s4"># - a model containing the outlier</span>
    <span class="s4"># - a model without the outlier</span>
    <span class="s4"># - a model containing the outlier but with a null sample-weight</span>
    <span class="s1">regr_with_outlier</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">regr_no_outlier</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">[:-</span><span class="s5">1</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[:-</span><span class="s5">1</span><span class="s3">])</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones_like</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">sample_weight</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">] = </span><span class="s5">0</span>
    <span class="s1">regr_with_weight</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>

    <span class="s1">score_with_outlier </span><span class="s3">= </span><span class="s1">regr_with_outlier</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">X</span><span class="s3">[:-</span><span class="s5">1</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[:-</span><span class="s5">1</span><span class="s3">])</span>
    <span class="s1">score_no_outlier </span><span class="s3">= </span><span class="s1">regr_no_outlier</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">X</span><span class="s3">[:-</span><span class="s5">1</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[:-</span><span class="s5">1</span><span class="s3">])</span>
    <span class="s1">score_with_weight </span><span class="s3">= </span><span class="s1">regr_with_weight</span><span class="s3">.</span><span class="s1">score</span><span class="s3">(</span><span class="s1">X</span><span class="s3">[:-</span><span class="s5">1</span><span class="s3">], </span><span class="s1">y</span><span class="s3">[:-</span><span class="s5">1</span><span class="s3">])</span>

    <span class="s2">assert </span><span class="s1">score_with_outlier </span><span class="s3">&lt; </span><span class="s1">score_no_outlier</span>
    <span class="s2">assert </span><span class="s1">score_with_outlier </span><span class="s3">&lt; </span><span class="s1">score_with_weight</span>
    <span class="s2">assert </span><span class="s1">score_no_outlier </span><span class="s3">== </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">approx</span><span class="s3">(</span><span class="s1">score_with_weight</span><span class="s3">)</span>


<span class="s4"># TODO(1.6): remove &quot;@pytest.mark.filterwarnings&quot; as SAMME.R will be removed</span>
<span class="s4"># and substituted with the SAMME algorithm as a default; also re-write test to</span>
<span class="s4"># only consider &quot;SAMME&quot;</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s6">&quot;ignore:The SAMME.R algorithm&quot;</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;algorithm&quot;</span><span class="s3">, [</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">, </span><span class="s6">&quot;SAMME.R&quot;</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_adaboost_consistent_predict</span><span class="s3">(</span><span class="s1">algorithm</span><span class="s3">):</span>
    <span class="s4"># check that predict_proba and predict give consistent results</span>
    <span class="s4"># regression test for:</span>
    <span class="s4"># https://github.com/scikit-learn/scikit-learn/issues/14084</span>
    <span class="s1">X_train</span><span class="s3">, </span><span class="s1">X_test</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">y_test </span><span class="s3">= </span><span class="s1">train_test_split</span><span class="s3">(</span>
        <span class="s3">*</span><span class="s1">datasets</span><span class="s3">.</span><span class="s1">load_digits</span><span class="s3">(</span><span class="s1">return_X_y</span><span class="s3">=</span><span class="s2">True</span><span class="s3">), </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">42</span>
    <span class="s3">)</span>
    <span class="s1">model </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">algorithm</span><span class="s3">=</span><span class="s1">algorithm</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">42</span><span class="s3">)</span>
    <span class="s1">model</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">)</span>

    <span class="s1">assert_array_equal</span><span class="s3">(</span>
        <span class="s1">np</span><span class="s3">.</span><span class="s1">argmax</span><span class="s3">(</span><span class="s1">model</span><span class="s3">.</span><span class="s1">predict_proba</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">), </span><span class="s1">axis</span><span class="s3">=</span><span class="s5">1</span><span class="s3">), </span><span class="s1">model</span><span class="s3">.</span><span class="s1">predict</span><span class="s3">(</span><span class="s1">X_test</span><span class="s3">)</span>
    <span class="s3">)</span>


<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span>
    <span class="s6">&quot;model, X, y&quot;</span><span class="s3">,</span>
    <span class="s3">[</span>
        <span class="s3">(</span><span class="s1">AdaBoostClassifier</span><span class="s3">(), </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">iris</span><span class="s3">.</span><span class="s1">target</span><span class="s3">),</span>
        <span class="s3">(</span><span class="s1">AdaBoostRegressor</span><span class="s3">(), </span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">data</span><span class="s3">, </span><span class="s1">diabetes</span><span class="s3">.</span><span class="s1">target</span><span class="s3">),</span>
    <span class="s3">],</span>
<span class="s3">)</span>
<span class="s2">def </span><span class="s1">test_adaboost_negative_weight_error</span><span class="s3">(</span><span class="s1">model</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">):</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones_like</span><span class="s3">(</span><span class="s1">y</span><span class="s3">)</span>
    <span class="s1">sample_weight</span><span class="s3">[-</span><span class="s5">1</span><span class="s3">] = -</span><span class="s5">10</span>

    <span class="s1">err_msg </span><span class="s3">= </span><span class="s6">&quot;Negative values in data passed to `sample_weight`&quot;</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">raises</span><span class="s3">(</span><span class="s1">ValueError</span><span class="s3">, </span><span class="s1">match</span><span class="s3">=</span><span class="s1">err_msg</span><span class="s3">):</span>
        <span class="s1">model</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>


<span class="s2">def </span><span class="s1">test_adaboost_numerically_stable_feature_importance_with_small_weights</span><span class="s3">():</span>
    <span class="s0">&quot;&quot;&quot;Check that we don't create NaN feature importance with numerically 
    instable inputs. 
 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/20320 
    &quot;&quot;&quot;</span>
    <span class="s1">rng </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">RandomState</span><span class="s3">(</span><span class="s5">42</span><span class="s3">)</span>
    <span class="s1">X </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">normal</span><span class="s3">(</span><span class="s1">size</span><span class="s3">=(</span><span class="s5">1000</span><span class="s3">, </span><span class="s5">10</span><span class="s3">))</span>
    <span class="s1">y </span><span class="s3">= </span><span class="s1">rng</span><span class="s3">.</span><span class="s1">choice</span><span class="s3">([</span><span class="s5">0</span><span class="s3">, </span><span class="s5">1</span><span class="s3">], </span><span class="s1">size</span><span class="s3">=</span><span class="s5">1000</span><span class="s3">)</span>
    <span class="s1">sample_weight </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">ones_like</span><span class="s3">(</span><span class="s1">y</span><span class="s3">) * </span><span class="s5">1e-263</span>
    <span class="s1">tree </span><span class="s3">= </span><span class="s1">DecisionTreeClassifier</span><span class="s3">(</span><span class="s1">max_depth</span><span class="s3">=</span><span class="s5">10</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">12</span><span class="s3">)</span>
    <span class="s1">ada_model </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span>
        <span class="s1">estimator</span><span class="s3">=</span><span class="s1">tree</span><span class="s3">, </span><span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">20</span><span class="s3">, </span><span class="s1">algorithm</span><span class="s3">=</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s5">12</span>
    <span class="s3">)</span>
    <span class="s1">ada_model</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">, </span><span class="s1">sample_weight</span><span class="s3">=</span><span class="s1">sample_weight</span><span class="s3">)</span>
    <span class="s2">assert </span><span class="s1">np</span><span class="s3">.</span><span class="s1">isnan</span><span class="s3">(</span><span class="s1">ada_model</span><span class="s3">.</span><span class="s1">feature_importances_</span><span class="s3">).</span><span class="s1">sum</span><span class="s3">() == </span><span class="s5">0</span>


<span class="s4"># TODO(1.6): remove &quot;@pytest.mark.filterwarnings&quot; as SAMME.R will be removed</span>
<span class="s4"># and substituted with the SAMME algorithm as a default; also re-write test to</span>
<span class="s4"># only consider &quot;SAMME&quot;</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">filterwarnings</span><span class="s3">(</span><span class="s6">&quot;ignore:The SAMME.R algorithm&quot;</span><span class="s3">)</span>
<span class="s3">@</span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">mark</span><span class="s3">.</span><span class="s1">parametrize</span><span class="s3">(</span><span class="s6">&quot;algorithm&quot;</span><span class="s3">, [</span><span class="s6">&quot;SAMME&quot;</span><span class="s3">, </span><span class="s6">&quot;SAMME.R&quot;</span><span class="s3">])</span>
<span class="s2">def </span><span class="s1">test_adaboost_decision_function</span><span class="s3">(</span><span class="s1">algorithm</span><span class="s3">, </span><span class="s1">global_random_seed</span><span class="s3">):</span>
    <span class="s0">&quot;&quot;&quot;Check that the decision function respects the symmetric constraint for weak 
    learners. 
 
    Non-regression test for: 
    https://github.com/scikit-learn/scikit-learn/issues/26520 
    &quot;&quot;&quot;</span>
    <span class="s1">n_classes </span><span class="s3">= </span><span class="s5">3</span>
    <span class="s1">X</span><span class="s3">, </span><span class="s1">y </span><span class="s3">= </span><span class="s1">datasets</span><span class="s3">.</span><span class="s1">make_classification</span><span class="s3">(</span>
        <span class="s1">n_classes</span><span class="s3">=</span><span class="s1">n_classes</span><span class="s3">, </span><span class="s1">n_clusters_per_class</span><span class="s3">=</span><span class="s5">1</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s1">global_random_seed</span>
    <span class="s3">)</span>
    <span class="s1">clf </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span>
        <span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">1</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s1">global_random_seed</span><span class="s3">, </span><span class="s1">algorithm</span><span class="s3">=</span><span class="s1">algorithm</span>
    <span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">y_score </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">decision_function</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">y_score</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">axis</span><span class="s3">=</span><span class="s5">1</span><span class="s3">), </span><span class="s5">0</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s5">1e-8</span><span class="s3">)</span>

    <span class="s2">if </span><span class="s1">algorithm </span><span class="s3">== </span><span class="s6">&quot;SAMME&quot;</span><span class="s3">:</span>
        <span class="s4"># With a single learner, we expect to have a decision function in</span>
        <span class="s4"># {1, - 1 / (n_classes - 1)}.</span>
        <span class="s2">assert </span><span class="s1">set</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">unique</span><span class="s3">(</span><span class="s1">y_score</span><span class="s3">)) == {</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">1 </span><span class="s3">/ (</span><span class="s1">n_classes </span><span class="s3">- </span><span class="s5">1</span><span class="s3">)}</span>

    <span class="s4"># We can assert the same for staged_decision_function since we have a single learner</span>
    <span class="s2">for </span><span class="s1">y_score </span><span class="s2">in </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">staged_decision_function</span><span class="s3">(</span><span class="s1">X</span><span class="s3">):</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">y_score</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">axis</span><span class="s3">=</span><span class="s5">1</span><span class="s3">), </span><span class="s5">0</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s5">1e-8</span><span class="s3">)</span>

        <span class="s2">if </span><span class="s1">algorithm </span><span class="s3">== </span><span class="s6">&quot;SAMME&quot;</span><span class="s3">:</span>
            <span class="s4"># With a single learner, we expect to have a decision function in</span>
            <span class="s4"># {1, - 1 / (n_classes - 1)}.</span>
            <span class="s2">assert </span><span class="s1">set</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">unique</span><span class="s3">(</span><span class="s1">y_score</span><span class="s3">)) == {</span><span class="s5">1</span><span class="s3">, -</span><span class="s5">1 </span><span class="s3">/ (</span><span class="s1">n_classes </span><span class="s3">- </span><span class="s5">1</span><span class="s3">)}</span>

    <span class="s1">clf</span><span class="s3">.</span><span class="s1">set_params</span><span class="s3">(</span><span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">5</span><span class="s3">).</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y</span><span class="s3">)</span>

    <span class="s1">y_score </span><span class="s3">= </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">decision_function</span><span class="s3">(</span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">y_score</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">axis</span><span class="s3">=</span><span class="s5">1</span><span class="s3">), </span><span class="s5">0</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s5">1e-8</span><span class="s3">)</span>

    <span class="s2">for </span><span class="s1">y_score </span><span class="s2">in </span><span class="s1">clf</span><span class="s3">.</span><span class="s1">staged_decision_function</span><span class="s3">(</span><span class="s1">X</span><span class="s3">):</span>
        <span class="s1">assert_allclose</span><span class="s3">(</span><span class="s1">y_score</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">axis</span><span class="s3">=</span><span class="s5">1</span><span class="s3">), </span><span class="s5">0</span><span class="s3">, </span><span class="s1">atol</span><span class="s3">=</span><span class="s5">1e-8</span><span class="s3">)</span>


<span class="s4"># TODO(1.6): remove</span>
<span class="s2">def </span><span class="s1">test_deprecated_samme_r_algorithm</span><span class="s3">():</span>
    <span class="s1">adaboost_clf </span><span class="s3">= </span><span class="s1">AdaBoostClassifier</span><span class="s3">(</span><span class="s1">n_estimators</span><span class="s3">=</span><span class="s5">1</span><span class="s3">)</span>
    <span class="s2">with </span><span class="s1">pytest</span><span class="s3">.</span><span class="s1">warns</span><span class="s3">(</span>
        <span class="s1">FutureWarning</span><span class="s3">,</span>
        <span class="s1">match</span><span class="s3">=</span><span class="s1">re</span><span class="s3">.</span><span class="s1">escape</span><span class="s3">(</span><span class="s6">&quot;The SAMME.R algorithm (the default) is deprecated&quot;</span><span class="s3">),</span>
    <span class="s3">):</span>
        <span class="s1">adaboost_clf</span><span class="s3">.</span><span class="s1">fit</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">y_class</span><span class="s3">)</span>
</pre>
</body>
</html>