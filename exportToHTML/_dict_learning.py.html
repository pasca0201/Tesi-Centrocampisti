<html>
<head>
<title>_dict_learning.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #5f826b; font-style: italic;}
.s1 { color: #bcbec4;}
.s2 { color: #7a7e85;}
.s3 { color: #cf8e6d;}
.s4 { color: #bcbec4;}
.s5 { color: #6aab73;}
.s6 { color: #2aacb8;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
_dict_learning.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Dictionary learning.&quot;&quot;&quot;</span>

<span class="s2"># Author: Vlad Niculae, Gael Varoquaux, Alexandre Gramfort</span>
<span class="s2"># License: BSD 3 clause</span>

<span class="s3">import </span><span class="s1">itertools</span>
<span class="s3">import </span><span class="s1">sys</span>
<span class="s3">import </span><span class="s1">time</span>
<span class="s3">from </span><span class="s1">numbers </span><span class="s3">import </span><span class="s1">Integral</span><span class="s4">, </span><span class="s1">Real</span>
<span class="s3">from </span><span class="s1">warnings </span><span class="s3">import </span><span class="s1">warn</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>
<span class="s3">from </span><span class="s1">joblib </span><span class="s3">import </span><span class="s1">effective_n_jobs</span>
<span class="s3">from </span><span class="s1">scipy </span><span class="s3">import </span><span class="s1">linalg</span>

<span class="s3">from </span><span class="s4">..</span><span class="s1">base </span><span class="s3">import </span><span class="s4">(</span>
    <span class="s1">BaseEstimator</span><span class="s4">,</span>
    <span class="s1">ClassNamePrefixFeaturesOutMixin</span><span class="s4">,</span>
    <span class="s1">TransformerMixin</span><span class="s4">,</span>
    <span class="s1">_fit_context</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">linear_model </span><span class="s3">import </span><span class="s1">Lars</span><span class="s4">, </span><span class="s1">Lasso</span><span class="s4">, </span><span class="s1">LassoLars</span><span class="s4">, </span><span class="s1">orthogonal_mp_gram</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils </span><span class="s3">import </span><span class="s1">check_array</span><span class="s4">, </span><span class="s1">check_random_state</span><span class="s4">, </span><span class="s1">gen_batches</span><span class="s4">, </span><span class="s1">gen_even_slices</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">_param_validation </span><span class="s3">import </span><span class="s1">Hidden</span><span class="s4">, </span><span class="s1">Interval</span><span class="s4">, </span><span class="s1">StrOptions</span><span class="s4">, </span><span class="s1">validate_params</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">extmath </span><span class="s3">import </span><span class="s1">randomized_svd</span><span class="s4">, </span><span class="s1">row_norms</span><span class="s4">, </span><span class="s1">svd_flip</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">parallel </span><span class="s3">import </span><span class="s1">Parallel</span><span class="s4">, </span><span class="s1">delayed</span>
<span class="s3">from </span><span class="s4">..</span><span class="s1">utils</span><span class="s4">.</span><span class="s1">validation </span><span class="s3">import </span><span class="s1">check_is_fitted</span>


<span class="s3">def </span><span class="s1">_check_positive_coding</span><span class="s4">(</span><span class="s1">method</span><span class="s4">, </span><span class="s1">positive</span><span class="s4">):</span>
    <span class="s3">if </span><span class="s1">positive </span><span class="s3">and </span><span class="s1">method </span><span class="s3">in </span><span class="s4">[</span><span class="s5">&quot;omp&quot;</span><span class="s4">, </span><span class="s5">&quot;lars&quot;</span><span class="s4">]:</span>
        <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
            <span class="s5">&quot;Positive constraint not supported for '{}' coding method.&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span><span class="s1">method</span><span class="s4">)</span>
        <span class="s4">)</span>


<span class="s3">def </span><span class="s1">_sparse_encode_precomputed</span><span class="s4">(</span>
    <span class="s1">X</span><span class="s4">,</span>
    <span class="s1">dictionary</span><span class="s4">,</span>
    <span class="s4">*,</span>
    <span class="s1">gram</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">cov</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">algorithm</span><span class="s4">=</span><span class="s5">&quot;lasso_lars&quot;</span><span class="s4">,</span>
    <span class="s1">regularization</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">copy_cov</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
    <span class="s1">init</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">1000</span><span class="s4">,</span>
    <span class="s1">verbose</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
    <span class="s1">positive</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
<span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Generic sparse coding with precomputed Gram and/or covariance matrices. 
 
    Each row of the result is the solution to a Lasso problem. 
 
    Parameters 
    ---------- 
    X : ndarray of shape (n_samples, n_features) 
        Data matrix. 
 
    dictionary : ndarray of shape (n_components, n_features) 
        The dictionary matrix against which to solve the sparse coding of 
        the data. Some of the algorithms assume normalized rows. 
 
    gram : ndarray of shape (n_components, n_components), default=None 
        Precomputed Gram matrix, `dictionary * dictionary'` 
        gram can be `None` if method is 'threshold'. 
 
    cov : ndarray of shape (n_components, n_samples), default=None 
        Precomputed covariance, `dictionary * X'`. 
 
    algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp', 'threshold'}, \ 
            default='lasso_lars' 
        The algorithm used: 
 
        * `'lars'`: uses the least angle regression method 
          (`linear_model.lars_path`); 
        * `'lasso_lars'`: uses Lars to compute the Lasso solution; 
        * `'lasso_cd'`: uses the coordinate descent method to compute the 
          Lasso solution (`linear_model.Lasso`). lasso_lars will be faster if 
          the estimated components are sparse; 
        * `'omp'`: uses orthogonal matching pursuit to estimate the sparse 
          solution; 
        * `'threshold'`: squashes to zero all coefficients less than 
          regularization from the projection `dictionary * data'`. 
 
    regularization : int or float, default=None 
        The regularization parameter. It corresponds to alpha when 
        algorithm is `'lasso_lars'`, `'lasso_cd'` or `'threshold'`. 
        Otherwise it corresponds to `n_nonzero_coefs`. 
 
    init : ndarray of shape (n_samples, n_components), default=None 
        Initialization value of the sparse code. Only used if 
        `algorithm='lasso_cd'`. 
 
    max_iter : int, default=1000 
        Maximum number of iterations to perform if `algorithm='lasso_cd'` or 
        `'lasso_lars'`. 
 
    copy_cov : bool, default=True 
        Whether to copy the precomputed covariance matrix; if `False`, it may 
        be overwritten. 
 
    verbose : int, default=0 
        Controls the verbosity; the higher, the more messages. 
 
    positive: bool, default=False 
        Whether to enforce a positivity constraint on the sparse code. 
 
        .. versionadded:: 0.20 
 
    Returns 
    ------- 
    code : ndarray of shape (n_components, n_features) 
        The sparse codes. 
    &quot;&quot;&quot;</span>
    <span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_features </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span>
    <span class="s1">n_components </span><span class="s4">= </span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>

    <span class="s3">if </span><span class="s1">algorithm </span><span class="s4">== </span><span class="s5">&quot;lasso_lars&quot;</span><span class="s4">:</span>
        <span class="s1">alpha </span><span class="s4">= </span><span class="s1">float</span><span class="s4">(</span><span class="s1">regularization</span><span class="s4">) / </span><span class="s1">n_features  </span><span class="s2"># account for scaling</span>
        <span class="s3">try</span><span class="s4">:</span>
            <span class="s1">err_mgt </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">seterr</span><span class="s4">(</span><span class="s1">all</span><span class="s4">=</span><span class="s5">&quot;ignore&quot;</span><span class="s4">)</span>

            <span class="s2"># Not passing in verbose=max(0, verbose-1) because Lars.fit already</span>
            <span class="s2"># corrects the verbosity level.</span>
            <span class="s1">lasso_lars </span><span class="s4">= </span><span class="s1">LassoLars</span><span class="s4">(</span>
                <span class="s1">alpha</span><span class="s4">=</span><span class="s1">alpha</span><span class="s4">,</span>
                <span class="s1">fit_intercept</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
                <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
                <span class="s1">precompute</span><span class="s4">=</span><span class="s1">gram</span><span class="s4">,</span>
                <span class="s1">fit_path</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
                <span class="s1">positive</span><span class="s4">=</span><span class="s1">positive</span><span class="s4">,</span>
                <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span><span class="s4">,</span>
            <span class="s4">)</span>
            <span class="s1">lasso_lars</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">T</span><span class="s4">, </span><span class="s1">X</span><span class="s4">.</span><span class="s1">T</span><span class="s4">, </span><span class="s1">Xy</span><span class="s4">=</span><span class="s1">cov</span><span class="s4">)</span>
            <span class="s1">new_code </span><span class="s4">= </span><span class="s1">lasso_lars</span><span class="s4">.</span><span class="s1">coef_</span>
        <span class="s3">finally</span><span class="s4">:</span>
            <span class="s1">np</span><span class="s4">.</span><span class="s1">seterr</span><span class="s4">(**</span><span class="s1">err_mgt</span><span class="s4">)</span>

    <span class="s3">elif </span><span class="s1">algorithm </span><span class="s4">== </span><span class="s5">&quot;lasso_cd&quot;</span><span class="s4">:</span>
        <span class="s1">alpha </span><span class="s4">= </span><span class="s1">float</span><span class="s4">(</span><span class="s1">regularization</span><span class="s4">) / </span><span class="s1">n_features  </span><span class="s2"># account for scaling</span>

        <span class="s2"># TODO: Make verbosity argument for Lasso?</span>
        <span class="s2"># sklearn.linear_model.coordinate_descent.enet_path has a verbosity</span>
        <span class="s2"># argument that we could pass in from Lasso.</span>
        <span class="s1">clf </span><span class="s4">= </span><span class="s1">Lasso</span><span class="s4">(</span>
            <span class="s1">alpha</span><span class="s4">=</span><span class="s1">alpha</span><span class="s4">,</span>
            <span class="s1">fit_intercept</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
            <span class="s1">precompute</span><span class="s4">=</span><span class="s1">gram</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span><span class="s4">,</span>
            <span class="s1">warm_start</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">positive</span><span class="s4">=</span><span class="s1">positive</span><span class="s4">,</span>
        <span class="s4">)</span>

        <span class="s3">if </span><span class="s1">init </span><span class="s3">is not None</span><span class="s4">:</span>
            <span class="s2"># In some workflows using coordinate descent algorithms:</span>
            <span class="s2">#  - users might provide NumPy arrays with read-only buffers</span>
            <span class="s2">#  - `joblib` might memmap arrays making their buffer read-only</span>
            <span class="s2"># TODO: move this handling (which is currently too broad)</span>
            <span class="s2"># closer to the actual private function which need buffers to be writable.</span>
            <span class="s3">if not </span><span class="s1">init</span><span class="s4">.</span><span class="s1">flags</span><span class="s4">[</span><span class="s5">&quot;WRITEABLE&quot;</span><span class="s4">]:</span>
                <span class="s1">init </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span><span class="s1">init</span><span class="s4">)</span>
            <span class="s1">clf</span><span class="s4">.</span><span class="s1">coef_ </span><span class="s4">= </span><span class="s1">init</span>

        <span class="s1">clf</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">T</span><span class="s4">, </span><span class="s1">X</span><span class="s4">.</span><span class="s1">T</span><span class="s4">, </span><span class="s1">check_input</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>
        <span class="s1">new_code </span><span class="s4">= </span><span class="s1">clf</span><span class="s4">.</span><span class="s1">coef_</span>

    <span class="s3">elif </span><span class="s1">algorithm </span><span class="s4">== </span><span class="s5">&quot;lars&quot;</span><span class="s4">:</span>
        <span class="s3">try</span><span class="s4">:</span>
            <span class="s1">err_mgt </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">seterr</span><span class="s4">(</span><span class="s1">all</span><span class="s4">=</span><span class="s5">&quot;ignore&quot;</span><span class="s4">)</span>

            <span class="s2"># Not passing in verbose=max(0, verbose-1) because Lars.fit already</span>
            <span class="s2"># corrects the verbosity level.</span>
            <span class="s1">lars </span><span class="s4">= </span><span class="s1">Lars</span><span class="s4">(</span>
                <span class="s1">fit_intercept</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
                <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
                <span class="s1">precompute</span><span class="s4">=</span><span class="s1">gram</span><span class="s4">,</span>
                <span class="s1">n_nonzero_coefs</span><span class="s4">=</span><span class="s1">int</span><span class="s4">(</span><span class="s1">regularization</span><span class="s4">),</span>
                <span class="s1">fit_path</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
            <span class="s4">)</span>
            <span class="s1">lars</span><span class="s4">.</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">T</span><span class="s4">, </span><span class="s1">X</span><span class="s4">.</span><span class="s1">T</span><span class="s4">, </span><span class="s1">Xy</span><span class="s4">=</span><span class="s1">cov</span><span class="s4">)</span>
            <span class="s1">new_code </span><span class="s4">= </span><span class="s1">lars</span><span class="s4">.</span><span class="s1">coef_</span>
        <span class="s3">finally</span><span class="s4">:</span>
            <span class="s1">np</span><span class="s4">.</span><span class="s1">seterr</span><span class="s4">(**</span><span class="s1">err_mgt</span><span class="s4">)</span>

    <span class="s3">elif </span><span class="s1">algorithm </span><span class="s4">== </span><span class="s5">&quot;threshold&quot;</span><span class="s4">:</span>
        <span class="s1">new_code </span><span class="s4">= (</span><span class="s1">np</span><span class="s4">.</span><span class="s1">sign</span><span class="s4">(</span><span class="s1">cov</span><span class="s4">) * </span><span class="s1">np</span><span class="s4">.</span><span class="s1">maximum</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">abs</span><span class="s4">(</span><span class="s1">cov</span><span class="s4">) - </span><span class="s1">regularization</span><span class="s4">, </span><span class="s6">0</span><span class="s4">)).</span><span class="s1">T</span>
        <span class="s3">if </span><span class="s1">positive</span><span class="s4">:</span>
            <span class="s1">np</span><span class="s4">.</span><span class="s1">clip</span><span class="s4">(</span><span class="s1">new_code</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">out</span><span class="s4">=</span><span class="s1">new_code</span><span class="s4">)</span>

    <span class="s3">elif </span><span class="s1">algorithm </span><span class="s4">== </span><span class="s5">&quot;omp&quot;</span><span class="s4">:</span>
        <span class="s1">new_code </span><span class="s4">= </span><span class="s1">orthogonal_mp_gram</span><span class="s4">(</span>
            <span class="s1">Gram</span><span class="s4">=</span><span class="s1">gram</span><span class="s4">,</span>
            <span class="s1">Xy</span><span class="s4">=</span><span class="s1">cov</span><span class="s4">,</span>
            <span class="s1">n_nonzero_coefs</span><span class="s4">=</span><span class="s1">int</span><span class="s4">(</span><span class="s1">regularization</span><span class="s4">),</span>
            <span class="s1">tol</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
            <span class="s1">norms_squared</span><span class="s4">=</span><span class="s1">row_norms</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">squared</span><span class="s4">=</span><span class="s3">True</span><span class="s4">),</span>
            <span class="s1">copy_Xy</span><span class="s4">=</span><span class="s1">copy_cov</span><span class="s4">,</span>
        <span class="s4">).</span><span class="s1">T</span>

    <span class="s3">return </span><span class="s1">new_code</span><span class="s4">.</span><span class="s1">reshape</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_components</span><span class="s4">)</span>


<span class="s4">@</span><span class="s1">validate_params</span><span class="s4">(</span>
    <span class="s4">{</span>
        <span class="s5">&quot;X&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;dictionary&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;gram&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">, </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;cov&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">, </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;algorithm&quot;</span><span class="s4">: [</span>
            <span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;lasso_lars&quot;</span><span class="s4">, </span><span class="s5">&quot;lasso_cd&quot;</span><span class="s4">, </span><span class="s5">&quot;lars&quot;</span><span class="s4">, </span><span class="s5">&quot;omp&quot;</span><span class="s4">, </span><span class="s5">&quot;threshold&quot;</span><span class="s4">})</span>
        <span class="s4">],</span>
        <span class="s5">&quot;n_nonzero_coefs&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;alpha&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;copy_cov&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;init&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">, </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;max_iter&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;n_jobs&quot;</span><span class="s4">: [</span><span class="s1">Integral</span><span class="s4">, </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;check_input&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;verbose&quot;</span><span class="s4">: [</span><span class="s5">&quot;verbose&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;positive&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
    <span class="s4">},</span>
    <span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s2"># XXX : could be moved to the linear_model module</span>
<span class="s3">def </span><span class="s1">sparse_encode</span><span class="s4">(</span>
    <span class="s1">X</span><span class="s4">,</span>
    <span class="s1">dictionary</span><span class="s4">,</span>
    <span class="s4">*,</span>
    <span class="s1">gram</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">cov</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">algorithm</span><span class="s4">=</span><span class="s5">&quot;lasso_lars&quot;</span><span class="s4">,</span>
    <span class="s1">n_nonzero_coefs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">alpha</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">copy_cov</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
    <span class="s1">init</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">1000</span><span class="s4">,</span>
    <span class="s1">n_jobs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">check_input</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
    <span class="s1">verbose</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
    <span class="s1">positive</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
<span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Sparse coding. 
 
    Each row of the result is the solution to a sparse coding problem. 
    The goal is to find a sparse array `code` such that:: 
 
        X ~= code * dictionary 
 
    Read more in the :ref:`User Guide &lt;SparseCoder&gt;`. 
 
    Parameters 
    ---------- 
    X : array-like of shape (n_samples, n_features) 
        Data matrix. 
 
    dictionary : array-like of shape (n_components, n_features) 
        The dictionary matrix against which to solve the sparse coding of 
        the data. Some of the algorithms assume normalized rows for meaningful 
        output. 
 
    gram : array-like of shape (n_components, n_components), default=None 
        Precomputed Gram matrix, `dictionary * dictionary'`. 
 
    cov : array-like of shape (n_components, n_samples), default=None 
        Precomputed covariance, `dictionary' * X`. 
 
    algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp', 'threshold'}, \ 
            default='lasso_lars' 
        The algorithm used: 
 
        * `'lars'`: uses the least angle regression method 
          (`linear_model.lars_path`); 
        * `'lasso_lars'`: uses Lars to compute the Lasso solution; 
        * `'lasso_cd'`: uses the coordinate descent method to compute the 
          Lasso solution (`linear_model.Lasso`). lasso_lars will be faster if 
          the estimated components are sparse; 
        * `'omp'`: uses orthogonal matching pursuit to estimate the sparse 
          solution; 
        * `'threshold'`: squashes to zero all coefficients less than 
          regularization from the projection `dictionary * data'`. 
 
    n_nonzero_coefs : int, default=None 
        Number of nonzero coefficients to target in each column of the 
        solution. This is only used by `algorithm='lars'` and `algorithm='omp'` 
        and is overridden by `alpha` in the `omp` case. If `None`, then 
        `n_nonzero_coefs=int(n_features / 10)`. 
 
    alpha : float, default=None 
        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`, `alpha` is the 
        penalty applied to the L1 norm. 
        If `algorithm='threshold'`, `alpha` is the absolute value of the 
        threshold below which coefficients will be squashed to zero. 
        If `algorithm='omp'`, `alpha` is the tolerance parameter: the value of 
        the reconstruction error targeted. In this case, it overrides 
        `n_nonzero_coefs`. 
        If `None`, default to 1. 
 
    copy_cov : bool, default=True 
        Whether to copy the precomputed covariance matrix; if `False`, it may 
        be overwritten. 
 
    init : ndarray of shape (n_samples, n_components), default=None 
        Initialization value of the sparse codes. Only used if 
        `algorithm='lasso_cd'`. 
 
    max_iter : int, default=1000 
        Maximum number of iterations to perform if `algorithm='lasso_cd'` or 
        `'lasso_lars'`. 
 
    n_jobs : int, default=None 
        Number of parallel jobs to run. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    check_input : bool, default=True 
        If `False`, the input arrays X and dictionary will not be checked. 
 
    verbose : int, default=0 
        Controls the verbosity; the higher, the more messages. 
 
    positive : bool, default=False 
        Whether to enforce positivity when finding the encoding. 
 
        .. versionadded:: 0.20 
 
    Returns 
    ------- 
    code : ndarray of shape (n_samples, n_components) 
        The sparse codes. 
 
    See Also 
    -------- 
    sklearn.linear_model.lars_path : Compute Least Angle Regression or Lasso 
        path using LARS algorithm. 
    sklearn.linear_model.orthogonal_mp : Solves Orthogonal Matching Pursuit problems. 
    sklearn.linear_model.Lasso : Train Linear Model with L1 prior as regularizer. 
    SparseCoder : Find a sparse representation of data from a fixed precomputed 
        dictionary. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.decomposition import sparse_encode 
    &gt;&gt;&gt; X = np.array([[-1, -1, -1], [0, 0, 3]]) 
    &gt;&gt;&gt; dictionary = np.array( 
    ...     [[0, 1, 0], 
    ...      [-1, -1, 2], 
    ...      [1, 1, 1], 
    ...      [0, 1, 1], 
    ...      [0, 2, 1]], 
    ...    dtype=np.float64 
    ... ) 
    &gt;&gt;&gt; sparse_encode(X, dictionary, alpha=1e-10) 
    array([[ 0.,  0., -1.,  0.,  0.], 
           [ 0.,  1.,  1.,  0.,  0.]]) 
    &quot;&quot;&quot;</span>
    <span class="s3">if </span><span class="s1">check_input</span><span class="s4">:</span>
        <span class="s3">if </span><span class="s1">algorithm </span><span class="s4">== </span><span class="s5">&quot;lasso_cd&quot;</span><span class="s4">:</span>
            <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span>
                <span class="s1">dictionary</span><span class="s4">, </span><span class="s1">order</span><span class="s4">=</span><span class="s5">&quot;C&quot;</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">]</span>
            <span class="s4">)</span>
            <span class="s1">X </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">order</span><span class="s4">=</span><span class="s5">&quot;C&quot;</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">])</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">)</span>
            <span class="s1">X </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s3">if </span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">] != </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]:</span>
        <span class="s3">raise </span><span class="s1">ValueError</span><span class="s4">(</span>
            <span class="s5">&quot;Dictionary and X have different numbers of features:&quot;</span>
            <span class="s5">&quot;dictionary.shape: {} X.shape{}&quot;</span><span class="s4">.</span><span class="s1">format</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">, </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">)</span>
        <span class="s4">)</span>

    <span class="s1">_check_positive_coding</span><span class="s4">(</span><span class="s1">algorithm</span><span class="s4">, </span><span class="s1">positive</span><span class="s4">)</span>

    <span class="s3">return </span><span class="s1">_sparse_encode</span><span class="s4">(</span>
        <span class="s1">X</span><span class="s4">,</span>
        <span class="s1">dictionary</span><span class="s4">,</span>
        <span class="s1">gram</span><span class="s4">=</span><span class="s1">gram</span><span class="s4">,</span>
        <span class="s1">cov</span><span class="s4">=</span><span class="s1">cov</span><span class="s4">,</span>
        <span class="s1">algorithm</span><span class="s4">=</span><span class="s1">algorithm</span><span class="s4">,</span>
        <span class="s1">n_nonzero_coefs</span><span class="s4">=</span><span class="s1">n_nonzero_coefs</span><span class="s4">,</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s1">alpha</span><span class="s4">,</span>
        <span class="s1">copy_cov</span><span class="s4">=</span><span class="s1">copy_cov</span><span class="s4">,</span>
        <span class="s1">init</span><span class="s4">=</span><span class="s1">init</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span><span class="s4">,</span>
        <span class="s1">n_jobs</span><span class="s4">=</span><span class="s1">n_jobs</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
        <span class="s1">positive</span><span class="s4">=</span><span class="s1">positive</span><span class="s4">,</span>
    <span class="s4">)</span>


<span class="s3">def </span><span class="s1">_sparse_encode</span><span class="s4">(</span>
    <span class="s1">X</span><span class="s4">,</span>
    <span class="s1">dictionary</span><span class="s4">,</span>
    <span class="s4">*,</span>
    <span class="s1">gram</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">cov</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">algorithm</span><span class="s4">=</span><span class="s5">&quot;lasso_lars&quot;</span><span class="s4">,</span>
    <span class="s1">n_nonzero_coefs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">alpha</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">copy_cov</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
    <span class="s1">init</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">1000</span><span class="s4">,</span>
    <span class="s1">n_jobs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">verbose</span><span class="s4">=</span><span class="s6">0</span><span class="s4">,</span>
    <span class="s1">positive</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
<span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Sparse coding without input/parameter validation.&quot;&quot;&quot;</span>

    <span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_features </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span>
    <span class="s1">n_components </span><span class="s4">= </span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>

    <span class="s3">if </span><span class="s1">algorithm </span><span class="s3">in </span><span class="s4">(</span><span class="s5">&quot;lars&quot;</span><span class="s4">, </span><span class="s5">&quot;omp&quot;</span><span class="s4">):</span>
        <span class="s1">regularization </span><span class="s4">= </span><span class="s1">n_nonzero_coefs</span>
        <span class="s3">if </span><span class="s1">regularization </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">regularization </span><span class="s4">= </span><span class="s1">min</span><span class="s4">(</span><span class="s1">max</span><span class="s4">(</span><span class="s1">n_features </span><span class="s4">/ </span><span class="s6">10</span><span class="s4">, </span><span class="s6">1</span><span class="s4">), </span><span class="s1">n_components</span><span class="s4">)</span>
    <span class="s3">else</span><span class="s4">:</span>
        <span class="s1">regularization </span><span class="s4">= </span><span class="s1">alpha</span>
        <span class="s3">if </span><span class="s1">regularization </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">regularization </span><span class="s4">= </span><span class="s6">1.0</span>

    <span class="s3">if </span><span class="s1">gram </span><span class="s3">is None and </span><span class="s1">algorithm </span><span class="s4">!= </span><span class="s5">&quot;threshold&quot;</span><span class="s4">:</span>
        <span class="s1">gram </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">dot</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">, </span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">T</span><span class="s4">)</span>

    <span class="s3">if </span><span class="s1">cov </span><span class="s3">is None and </span><span class="s1">algorithm </span><span class="s4">!= </span><span class="s5">&quot;lasso_cd&quot;</span><span class="s4">:</span>
        <span class="s1">copy_cov </span><span class="s4">= </span><span class="s3">False</span>
        <span class="s1">cov </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">dot</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">, </span><span class="s1">X</span><span class="s4">.</span><span class="s1">T</span><span class="s4">)</span>

    <span class="s3">if </span><span class="s1">effective_n_jobs</span><span class="s4">(</span><span class="s1">n_jobs</span><span class="s4">) == </span><span class="s6">1 </span><span class="s3">or </span><span class="s1">algorithm </span><span class="s4">== </span><span class="s5">&quot;threshold&quot;</span><span class="s4">:</span>
        <span class="s1">code </span><span class="s4">= </span><span class="s1">_sparse_encode_precomputed</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">,</span>
            <span class="s1">dictionary</span><span class="s4">,</span>
            <span class="s1">gram</span><span class="s4">=</span><span class="s1">gram</span><span class="s4">,</span>
            <span class="s1">cov</span><span class="s4">=</span><span class="s1">cov</span><span class="s4">,</span>
            <span class="s1">algorithm</span><span class="s4">=</span><span class="s1">algorithm</span><span class="s4">,</span>
            <span class="s1">regularization</span><span class="s4">=</span><span class="s1">regularization</span><span class="s4">,</span>
            <span class="s1">copy_cov</span><span class="s4">=</span><span class="s1">copy_cov</span><span class="s4">,</span>
            <span class="s1">init</span><span class="s4">=</span><span class="s1">init</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
            <span class="s1">positive</span><span class="s4">=</span><span class="s1">positive</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s3">return </span><span class="s1">code</span>

    <span class="s2"># Enter parallel code block</span>
    <span class="s1">n_samples </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>
    <span class="s1">n_components </span><span class="s4">= </span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>
    <span class="s1">code </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">empty</span><span class="s4">((</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_components</span><span class="s4">))</span>
    <span class="s1">slices </span><span class="s4">= </span><span class="s1">list</span><span class="s4">(</span><span class="s1">gen_even_slices</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">effective_n_jobs</span><span class="s4">(</span><span class="s1">n_jobs</span><span class="s4">)))</span>

    <span class="s1">code_views </span><span class="s4">= </span><span class="s1">Parallel</span><span class="s4">(</span><span class="s1">n_jobs</span><span class="s4">=</span><span class="s1">n_jobs</span><span class="s4">, </span><span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">)(</span>
        <span class="s1">delayed</span><span class="s4">(</span><span class="s1">_sparse_encode_precomputed</span><span class="s4">)(</span>
            <span class="s1">X</span><span class="s4">[</span><span class="s1">this_slice</span><span class="s4">],</span>
            <span class="s1">dictionary</span><span class="s4">,</span>
            <span class="s1">gram</span><span class="s4">=</span><span class="s1">gram</span><span class="s4">,</span>
            <span class="s1">cov</span><span class="s4">=</span><span class="s1">cov</span><span class="s4">[:, </span><span class="s1">this_slice</span><span class="s4">] </span><span class="s3">if </span><span class="s1">cov </span><span class="s3">is not None else None</span><span class="s4">,</span>
            <span class="s1">algorithm</span><span class="s4">=</span><span class="s1">algorithm</span><span class="s4">,</span>
            <span class="s1">regularization</span><span class="s4">=</span><span class="s1">regularization</span><span class="s4">,</span>
            <span class="s1">copy_cov</span><span class="s4">=</span><span class="s1">copy_cov</span><span class="s4">,</span>
            <span class="s1">init</span><span class="s4">=</span><span class="s1">init</span><span class="s4">[</span><span class="s1">this_slice</span><span class="s4">] </span><span class="s3">if </span><span class="s1">init </span><span class="s3">is not None else None</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
            <span class="s1">positive</span><span class="s4">=</span><span class="s1">positive</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s3">for </span><span class="s1">this_slice </span><span class="s3">in </span><span class="s1">slices</span>
    <span class="s4">)</span>
    <span class="s3">for </span><span class="s1">this_slice</span><span class="s4">, </span><span class="s1">this_view </span><span class="s3">in </span><span class="s1">zip</span><span class="s4">(</span><span class="s1">slices</span><span class="s4">, </span><span class="s1">code_views</span><span class="s4">):</span>
        <span class="s1">code</span><span class="s4">[</span><span class="s1">this_slice</span><span class="s4">] = </span><span class="s1">this_view</span>
    <span class="s3">return </span><span class="s1">code</span>


<span class="s3">def </span><span class="s1">_update_dict</span><span class="s4">(</span>
    <span class="s1">dictionary</span><span class="s4">,</span>
    <span class="s1">Y</span><span class="s4">,</span>
    <span class="s1">code</span><span class="s4">,</span>
    <span class="s1">A</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">B</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">verbose</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">positive</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
<span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Update the dense dictionary factor in place. 
 
    Parameters 
    ---------- 
    dictionary : ndarray of shape (n_components, n_features) 
        Value of the dictionary at the previous iteration. 
 
    Y : ndarray of shape (n_samples, n_features) 
        Data matrix. 
 
    code : ndarray of shape (n_samples, n_components) 
        Sparse coding of the data against which to optimize the dictionary. 
 
    A : ndarray of shape (n_components, n_components), default=None 
        Together with `B`, sufficient stats of the online model to update the 
        dictionary. 
 
    B : ndarray of shape (n_features, n_components), default=None 
        Together with `A`, sufficient stats of the online model to update the 
        dictionary. 
 
    verbose: bool, default=False 
        Degree of output the procedure will print. 
 
    random_state : int, RandomState instance or None, default=None 
        Used for randomly initializing the dictionary. Pass an int for 
        reproducible results across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    positive : bool, default=False 
        Whether to enforce positivity when finding the dictionary. 
 
        .. versionadded:: 0.20 
    &quot;&quot;&quot;</span>
    <span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_components </span><span class="s4">= </span><span class="s1">code</span><span class="s4">.</span><span class="s1">shape</span>
    <span class="s1">random_state </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">random_state</span><span class="s4">)</span>

    <span class="s3">if </span><span class="s1">A </span><span class="s3">is None</span><span class="s4">:</span>
        <span class="s1">A </span><span class="s4">= </span><span class="s1">code</span><span class="s4">.</span><span class="s1">T </span><span class="s4">@ </span><span class="s1">code</span>
    <span class="s3">if </span><span class="s1">B </span><span class="s3">is None</span><span class="s4">:</span>
        <span class="s1">B </span><span class="s4">= </span><span class="s1">Y</span><span class="s4">.</span><span class="s1">T </span><span class="s4">@ </span><span class="s1">code</span>

    <span class="s1">n_unused </span><span class="s4">= </span><span class="s6">0</span>

    <span class="s3">for </span><span class="s1">k </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">n_components</span><span class="s4">):</span>
        <span class="s3">if </span><span class="s1">A</span><span class="s4">[</span><span class="s1">k</span><span class="s4">, </span><span class="s1">k</span><span class="s4">] &gt; </span><span class="s6">1e-6</span><span class="s4">:</span>
            <span class="s2"># 1e-6 is arbitrary but consistent with the spams implementation</span>
            <span class="s1">dictionary</span><span class="s4">[</span><span class="s1">k</span><span class="s4">] += (</span><span class="s1">B</span><span class="s4">[:, </span><span class="s1">k</span><span class="s4">] - </span><span class="s1">A</span><span class="s4">[</span><span class="s1">k</span><span class="s4">] @ </span><span class="s1">dictionary</span><span class="s4">) / </span><span class="s1">A</span><span class="s4">[</span><span class="s1">k</span><span class="s4">, </span><span class="s1">k</span><span class="s4">]</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s2"># kth atom is almost never used -&gt; sample a new one from the data</span>
            <span class="s1">newd </span><span class="s4">= </span><span class="s1">Y</span><span class="s4">[</span><span class="s1">random_state</span><span class="s4">.</span><span class="s1">choice</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">)]</span>

            <span class="s2"># add small noise to avoid making the sparse coding ill conditioned</span>
            <span class="s1">noise_level </span><span class="s4">= </span><span class="s6">0.01 </span><span class="s4">* (</span><span class="s1">newd</span><span class="s4">.</span><span class="s1">std</span><span class="s4">() </span><span class="s3">or </span><span class="s6">1</span><span class="s4">)  </span><span class="s2"># avoid 0 std</span>
            <span class="s1">noise </span><span class="s4">= </span><span class="s1">random_state</span><span class="s4">.</span><span class="s1">normal</span><span class="s4">(</span><span class="s6">0</span><span class="s4">, </span><span class="s1">noise_level</span><span class="s4">, </span><span class="s1">size</span><span class="s4">=</span><span class="s1">len</span><span class="s4">(</span><span class="s1">newd</span><span class="s4">))</span>

            <span class="s1">dictionary</span><span class="s4">[</span><span class="s1">k</span><span class="s4">] = </span><span class="s1">newd </span><span class="s4">+ </span><span class="s1">noise</span>
            <span class="s1">code</span><span class="s4">[:, </span><span class="s1">k</span><span class="s4">] = </span><span class="s6">0</span>
            <span class="s1">n_unused </span><span class="s4">+= </span><span class="s6">1</span>

        <span class="s3">if </span><span class="s1">positive</span><span class="s4">:</span>
            <span class="s1">np</span><span class="s4">.</span><span class="s1">clip</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">[</span><span class="s1">k</span><span class="s4">], </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">out</span><span class="s4">=</span><span class="s1">dictionary</span><span class="s4">[</span><span class="s1">k</span><span class="s4">])</span>

        <span class="s2"># Projection on the constraint set ||V_k|| &lt;= 1</span>
        <span class="s1">dictionary</span><span class="s4">[</span><span class="s1">k</span><span class="s4">] /= </span><span class="s1">max</span><span class="s4">(</span><span class="s1">linalg</span><span class="s4">.</span><span class="s1">norm</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">[</span><span class="s1">k</span><span class="s4">]), </span><span class="s6">1</span><span class="s4">)</span>

    <span class="s3">if </span><span class="s1">verbose </span><span class="s3">and </span><span class="s1">n_unused </span><span class="s4">&gt; </span><span class="s6">0</span><span class="s4">:</span>
        <span class="s1">print</span><span class="s4">(</span><span class="s5">f&quot;</span><span class="s3">{</span><span class="s1">n_unused</span><span class="s3">} </span><span class="s5">unused atoms resampled.&quot;</span><span class="s4">)</span>


<span class="s3">def </span><span class="s1">_dict_learning</span><span class="s4">(</span>
    <span class="s1">X</span><span class="s4">,</span>
    <span class="s1">n_components</span><span class="s4">,</span>
    <span class="s4">*,</span>
    <span class="s1">alpha</span><span class="s4">,</span>
    <span class="s1">max_iter</span><span class="s4">,</span>
    <span class="s1">tol</span><span class="s4">,</span>
    <span class="s1">method</span><span class="s4">,</span>
    <span class="s1">n_jobs</span><span class="s4">,</span>
    <span class="s1">dict_init</span><span class="s4">,</span>
    <span class="s1">code_init</span><span class="s4">,</span>
    <span class="s1">callback</span><span class="s4">,</span>
    <span class="s1">verbose</span><span class="s4">,</span>
    <span class="s1">random_state</span><span class="s4">,</span>
    <span class="s1">return_n_iter</span><span class="s4">,</span>
    <span class="s1">positive_dict</span><span class="s4">,</span>
    <span class="s1">positive_code</span><span class="s4">,</span>
    <span class="s1">method_max_iter</span><span class="s4">,</span>
<span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Main dictionary learning algorithm&quot;&quot;&quot;</span>
    <span class="s1">t0 </span><span class="s4">= </span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">()</span>
    <span class="s2"># Init the code and the dictionary with SVD of Y</span>
    <span class="s3">if </span><span class="s1">code_init </span><span class="s3">is not None and </span><span class="s1">dict_init </span><span class="s3">is not None</span><span class="s4">:</span>
        <span class="s1">code </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">array</span><span class="s4">(</span><span class="s1">code_init</span><span class="s4">, </span><span class="s1">order</span><span class="s4">=</span><span class="s5">&quot;F&quot;</span><span class="s4">)</span>
        <span class="s2"># Don't copy V, it will happen below</span>
        <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">dict_init</span>
    <span class="s3">else</span><span class="s4">:</span>
        <span class="s1">code</span><span class="s4">, </span><span class="s1">S</span><span class="s4">, </span><span class="s1">dictionary </span><span class="s4">= </span><span class="s1">linalg</span><span class="s4">.</span><span class="s1">svd</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">full_matrices</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>
        <span class="s2"># flip the initial code's sign to enforce deterministic output</span>
        <span class="s1">code</span><span class="s4">, </span><span class="s1">dictionary </span><span class="s4">= </span><span class="s1">svd_flip</span><span class="s4">(</span><span class="s1">code</span><span class="s4">, </span><span class="s1">dictionary</span><span class="s4">)</span>
        <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">S</span><span class="s4">[:, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">newaxis</span><span class="s4">] * </span><span class="s1">dictionary</span>
    <span class="s1">r </span><span class="s4">= </span><span class="s1">len</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">)</span>
    <span class="s3">if </span><span class="s1">n_components </span><span class="s4">&lt;= </span><span class="s1">r</span><span class="s4">:  </span><span class="s2"># True even if n_components=None</span>
        <span class="s1">code </span><span class="s4">= </span><span class="s1">code</span><span class="s4">[:, :</span><span class="s1">n_components</span><span class="s4">]</span>
        <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">dictionary</span><span class="s4">[:</span><span class="s1">n_components</span><span class="s4">, :]</span>
    <span class="s3">else</span><span class="s4">:</span>
        <span class="s1">code </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">c_</span><span class="s4">[</span><span class="s1">code</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">((</span><span class="s1">len</span><span class="s4">(</span><span class="s1">code</span><span class="s4">), </span><span class="s1">n_components </span><span class="s4">- </span><span class="s1">r</span><span class="s4">))]</span>
        <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">r_</span><span class="s4">[</span>
            <span class="s1">dictionary</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">((</span><span class="s1">n_components </span><span class="s4">- </span><span class="s1">r</span><span class="s4">, </span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]))</span>
        <span class="s4">]</span>

    <span class="s2"># Fortran-order dict better suited for the sparse coding which is the</span>
    <span class="s2"># bottleneck of this algorithm.</span>
    <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">asfortranarray</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">)</span>

    <span class="s1">errors </span><span class="s4">= []</span>
    <span class="s1">current_cost </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">nan</span>

    <span class="s3">if </span><span class="s1">verbose </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
        <span class="s1">print</span><span class="s4">(</span><span class="s5">&quot;[dict_learning]&quot;</span><span class="s4">, </span><span class="s1">end</span><span class="s4">=</span><span class="s5">&quot; &quot;</span><span class="s4">)</span>

    <span class="s2"># If max_iter is 0, number of iterations returned should be zero</span>
    <span class="s1">ii </span><span class="s4">= -</span><span class="s6">1</span>

    <span class="s3">for </span><span class="s1">ii </span><span class="s3">in </span><span class="s1">range</span><span class="s4">(</span><span class="s1">max_iter</span><span class="s4">):</span>
        <span class="s1">dt </span><span class="s4">= </span><span class="s1">time</span><span class="s4">.</span><span class="s1">time</span><span class="s4">() - </span><span class="s1">t0</span>
        <span class="s3">if </span><span class="s1">verbose </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
            <span class="s1">sys</span><span class="s4">.</span><span class="s1">stdout</span><span class="s4">.</span><span class="s1">write</span><span class="s4">(</span><span class="s5">&quot;.&quot;</span><span class="s4">)</span>
            <span class="s1">sys</span><span class="s4">.</span><span class="s1">stdout</span><span class="s4">.</span><span class="s1">flush</span><span class="s4">()</span>
        <span class="s3">elif </span><span class="s1">verbose</span><span class="s4">:</span>
            <span class="s1">print</span><span class="s4">(</span>
                <span class="s5">&quot;Iteration % 3i (elapsed time: % 3is, % 4.1fmn, current cost % 7.3f)&quot;</span>
                <span class="s4">% (</span><span class="s1">ii</span><span class="s4">, </span><span class="s1">dt</span><span class="s4">, </span><span class="s1">dt </span><span class="s4">/ </span><span class="s6">60</span><span class="s4">, </span><span class="s1">current_cost</span><span class="s4">)</span>
            <span class="s4">)</span>

        <span class="s2"># Update code</span>
        <span class="s1">code </span><span class="s4">= </span><span class="s1">sparse_encode</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">,</span>
            <span class="s1">dictionary</span><span class="s4">,</span>
            <span class="s1">algorithm</span><span class="s4">=</span><span class="s1">method</span><span class="s4">,</span>
            <span class="s1">alpha</span><span class="s4">=</span><span class="s1">alpha</span><span class="s4">,</span>
            <span class="s1">init</span><span class="s4">=</span><span class="s1">code</span><span class="s4">,</span>
            <span class="s1">n_jobs</span><span class="s4">=</span><span class="s1">n_jobs</span><span class="s4">,</span>
            <span class="s1">positive</span><span class="s4">=</span><span class="s1">positive_code</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">method_max_iter</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
        <span class="s4">)</span>

        <span class="s2"># Update dictionary in place</span>
        <span class="s1">_update_dict</span><span class="s4">(</span>
            <span class="s1">dictionary</span><span class="s4">,</span>
            <span class="s1">X</span><span class="s4">,</span>
            <span class="s1">code</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span><span class="s4">,</span>
            <span class="s1">positive</span><span class="s4">=</span><span class="s1">positive_dict</span><span class="s4">,</span>
        <span class="s4">)</span>

        <span class="s2"># Cost function</span>
        <span class="s1">current_cost </span><span class="s4">= </span><span class="s6">0.5 </span><span class="s4">* </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">((</span><span class="s1">X </span><span class="s4">- </span><span class="s1">code </span><span class="s4">@ </span><span class="s1">dictionary</span><span class="s4">) ** </span><span class="s6">2</span><span class="s4">) + </span><span class="s1">alpha </span><span class="s4">* </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span>
            <span class="s1">np</span><span class="s4">.</span><span class="s1">abs</span><span class="s4">(</span><span class="s1">code</span><span class="s4">)</span>
        <span class="s4">)</span>
        <span class="s1">errors</span><span class="s4">.</span><span class="s1">append</span><span class="s4">(</span><span class="s1">current_cost</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">ii </span><span class="s4">&gt; </span><span class="s6">0</span><span class="s4">:</span>
            <span class="s1">dE </span><span class="s4">= </span><span class="s1">errors</span><span class="s4">[-</span><span class="s6">2</span><span class="s4">] - </span><span class="s1">errors</span><span class="s4">[-</span><span class="s6">1</span><span class="s4">]</span>
            <span class="s2"># assert(dE &gt;= -tol * errors[-1])</span>
            <span class="s3">if </span><span class="s1">dE </span><span class="s4">&lt; </span><span class="s1">tol </span><span class="s4">* </span><span class="s1">errors</span><span class="s4">[-</span><span class="s6">1</span><span class="s4">]:</span>
                <span class="s3">if </span><span class="s1">verbose </span><span class="s4">== </span><span class="s6">1</span><span class="s4">:</span>
                    <span class="s2"># A line return</span>
                    <span class="s1">print</span><span class="s4">(</span><span class="s5">&quot;&quot;</span><span class="s4">)</span>
                <span class="s3">elif </span><span class="s1">verbose</span><span class="s4">:</span>
                    <span class="s1">print</span><span class="s4">(</span><span class="s5">&quot;--- Convergence reached after %d iterations&quot; </span><span class="s4">% </span><span class="s1">ii</span><span class="s4">)</span>
                <span class="s3">break</span>
        <span class="s3">if </span><span class="s1">ii </span><span class="s4">% </span><span class="s6">5 </span><span class="s4">== </span><span class="s6">0 </span><span class="s3">and </span><span class="s1">callback </span><span class="s3">is not None</span><span class="s4">:</span>
            <span class="s1">callback</span><span class="s4">(</span><span class="s1">locals</span><span class="s4">())</span>

    <span class="s3">if </span><span class="s1">return_n_iter</span><span class="s4">:</span>
        <span class="s3">return </span><span class="s1">code</span><span class="s4">, </span><span class="s1">dictionary</span><span class="s4">, </span><span class="s1">errors</span><span class="s4">, </span><span class="s1">ii </span><span class="s4">+ </span><span class="s6">1</span>
    <span class="s3">else</span><span class="s4">:</span>
        <span class="s3">return </span><span class="s1">code</span><span class="s4">, </span><span class="s1">dictionary</span><span class="s4">, </span><span class="s1">errors</span>


<span class="s4">@</span><span class="s1">validate_params</span><span class="s4">(</span>
    <span class="s4">{</span>
        <span class="s5">&quot;X&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;return_code&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;method&quot;</span><span class="s4">: [</span><span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;cd&quot;</span><span class="s4">, </span><span class="s5">&quot;lars&quot;</span><span class="s4">})],</span>
        <span class="s5">&quot;method_max_iter&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
    <span class="s4">},</span>
    <span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">def </span><span class="s1">dict_learning_online</span><span class="s4">(</span>
    <span class="s1">X</span><span class="s4">,</span>
    <span class="s1">n_components</span><span class="s4">=</span><span class="s6">2</span><span class="s4">,</span>
    <span class="s4">*,</span>
    <span class="s1">alpha</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
    <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">100</span><span class="s4">,</span>
    <span class="s1">return_code</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
    <span class="s1">dict_init</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">callback</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">batch_size</span><span class="s4">=</span><span class="s6">256</span><span class="s4">,</span>
    <span class="s1">verbose</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s1">shuffle</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
    <span class="s1">n_jobs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">method</span><span class="s4">=</span><span class="s5">&quot;lars&quot;</span><span class="s4">,</span>
    <span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">positive_dict</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s1">positive_code</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s1">method_max_iter</span><span class="s4">=</span><span class="s6">1000</span><span class="s4">,</span>
    <span class="s1">tol</span><span class="s4">=</span><span class="s6">1e-3</span><span class="s4">,</span>
    <span class="s1">max_no_improvement</span><span class="s4">=</span><span class="s6">10</span><span class="s4">,</span>
<span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Solve a dictionary learning matrix factorization problem online. 
 
    Finds the best dictionary and the corresponding sparse code for 
    approximating the data matrix X by solving:: 
 
        (U^*, V^*) = argmin 0.5 || X - U V ||_Fro^2 + alpha * || U ||_1,1 
                     (U,V) 
                     with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components 
 
    where V is the dictionary and U is the sparse code. ||.||_Fro stands for 
    the Frobenius norm and ||.||_1,1 stands for the entry-wise matrix norm 
    which is the sum of the absolute values of all the entries in the matrix. 
    This is accomplished by repeatedly iterating over mini-batches by slicing 
    the input data. 
 
    Read more in the :ref:`User Guide &lt;DictionaryLearning&gt;`. 
 
    Parameters 
    ---------- 
    X : array-like of shape (n_samples, n_features) 
        Data matrix. 
 
    n_components : int or None, default=2 
        Number of dictionary atoms to extract. If None, then ``n_components`` 
        is set to ``n_features``. 
 
    alpha : float, default=1 
        Sparsity controlling parameter. 
 
    max_iter : int, default=100 
        Maximum number of iterations over the complete dataset before 
        stopping independently of any early stopping criterion heuristics. 
 
        .. versionadded:: 1.1 
 
        .. deprecated:: 1.4 
           `max_iter=None` is deprecated in 1.4 and will be removed in 1.6. 
           Use the default value (i.e. `100`) instead. 
 
    return_code : bool, default=True 
        Whether to also return the code U or just the dictionary `V`. 
 
    dict_init : ndarray of shape (n_components, n_features), default=None 
        Initial values for the dictionary for warm restart scenarios. 
        If `None`, the initial values for the dictionary are created 
        with an SVD decomposition of the data via 
        :func:`~sklearn.utils.extmath.randomized_svd`. 
 
    callback : callable, default=None 
        A callable that gets invoked at the end of each iteration. 
 
    batch_size : int, default=256 
        The number of samples to take in each batch. 
 
        .. versionchanged:: 1.3 
           The default value of `batch_size` changed from 3 to 256 in version 1.3. 
 
    verbose : bool, default=False 
        To control the verbosity of the procedure. 
 
    shuffle : bool, default=True 
        Whether to shuffle the data before splitting it in batches. 
 
    n_jobs : int, default=None 
        Number of parallel jobs to run. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    method : {'lars', 'cd'}, default='lars' 
        * `'lars'`: uses the least angle regression method to solve the lasso 
          problem (`linear_model.lars_path`); 
        * `'cd'`: uses the coordinate descent method to compute the 
          Lasso solution (`linear_model.Lasso`). Lars will be faster if 
          the estimated components are sparse. 
 
    random_state : int, RandomState instance or None, default=None 
        Used for initializing the dictionary when ``dict_init`` is not 
        specified, randomly shuffling the data when ``shuffle`` is set to 
        ``True``, and updating the dictionary. Pass an int for reproducible 
        results across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    positive_dict : bool, default=False 
        Whether to enforce positivity when finding the dictionary. 
 
        .. versionadded:: 0.20 
 
    positive_code : bool, default=False 
        Whether to enforce positivity when finding the code. 
 
        .. versionadded:: 0.20 
 
    method_max_iter : int, default=1000 
        Maximum number of iterations to perform when solving the lasso problem. 
 
        .. versionadded:: 0.22 
 
    tol : float, default=1e-3 
        Control early stopping based on the norm of the differences in the 
        dictionary between 2 steps. 
 
        To disable early stopping based on changes in the dictionary, set 
        `tol` to 0.0. 
 
        .. versionadded:: 1.1 
 
    max_no_improvement : int, default=10 
        Control early stopping based on the consecutive number of mini batches 
        that does not yield an improvement on the smoothed cost function. 
 
        To disable convergence detection based on cost function, set 
        `max_no_improvement` to None. 
 
        .. versionadded:: 1.1 
 
    Returns 
    ------- 
    code : ndarray of shape (n_samples, n_components), 
        The sparse code (only returned if `return_code=True`). 
 
    dictionary : ndarray of shape (n_components, n_features), 
        The solutions to the dictionary learning problem. 
 
    n_iter : int 
        Number of iterations run. Returned only if `return_n_iter` is 
        set to `True`. 
 
    See Also 
    -------- 
    dict_learning : Solve a dictionary learning matrix factorization problem. 
    DictionaryLearning : Find a dictionary that sparsely encodes data. 
    MiniBatchDictionaryLearning : A faster, less accurate, version of the dictionary 
        learning algorithm. 
    SparsePCA : Sparse Principal Components Analysis. 
    MiniBatchSparsePCA : Mini-batch Sparse Principal Components Analysis. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.datasets import make_sparse_coded_signal 
    &gt;&gt;&gt; from sklearn.decomposition import dict_learning_online 
    &gt;&gt;&gt; X, _, _ = make_sparse_coded_signal( 
    ...     n_samples=30, n_components=15, n_features=20, n_nonzero_coefs=10, 
    ...     random_state=42, 
    ... ) 
    &gt;&gt;&gt; U, V = dict_learning_online( 
    ...     X, n_components=15, alpha=0.2, max_iter=20, batch_size=3, random_state=42 
    ... ) 
 
    We can check the level of sparsity of `U`: 
 
    &gt;&gt;&gt; np.mean(U == 0) 
    np.float64(0.53...) 
 
    We can compare the average squared euclidean norm of the reconstruction 
    error of the sparse coded signal relative to the squared euclidean norm of 
    the original signal: 
 
    &gt;&gt;&gt; X_hat = U @ V 
    &gt;&gt;&gt; np.mean(np.sum((X_hat - X) ** 2, axis=1) / np.sum(X ** 2, axis=1)) 
    np.float64(0.05...) 
    &quot;&quot;&quot;</span>
    <span class="s2"># TODO(1.6): remove in 1.6</span>
    <span class="s3">if </span><span class="s1">max_iter </span><span class="s3">is None</span><span class="s4">:</span>
        <span class="s1">warn</span><span class="s4">(</span>
            <span class="s4">(</span>
                <span class="s5">&quot;`max_iter=None` is deprecated in version 1.4 and will be removed in &quot;</span>
                <span class="s5">&quot;version 1.6. Use the default value (i.e. `100`) instead.&quot;</span>
            <span class="s4">),</span>
            <span class="s1">FutureWarning</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">max_iter </span><span class="s4">= </span><span class="s6">100</span>

    <span class="s1">transform_algorithm </span><span class="s4">= </span><span class="s5">&quot;lasso_&quot; </span><span class="s4">+ </span><span class="s1">method</span>

    <span class="s1">est </span><span class="s4">= </span><span class="s1">MiniBatchDictionaryLearning</span><span class="s4">(</span>
        <span class="s1">n_components</span><span class="s4">=</span><span class="s1">n_components</span><span class="s4">,</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s1">alpha</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span><span class="s4">,</span>
        <span class="s1">n_jobs</span><span class="s4">=</span><span class="s1">n_jobs</span><span class="s4">,</span>
        <span class="s1">fit_algorithm</span><span class="s4">=</span><span class="s1">method</span><span class="s4">,</span>
        <span class="s1">batch_size</span><span class="s4">=</span><span class="s1">batch_size</span><span class="s4">,</span>
        <span class="s1">shuffle</span><span class="s4">=</span><span class="s1">shuffle</span><span class="s4">,</span>
        <span class="s1">dict_init</span><span class="s4">=</span><span class="s1">dict_init</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span><span class="s4">,</span>
        <span class="s1">transform_algorithm</span><span class="s4">=</span><span class="s1">transform_algorithm</span><span class="s4">,</span>
        <span class="s1">transform_alpha</span><span class="s4">=</span><span class="s1">alpha</span><span class="s4">,</span>
        <span class="s1">positive_code</span><span class="s4">=</span><span class="s1">positive_code</span><span class="s4">,</span>
        <span class="s1">positive_dict</span><span class="s4">=</span><span class="s1">positive_dict</span><span class="s4">,</span>
        <span class="s1">transform_max_iter</span><span class="s4">=</span><span class="s1">method_max_iter</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
        <span class="s1">callback</span><span class="s4">=</span><span class="s1">callback</span><span class="s4">,</span>
        <span class="s1">tol</span><span class="s4">=</span><span class="s1">tol</span><span class="s4">,</span>
        <span class="s1">max_no_improvement</span><span class="s4">=</span><span class="s1">max_no_improvement</span><span class="s4">,</span>
    <span class="s4">).</span><span class="s1">fit</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

    <span class="s3">if not </span><span class="s1">return_code</span><span class="s4">:</span>
        <span class="s3">return </span><span class="s1">est</span><span class="s4">.</span><span class="s1">components_</span>
    <span class="s3">else</span><span class="s4">:</span>
        <span class="s1">code </span><span class="s4">= </span><span class="s1">est</span><span class="s4">.</span><span class="s1">transform</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">code</span><span class="s4">, </span><span class="s1">est</span><span class="s4">.</span><span class="s1">components_</span>


<span class="s4">@</span><span class="s1">validate_params</span><span class="s4">(</span>
    <span class="s4">{</span>
        <span class="s5">&quot;X&quot;</span><span class="s4">: [</span><span class="s5">&quot;array-like&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;method&quot;</span><span class="s4">: [</span><span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;lars&quot;</span><span class="s4">, </span><span class="s5">&quot;cd&quot;</span><span class="s4">})],</span>
        <span class="s5">&quot;return_n_iter&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;method_max_iter&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
    <span class="s4">},</span>
    <span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
<span class="s4">)</span>
<span class="s3">def </span><span class="s1">dict_learning</span><span class="s4">(</span>
    <span class="s1">X</span><span class="s4">,</span>
    <span class="s1">n_components</span><span class="s4">,</span>
    <span class="s4">*,</span>
    <span class="s1">alpha</span><span class="s4">,</span>
    <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">100</span><span class="s4">,</span>
    <span class="s1">tol</span><span class="s4">=</span><span class="s6">1e-8</span><span class="s4">,</span>
    <span class="s1">method</span><span class="s4">=</span><span class="s5">&quot;lars&quot;</span><span class="s4">,</span>
    <span class="s1">n_jobs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">dict_init</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">code_init</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">callback</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">verbose</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
    <span class="s1">return_n_iter</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s1">positive_dict</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s1">positive_code</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
    <span class="s1">method_max_iter</span><span class="s4">=</span><span class="s6">1000</span><span class="s4">,</span>
<span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Solve a dictionary learning matrix factorization problem. 
 
    Finds the best dictionary and the corresponding sparse code for 
    approximating the data matrix X by solving:: 
 
        (U^*, V^*) = argmin 0.5 || X - U V ||_Fro^2 + alpha * || U ||_1,1 
                     (U,V) 
                    with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components 
 
    where V is the dictionary and U is the sparse code. ||.||_Fro stands for 
    the Frobenius norm and ||.||_1,1 stands for the entry-wise matrix norm 
    which is the sum of the absolute values of all the entries in the matrix. 
 
    Read more in the :ref:`User Guide &lt;DictionaryLearning&gt;`. 
 
    Parameters 
    ---------- 
    X : array-like of shape (n_samples, n_features) 
        Data matrix. 
 
    n_components : int 
        Number of dictionary atoms to extract. 
 
    alpha : int or float 
        Sparsity controlling parameter. 
 
    max_iter : int, default=100 
        Maximum number of iterations to perform. 
 
    tol : float, default=1e-8 
        Tolerance for the stopping condition. 
 
    method : {'lars', 'cd'}, default='lars' 
        The method used: 
 
        * `'lars'`: uses the least angle regression method to solve the lasso 
           problem (`linear_model.lars_path`); 
        * `'cd'`: uses the coordinate descent method to compute the 
          Lasso solution (`linear_model.Lasso`). Lars will be faster if 
          the estimated components are sparse. 
 
    n_jobs : int, default=None 
        Number of parallel jobs to run. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    dict_init : ndarray of shape (n_components, n_features), default=None 
        Initial value for the dictionary for warm restart scenarios. Only used 
        if `code_init` and `dict_init` are not None. 
 
    code_init : ndarray of shape (n_samples, n_components), default=None 
        Initial value for the sparse code for warm restart scenarios. Only used 
        if `code_init` and `dict_init` are not None. 
 
    callback : callable, default=None 
        Callable that gets invoked every five iterations. 
 
    verbose : bool, default=False 
        To control the verbosity of the procedure. 
 
    random_state : int, RandomState instance or None, default=None 
        Used for randomly initializing the dictionary. Pass an int for 
        reproducible results across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    return_n_iter : bool, default=False 
        Whether or not to return the number of iterations. 
 
    positive_dict : bool, default=False 
        Whether to enforce positivity when finding the dictionary. 
 
        .. versionadded:: 0.20 
 
    positive_code : bool, default=False 
        Whether to enforce positivity when finding the code. 
 
        .. versionadded:: 0.20 
 
    method_max_iter : int, default=1000 
        Maximum number of iterations to perform. 
 
        .. versionadded:: 0.22 
 
    Returns 
    ------- 
    code : ndarray of shape (n_samples, n_components) 
        The sparse code factor in the matrix factorization. 
 
    dictionary : ndarray of shape (n_components, n_features), 
        The dictionary factor in the matrix factorization. 
 
    errors : array 
        Vector of errors at each iteration. 
 
    n_iter : int 
        Number of iterations run. Returned only if `return_n_iter` is 
        set to True. 
 
    See Also 
    -------- 
    dict_learning_online : Solve a dictionary learning matrix factorization 
        problem online. 
    DictionaryLearning : Find a dictionary that sparsely encodes data. 
    MiniBatchDictionaryLearning : A faster, less accurate version 
        of the dictionary learning algorithm. 
    SparsePCA : Sparse Principal Components Analysis. 
    MiniBatchSparsePCA : Mini-batch Sparse Principal Components Analysis. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.datasets import make_sparse_coded_signal 
    &gt;&gt;&gt; from sklearn.decomposition import dict_learning 
    &gt;&gt;&gt; X, _, _ = make_sparse_coded_signal( 
    ...     n_samples=30, n_components=15, n_features=20, n_nonzero_coefs=10, 
    ...     random_state=42, 
    ... ) 
    &gt;&gt;&gt; U, V, errors = dict_learning(X, n_components=15, alpha=0.1, random_state=42) 
 
    We can check the level of sparsity of `U`: 
 
    &gt;&gt;&gt; np.mean(U == 0) 
    np.float64(0.6...) 
 
    We can compare the average squared euclidean norm of the reconstruction 
    error of the sparse coded signal relative to the squared euclidean norm of 
    the original signal: 
 
    &gt;&gt;&gt; X_hat = U @ V 
    &gt;&gt;&gt; np.mean(np.sum((X_hat - X) ** 2, axis=1) / np.sum(X ** 2, axis=1)) 
    np.float64(0.01...) 
    &quot;&quot;&quot;</span>
    <span class="s1">estimator </span><span class="s4">= </span><span class="s1">DictionaryLearning</span><span class="s4">(</span>
        <span class="s1">n_components</span><span class="s4">=</span><span class="s1">n_components</span><span class="s4">,</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s1">alpha</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">max_iter</span><span class="s4">,</span>
        <span class="s1">tol</span><span class="s4">=</span><span class="s1">tol</span><span class="s4">,</span>
        <span class="s1">fit_algorithm</span><span class="s4">=</span><span class="s1">method</span><span class="s4">,</span>
        <span class="s1">n_jobs</span><span class="s4">=</span><span class="s1">n_jobs</span><span class="s4">,</span>
        <span class="s1">dict_init</span><span class="s4">=</span><span class="s1">dict_init</span><span class="s4">,</span>
        <span class="s1">callback</span><span class="s4">=</span><span class="s1">callback</span><span class="s4">,</span>
        <span class="s1">code_init</span><span class="s4">=</span><span class="s1">code_init</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s1">verbose</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span><span class="s4">,</span>
        <span class="s1">positive_code</span><span class="s4">=</span><span class="s1">positive_code</span><span class="s4">,</span>
        <span class="s1">positive_dict</span><span class="s4">=</span><span class="s1">positive_dict</span><span class="s4">,</span>
        <span class="s1">transform_max_iter</span><span class="s4">=</span><span class="s1">method_max_iter</span><span class="s4">,</span>
    <span class="s4">).</span><span class="s1">set_output</span><span class="s4">(</span><span class="s1">transform</span><span class="s4">=</span><span class="s5">&quot;default&quot;</span><span class="s4">)</span>
    <span class="s1">code </span><span class="s4">= </span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">fit_transform</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
    <span class="s3">if </span><span class="s1">return_n_iter</span><span class="s4">:</span>
        <span class="s3">return </span><span class="s4">(</span>
            <span class="s1">code</span><span class="s4">,</span>
            <span class="s1">estimator</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">,</span>
            <span class="s1">estimator</span><span class="s4">.</span><span class="s1">error_</span><span class="s4">,</span>
            <span class="s1">estimator</span><span class="s4">.</span><span class="s1">n_iter_</span><span class="s4">,</span>
        <span class="s4">)</span>
    <span class="s3">return </span><span class="s1">code</span><span class="s4">, </span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">, </span><span class="s1">estimator</span><span class="s4">.</span><span class="s1">error_</span>


<span class="s3">class </span><span class="s1">_BaseSparseCoding</span><span class="s4">(</span><span class="s1">ClassNamePrefixFeaturesOutMixin</span><span class="s4">, </span><span class="s1">TransformerMixin</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Base class from SparseCoder and DictionaryLearning algorithms.&quot;&quot;&quot;</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">transform_algorithm</span><span class="s4">,</span>
        <span class="s1">transform_n_nonzero_coefs</span><span class="s4">,</span>
        <span class="s1">transform_alpha</span><span class="s4">,</span>
        <span class="s1">split_sign</span><span class="s4">,</span>
        <span class="s1">n_jobs</span><span class="s4">,</span>
        <span class="s1">positive_code</span><span class="s4">,</span>
        <span class="s1">transform_max_iter</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">transform_algorithm </span><span class="s4">= </span><span class="s1">transform_algorithm</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">transform_n_nonzero_coefs </span><span class="s4">= </span><span class="s1">transform_n_nonzero_coefs</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">transform_alpha </span><span class="s4">= </span><span class="s1">transform_alpha</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">transform_max_iter </span><span class="s4">= </span><span class="s1">transform_max_iter</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">split_sign </span><span class="s4">= </span><span class="s1">split_sign</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_jobs </span><span class="s4">= </span><span class="s1">n_jobs</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">positive_code </span><span class="s4">= </span><span class="s1">positive_code</span>

    <span class="s3">def </span><span class="s1">_transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">dictionary</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Private method allowing to accommodate both DictionaryLearning and 
        SparseCoder.&quot;&quot;&quot;</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">reset</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;alpha&quot;</span><span class="s4">) </span><span class="s3">and </span><span class="s1">self</span><span class="s4">.</span><span class="s1">transform_alpha </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">transform_alpha </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">alpha</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">transform_alpha </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">transform_alpha</span>

        <span class="s1">code </span><span class="s4">= </span><span class="s1">sparse_encode</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">,</span>
            <span class="s1">dictionary</span><span class="s4">,</span>
            <span class="s1">algorithm</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">transform_algorithm</span><span class="s4">,</span>
            <span class="s1">n_nonzero_coefs</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">transform_n_nonzero_coefs</span><span class="s4">,</span>
            <span class="s1">alpha</span><span class="s4">=</span><span class="s1">transform_alpha</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">transform_max_iter</span><span class="s4">,</span>
            <span class="s1">n_jobs</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_jobs</span><span class="s4">,</span>
            <span class="s1">positive</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">positive_code</span><span class="s4">,</span>
        <span class="s4">)</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">split_sign</span><span class="s4">:</span>
            <span class="s2"># feature vector is split into a positive and negative side</span>
            <span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_features </span><span class="s4">= </span><span class="s1">code</span><span class="s4">.</span><span class="s1">shape</span>
            <span class="s1">split_code </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">empty</span><span class="s4">((</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s6">2 </span><span class="s4">* </span><span class="s1">n_features</span><span class="s4">))</span>
            <span class="s1">split_code</span><span class="s4">[:, :</span><span class="s1">n_features</span><span class="s4">] = </span><span class="s1">np</span><span class="s4">.</span><span class="s1">maximum</span><span class="s4">(</span><span class="s1">code</span><span class="s4">, </span><span class="s6">0</span><span class="s4">)</span>
            <span class="s1">split_code</span><span class="s4">[:, </span><span class="s1">n_features</span><span class="s4">:] = -</span><span class="s1">np</span><span class="s4">.</span><span class="s1">minimum</span><span class="s4">(</span><span class="s1">code</span><span class="s4">, </span><span class="s6">0</span><span class="s4">)</span>
            <span class="s1">code </span><span class="s4">= </span><span class="s1">split_code</span>

        <span class="s3">return </span><span class="s1">code</span>

    <span class="s3">def </span><span class="s1">transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Encode the data as a sparse combination of the dictionary atoms. 
 
        Coding method is determined by the object parameter 
        `transform_algorithm`. 
 
        Parameters 
        ---------- 
        X : ndarray of shape (n_samples, n_features) 
            Test data to be transformed, must have the same number of 
            features as the data used to train the model. 
 
        Returns 
        ------- 
        X_new : ndarray of shape (n_samples, n_components) 
            Transformed data. 
        &quot;&quot;&quot;</span>
        <span class="s1">check_is_fitted</span><span class="s4">(</span><span class="s1">self</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_transform</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">)</span>


<span class="s3">class </span><span class="s1">SparseCoder</span><span class="s4">(</span><span class="s1">_BaseSparseCoding</span><span class="s4">, </span><span class="s1">BaseEstimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Sparse coding. 
 
    Finds a sparse representation of data against a fixed, precomputed 
    dictionary. 
 
    Each row of the result is the solution to a sparse coding problem. 
    The goal is to find a sparse array `code` such that:: 
 
        X ~= code * dictionary 
 
    Read more in the :ref:`User Guide &lt;SparseCoder&gt;`. 
 
    Parameters 
    ---------- 
    dictionary : ndarray of shape (n_components, n_features) 
        The dictionary atoms used for sparse coding. Lines are assumed to be 
        normalized to unit norm. 
 
    transform_algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp', \ 
            'threshold'}, default='omp' 
        Algorithm used to transform the data: 
 
        - `'lars'`: uses the least angle regression method 
          (`linear_model.lars_path`); 
        - `'lasso_lars'`: uses Lars to compute the Lasso solution; 
        - `'lasso_cd'`: uses the coordinate descent method to compute the 
          Lasso solution (linear_model.Lasso). `'lasso_lars'` will be faster if 
          the estimated components are sparse; 
        - `'omp'`: uses orthogonal matching pursuit to estimate the sparse 
          solution; 
        - `'threshold'`: squashes to zero all coefficients less than alpha from 
          the projection ``dictionary * X'``. 
 
    transform_n_nonzero_coefs : int, default=None 
        Number of nonzero coefficients to target in each column of the 
        solution. This is only used by `algorithm='lars'` and `algorithm='omp'` 
        and is overridden by `alpha` in the `omp` case. If `None`, then 
        `transform_n_nonzero_coefs=int(n_features / 10)`. 
 
    transform_alpha : float, default=None 
        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`, `alpha` is the 
        penalty applied to the L1 norm. 
        If `algorithm='threshold'`, `alpha` is the absolute value of the 
        threshold below which coefficients will be squashed to zero. 
        If `algorithm='omp'`, `alpha` is the tolerance parameter: the value of 
        the reconstruction error targeted. In this case, it overrides 
        `n_nonzero_coefs`. 
        If `None`, default to 1. 
 
    split_sign : bool, default=False 
        Whether to split the sparse feature vector into the concatenation of 
        its negative part and its positive part. This can improve the 
        performance of downstream classifiers. 
 
    n_jobs : int, default=None 
        Number of parallel jobs to run. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    positive_code : bool, default=False 
        Whether to enforce positivity when finding the code. 
 
        .. versionadded:: 0.20 
 
    transform_max_iter : int, default=1000 
        Maximum number of iterations to perform if `algorithm='lasso_cd'` or 
        `lasso_lars`. 
 
        .. versionadded:: 0.22 
 
    Attributes 
    ---------- 
    n_components_ : int 
        Number of atoms. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    See Also 
    -------- 
    DictionaryLearning : Find a dictionary that sparsely encodes data. 
    MiniBatchDictionaryLearning : A faster, less accurate, version of the 
        dictionary learning algorithm. 
    MiniBatchSparsePCA : Mini-batch Sparse Principal Components Analysis. 
    SparsePCA : Sparse Principal Components Analysis. 
    sparse_encode : Sparse coding where each row of the result is the solution 
        to a sparse coding problem. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.decomposition import SparseCoder 
    &gt;&gt;&gt; X = np.array([[-1, -1, -1], [0, 0, 3]]) 
    &gt;&gt;&gt; dictionary = np.array( 
    ...     [[0, 1, 0], 
    ...      [-1, -1, 2], 
    ...      [1, 1, 1], 
    ...      [0, 1, 1], 
    ...      [0, 2, 1]], 
    ...    dtype=np.float64 
    ... ) 
    &gt;&gt;&gt; coder = SparseCoder( 
    ...     dictionary=dictionary, transform_algorithm='lasso_lars', 
    ...     transform_alpha=1e-10, 
    ... ) 
    &gt;&gt;&gt; coder.transform(X) 
    array([[ 0.,  0., -1.,  0.,  0.], 
           [ 0.,  1.,  1.,  0.,  0.]]) 
    &quot;&quot;&quot;</span>

    <span class="s1">_required_parameters </span><span class="s4">= [</span><span class="s5">&quot;dictionary&quot;</span><span class="s4">]</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">dictionary</span><span class="s4">,</span>
        <span class="s4">*,</span>
        <span class="s1">transform_algorithm</span><span class="s4">=</span><span class="s5">&quot;omp&quot;</span><span class="s4">,</span>
        <span class="s1">transform_n_nonzero_coefs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">transform_alpha</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">split_sign</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">n_jobs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">positive_code</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">transform_max_iter</span><span class="s4">=</span><span class="s6">1000</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">super</span><span class="s4">().</span><span class="s1">__init__</span><span class="s4">(</span>
            <span class="s1">transform_algorithm</span><span class="s4">,</span>
            <span class="s1">transform_n_nonzero_coefs</span><span class="s4">,</span>
            <span class="s1">transform_alpha</span><span class="s4">,</span>
            <span class="s1">split_sign</span><span class="s4">,</span>
            <span class="s1">n_jobs</span><span class="s4">,</span>
            <span class="s1">positive_code</span><span class="s4">,</span>
            <span class="s1">transform_max_iter</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">dictionary </span><span class="s4">= </span><span class="s1">dictionary</span>

    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Do nothing and return the estimator unchanged. 
 
        This method is just there to implement the usual API and hence 
        work in pipelines. 
 
        Parameters 
        ---------- 
        X : Ignored 
            Not used, present for API consistency by convention. 
 
        y : Ignored 
            Not used, present for API consistency by convention. 
 
        Returns 
        ------- 
        self : object 
            Returns the instance itself. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self</span>

    <span class="s3">def </span><span class="s1">transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Encode the data as a sparse combination of the dictionary atoms. 
 
        Coding method is determined by the object parameter 
        `transform_algorithm`. 
 
        Parameters 
        ---------- 
        X : ndarray of shape (n_samples, n_features) 
            Training vector, where `n_samples` is the number of samples 
            and `n_features` is the number of features. 
 
        y : Ignored 
            Not used, present for API consistency by convention. 
 
        Returns 
        ------- 
        X_new : ndarray of shape (n_samples, n_components) 
            Transformed data. 
        &quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">super</span><span class="s4">().</span><span class="s1">_transform</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">dictionary</span><span class="s4">)</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span>
            <span class="s5">&quot;requires_fit&quot;</span><span class="s4">: </span><span class="s3">False</span><span class="s4">,</span>
            <span class="s5">&quot;preserves_dtype&quot;</span><span class="s4">: [</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">],</span>
        <span class="s4">}</span>

    <span class="s4">@</span><span class="s1">property</span>
    <span class="s3">def </span><span class="s1">n_components_</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Number of atoms.&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>

    <span class="s4">@</span><span class="s1">property</span>
    <span class="s3">def </span><span class="s1">n_features_in_</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Number of features seen during `fit`.&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]</span>

    <span class="s4">@</span><span class="s1">property</span>
    <span class="s3">def </span><span class="s1">_n_features_out</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Number of transformed output features.&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components_</span>


<span class="s3">class </span><span class="s1">DictionaryLearning</span><span class="s4">(</span><span class="s1">_BaseSparseCoding</span><span class="s4">, </span><span class="s1">BaseEstimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Dictionary learning. 
 
    Finds a dictionary (a set of atoms) that performs well at sparsely 
    encoding the fitted data. 
 
    Solves the optimization problem:: 
 
        (U^*,V^*) = argmin 0.5 || X - U V ||_Fro^2 + alpha * || U ||_1,1 
                    (U,V) 
                    with || V_k ||_2 &lt;= 1 for all  0 &lt;= k &lt; n_components 
 
    ||.||_Fro stands for the Frobenius norm and ||.||_1,1 stands for 
    the entry-wise matrix norm which is the sum of the absolute values 
    of all the entries in the matrix. 
 
    Read more in the :ref:`User Guide &lt;DictionaryLearning&gt;`. 
 
    Parameters 
    ---------- 
    n_components : int, default=None 
        Number of dictionary elements to extract. If None, then ``n_components`` 
        is set to ``n_features``. 
 
    alpha : float, default=1.0 
        Sparsity controlling parameter. 
 
    max_iter : int, default=1000 
        Maximum number of iterations to perform. 
 
    tol : float, default=1e-8 
        Tolerance for numerical error. 
 
    fit_algorithm : {'lars', 'cd'}, default='lars' 
        * `'lars'`: uses the least angle regression method to solve the lasso 
          problem (:func:`~sklearn.linear_model.lars_path`); 
        * `'cd'`: uses the coordinate descent method to compute the 
          Lasso solution (:class:`~sklearn.linear_model.Lasso`). Lars will be 
          faster if the estimated components are sparse. 
 
        .. versionadded:: 0.17 
           *cd* coordinate descent method to improve speed. 
 
    transform_algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp', \ 
            'threshold'}, default='omp' 
        Algorithm used to transform the data: 
 
        - `'lars'`: uses the least angle regression method 
          (:func:`~sklearn.linear_model.lars_path`); 
        - `'lasso_lars'`: uses Lars to compute the Lasso solution. 
        - `'lasso_cd'`: uses the coordinate descent method to compute the 
          Lasso solution (:class:`~sklearn.linear_model.Lasso`). `'lasso_lars'` 
          will be faster if the estimated components are sparse. 
        - `'omp'`: uses orthogonal matching pursuit to estimate the sparse 
          solution. 
        - `'threshold'`: squashes to zero all coefficients less than alpha from 
          the projection ``dictionary * X'``. 
 
        .. versionadded:: 0.17 
           *lasso_cd* coordinate descent method to improve speed. 
 
    transform_n_nonzero_coefs : int, default=None 
        Number of nonzero coefficients to target in each column of the 
        solution. This is only used by `algorithm='lars'` and 
        `algorithm='omp'`. If `None`, then 
        `transform_n_nonzero_coefs=int(n_features / 10)`. 
 
    transform_alpha : float, default=None 
        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`, `alpha` is the 
        penalty applied to the L1 norm. 
        If `algorithm='threshold'`, `alpha` is the absolute value of the 
        threshold below which coefficients will be squashed to zero. 
        If `None`, defaults to `alpha`. 
 
        .. versionchanged:: 1.2 
            When None, default value changed from 1.0 to `alpha`. 
 
    n_jobs : int or None, default=None 
        Number of parallel jobs to run. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    code_init : ndarray of shape (n_samples, n_components), default=None 
        Initial value for the code, for warm restart. Only used if `code_init` 
        and `dict_init` are not None. 
 
    dict_init : ndarray of shape (n_components, n_features), default=None 
        Initial values for the dictionary, for warm restart. Only used if 
        `code_init` and `dict_init` are not None. 
 
    callback : callable, default=None 
        Callable that gets invoked every five iterations. 
 
        .. versionadded:: 1.3 
 
    verbose : bool, default=False 
        To control the verbosity of the procedure. 
 
    split_sign : bool, default=False 
        Whether to split the sparse feature vector into the concatenation of 
        its negative part and its positive part. This can improve the 
        performance of downstream classifiers. 
 
    random_state : int, RandomState instance or None, default=None 
        Used for initializing the dictionary when ``dict_init`` is not 
        specified, randomly shuffling the data when ``shuffle`` is set to 
        ``True``, and updating the dictionary. Pass an int for reproducible 
        results across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    positive_code : bool, default=False 
        Whether to enforce positivity when finding the code. 
 
        .. versionadded:: 0.20 
 
    positive_dict : bool, default=False 
        Whether to enforce positivity when finding the dictionary. 
 
        .. versionadded:: 0.20 
 
    transform_max_iter : int, default=1000 
        Maximum number of iterations to perform if `algorithm='lasso_cd'` or 
        `'lasso_lars'`. 
 
        .. versionadded:: 0.22 
 
    Attributes 
    ---------- 
    components_ : ndarray of shape (n_components, n_features) 
        dictionary atoms extracted from the data 
 
    error_ : array 
        vector of errors at each iteration 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    n_iter_ : int 
        Number of iterations run. 
 
    See Also 
    -------- 
    MiniBatchDictionaryLearning: A faster, less accurate, version of the 
        dictionary learning algorithm. 
    MiniBatchSparsePCA : Mini-batch Sparse Principal Components Analysis. 
    SparseCoder : Find a sparse representation of data from a fixed, 
        precomputed dictionary. 
    SparsePCA : Sparse Principal Components Analysis. 
 
    References 
    ---------- 
 
    J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning 
    for sparse coding (https://www.di.ens.fr/sierra/pdfs/icml09.pdf) 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.datasets import make_sparse_coded_signal 
    &gt;&gt;&gt; from sklearn.decomposition import DictionaryLearning 
    &gt;&gt;&gt; X, dictionary, code = make_sparse_coded_signal( 
    ...     n_samples=30, n_components=15, n_features=20, n_nonzero_coefs=10, 
    ...     random_state=42, 
    ... ) 
    &gt;&gt;&gt; dict_learner = DictionaryLearning( 
    ...     n_components=15, transform_algorithm='lasso_lars', transform_alpha=0.1, 
    ...     random_state=42, 
    ... ) 
    &gt;&gt;&gt; X_transformed = dict_learner.fit(X).transform(X) 
 
    We can check the level of sparsity of `X_transformed`: 
 
    &gt;&gt;&gt; np.mean(X_transformed == 0) 
    np.float64(0.52...) 
 
    We can compare the average squared euclidean norm of the reconstruction 
    error of the sparse coded signal relative to the squared euclidean norm of 
    the original signal: 
 
    &gt;&gt;&gt; X_hat = X_transformed @ dict_learner.components_ 
    &gt;&gt;&gt; np.mean(np.sum((X_hat - X) ** 2, axis=1) / np.sum(X ** 2, axis=1)) 
    np.float64(0.05...) 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s5">&quot;n_components&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;alpha&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;max_iter&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;tol&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;fit_algorithm&quot;</span><span class="s4">: [</span><span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;lars&quot;</span><span class="s4">, </span><span class="s5">&quot;cd&quot;</span><span class="s4">})],</span>
        <span class="s5">&quot;transform_algorithm&quot;</span><span class="s4">: [</span>
            <span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;lasso_lars&quot;</span><span class="s4">, </span><span class="s5">&quot;lasso_cd&quot;</span><span class="s4">, </span><span class="s5">&quot;lars&quot;</span><span class="s4">, </span><span class="s5">&quot;omp&quot;</span><span class="s4">, </span><span class="s5">&quot;threshold&quot;</span><span class="s4">})</span>
        <span class="s4">],</span>
        <span class="s5">&quot;transform_n_nonzero_coefs&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;transform_alpha&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;n_jobs&quot;</span><span class="s4">: [</span><span class="s1">Integral</span><span class="s4">, </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;code_init&quot;</span><span class="s4">: [</span><span class="s1">np</span><span class="s4">.</span><span class="s1">ndarray</span><span class="s4">, </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;dict_init&quot;</span><span class="s4">: [</span><span class="s1">np</span><span class="s4">.</span><span class="s1">ndarray</span><span class="s4">, </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;callback&quot;</span><span class="s4">: [</span><span class="s1">callable</span><span class="s4">, </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;verbose&quot;</span><span class="s4">: [</span><span class="s5">&quot;verbose&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;split_sign&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;random_state&quot;</span><span class="s4">: [</span><span class="s5">&quot;random_state&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;positive_code&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;positive_dict&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;transform_max_iter&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
    <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">n_components</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s4">*,</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">1000</span><span class="s4">,</span>
        <span class="s1">tol</span><span class="s4">=</span><span class="s6">1e-8</span><span class="s4">,</span>
        <span class="s1">fit_algorithm</span><span class="s4">=</span><span class="s5">&quot;lars&quot;</span><span class="s4">,</span>
        <span class="s1">transform_algorithm</span><span class="s4">=</span><span class="s5">&quot;omp&quot;</span><span class="s4">,</span>
        <span class="s1">transform_n_nonzero_coefs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">transform_alpha</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">n_jobs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">code_init</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">dict_init</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">callback</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">split_sign</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">positive_code</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">positive_dict</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">transform_max_iter</span><span class="s4">=</span><span class="s6">1000</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">super</span><span class="s4">().</span><span class="s1">__init__</span><span class="s4">(</span>
            <span class="s1">transform_algorithm</span><span class="s4">,</span>
            <span class="s1">transform_n_nonzero_coefs</span><span class="s4">,</span>
            <span class="s1">transform_alpha</span><span class="s4">,</span>
            <span class="s1">split_sign</span><span class="s4">,</span>
            <span class="s1">n_jobs</span><span class="s4">,</span>
            <span class="s1">positive_code</span><span class="s4">,</span>
            <span class="s1">transform_max_iter</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_components </span><span class="s4">= </span><span class="s1">n_components</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">alpha </span><span class="s4">= </span><span class="s1">alpha</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">max_iter </span><span class="s4">= </span><span class="s1">max_iter</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">tol </span><span class="s4">= </span><span class="s1">tol</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">fit_algorithm </span><span class="s4">= </span><span class="s1">fit_algorithm</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">code_init </span><span class="s4">= </span><span class="s1">code_init</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">dict_init </span><span class="s4">= </span><span class="s1">dict_init</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">callback </span><span class="s4">= </span><span class="s1">callback</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">verbose </span><span class="s4">= </span><span class="s1">verbose</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">random_state </span><span class="s4">= </span><span class="s1">random_state</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">positive_dict </span><span class="s4">= </span><span class="s1">positive_dict</span>

    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Fit the model from data in X. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Training vector, where `n_samples` is the number of samples 
            and `n_features` is the number of features. 
 
        y : Ignored 
            Not used, present for API consistency by convention. 
 
        Returns 
        ------- 
        self : object 
            Returns the instance itself. 
        &quot;&quot;&quot;</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">fit_transform</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s3">return </span><span class="s1">self</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">def </span><span class="s1">fit_transform</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Fit the model from data in X and return the transformed data. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Training vector, where `n_samples` is the number of samples 
            and `n_features` is the number of features. 
 
        y : Ignored 
            Not used, present for API consistency by convention. 
 
        Returns 
        ------- 
        V : ndarray of shape (n_samples, n_components) 
            Transformed data. 
        &quot;&quot;&quot;</span>
        <span class="s1">_check_positive_coding</span><span class="s4">(</span><span class="s1">method</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">fit_algorithm</span><span class="s4">, </span><span class="s1">positive</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">positive_code</span><span class="s4">)</span>

        <span class="s1">method </span><span class="s4">= </span><span class="s5">&quot;lasso_&quot; </span><span class="s4">+ </span><span class="s1">self</span><span class="s4">.</span><span class="s1">fit_algorithm</span>

        <span class="s1">random_state </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">n_components </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">n_components </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components</span>

        <span class="s1">V</span><span class="s4">, </span><span class="s1">U</span><span class="s4">, </span><span class="s1">E</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter_ </span><span class="s4">= </span><span class="s1">_dict_learning</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">,</span>
            <span class="s1">n_components</span><span class="s4">,</span>
            <span class="s1">alpha</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">alpha</span><span class="s4">,</span>
            <span class="s1">tol</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">tol</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">max_iter</span><span class="s4">,</span>
            <span class="s1">method</span><span class="s4">=</span><span class="s1">method</span><span class="s4">,</span>
            <span class="s1">method_max_iter</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">transform_max_iter</span><span class="s4">,</span>
            <span class="s1">n_jobs</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_jobs</span><span class="s4">,</span>
            <span class="s1">code_init</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">code_init</span><span class="s4">,</span>
            <span class="s1">dict_init</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">dict_init</span><span class="s4">,</span>
            <span class="s1">callback</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">callback</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span><span class="s4">,</span>
            <span class="s1">return_n_iter</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
            <span class="s1">positive_dict</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">positive_dict</span><span class="s4">,</span>
            <span class="s1">positive_code</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">positive_code</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">components_ </span><span class="s4">= </span><span class="s1">U</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">error_ </span><span class="s4">= </span><span class="s1">E</span>

        <span class="s3">return </span><span class="s1">V</span>

    <span class="s4">@</span><span class="s1">property</span>
    <span class="s3">def </span><span class="s1">_n_features_out</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Number of transformed output features.&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span>
            <span class="s5">&quot;preserves_dtype&quot;</span><span class="s4">: [</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">],</span>
        <span class="s4">}</span>


<span class="s3">class </span><span class="s1">MiniBatchDictionaryLearning</span><span class="s4">(</span><span class="s1">_BaseSparseCoding</span><span class="s4">, </span><span class="s1">BaseEstimator</span><span class="s4">):</span>
    <span class="s0">&quot;&quot;&quot;Mini-batch dictionary learning. 
 
    Finds a dictionary (a set of atoms) that performs well at sparsely 
    encoding the fitted data. 
 
    Solves the optimization problem:: 
 
       (U^*,V^*) = argmin 0.5 || X - U V ||_Fro^2 + alpha * || U ||_1,1 
                    (U,V) 
                    with || V_k ||_2 &lt;= 1 for all  0 &lt;= k &lt; n_components 
 
    ||.||_Fro stands for the Frobenius norm and ||.||_1,1 stands for 
    the entry-wise matrix norm which is the sum of the absolute values 
    of all the entries in the matrix. 
 
    Read more in the :ref:`User Guide &lt;DictionaryLearning&gt;`. 
 
    Parameters 
    ---------- 
    n_components : int, default=None 
        Number of dictionary elements to extract. 
 
    alpha : float, default=1 
        Sparsity controlling parameter. 
 
    max_iter : int, default=1_000 
        Maximum number of iterations over the complete dataset before 
        stopping independently of any early stopping criterion heuristics. 
 
        .. versionadded:: 1.1 
 
        .. deprecated:: 1.4 
           `max_iter=None` is deprecated in 1.4 and will be removed in 1.6. 
           Use the default value (i.e. `1_000`) instead. 
 
    fit_algorithm : {'lars', 'cd'}, default='lars' 
        The algorithm used: 
 
        - `'lars'`: uses the least angle regression method to solve the lasso 
          problem (`linear_model.lars_path`) 
        - `'cd'`: uses the coordinate descent method to compute the 
          Lasso solution (`linear_model.Lasso`). Lars will be faster if 
          the estimated components are sparse. 
 
    n_jobs : int, default=None 
        Number of parallel jobs to run. 
        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. 
        ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` 
        for more details. 
 
    batch_size : int, default=256 
        Number of samples in each mini-batch. 
 
        .. versionchanged:: 1.3 
           The default value of `batch_size` changed from 3 to 256 in version 1.3. 
 
    shuffle : bool, default=True 
        Whether to shuffle the samples before forming batches. 
 
    dict_init : ndarray of shape (n_components, n_features), default=None 
        Initial value of the dictionary for warm restart scenarios. 
 
    transform_algorithm : {'lasso_lars', 'lasso_cd', 'lars', 'omp', \ 
            'threshold'}, default='omp' 
        Algorithm used to transform the data: 
 
        - `'lars'`: uses the least angle regression method 
          (`linear_model.lars_path`); 
        - `'lasso_lars'`: uses Lars to compute the Lasso solution. 
        - `'lasso_cd'`: uses the coordinate descent method to compute the 
          Lasso solution (`linear_model.Lasso`). `'lasso_lars'` will be faster 
          if the estimated components are sparse. 
        - `'omp'`: uses orthogonal matching pursuit to estimate the sparse 
          solution. 
        - `'threshold'`: squashes to zero all coefficients less than alpha from 
          the projection ``dictionary * X'``. 
 
    transform_n_nonzero_coefs : int, default=None 
        Number of nonzero coefficients to target in each column of the 
        solution. This is only used by `algorithm='lars'` and 
        `algorithm='omp'`. If `None`, then 
        `transform_n_nonzero_coefs=int(n_features / 10)`. 
 
    transform_alpha : float, default=None 
        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`, `alpha` is the 
        penalty applied to the L1 norm. 
        If `algorithm='threshold'`, `alpha` is the absolute value of the 
        threshold below which coefficients will be squashed to zero. 
        If `None`, defaults to `alpha`. 
 
        .. versionchanged:: 1.2 
            When None, default value changed from 1.0 to `alpha`. 
 
    verbose : bool or int, default=False 
        To control the verbosity of the procedure. 
 
    split_sign : bool, default=False 
        Whether to split the sparse feature vector into the concatenation of 
        its negative part and its positive part. This can improve the 
        performance of downstream classifiers. 
 
    random_state : int, RandomState instance or None, default=None 
        Used for initializing the dictionary when ``dict_init`` is not 
        specified, randomly shuffling the data when ``shuffle`` is set to 
        ``True``, and updating the dictionary. Pass an int for reproducible 
        results across multiple function calls. 
        See :term:`Glossary &lt;random_state&gt;`. 
 
    positive_code : bool, default=False 
        Whether to enforce positivity when finding the code. 
 
        .. versionadded:: 0.20 
 
    positive_dict : bool, default=False 
        Whether to enforce positivity when finding the dictionary. 
 
        .. versionadded:: 0.20 
 
    transform_max_iter : int, default=1000 
        Maximum number of iterations to perform if `algorithm='lasso_cd'` or 
        `'lasso_lars'`. 
 
        .. versionadded:: 0.22 
 
    callback : callable, default=None 
        A callable that gets invoked at the end of each iteration. 
 
        .. versionadded:: 1.1 
 
    tol : float, default=1e-3 
        Control early stopping based on the norm of the differences in the 
        dictionary between 2 steps. 
 
        To disable early stopping based on changes in the dictionary, set 
        `tol` to 0.0. 
 
        .. versionadded:: 1.1 
 
    max_no_improvement : int, default=10 
        Control early stopping based on the consecutive number of mini batches 
        that does not yield an improvement on the smoothed cost function. 
 
        To disable convergence detection based on cost function, set 
        `max_no_improvement` to None. 
 
        .. versionadded:: 1.1 
 
    Attributes 
    ---------- 
    components_ : ndarray of shape (n_components, n_features) 
        Components extracted from the data. 
 
    n_features_in_ : int 
        Number of features seen during :term:`fit`. 
 
        .. versionadded:: 0.24 
 
    feature_names_in_ : ndarray of shape (`n_features_in_`,) 
        Names of features seen during :term:`fit`. Defined only when `X` 
        has feature names that are all strings. 
 
        .. versionadded:: 1.0 
 
    n_iter_ : int 
        Number of iterations over the full dataset. 
 
    n_steps_ : int 
        Number of mini-batches processed. 
 
        .. versionadded:: 1.1 
 
    See Also 
    -------- 
    DictionaryLearning : Find a dictionary that sparsely encodes data. 
    MiniBatchSparsePCA : Mini-batch Sparse Principal Components Analysis. 
    SparseCoder : Find a sparse representation of data from a fixed, 
        precomputed dictionary. 
    SparsePCA : Sparse Principal Components Analysis. 
 
    References 
    ---------- 
 
    J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning 
    for sparse coding (https://www.di.ens.fr/sierra/pdfs/icml09.pdf) 
 
    Examples 
    -------- 
    &gt;&gt;&gt; import numpy as np 
    &gt;&gt;&gt; from sklearn.datasets import make_sparse_coded_signal 
    &gt;&gt;&gt; from sklearn.decomposition import MiniBatchDictionaryLearning 
    &gt;&gt;&gt; X, dictionary, code = make_sparse_coded_signal( 
    ...     n_samples=30, n_components=15, n_features=20, n_nonzero_coefs=10, 
    ...     random_state=42) 
    &gt;&gt;&gt; dict_learner = MiniBatchDictionaryLearning( 
    ...     n_components=15, batch_size=3, transform_algorithm='lasso_lars', 
    ...     transform_alpha=0.1, max_iter=20, random_state=42) 
    &gt;&gt;&gt; X_transformed = dict_learner.fit_transform(X) 
 
    We can check the level of sparsity of `X_transformed`: 
 
    &gt;&gt;&gt; np.mean(X_transformed == 0) &gt; 0.5 
    np.True_ 
 
    We can compare the average squared euclidean norm of the reconstruction 
    error of the sparse coded signal relative to the squared euclidean norm of 
    the original signal: 
 
    &gt;&gt;&gt; X_hat = X_transformed @ dict_learner.components_ 
    &gt;&gt;&gt; np.mean(np.sum((X_hat - X) ** 2, axis=1) / np.sum(X ** 2, axis=1)) 
    np.float64(0.052...) 
    &quot;&quot;&quot;</span>

    <span class="s1">_parameter_constraints</span><span class="s4">: </span><span class="s1">dict </span><span class="s4">= {</span>
        <span class="s5">&quot;n_components&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;alpha&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;max_iter&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">), </span><span class="s1">Hidden</span><span class="s4">(</span><span class="s3">None</span><span class="s4">)],</span>
        <span class="s5">&quot;fit_algorithm&quot;</span><span class="s4">: [</span><span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;cd&quot;</span><span class="s4">, </span><span class="s5">&quot;lars&quot;</span><span class="s4">})],</span>
        <span class="s5">&quot;n_jobs&quot;</span><span class="s4">: [</span><span class="s3">None</span><span class="s4">, </span><span class="s1">Integral</span><span class="s4">],</span>
        <span class="s5">&quot;batch_size&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;shuffle&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;dict_init&quot;</span><span class="s4">: [</span><span class="s3">None</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ndarray</span><span class="s4">],</span>
        <span class="s5">&quot;transform_algorithm&quot;</span><span class="s4">: [</span>
            <span class="s1">StrOptions</span><span class="s4">({</span><span class="s5">&quot;lasso_lars&quot;</span><span class="s4">, </span><span class="s5">&quot;lasso_cd&quot;</span><span class="s4">, </span><span class="s5">&quot;lars&quot;</span><span class="s4">, </span><span class="s5">&quot;omp&quot;</span><span class="s4">, </span><span class="s5">&quot;threshold&quot;</span><span class="s4">})</span>
        <span class="s4">],</span>
        <span class="s5">&quot;transform_n_nonzero_coefs&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">1</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;transform_alpha&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
        <span class="s5">&quot;verbose&quot;</span><span class="s4">: [</span><span class="s5">&quot;verbose&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;split_sign&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;random_state&quot;</span><span class="s4">: [</span><span class="s5">&quot;random_state&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;positive_code&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;positive_dict&quot;</span><span class="s4">: [</span><span class="s5">&quot;boolean&quot;</span><span class="s4">],</span>
        <span class="s5">&quot;transform_max_iter&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;callback&quot;</span><span class="s4">: [</span><span class="s3">None</span><span class="s4">, </span><span class="s1">callable</span><span class="s4">],</span>
        <span class="s5">&quot;tol&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Real</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">)],</span>
        <span class="s5">&quot;max_no_improvement&quot;</span><span class="s4">: [</span><span class="s1">Interval</span><span class="s4">(</span><span class="s1">Integral</span><span class="s4">, </span><span class="s6">0</span><span class="s4">, </span><span class="s3">None</span><span class="s4">, </span><span class="s1">closed</span><span class="s4">=</span><span class="s5">&quot;left&quot;</span><span class="s4">), </span><span class="s3">None</span><span class="s4">],</span>
    <span class="s4">}</span>

    <span class="s3">def </span><span class="s1">__init__</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">,</span>
        <span class="s1">n_components</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s4">*,</span>
        <span class="s1">alpha</span><span class="s4">=</span><span class="s6">1</span><span class="s4">,</span>
        <span class="s1">max_iter</span><span class="s4">=</span><span class="s6">1_000</span><span class="s4">,</span>
        <span class="s1">fit_algorithm</span><span class="s4">=</span><span class="s5">&quot;lars&quot;</span><span class="s4">,</span>
        <span class="s1">n_jobs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">batch_size</span><span class="s4">=</span><span class="s6">256</span><span class="s4">,</span>
        <span class="s1">shuffle</span><span class="s4">=</span><span class="s3">True</span><span class="s4">,</span>
        <span class="s1">dict_init</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">transform_algorithm</span><span class="s4">=</span><span class="s5">&quot;omp&quot;</span><span class="s4">,</span>
        <span class="s1">transform_n_nonzero_coefs</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">transform_alpha</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">verbose</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">split_sign</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">random_state</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">positive_code</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">positive_dict</span><span class="s4">=</span><span class="s3">False</span><span class="s4">,</span>
        <span class="s1">transform_max_iter</span><span class="s4">=</span><span class="s6">1000</span><span class="s4">,</span>
        <span class="s1">callback</span><span class="s4">=</span><span class="s3">None</span><span class="s4">,</span>
        <span class="s1">tol</span><span class="s4">=</span><span class="s6">1e-3</span><span class="s4">,</span>
        <span class="s1">max_no_improvement</span><span class="s4">=</span><span class="s6">10</span><span class="s4">,</span>
    <span class="s4">):</span>
        <span class="s1">super</span><span class="s4">().</span><span class="s1">__init__</span><span class="s4">(</span>
            <span class="s1">transform_algorithm</span><span class="s4">,</span>
            <span class="s1">transform_n_nonzero_coefs</span><span class="s4">,</span>
            <span class="s1">transform_alpha</span><span class="s4">,</span>
            <span class="s1">split_sign</span><span class="s4">,</span>
            <span class="s1">n_jobs</span><span class="s4">,</span>
            <span class="s1">positive_code</span><span class="s4">,</span>
            <span class="s1">transform_max_iter</span><span class="s4">,</span>
        <span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_components </span><span class="s4">= </span><span class="s1">n_components</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">alpha </span><span class="s4">= </span><span class="s1">alpha</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">max_iter </span><span class="s4">= </span><span class="s1">max_iter</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">fit_algorithm </span><span class="s4">= </span><span class="s1">fit_algorithm</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">dict_init </span><span class="s4">= </span><span class="s1">dict_init</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">verbose </span><span class="s4">= </span><span class="s1">verbose</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">shuffle </span><span class="s4">= </span><span class="s1">shuffle</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">batch_size </span><span class="s4">= </span><span class="s1">batch_size</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">split_sign </span><span class="s4">= </span><span class="s1">split_sign</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">random_state </span><span class="s4">= </span><span class="s1">random_state</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">positive_dict </span><span class="s4">= </span><span class="s1">positive_dict</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">callback </span><span class="s4">= </span><span class="s1">callback</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">max_no_improvement </span><span class="s4">= </span><span class="s1">max_no_improvement</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">tol </span><span class="s4">= </span><span class="s1">tol</span>

    <span class="s3">def </span><span class="s1">_check_params</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">):</span>
        <span class="s2"># n_components</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_components</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]</span>

        <span class="s2"># fit_algorithm</span>
        <span class="s1">_check_positive_coding</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">fit_algorithm</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">positive_code</span><span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_fit_algorithm </span><span class="s4">= </span><span class="s5">&quot;lasso_&quot; </span><span class="s4">+ </span><span class="s1">self</span><span class="s4">.</span><span class="s1">fit_algorithm</span>

        <span class="s2"># batch_size</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_batch_size </span><span class="s4">= </span><span class="s1">min</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">batch_size</span><span class="s4">, </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">])</span>

    <span class="s3">def </span><span class="s1">_initialize_dict</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Initialization of the dictionary.&quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">dict_init </span><span class="s3">is not None</span><span class="s4">:</span>
            <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">dict_init</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s2"># Init V with SVD of X</span>
            <span class="s1">_</span><span class="s4">, </span><span class="s1">S</span><span class="s4">, </span><span class="s1">dictionary </span><span class="s4">= </span><span class="s1">randomized_svd</span><span class="s4">(</span>
                <span class="s1">X</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span>
            <span class="s4">)</span>
            <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">S</span><span class="s4">[:, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">newaxis</span><span class="s4">] * </span><span class="s1">dictionary</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components </span><span class="s4">&lt;= </span><span class="s1">len</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">):</span>
            <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">dictionary</span><span class="s4">[: </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components</span><span class="s4">, :]</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">concatenate</span><span class="s4">(</span>
                <span class="s4">(</span>
                    <span class="s1">dictionary</span><span class="s4">,</span>
                    <span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span>
                        <span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components </span><span class="s4">- </span><span class="s1">len</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">), </span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">]),</span>
                        <span class="s1">dtype</span><span class="s4">=</span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">,</span>
                    <span class="s4">),</span>
                <span class="s4">)</span>
            <span class="s4">)</span>

        <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">check_array</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">, </span><span class="s1">order</span><span class="s4">=</span><span class="s5">&quot;F&quot;</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">X</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">, </span><span class="s1">copy</span><span class="s4">=</span><span class="s3">False</span><span class="s4">)</span>
        <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">require</span><span class="s4">(</span><span class="s1">dictionary</span><span class="s4">, </span><span class="s1">requirements</span><span class="s4">=</span><span class="s5">&quot;W&quot;</span><span class="s4">)</span>

        <span class="s3">return </span><span class="s1">dictionary</span>

    <span class="s3">def </span><span class="s1">_update_inner_stats</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">code</span><span class="s4">, </span><span class="s1">batch_size</span><span class="s4">, </span><span class="s1">step</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Update the inner stats inplace.&quot;&quot;&quot;</span>
        <span class="s3">if </span><span class="s1">step </span><span class="s4">&lt; </span><span class="s1">batch_size </span><span class="s4">- </span><span class="s6">1</span><span class="s4">:</span>
            <span class="s1">theta </span><span class="s4">= (</span><span class="s1">step </span><span class="s4">+ </span><span class="s6">1</span><span class="s4">) * </span><span class="s1">batch_size</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">theta </span><span class="s4">= </span><span class="s1">batch_size</span><span class="s4">**</span><span class="s6">2 </span><span class="s4">+ </span><span class="s1">step </span><span class="s4">+ </span><span class="s6">1 </span><span class="s4">- </span><span class="s1">batch_size</span>
        <span class="s1">beta </span><span class="s4">= (</span><span class="s1">theta </span><span class="s4">+ </span><span class="s6">1 </span><span class="s4">- </span><span class="s1">batch_size</span><span class="s4">) / (</span><span class="s1">theta </span><span class="s4">+ </span><span class="s6">1</span><span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">_A </span><span class="s4">*= </span><span class="s1">beta</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_A </span><span class="s4">+= </span><span class="s1">code</span><span class="s4">.</span><span class="s1">T </span><span class="s4">@ </span><span class="s1">code </span><span class="s4">/ </span><span class="s1">batch_size</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_B </span><span class="s4">*= </span><span class="s1">beta</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_B </span><span class="s4">+= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">T </span><span class="s4">@ </span><span class="s1">code </span><span class="s4">/ </span><span class="s1">batch_size</span>

    <span class="s3">def </span><span class="s1">_minibatch_step</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">dictionary</span><span class="s4">, </span><span class="s1">random_state</span><span class="s4">, </span><span class="s1">step</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Perform the update on the dictionary for one minibatch.&quot;&quot;&quot;</span>
        <span class="s1">batch_size </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>

        <span class="s2"># Compute code for this batch</span>
        <span class="s1">code </span><span class="s4">= </span><span class="s1">_sparse_encode</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">,</span>
            <span class="s1">dictionary</span><span class="s4">,</span>
            <span class="s1">algorithm</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">_fit_algorithm</span><span class="s4">,</span>
            <span class="s1">alpha</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">alpha</span><span class="s4">,</span>
            <span class="s1">n_jobs</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_jobs</span><span class="s4">,</span>
            <span class="s1">positive</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">positive_code</span><span class="s4">,</span>
            <span class="s1">max_iter</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">transform_max_iter</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">,</span>
        <span class="s4">)</span>

        <span class="s1">batch_cost </span><span class="s4">= (</span>
            <span class="s6">0.5 </span><span class="s4">* ((</span><span class="s1">X </span><span class="s4">- </span><span class="s1">code </span><span class="s4">@ </span><span class="s1">dictionary</span><span class="s4">) ** </span><span class="s6">2</span><span class="s4">).</span><span class="s1">sum</span><span class="s4">()</span>
            <span class="s4">+ </span><span class="s1">self</span><span class="s4">.</span><span class="s1">alpha </span><span class="s4">* </span><span class="s1">np</span><span class="s4">.</span><span class="s1">sum</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">abs</span><span class="s4">(</span><span class="s1">code</span><span class="s4">))</span>
        <span class="s4">) / </span><span class="s1">batch_size</span>

        <span class="s2"># Update inner stats</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_update_inner_stats</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">code</span><span class="s4">, </span><span class="s1">batch_size</span><span class="s4">, </span><span class="s1">step</span><span class="s4">)</span>

        <span class="s2"># Update dictionary</span>
        <span class="s1">_update_dict</span><span class="s4">(</span>
            <span class="s1">dictionary</span><span class="s4">,</span>
            <span class="s1">X</span><span class="s4">,</span>
            <span class="s1">code</span><span class="s4">,</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_A</span><span class="s4">,</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_B</span><span class="s4">,</span>
            <span class="s1">verbose</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">,</span>
            <span class="s1">random_state</span><span class="s4">=</span><span class="s1">random_state</span><span class="s4">,</span>
            <span class="s1">positive</span><span class="s4">=</span><span class="s1">self</span><span class="s4">.</span><span class="s1">positive_dict</span><span class="s4">,</span>
        <span class="s4">)</span>

        <span class="s3">return </span><span class="s1">batch_cost</span>

    <span class="s3">def </span><span class="s1">_check_convergence</span><span class="s4">(</span>
        <span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">batch_cost</span><span class="s4">, </span><span class="s1">new_dict</span><span class="s4">, </span><span class="s1">old_dict</span><span class="s4">, </span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">step</span><span class="s4">, </span><span class="s1">n_steps</span>
    <span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Helper function to encapsulate the early stopping logic. 
 
        Early stopping is based on two factors: 
        - A small change of the dictionary between two minibatch updates. This is 
          controlled by the tol parameter. 
        - No more improvement on a smoothed estimate of the objective function for a 
          a certain number of consecutive minibatch updates. This is controlled by 
          the max_no_improvement parameter. 
        &quot;&quot;&quot;</span>
        <span class="s1">batch_size </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>

        <span class="s2"># counts steps starting from 1 for user friendly verbose mode.</span>
        <span class="s1">step </span><span class="s4">= </span><span class="s1">step </span><span class="s4">+ </span><span class="s6">1</span>

        <span class="s2"># Ignore 100 first steps or 1 epoch to avoid initializing the ewa_cost with a</span>
        <span class="s2"># too bad value</span>
        <span class="s3">if </span><span class="s1">step </span><span class="s4">&lt;= </span><span class="s1">min</span><span class="s4">(</span><span class="s6">100</span><span class="s4">, </span><span class="s1">n_samples </span><span class="s4">/ </span><span class="s1">batch_size</span><span class="s4">):</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">:</span>
                <span class="s1">print</span><span class="s4">(</span><span class="s5">f&quot;Minibatch step </span><span class="s3">{</span><span class="s1">step</span><span class="s3">}</span><span class="s5">/</span><span class="s3">{</span><span class="s1">n_steps</span><span class="s3">}</span><span class="s5">: mean batch cost: </span><span class="s3">{</span><span class="s1">batch_cost</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s4">)</span>
            <span class="s3">return False</span>

        <span class="s2"># Compute an Exponentially Weighted Average of the cost function to</span>
        <span class="s2"># monitor the convergence while discarding minibatch-local stochastic</span>
        <span class="s2"># variability: https://en.wikipedia.org/wiki/Moving_average</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_ewa_cost </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_ewa_cost </span><span class="s4">= </span><span class="s1">batch_cost</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">alpha </span><span class="s4">= </span><span class="s1">batch_size </span><span class="s4">/ (</span><span class="s1">n_samples </span><span class="s4">+ </span><span class="s6">1</span><span class="s4">)</span>
            <span class="s1">alpha </span><span class="s4">= </span><span class="s1">min</span><span class="s4">(</span><span class="s1">alpha</span><span class="s4">, </span><span class="s6">1</span><span class="s4">)</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_ewa_cost </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_ewa_cost </span><span class="s4">* (</span><span class="s6">1 </span><span class="s4">- </span><span class="s1">alpha</span><span class="s4">) + </span><span class="s1">batch_cost </span><span class="s4">* </span><span class="s1">alpha</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">:</span>
            <span class="s1">print</span><span class="s4">(</span>
                <span class="s5">f&quot;Minibatch step </span><span class="s3">{</span><span class="s1">step</span><span class="s3">}</span><span class="s5">/</span><span class="s3">{</span><span class="s1">n_steps</span><span class="s3">}</span><span class="s5">: mean batch cost: &quot;</span>
                <span class="s5">f&quot;</span><span class="s3">{</span><span class="s1">batch_cost</span><span class="s3">}</span><span class="s5">, ewa cost: </span><span class="s3">{</span><span class="s1">self</span><span class="s4">.</span><span class="s1">_ewa_cost</span><span class="s3">}</span><span class="s5">&quot;</span>
            <span class="s4">)</span>

        <span class="s2"># Early stopping based on change of dictionary</span>
        <span class="s1">dict_diff </span><span class="s4">= </span><span class="s1">linalg</span><span class="s4">.</span><span class="s1">norm</span><span class="s4">(</span><span class="s1">new_dict </span><span class="s4">- </span><span class="s1">old_dict</span><span class="s4">) / </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">tol </span><span class="s4">&gt; </span><span class="s6">0 </span><span class="s3">and </span><span class="s1">dict_diff </span><span class="s4">&lt;= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">tol</span><span class="s4">:</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">:</span>
                <span class="s1">print</span><span class="s4">(</span><span class="s5">f&quot;Converged (small dictionary change) at step </span><span class="s3">{</span><span class="s1">step</span><span class="s3">}</span><span class="s5">/</span><span class="s3">{</span><span class="s1">n_steps</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s4">)</span>
            <span class="s3">return True</span>

        <span class="s2"># Early stopping heuristic due to lack of improvement on smoothed</span>
        <span class="s2"># cost function</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_ewa_cost_min </span><span class="s3">is None or </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_ewa_cost </span><span class="s4">&lt; </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_ewa_cost_min</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_no_improvement </span><span class="s4">= </span><span class="s6">0</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_ewa_cost_min </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_ewa_cost</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_no_improvement </span><span class="s4">+= </span><span class="s6">1</span>

        <span class="s3">if </span><span class="s4">(</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">max_no_improvement </span><span class="s3">is not None</span>
            <span class="s3">and </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_no_improvement </span><span class="s4">&gt;= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">max_no_improvement</span>
        <span class="s4">):</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">:</span>
                <span class="s1">print</span><span class="s4">(</span>
                    <span class="s5">&quot;Converged (lack of improvement in objective function) &quot;</span>
                    <span class="s5">f&quot;at step </span><span class="s3">{</span><span class="s1">step</span><span class="s3">}</span><span class="s5">/</span><span class="s3">{</span><span class="s1">n_steps</span><span class="s3">}</span><span class="s5">&quot;</span>
                <span class="s4">)</span>
            <span class="s3">return True</span>

        <span class="s3">return False</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">def </span><span class="s1">fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Fit the model from data in X. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Training vector, where `n_samples` is the number of samples 
            and `n_features` is the number of features. 
 
        y : Ignored 
            Not used, present for API consistency by convention. 
 
        Returns 
        ------- 
        self : object 
            Returns the instance itself. 
        &quot;&quot;&quot;</span>
        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">], </span><span class="s1">order</span><span class="s4">=</span><span class="s5">&quot;C&quot;</span><span class="s4">, </span><span class="s1">copy</span><span class="s4">=</span><span class="s3">False</span>
        <span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">_check_params</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_random_state </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>

        <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_initialize_dict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_random_state</span><span class="s4">)</span>
        <span class="s1">old_dict </span><span class="s4">= </span><span class="s1">dictionary</span><span class="s4">.</span><span class="s1">copy</span><span class="s4">()</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">shuffle</span><span class="s4">:</span>
            <span class="s1">X_train </span><span class="s4">= </span><span class="s1">X</span><span class="s4">.</span><span class="s1">copy</span><span class="s4">()</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_random_state</span><span class="s4">.</span><span class="s1">shuffle</span><span class="s4">(</span><span class="s1">X_train</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">X_train </span><span class="s4">= </span><span class="s1">X</span>

        <span class="s1">n_samples</span><span class="s4">, </span><span class="s1">n_features </span><span class="s4">= </span><span class="s1">X_train</span><span class="s4">.</span><span class="s1">shape</span>

        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">verbose</span><span class="s4">:</span>
            <span class="s1">print</span><span class="s4">(</span><span class="s5">&quot;[dict_learning]&quot;</span><span class="s4">)</span>

        <span class="s2"># Inner stats</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_A </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">(</span>
            <span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components</span><span class="s4">), </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">X_train</span><span class="s4">.</span><span class="s1">dtype</span>
        <span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_B </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">((</span><span class="s1">n_features</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components</span><span class="s4">), </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">X_train</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">)</span>

        <span class="s2"># TODO(1.6): remove in 1.6</span>
        <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">max_iter </span><span class="s3">is None</span><span class="s4">:</span>
            <span class="s1">warn</span><span class="s4">(</span>
                <span class="s4">(</span>
                    <span class="s5">&quot;`max_iter=None` is deprecated in version 1.4 and will be removed&quot;</span>
                    <span class="s5">&quot; in version 1.6. Use the default value (i.e. `1_000`) instead.&quot;</span>
                <span class="s4">),</span>
                <span class="s1">FutureWarning</span><span class="s4">,</span>
            <span class="s4">)</span>
            <span class="s1">max_iter </span><span class="s4">= </span><span class="s6">1_000</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">max_iter </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">max_iter</span>

        <span class="s2"># Attributes to monitor the convergence</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_ewa_cost </span><span class="s4">= </span><span class="s3">None</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_ewa_cost_min </span><span class="s4">= </span><span class="s3">None</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">_no_improvement </span><span class="s4">= </span><span class="s6">0</span>

        <span class="s1">batches </span><span class="s4">= </span><span class="s1">gen_batches</span><span class="s4">(</span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_batch_size</span><span class="s4">)</span>
        <span class="s1">batches </span><span class="s4">= </span><span class="s1">itertools</span><span class="s4">.</span><span class="s1">cycle</span><span class="s4">(</span><span class="s1">batches</span><span class="s4">)</span>
        <span class="s1">n_steps_per_iter </span><span class="s4">= </span><span class="s1">int</span><span class="s4">(</span><span class="s1">np</span><span class="s4">.</span><span class="s1">ceil</span><span class="s4">(</span><span class="s1">n_samples </span><span class="s4">/ </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_batch_size</span><span class="s4">))</span>
        <span class="s1">n_steps </span><span class="s4">= </span><span class="s1">max_iter </span><span class="s4">* </span><span class="s1">n_steps_per_iter</span>

        <span class="s1">i </span><span class="s4">= -</span><span class="s6">1  </span><span class="s2"># to allow max_iter = 0</span>

        <span class="s3">for </span><span class="s1">i</span><span class="s4">, </span><span class="s1">batch </span><span class="s3">in </span><span class="s1">zip</span><span class="s4">(</span><span class="s1">range</span><span class="s4">(</span><span class="s1">n_steps</span><span class="s4">), </span><span class="s1">batches</span><span class="s4">):</span>
            <span class="s1">X_batch </span><span class="s4">= </span><span class="s1">X_train</span><span class="s4">[</span><span class="s1">batch</span><span class="s4">]</span>

            <span class="s1">batch_cost </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_minibatch_step</span><span class="s4">(</span>
                <span class="s1">X_batch</span><span class="s4">, </span><span class="s1">dictionary</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_random_state</span><span class="s4">, </span><span class="s1">i</span>
            <span class="s4">)</span>

            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_check_convergence</span><span class="s4">(</span>
                <span class="s1">X_batch</span><span class="s4">, </span><span class="s1">batch_cost</span><span class="s4">, </span><span class="s1">dictionary</span><span class="s4">, </span><span class="s1">old_dict</span><span class="s4">, </span><span class="s1">n_samples</span><span class="s4">, </span><span class="s1">i</span><span class="s4">, </span><span class="s1">n_steps</span>
            <span class="s4">):</span>
                <span class="s3">break</span>

            <span class="s2"># XXX callback param added for backward compat in #18975 but a common</span>
            <span class="s2"># unified callback API should be preferred</span>
            <span class="s3">if </span><span class="s1">self</span><span class="s4">.</span><span class="s1">callback </span><span class="s3">is not None</span><span class="s4">:</span>
                <span class="s1">self</span><span class="s4">.</span><span class="s1">callback</span><span class="s4">(</span><span class="s1">locals</span><span class="s4">())</span>

            <span class="s1">old_dict</span><span class="s4">[:] = </span><span class="s1">dictionary</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_steps_ </span><span class="s4">= </span><span class="s1">i </span><span class="s4">+ </span><span class="s6">1</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_iter_ </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">ceil</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_steps_ </span><span class="s4">/ </span><span class="s1">n_steps_per_iter</span><span class="s4">)</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">components_ </span><span class="s4">= </span><span class="s1">dictionary</span>

        <span class="s3">return </span><span class="s1">self</span>

    <span class="s4">@</span><span class="s1">_fit_context</span><span class="s4">(</span><span class="s1">prefer_skip_nested_validation</span><span class="s4">=</span><span class="s3">True</span><span class="s4">)</span>
    <span class="s3">def </span><span class="s1">partial_fit</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s1">X</span><span class="s4">, </span><span class="s1">y</span><span class="s4">=</span><span class="s3">None</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Update the model using the data in X as a mini-batch. 
 
        Parameters 
        ---------- 
        X : array-like of shape (n_samples, n_features) 
            Training vector, where `n_samples` is the number of samples 
            and `n_features` is the number of features. 
 
        y : Ignored 
            Not used, present for API consistency by convention. 
 
        Returns 
        ------- 
        self : object 
            Return the instance itself. 
        &quot;&quot;&quot;</span>
        <span class="s1">has_components </span><span class="s4">= </span><span class="s1">hasattr</span><span class="s4">(</span><span class="s1">self</span><span class="s4">, </span><span class="s5">&quot;components_&quot;</span><span class="s4">)</span>

        <span class="s1">X </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_validate_data</span><span class="s4">(</span>
            <span class="s1">X</span><span class="s4">, </span><span class="s1">dtype</span><span class="s4">=[</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">], </span><span class="s1">order</span><span class="s4">=</span><span class="s5">&quot;C&quot;</span><span class="s4">, </span><span class="s1">reset</span><span class="s4">=</span><span class="s3">not </span><span class="s1">has_components</span>
        <span class="s4">)</span>

        <span class="s3">if not </span><span class="s1">has_components</span><span class="s4">:</span>
            <span class="s2"># This instance has not been fitted yet (fit or partial_fit)</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_check_params</span><span class="s4">(</span><span class="s1">X</span><span class="s4">)</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_random_state </span><span class="s4">= </span><span class="s1">check_random_state</span><span class="s4">(</span><span class="s1">self</span><span class="s4">.</span><span class="s1">random_state</span><span class="s4">)</span>

            <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_initialize_dict</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_random_state</span><span class="s4">)</span>

            <span class="s1">self</span><span class="s4">.</span><span class="s1">n_steps_ </span><span class="s4">= </span><span class="s6">0</span>

            <span class="s1">self</span><span class="s4">.</span><span class="s1">_A </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">((</span><span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components</span><span class="s4">), </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">X</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">)</span>
            <span class="s1">self</span><span class="s4">.</span><span class="s1">_B </span><span class="s4">= </span><span class="s1">np</span><span class="s4">.</span><span class="s1">zeros</span><span class="s4">((</span><span class="s1">X</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">1</span><span class="s4">], </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_n_components</span><span class="s4">), </span><span class="s1">dtype</span><span class="s4">=</span><span class="s1">X</span><span class="s4">.</span><span class="s1">dtype</span><span class="s4">)</span>
        <span class="s3">else</span><span class="s4">:</span>
            <span class="s1">dictionary </span><span class="s4">= </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">_minibatch_step</span><span class="s4">(</span><span class="s1">X</span><span class="s4">, </span><span class="s1">dictionary</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">_random_state</span><span class="s4">, </span><span class="s1">self</span><span class="s4">.</span><span class="s1">n_steps_</span><span class="s4">)</span>

        <span class="s1">self</span><span class="s4">.</span><span class="s1">components_ </span><span class="s4">= </span><span class="s1">dictionary</span>
        <span class="s1">self</span><span class="s4">.</span><span class="s1">n_steps_ </span><span class="s4">+= </span><span class="s6">1</span>

        <span class="s3">return </span><span class="s1">self</span>

    <span class="s4">@</span><span class="s1">property</span>
    <span class="s3">def </span><span class="s1">_n_features_out</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s0">&quot;&quot;&quot;Number of transformed output features.&quot;&quot;&quot;</span>
        <span class="s3">return </span><span class="s1">self</span><span class="s4">.</span><span class="s1">components_</span><span class="s4">.</span><span class="s1">shape</span><span class="s4">[</span><span class="s6">0</span><span class="s4">]</span>

    <span class="s3">def </span><span class="s1">_more_tags</span><span class="s4">(</span><span class="s1">self</span><span class="s4">):</span>
        <span class="s3">return </span><span class="s4">{</span>
            <span class="s5">&quot;preserves_dtype&quot;</span><span class="s4">: [</span><span class="s1">np</span><span class="s4">.</span><span class="s1">float64</span><span class="s4">, </span><span class="s1">np</span><span class="s4">.</span><span class="s1">float32</span><span class="s4">],</span>
        <span class="s4">}</span>
</pre>
</body>
</html>